#!/usr/bin/env python3
"""
è°ƒè¯•æ¯ä¸ªä½ç½®çš„reward
"""

from GameInterface import GameInterface
from mcts.MCTS_real_physics import RealPhysicsMCTSAgent
import numpy as np

print("="*70)
print("ğŸ” è°ƒè¯•Rewardè®¡ç®—")
print("="*70)

env = GameInterface()
env.reset(seed=888)

# ç©å‡ æ­¥
for i in range(5):
    action = np.random.randint(0, 16)
    env.next(action)

print(f"\nğŸ“Š å½“å‰çŠ¶æ€:")
print(f"  åœºä¸Šæ°´æœæ•°: {len(env.game.fruits)}")
print(f"  æ‰‹é‡Œæ°´æœç±»å‹: {env.game.current_fruit_type}")

print(f"\nåœºä¸Šæ°´æœè¯¦æƒ…:")
for i, (ball, fruit) in enumerate(zip(env.game.balls, env.game.fruits)):
    x = ball.body.position.x
    action_pos = int(x / (env.game.width / 16))
    print(f"  æ°´æœ{i}: type={fruit.type}, action_posâ‰ˆ{action_pos}")

# æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªactionçš„reward
agent = RealPhysicsMCTSAgent(num_simulations=10)

original_state = agent.mcts._save_state(env)

print(f"\nğŸ“ˆ æ¯ä¸ªä½ç½®çš„Rewardè®¡ç®—:")
print(f"{'Action':>6} | {'Reward1':>8} | {'MaxReward2':>10} | {'Total':>8}")
print("-"*50)

for action1 in range(16):
    # æ¢å¤åˆå§‹çŠ¶æ€
    agent.mcts._restore_state(env, original_state)

    # è®°å½•åˆå§‹çŠ¶æ€
    score_before = env.game.score
    fruits_before = agent.mcts._get_fruits_info(env)

    # æ‰§è¡Œç¬¬ä¸€æ­¥
    agent.mcts._apply_action(env, action1)

    # è®¡ç®—ç¬¬ä¸€æ­¥reward
    reward1 = agent.mcts._calculate_reward(env, score_before, fruits_before)

    # è®°å½•ç¬¬ä¸€æ­¥åçŠ¶æ€
    state_after_step1 = agent.mcts._save_state(env)
    score_after1 = env.game.score
    fruits_after1 = agent.mcts._get_fruits_info(env)

    # è®¡ç®—ç¬¬äºŒæ­¥æ‰€æœ‰å¯èƒ½çš„reward
    max_reward2 = float('-inf')
    best_action2 = -1

    for action2 in range(16):
        agent.mcts._restore_state(env, state_after_step1)
        agent.mcts._apply_action(env, action2)
        reward2 = agent.mcts._calculate_reward(env, score_after1, fruits_after1)

        if reward2 > max_reward2:
            max_reward2 = reward2
            best_action2 = action2

    total_reward = reward1 + max_reward2

    # æ£€æŸ¥æ˜¯å¦èƒ½merge
    can_merge = False
    for ball, fruit in zip(env.game.balls, env.game.fruits):
        if fruit.type == env.game.current_fruit_type:
            action_pos = int(ball.body.position.x / (env.game.width / 16))
            if abs(action1 - action_pos) <= 1:
                can_merge = True
                break

    marker = "â­" if can_merge else "  "
    print(f"{action1:6d} | {reward1:8.2f} | {max_reward2:10.2f} | {total_reward:8.2f} {marker}")

# è¿è¡ŒMCTS
print(f"\nğŸ® MCTSé€‰æ‹©:")
agent.mcts._restore_state(env, original_state)
best_action = agent.mcts.search(env, 10)
print(f"  æœ€ä½³åŠ¨ä½œ: {best_action}")

print("="*70)
