#!/usr/bin/env python3
"""
æµ‹è¯• Real Physics MCTS
"""

from GameInterface import GameInterface
from mcts.MCTS_real_physics import RealPhysicsMCTSAgent
import numpy as np
import time

def test_real_physics_mcts(seed=888, num_sims=50, max_steps=50):
    """æµ‹è¯•Real Physics MCTS"""

    print("="*70)
    print("ğŸ® Real Physics MCTS æµ‹è¯•")
    print("="*70)
    print(f"é…ç½®:")
    print(f"  Seed: {seed}")
    print(f"  Simulations: {num_sims}")
    print(f"  Max Steps: {max_steps}")
    print("="*70)

    # åˆ›å»ºç¯å¢ƒå’Œæ™ºèƒ½ä½“
    env = GameInterface()
    agent = RealPhysicsMCTSAgent(num_simulations=num_sims)

    # é‡ç½®æ¸¸æˆ
    env.reset(seed=seed)

    # ç¬¬ä¸€æ­¥éšæœº
    action = np.random.randint(0, env.action_num)
    feature, _, alive = env.next(action)

    step = 0
    scores = [0]
    start_time = time.time()

    print(f"\nğŸš€ å¼€å§‹æ¸¸æˆ...\n")

    while alive and step < max_steps:
        step += 1

        # æ‰“å°è¿›åº¦
        if step % 5 == 0:
            elapsed = time.time() - start_time
            print(f"  Step {step:2d}: Score={env.game.score:3d}, "
                  f"Fruits={len(env.game.fruits):2d}, "
                  f"Time={elapsed:.1f}s")

        # MCTSå†³ç­–ï¼ˆä½¿ç”¨çœŸå®ç‰©ç†ï¼‰
        step_start = time.time()
        action = agent.predict(env)[0]
        decision_time = time.time() - step_start

        # æ‰§è¡ŒåŠ¨ä½œ
        feature, reward, alive = env.next(action)
        scores.append(env.game.score)

    total_time = time.time() - start_time

    print(f"\n{'='*70}")
    print("ğŸ æ¸¸æˆç»“æŸ!")
    print(f"{'='*70}")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"  æœ€ç»ˆå¾—åˆ†: {env.game.score}")
    print(f"  æ€»æ­¥æ•°: {step}")
    print(f"  å¹³å‡æ¯æ­¥å¾—åˆ†: {env.game.score/step:.2f}")
    print(f"  æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"  å¹³å‡æ¯æ­¥è€—æ—¶: {total_time/step:.2f}ç§’")
    print(f"{'='*70}")

    return env.game.score, step


def compare_mcts_versions(seed=888):
    """å¯¹æ¯”ä¸åŒMCTSç‰ˆæœ¬"""

    from mcts.MCTS_optimized import FastMCTSAgent as OldMCTS
    from mcts.MCTS_tuned import TunedMCTSAgent as TunedMCTS

    print("\n" + "="*70)
    print("ğŸ”¬ å¯¹æ¯”ä¸‰ç§MCTSç‰ˆæœ¬")
    print("="*70)

    seeds = [seed, seed+1, seed+2]
    results = {}

    # æµ‹è¯•Real Physics MCTS
    print(f"\n{'â”€'*70}")
    print("1ï¸âƒ£ Real Physics MCTS (50 sims, çœŸå®ç‰©ç†)")
    print(f"{'â”€'*70}")

    env = GameInterface()
    agent = RealPhysicsMCTSAgent(num_simulations=50)
    scores = []

    for s in seeds:
        env.reset(seed=s)
        env.next(np.random.randint(0, 16))

        step = 0
        while env.game.alive and step < 100:
            action = agent.predict(env)[0]
            env.next(action)
            step += 1

        scores.append(env.game.score)
        print(f"  Seed {s}: {env.game.score}")

    results['Real Physics'] = {
        'scores': scores,
        'avg': np.mean(scores),
        'sims': 50
    }
    print(f"  â†’ å¹³å‡: {np.mean(scores):.1f}")

    # æµ‹è¯•Tuned MCTS
    print(f"\n{'â”€'*70}")
    print("2ï¸âƒ£ Tuned MCTS (100 sims, ç®€åŒ–ç½‘æ ¼)")
    print(f"{'â”€'*70}")

    agent2 = TunedMCTS(num_simulations=100)
    scores2 = []

    for s in seeds:
        env.reset(seed=s)
        env.next(np.random.randint(0, 16))

        step = 0
        while env.game.alive and step < 100:
            action = agent2.predict(env)[0]
            env.next(action)
            step += 1

        scores2.append(env.game.score)
        print(f"  Seed {s}: {env.game.score}")

    results['Tuned'] = {
        'scores': scores2,
        'avg': np.mean(scores2),
        'sims': 100
    }
    print(f"  â†’ å¹³å‡: {np.mean(scores2):.1f}")

    # æµ‹è¯•Old MCTS
    print(f"\n{'â”€'*70}")
    print("3ï¸âƒ£ Optimized MCTS (200 sims, ç®€åŒ–ç½‘æ ¼)")
    print(f"{'â”€'*70}")

    agent3 = OldMCTS(num_simulations=200)
    scores3 = []

    for s in seeds:
        env.reset(seed=s)
        env.next(np.random.randint(0, 16))

        step = 0
        while env.game.alive and step < 100:
            action = agent3.predict(env)[0]
            env.next(action)
            step += 1

        scores3.append(env.game.score)
        print(f"  Seed {s}: {env.game.score}")

    results['Optimized'] = {
        'scores': scores3,
        'avg': np.mean(scores3),
        'sims': 200
    }
    print(f"  â†’ å¹³å‡: {np.mean(scores3):.1f}")

    # æ±‡æ€»å¯¹æ¯”
    print(f"\n{'='*70}")
    print("ğŸ“Š å¯¹æ¯”ç»“æœ")
    print(f"{'='*70}")
    print(f"{'ç‰ˆæœ¬':<20} | {'Sims':>6} | {'å¹³å‡å¾—åˆ†':>8} | {'é€Ÿåº¦':>10}")
    print("â”€"*70)

    for name, data in results.items():
        sims = data['sims']
        avg = data['avg']
        speed_ratio = sims / 50  # ç›¸å¯¹äºReal Physics
        print(f"{name:<20} | {sims:6d} | {avg:8.1f} | {speed_ratio:5.1f}x slower")

    print("="*70)

    # æ‰¾å‡ºæœ€ä½³
    best = max(results.items(), key=lambda x: x[1]['avg'])
    print(f"\nğŸ† æœ€ä½³: {best[0]} - {best[1]['avg']:.1f}åˆ†")

    # é€Ÿåº¦/è´¨é‡æ¯”
    print(f"\nâš¡ é€Ÿåº¦/è´¨é‡æ¯”:")
    for name, data in results.items():
        ratio = data['avg'] / data['sims']
        print(f"  {name}: {ratio:.2f} åˆ†/sim")

    print("="*70)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Real Physics MCTSæµ‹è¯•')
    parser.add_argument('--seed', type=int, default=888, help='éšæœºç§å­')
    parser.add_argument('--sims', type=int, default=50, help='æ¨¡æ‹Ÿæ¬¡æ•°')
    parser.add_argument('--steps', type=int, default=50, help='æœ€å¤§æ­¥æ•°')
    parser.add_argument('--compare', action='store_true', help='å¯¹æ¯”ä¸åŒç‰ˆæœ¬')

    args = parser.parse_args()

    if args.compare:
        compare_mcts_versions(seed=args.seed)
    else:
        test_real_physics_mcts(
            seed=args.seed,
            num_sims=args.sims,
            max_steps=args.steps
        )

    print("\nâœ… å®Œæˆ!")
