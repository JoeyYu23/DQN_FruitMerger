#!/usr/bin/env python3
"""
æµ‹è¯•å¹¶å¯è§†åŒ–è®­ç»ƒå¥½çš„AlphaZeroæ¨¡å‹
åŒ…å«ï¼šå½•åˆ¶è§†é¢‘ã€å±•ç¤ºæ¸¸æˆè¿‡ç¨‹ã€åˆ†æå†³ç­–
"""

import numpy as np
import paddle
import cv2
import matplotlib.pyplot as plt
import os
from typing import List

from SuikaNet import SuikaNet
from AlphaZeroMCTS import AlphaZeroMCTS
from GameInterface import GameInterface
from StateConverter import StateConverter


def test_model_with_visualization(model_path: str,
                                  num_games: int = 5,
                                  simulations: int = 100,
                                  save_video: bool = True,
                                  show_frames: bool = True):
    """
    æµ‹è¯•æ¨¡å‹å¹¶å¯è§†åŒ–æ¸¸æˆè¿‡ç¨‹

    Args:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„
        num_games: æµ‹è¯•æ¸¸æˆå±€æ•°
        simulations: MCTSæ¨¡æ‹Ÿæ¬¡æ•°
        save_video: æ˜¯å¦ä¿å­˜è§†é¢‘
        show_frames: æ˜¯å¦æ˜¾ç¤ºå…³é”®å¸§
    """
    print("\n" + "="*70)
    print(f"  æµ‹è¯•æ¨¡å‹: {os.path.basename(model_path)}")
    print("="*70)

    # åŠ è½½æ¨¡å‹
    network = SuikaNet(input_channels=13, num_actions=16, hidden_channels=64)
    network.set_state_dict(paddle.load(model_path))
    network.eval()

    # åˆ›å»ºMCTSå’ŒçŠ¶æ€è½¬æ¢å™¨
    mcts = AlphaZeroMCTS(
        network=network,
        num_simulations=simulations,
        temperature=0.0,
        add_dirichlet_noise=False
    )

    converter = StateConverter(
        grid_height=network.board_h,
        grid_width=network.board_w,
        feature_height=network.board_h,
        feature_width=network.board_w
    )

    # æµ‹è¯•æ¸¸æˆ
    all_scores = []
    all_steps = []

    for game_idx in range(num_games):
        print(f"\nğŸ® æ¸¸æˆ {game_idx+1}/{num_games}")
        print("-" * 70)

        game = GameInterface()
        game.reset(seed=3000 + game_idx)

        steps = 0
        frames = []
        actions = []
        scores_history = []

        while game.game.alive and steps < 100:
            # è·å–çŠ¶æ€å¹¶å†³ç­–
            simplified_state = converter.game_to_simplified(game)
            action = mcts.get_action(simplified_state)

            # è®°å½•å†³ç­–
            actions.append(action)
            scores_history.append(game.game.score)

            # æ‰§è¡ŒåŠ¨ä½œ
            _, _, alive = game.next(action)
            steps += 1

            # è®°å½•å¸§
            game.game.draw()
            frame = game.game.screen.copy()
            frames.append(frame)

            # æ‰“å°è¿›åº¦
            if steps % 10 == 0:
                print(f"  æ­¥æ•°: {steps}, å¾—åˆ†: {game.game.score}, åŠ¨ä½œ: {action}")

        final_score = game.game.score
        all_scores.append(final_score)
        all_steps.append(steps)

        print(f"\nâœ… æ¸¸æˆ {game_idx+1} å®Œæˆ:")
        print(f"   æœ€ç»ˆå¾—åˆ†: {final_score}")
        print(f"   æ€»æ­¥æ•°: {steps}")
        print(f"   å¹³å‡æ¯æ­¥å¾—åˆ†: {final_score/steps:.2f}")

        # ç¬¬ä¸€å±€æ¸¸æˆï¼šå±•ç¤ºè¯¦ç»†ä¿¡æ¯
        if game_idx == 0:
            # ä¿å­˜è§†é¢‘
            if save_video and frames:
                video_path = f"game_test_{final_score}.mp4"
                save_game_video(frames, video_path, fps=5)
                print(f"   ğŸ“¹ è§†é¢‘å·²ä¿å­˜: {video_path}")

            # æ˜¾ç¤ºå…³é”®å¸§
            if show_frames and frames:
                show_game_frames(frames, final_score, steps)

            # åˆ†æåŠ¨ä½œåˆ†å¸ƒ
            analyze_actions(actions, scores_history)

    # ç»Ÿè®¡ç»“æœ
    print("\n" + "="*70)
    print("  ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)
    print(f"å¹³å‡å¾—åˆ†: {np.mean(all_scores):.1f} Â± {np.std(all_scores):.1f}")
    print(f"æœ€é«˜å¾—åˆ†: {max(all_scores)}")
    print(f"æœ€ä½å¾—åˆ†: {min(all_scores)}")
    print(f"å¹³å‡æ­¥æ•°: {np.mean(all_steps):.1f}")
    print("="*70)

    return all_scores, all_steps


def save_game_video(frames: List, output_path: str, fps: int = 10):
    """ä¿å­˜æ¸¸æˆè§†é¢‘"""
    if not frames:
        return

    height, width = frames[0].shape[:2]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    for frame in frames:
        # è½¬æ¢BGRAåˆ°BGR
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
        out.write(frame_bgr)

    out.release()


def show_game_frames(frames: List, score: int, steps: int):
    """æ˜¾ç¤ºå…³é”®å¸§"""
    num_display = min(12, len(frames))
    indices = np.linspace(0, len(frames)-1, num_display, dtype=int)

    fig, axes = plt.subplots(3, 4, figsize=(16, 12))
    axes = axes.flatten()

    for i, idx in enumerate(indices):
        frame = frames[idx]
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)

        axes[i].imshow(frame_rgb)
        axes[i].set_title(f'Step {idx}/{len(frames)}', fontsize=10)
        axes[i].axis('off')

    plt.suptitle(f'Game Replay (Score: {score}, Steps: {steps})',
                fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('game_frames.png', dpi=150, bbox_inches='tight')
    print(f"   ğŸ–¼ï¸  å…³é”®å¸§å·²ä¿å­˜: game_frames.png")
    plt.close()


def analyze_actions(actions: List[int], scores: List[int]):
    """åˆ†æåŠ¨ä½œåˆ†å¸ƒ"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

    # åŠ¨ä½œåˆ†å¸ƒ
    action_counts = np.bincount(actions, minlength=16)
    ax1.bar(range(16), action_counts, color='steelblue', alpha=0.7)
    ax1.set_xlabel('Action (Position)', fontsize=12)
    ax1.set_ylabel('Frequency', fontsize=12)
    ax1.set_title('Action Distribution', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.set_xticks(range(0, 16, 2))

    # å¾—åˆ†è¿›åº¦
    ax2.plot(scores, linewidth=2, color='green')
    ax2.set_xlabel('Step', fontsize=12)
    ax2.set_ylabel('Score', fontsize=12)
    ax2.set_title('Score Progress', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('action_analysis.png', dpi=150, bbox_inches='tight')
    print(f"   ğŸ“ˆ åŠ¨ä½œåˆ†æå·²ä¿å­˜: action_analysis.png")
    plt.close()


def compare_all_models(num_games: int = 10, simulations: int = 100):
    """æ¯”è¾ƒæ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹"""
    print("\n" + "="*70)
    print("  ğŸ” æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹")
    print("="*70)

    model_dir = "weights/alphazero"
    model_files = sorted([f for f in os.listdir(model_dir) if f.endswith('.pdparams')])

    if not model_files:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return

    results = {}

    for model_file in model_files:
        model_path = os.path.join(model_dir, model_file)
        model_name = model_file.replace('.pdparams', '')

        print(f"\næµ‹è¯•æ¨¡å‹: {model_name}")

        # åŠ è½½æ¨¡å‹
        network = SuikaNet(input_channels=13, num_actions=16, hidden_channels=64)
        network.set_state_dict(paddle.load(model_path))
        network.eval()

        mcts = AlphaZeroMCTS(network=network, num_simulations=simulations, temperature=0.0)
        converter = StateConverter(20, 16, 20, 16)

        scores = []
        for i in range(num_games):
            game = GameInterface()
            game.reset(seed=5000 + i)

            while game.game.alive:
                state = converter.game_to_simplified(game)
                action = mcts.get_action(state)
                _, _, _ = game.next(action)

            scores.append(game.game.score)

        results[model_name] = {
            'mean': np.mean(scores),
            'std': np.std(scores),
            'max': max(scores),
            'min': min(scores)
        }

        print(f"  å¹³å‡: {results[model_name]['mean']:.1f} Â± {results[model_name]['std']:.1f}")
        print(f"  æœ€é«˜: {results[model_name]['max']}")

    # ç»˜åˆ¶å¯¹æ¯”å›¾
    plot_model_comparison(results)

    return results


def plot_model_comparison(results: dict):
    """ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”å›¾"""
    fig, ax = plt.subplots(figsize=(12, 6))

    models = list(results.keys())
    means = [results[m]['mean'] for m in models]
    stds = [results[m]['std'] for m in models]

    x = np.arange(len(models))
    ax.bar(x, means, yerr=stds, capsize=5, color='skyblue', alpha=0.8, edgecolor='black')
    ax.set_xlabel('Model', fontsize=12)
    ax.set_ylabel('Mean Score', fontsize=12)
    ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(models, rotation=45, ha='right')
    ax.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')
    print(f"\nâœ… æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜: model_comparison.png")
    plt.close()


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='æµ‹è¯•å¹¶å¯è§†åŒ–AlphaZeroæ¨¡å‹')
    parser.add_argument('--model', type=str, default='weights/alphazero/iter_7.pdparams',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--games', type=int, default=5,
                       help='æµ‹è¯•æ¸¸æˆå±€æ•°')
    parser.add_argument('--simulations', type=int, default=100,
                       help='MCTSæ¨¡æ‹Ÿæ¬¡æ•°')
    parser.add_argument('--no-video', action='store_true',
                       help='ä¸ä¿å­˜è§†é¢‘')
    parser.add_argument('--no-frames', action='store_true',
                       help='ä¸æ˜¾ç¤ºå…³é”®å¸§')
    parser.add_argument('--compare-all', action='store_true',
                       help='æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹')

    args = parser.parse_args()

    if args.compare_all:
        compare_all_models(num_games=10, simulations=args.simulations)
    else:
        test_model_with_visualization(
            model_path=args.model,
            num_games=args.games,
            simulations=args.simulations,
            save_video=not args.no_video,
            show_frames=not args.no_frames
        )
