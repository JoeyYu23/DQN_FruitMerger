{
  "config": {
    "seed": 42,
    "max_episodes": 5000,
    "memory_size": 50000,
    "batch_size": 32,
    "learning_rate": 0.001,
    "gamma": 0.99,
    "eval_interval": 100,
    "checkpoint_interval": 500
  },
  "training": [
    {
      "episode": 0,
      "score": 152,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 19040.82431511257,
      "epsilon": 0.49494200000013533
    },
    {
      "episode": 1,
      "score": 127,
      "reward": -938.0,
      "steps": 40,
      "mean_loss": 19270.10638332367,
      "epsilon": 0.4949020000001364
    },
    {
      "episode": 2,
      "score": 78,
      "reward": -992.0,
      "steps": 37,
      "mean_loss": 18131.64749186748,
      "epsilon": 0.4948650000001374
    },
    {
      "episode": 3,
      "score": 181,
      "reward": -915.0,
      "steps": 54,
      "mean_loss": 20078.443020149512,
      "epsilon": 0.49481100000013883
    },
    {
      "episode": 4,
      "score": 119,
      "reward": -967.0,
      "steps": 47,
      "mean_loss": 23971.021602549452,
      "epsilon": 0.4947640000001401
    },
    {
      "episode": 5,
      "score": 91,
      "reward": -982.0,
      "steps": 43,
      "mean_loss": 21420.86725634198,
      "epsilon": 0.49472100000014124
    },
    {
      "episode": 6,
      "score": 152,
      "reward": -945.0,
      "steps": 50,
      "mean_loss": 13169.431175231934,
      "epsilon": 0.4946710000001426
    },
    {
      "episode": 7,
      "score": 121,
      "reward": -941.0,
      "steps": 43,
      "mean_loss": 15537.64936367301,
      "epsilon": 0.49462800000014373
    },
    {
      "episode": 8,
      "score": 109,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 20992.416214715868,
      "epsilon": 0.49458600000014485
    },
    {
      "episode": 9,
      "score": 98,
      "reward": -974.0,
      "steps": 42,
      "mean_loss": 15998.542812892369,
      "epsilon": 0.494544000000146
    },
    {
      "episode": 10,
      "score": 98,
      "reward": -959.0,
      "steps": 39,
      "mean_loss": 13422.391588846842,
      "epsilon": 0.494505000000147
    },
    {
      "episode": 11,
      "score": 126,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 15872.323070179333,
      "epsilon": 0.4944610000001482
    },
    {
      "episode": 12,
      "score": 142,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 18631.575537308403,
      "epsilon": 0.49441500000014943
    },
    {
      "episode": 13,
      "score": 84,
      "reward": -985.0,
      "steps": 36,
      "mean_loss": 17151.115866767035,
      "epsilon": 0.4943790000001504
    },
    {
      "episode": 14,
      "score": 156,
      "reward": -914.0,
      "steps": 45,
      "mean_loss": 16513.865600585938,
      "epsilon": 0.4943340000001516
    },
    {
      "episode": 15,
      "score": 74,
      "reward": -978.0,
      "steps": 35,
      "mean_loss": 13302.673316301618,
      "epsilon": 0.49429900000015253
    },
    {
      "episode": 16,
      "score": 181,
      "reward": -901.0,
      "steps": 53,
      "mean_loss": 14724.429580400574,
      "epsilon": 0.49424600000015395
    },
    {
      "episode": 17,
      "score": 161,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 15506.810506233802,
      "epsilon": 0.49419400000015534
    },
    {
      "episode": 18,
      "score": 144,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 14980.922327124554,
      "epsilon": 0.4941480000001566
    },
    {
      "episode": 19,
      "score": 173,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 13553.289999301616,
      "epsilon": 0.49409600000015796
    },
    {
      "episode": 20,
      "score": 216,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 12761.301215842917,
      "epsilon": 0.4940420000001594
    },
    {
      "episode": 21,
      "score": 132,
      "reward": -943.0,
      "steps": 45,
      "mean_loss": 14267.755301496718,
      "epsilon": 0.4939970000001606
    },
    {
      "episode": 22,
      "score": 166,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 14894.941759894877,
      "epsilon": 0.493946000000162
    },
    {
      "episode": 23,
      "score": 233,
      "reward": -874.0,
      "steps": 61,
      "mean_loss": 15435.314070154409,
      "epsilon": 0.4938850000001636
    },
    {
      "episode": 24,
      "score": 69,
      "reward": -984.0,
      "steps": 34,
      "mean_loss": 15231.131801829619,
      "epsilon": 0.4938510000001645
    },
    {
      "episode": 25,
      "score": 82,
      "reward": -993.0,
      "steps": 40,
      "mean_loss": 15200.507164001465,
      "epsilon": 0.4938110000001656
    },
    {
      "episode": 26,
      "score": 116,
      "reward": -942.0,
      "steps": 37,
      "mean_loss": 12234.527918635187,
      "epsilon": 0.4937740000001666
    },
    {
      "episode": 27,
      "score": 157,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 14136.858955227599,
      "epsilon": 0.4937250000001679
    },
    {
      "episode": 28,
      "score": 186,
      "reward": -895.0,
      "steps": 54,
      "mean_loss": 15597.79801552384,
      "epsilon": 0.49367100000016934
    },
    {
      "episode": 29,
      "score": 196,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 13187.067290977195,
      "epsilon": 0.4936170000001708
    },
    {
      "episode": 30,
      "score": 162,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 9404.92804855996,
      "epsilon": 0.49357000000017204
    },
    {
      "episode": 31,
      "score": 96,
      "reward": -971.0,
      "steps": 40,
      "mean_loss": 11597.990853881836,
      "epsilon": 0.4935300000001731
    },
    {
      "episode": 32,
      "score": 175,
      "reward": -891.0,
      "steps": 50,
      "mean_loss": 13043.1956791687,
      "epsilon": 0.49348000000017445
    },
    {
      "episode": 33,
      "score": 80,
      "reward": -983.0,
      "steps": 37,
      "mean_loss": 9056.217774262299,
      "epsilon": 0.49344300000017544
    },
    {
      "episode": 34,
      "score": 170,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 14745.061229160854,
      "epsilon": 0.49339400000017675
    },
    {
      "episode": 35,
      "score": 170,
      "reward": -905.0,
      "steps": 47,
      "mean_loss": 12128.094522192123,
      "epsilon": 0.493347000000178
    },
    {
      "episode": 36,
      "score": 164,
      "reward": -921.0,
      "steps": 51,
      "mean_loss": 13385.122608259613,
      "epsilon": 0.49329600000017937
    },
    {
      "episode": 37,
      "score": 156,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 14335.193716710928,
      "epsilon": 0.4932470000001807
    },
    {
      "episode": 38,
      "score": 133,
      "reward": -935.0,
      "steps": 45,
      "mean_loss": 10239.483971828884,
      "epsilon": 0.4932020000001819
    },
    {
      "episode": 39,
      "score": 106,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 10149.25518209284,
      "epsilon": 0.49315800000018306
    },
    {
      "episode": 40,
      "score": 117,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 6145.116160392761,
      "epsilon": 0.49311400000018424
    },
    {
      "episode": 41,
      "score": 133,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 10829.558359319513,
      "epsilon": 0.4930700000001854
    },
    {
      "episode": 42,
      "score": 165,
      "reward": -914.0,
      "steps": 52,
      "mean_loss": 10185.600850545443,
      "epsilon": 0.4930180000001868
    },
    {
      "episode": 43,
      "score": 109,
      "reward": -975.0,
      "steps": 44,
      "mean_loss": 14669.043522574684,
      "epsilon": 0.492974000000188
    },
    {
      "episode": 44,
      "score": 97,
      "reward": -966.0,
      "steps": 37,
      "mean_loss": 9706.791229248047,
      "epsilon": 0.492937000000189
    },
    {
      "episode": 45,
      "score": 182,
      "reward": -900.0,
      "steps": 52,
      "mean_loss": 7663.674379495474,
      "epsilon": 0.49288500000019037
    },
    {
      "episode": 46,
      "score": 134,
      "reward": -943.0,
      "steps": 46,
      "mean_loss": 12413.822257498035,
      "epsilon": 0.4928390000001916
    },
    {
      "episode": 47,
      "score": 160,
      "reward": -899.0,
      "steps": 47,
      "mean_loss": 11890.221102126101,
      "epsilon": 0.49279200000019285
    },
    {
      "episode": 48,
      "score": 164,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 7478.9767865199665,
      "epsilon": 0.4927410000001942
    },
    {
      "episode": 49,
      "score": 194,
      "reward": -890.0,
      "steps": 55,
      "mean_loss": 8472.404794727672,
      "epsilon": 0.4926860000001957
    },
    {
      "episode": 50,
      "score": 110,
      "reward": -946.0,
      "steps": 39,
      "mean_loss": 8781.119331555488,
      "epsilon": 0.49264700000019673
    },
    {
      "episode": 51,
      "score": 153,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 7443.243761590186,
      "epsilon": 0.492600000000198
    },
    {
      "episode": 52,
      "score": 163,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 11456.286022033692,
      "epsilon": 0.49255000000019933
    },
    {
      "episode": 53,
      "score": 153,
      "reward": -887.0,
      "steps": 41,
      "mean_loss": 11128.135348622392,
      "epsilon": 0.4925090000002004
    },
    {
      "episode": 54,
      "score": 138,
      "reward": -906.0,
      "steps": 41,
      "mean_loss": 11543.489977952911,
      "epsilon": 0.4924680000002015
    },
    {
      "episode": 55,
      "score": 111,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 8590.789728684858,
      "epsilon": 0.4924240000002027
    },
    {
      "episode": 56,
      "score": 162,
      "reward": -921.0,
      "steps": 51,
      "mean_loss": 8752.554015365302,
      "epsilon": 0.49237300000020406
    },
    {
      "episode": 57,
      "score": 119,
      "reward": -965.0,
      "steps": 46,
      "mean_loss": 7432.731537860373,
      "epsilon": 0.4923270000002053
    },
    {
      "episode": 58,
      "score": 115,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 8176.971844066273,
      "epsilon": 0.49228300000020647
    },
    {
      "episode": 59,
      "score": 70,
      "reward": -972.0,
      "steps": 28,
      "mean_loss": 7798.442828042166,
      "epsilon": 0.4922550000002072
    },
    {
      "episode": 60,
      "score": 190,
      "reward": -897.0,
      "steps": 56,
      "mean_loss": 7880.670986311777,
      "epsilon": 0.4921990000002087
    },
    {
      "episode": 61,
      "score": 95,
      "reward": -965.0,
      "steps": 35,
      "mean_loss": 11000.513073294504,
      "epsilon": 0.49216400000020966
    },
    {
      "episode": 62,
      "score": 143,
      "reward": -911.0,
      "steps": 44,
      "mean_loss": 7302.172438188033,
      "epsilon": 0.49212000000021083
    },
    {
      "episode": 63,
      "score": 170,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 6256.274416456035,
      "epsilon": 0.4920690000002122
    },
    {
      "episode": 64,
      "score": 153,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 8334.248431854248,
      "epsilon": 0.49201900000021354
    },
    {
      "episode": 65,
      "score": 176,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 7833.74204488901,
      "epsilon": 0.4919670000002149
    },
    {
      "episode": 66,
      "score": 139,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 11517.540502133577,
      "epsilon": 0.49192100000021616
    },
    {
      "episode": 67,
      "score": 148,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 7034.948938369751,
      "epsilon": 0.49187300000021744
    },
    {
      "episode": 68,
      "score": 119,
      "reward": -958.0,
      "steps": 45,
      "mean_loss": 7566.666054619684,
      "epsilon": 0.49182800000021865
    },
    {
      "episode": 69,
      "score": 135,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 5568.45778680355,
      "epsilon": 0.4917810000002199
    },
    {
      "episode": 70,
      "score": 71,
      "reward": -1003.0,
      "steps": 38,
      "mean_loss": 10372.083177666915,
      "epsilon": 0.4917430000002209
    },
    {
      "episode": 71,
      "score": 253,
      "reward": -839.0,
      "steps": 63,
      "mean_loss": 9193.344519478935,
      "epsilon": 0.4916800000002226
    },
    {
      "episode": 72,
      "score": 134,
      "reward": -927.0,
      "steps": 44,
      "mean_loss": 7043.589594754306,
      "epsilon": 0.4916360000002238
    },
    {
      "episode": 73,
      "score": 148,
      "reward": -935.0,
      "steps": 49,
      "mean_loss": 8390.097872364278,
      "epsilon": 0.4915870000002251
    },
    {
      "episode": 74,
      "score": 119,
      "reward": -948.0,
      "steps": 43,
      "mean_loss": 7974.045615617619,
      "epsilon": 0.49154400000022624
    },
    {
      "episode": 75,
      "score": 123,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 6031.406285719438,
      "epsilon": 0.4915000000002274
    },
    {
      "episode": 76,
      "score": 145,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 6775.183421741833,
      "epsilon": 0.4914560000002286
    },
    {
      "episode": 77,
      "score": 111,
      "reward": -971.0,
      "steps": 46,
      "mean_loss": 9715.570369886316,
      "epsilon": 0.49141000000022983
    },
    {
      "episode": 78,
      "score": 207,
      "reward": -879.0,
      "steps": 54,
      "mean_loss": 7292.250730867739,
      "epsilon": 0.4913560000002313
    },
    {
      "episode": 79,
      "score": 101,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 7710.64419596904,
      "epsilon": 0.49131900000023226
    },
    {
      "episode": 80,
      "score": 88,
      "reward": -967.0,
      "steps": 34,
      "mean_loss": 7486.636577157413,
      "epsilon": 0.4912850000002332
    },
    {
      "episode": 81,
      "score": 108,
      "reward": -967.0,
      "steps": 43,
      "mean_loss": 6112.082992376283,
      "epsilon": 0.4912420000002343
    },
    {
      "episode": 82,
      "score": 129,
      "reward": -936.0,
      "steps": 41,
      "mean_loss": 7762.789352789157,
      "epsilon": 0.4912010000002354
    },
    {
      "episode": 83,
      "score": 200,
      "reward": -890.0,
      "steps": 53,
      "mean_loss": 6353.265143412464,
      "epsilon": 0.49114800000023684
    },
    {
      "episode": 84,
      "score": 170,
      "reward": -901.0,
      "steps": 51,
      "mean_loss": 9863.009210623946,
      "epsilon": 0.4910970000002382
    },
    {
      "episode": 85,
      "score": 100,
      "reward": -967.0,
      "steps": 36,
      "mean_loss": 8211.272407531738,
      "epsilon": 0.49106100000023917
    },
    {
      "episode": 86,
      "score": 139,
      "reward": -929.0,
      "steps": 47,
      "mean_loss": 10095.424706641665,
      "epsilon": 0.4910140000002404
    },
    {
      "episode": 87,
      "score": 115,
      "reward": -957.0,
      "steps": 43,
      "mean_loss": 4809.208322214526,
      "epsilon": 0.4909710000002416
    },
    {
      "episode": 88,
      "score": 215,
      "reward": -884.0,
      "steps": 57,
      "mean_loss": 6960.070816575435,
      "epsilon": 0.4909140000002431
    },
    {
      "episode": 89,
      "score": 177,
      "reward": -904.0,
      "steps": 51,
      "mean_loss": 4964.632804421817,
      "epsilon": 0.49086300000024446
    },
    {
      "episode": 90,
      "score": 103,
      "reward": -968.0,
      "steps": 43,
      "mean_loss": 5232.449584251226,
      "epsilon": 0.4908200000002456
    },
    {
      "episode": 91,
      "score": 120,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 9319.68495279948,
      "epsilon": 0.4907750000002468
    },
    {
      "episode": 92,
      "score": 222,
      "reward": -876.0,
      "steps": 58,
      "mean_loss": 5990.202257090601,
      "epsilon": 0.49071700000024837
    },
    {
      "episode": 93,
      "score": 127,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 8254.927903955633,
      "epsilon": 0.49067300000024955
    },
    {
      "episode": 94,
      "score": 131,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 5218.599692162047,
      "epsilon": 0.4906260000002508
    },
    {
      "episode": 95,
      "score": 128,
      "reward": -964.0,
      "steps": 44,
      "mean_loss": 5969.209634954279,
      "epsilon": 0.490582000000252
    },
    {
      "episode": 96,
      "score": 88,
      "reward": -984.0,
      "steps": 39,
      "mean_loss": 6705.246965848482,
      "epsilon": 0.490543000000253
    },
    {
      "episode": 97,
      "score": 193,
      "reward": -897.0,
      "steps": 52,
      "mean_loss": 6217.948856647198,
      "epsilon": 0.4904910000002544
    },
    {
      "episode": 98,
      "score": 160,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 7119.8623000164425,
      "epsilon": 0.49044200000025573
    },
    {
      "episode": 99,
      "score": 95,
      "reward": -969.0,
      "steps": 40,
      "mean_loss": 4297.862920570374,
      "epsilon": 0.4904020000002568
    },
    {
      "episode": 100,
      "score": 144,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 7263.3485772964805,
      "epsilon": 0.49035500000025806
    },
    {
      "episode": 101,
      "score": 150,
      "reward": -932.0,
      "steps": 50,
      "mean_loss": 6034.624092712403,
      "epsilon": 0.4903050000002594
    },
    {
      "episode": 102,
      "score": 116,
      "reward": -943.0,
      "steps": 36,
      "mean_loss": 3430.596403333876,
      "epsilon": 0.49026900000026036
    },
    {
      "episode": 103,
      "score": 87,
      "reward": -990.0,
      "steps": 41,
      "mean_loss": 6881.308808117378,
      "epsilon": 0.49022800000026145
    },
    {
      "episode": 104,
      "score": 155,
      "reward": -922.0,
      "steps": 48,
      "mean_loss": 6495.038022200267,
      "epsilon": 0.49018000000026274
    },
    {
      "episode": 105,
      "score": 153,
      "reward": -950.0,
      "steps": 45,
      "mean_loss": 4586.758003065321,
      "epsilon": 0.49013500000026394
    },
    {
      "episode": 106,
      "score": 171,
      "reward": -899.0,
      "steps": 49,
      "mean_loss": 6863.117807505082,
      "epsilon": 0.49008600000026525
    },
    {
      "episode": 107,
      "score": 98,
      "reward": -979.0,
      "steps": 44,
      "mean_loss": 5970.518251939254,
      "epsilon": 0.49004200000026643
    },
    {
      "episode": 108,
      "score": 110,
      "reward": -960.0,
      "steps": 42,
      "mean_loss": 3817.7026840391613,
      "epsilon": 0.49000000000026755
    },
    {
      "episode": 109,
      "score": 136,
      "reward": -948.0,
      "steps": 46,
      "mean_loss": 3684.033784451692,
      "epsilon": 0.4899540000002688
    },
    {
      "episode": 110,
      "score": 169,
      "reward": -909.0,
      "steps": 50,
      "mean_loss": 5368.656952972412,
      "epsilon": 0.4899040000002701
    },
    {
      "episode": 111,
      "score": 167,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3531.062194525027,
      "epsilon": 0.4898530000002715
    },
    {
      "episode": 112,
      "score": 175,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 5392.095016767394,
      "epsilon": 0.4898000000002729
    },
    {
      "episode": 113,
      "score": 229,
      "reward": -865.0,
      "steps": 58,
      "mean_loss": 4779.151789698108,
      "epsilon": 0.48974200000027446
    },
    {
      "episode": 114,
      "score": 241,
      "reward": -867.0,
      "steps": 59,
      "mean_loss": 4451.580313343113,
      "epsilon": 0.48968300000027604
    },
    {
      "episode": 115,
      "score": 173,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 5050.457136190163,
      "epsilon": 0.48963000000027745
    },
    {
      "episode": 116,
      "score": 154,
      "reward": -920.0,
      "steps": 44,
      "mean_loss": 5593.190568403764,
      "epsilon": 0.48958600000027863
    },
    {
      "episode": 117,
      "score": 89,
      "reward": -968.0,
      "steps": 34,
      "mean_loss": 4228.600077909582,
      "epsilon": 0.48955200000027954
    },
    {
      "episode": 118,
      "score": 136,
      "reward": -947.0,
      "steps": 48,
      "mean_loss": 6519.090360403061,
      "epsilon": 0.4895040000002808
    },
    {
      "episode": 119,
      "score": 131,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 8595.515233675638,
      "epsilon": 0.4894560000002821
    },
    {
      "episode": 120,
      "score": 87,
      "reward": -975.0,
      "steps": 37,
      "mean_loss": 7320.17296208562,
      "epsilon": 0.4894190000002831
    },
    {
      "episode": 121,
      "score": 205,
      "reward": -899.0,
      "steps": 56,
      "mean_loss": 6320.899092129299,
      "epsilon": 0.4893630000002846
    },
    {
      "episode": 122,
      "score": 174,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 5354.144642028808,
      "epsilon": 0.48931300000028594
    },
    {
      "episode": 123,
      "score": 106,
      "reward": -974.0,
      "steps": 46,
      "mean_loss": 4267.311794944431,
      "epsilon": 0.48926700000028717
    },
    {
      "episode": 124,
      "score": 105,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 5262.15771484375,
      "epsilon": 0.48922600000028826
    },
    {
      "episode": 125,
      "score": 113,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 4114.623852816495,
      "epsilon": 0.48918200000028944
    },
    {
      "episode": 126,
      "score": 101,
      "reward": -968.0,
      "steps": 39,
      "mean_loss": 5338.669117854191,
      "epsilon": 0.4891430000002905
    },
    {
      "episode": 127,
      "score": 101,
      "reward": -961.0,
      "steps": 39,
      "mean_loss": 7266.271438598633,
      "epsilon": 0.48910400000029153
    },
    {
      "episode": 128,
      "score": 179,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 6410.559294790592,
      "epsilon": 0.48905100000029295
    },
    {
      "episode": 129,
      "score": 108,
      "reward": -946.0,
      "steps": 38,
      "mean_loss": 5348.674657721269,
      "epsilon": 0.48901300000029396
    },
    {
      "episode": 130,
      "score": 64,
      "reward": -974.0,
      "steps": 29,
      "mean_loss": 6477.293146593817,
      "epsilon": 0.48898400000029474
    },
    {
      "episode": 131,
      "score": 116,
      "reward": -963.0,
      "steps": 43,
      "mean_loss": 4401.912549041038,
      "epsilon": 0.4889410000002959
    },
    {
      "episode": 132,
      "score": 170,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 7206.324991810078,
      "epsilon": 0.4888920000002972
    },
    {
      "episode": 133,
      "score": 107,
      "reward": -976.0,
      "steps": 44,
      "mean_loss": 4621.171165466309,
      "epsilon": 0.4888480000002984
    },
    {
      "episode": 134,
      "score": 121,
      "reward": -941.0,
      "steps": 37,
      "mean_loss": 3814.166405136521,
      "epsilon": 0.48881100000029937
    },
    {
      "episode": 135,
      "score": 138,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 5005.196153194346,
      "epsilon": 0.4887640000003006
    },
    {
      "episode": 136,
      "score": 106,
      "reward": -964.0,
      "steps": 43,
      "mean_loss": 5464.512622921966,
      "epsilon": 0.4887210000003018
    },
    {
      "episode": 137,
      "score": 95,
      "reward": -959.0,
      "steps": 37,
      "mean_loss": 3575.018462928566,
      "epsilon": 0.48868400000030277
    },
    {
      "episode": 138,
      "score": 250,
      "reward": -846.0,
      "steps": 63,
      "mean_loss": 2927.3687461974127,
      "epsilon": 0.48862100000030445
    },
    {
      "episode": 139,
      "score": 133,
      "reward": -930.0,
      "steps": 43,
      "mean_loss": 4201.001828215843,
      "epsilon": 0.4885780000003056
    },
    {
      "episode": 140,
      "score": 147,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 2208.772638403851,
      "epsilon": 0.48853200000030683
    },
    {
      "episode": 141,
      "score": 157,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 5158.547462610098,
      "epsilon": 0.4884800000003082
    },
    {
      "episode": 142,
      "score": 180,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 5785.1493495725235,
      "epsilon": 0.48842700000030964
    },
    {
      "episode": 143,
      "score": 128,
      "reward": -960.0,
      "steps": 46,
      "mean_loss": 5057.479863705842,
      "epsilon": 0.48838100000031087
    },
    {
      "episode": 144,
      "score": 164,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 4551.936284285325,
      "epsilon": 0.48832900000031226
    },
    {
      "episode": 145,
      "score": 196,
      "reward": -888.0,
      "steps": 55,
      "mean_loss": 4451.27050968517,
      "epsilon": 0.48827400000031373
    },
    {
      "episode": 146,
      "score": 185,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 2922.354973572951,
      "epsilon": 0.4882220000003151
    },
    {
      "episode": 147,
      "score": 103,
      "reward": -956.0,
      "steps": 40,
      "mean_loss": 3603.9818815231324,
      "epsilon": 0.4881820000003162
    },
    {
      "episode": 148,
      "score": 127,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 6822.320407867432,
      "epsilon": 0.4881380000003174
    },
    {
      "episode": 149,
      "score": 150,
      "reward": -933.0,
      "steps": 48,
      "mean_loss": 4035.8818629582724,
      "epsilon": 0.48809000000031866
    },
    {
      "episode": 150,
      "score": 106,
      "reward": -946.0,
      "steps": 37,
      "mean_loss": 4279.27611624228,
      "epsilon": 0.48805300000031965
    },
    {
      "episode": 151,
      "score": 98,
      "reward": -964.0,
      "steps": 37,
      "mean_loss": 5656.3061395593595,
      "epsilon": 0.48801600000032064
    },
    {
      "episode": 152,
      "score": 109,
      "reward": -966.0,
      "steps": 42,
      "mean_loss": 3919.19418825422,
      "epsilon": 0.48797400000032176
    },
    {
      "episode": 153,
      "score": 237,
      "reward": -867.0,
      "steps": 59,
      "mean_loss": 4193.799525244762,
      "epsilon": 0.48791500000032334
    },
    {
      "episode": 154,
      "score": 139,
      "reward": -949.0,
      "steps": 49,
      "mean_loss": 4510.698735762616,
      "epsilon": 0.48786600000032465
    },
    {
      "episode": 155,
      "score": 130,
      "reward": -948.0,
      "steps": 45,
      "mean_loss": 5177.45794160631,
      "epsilon": 0.48782100000032586
    },
    {
      "episode": 156,
      "score": 162,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 5428.4710789489745,
      "epsilon": 0.4877710000003272
    },
    {
      "episode": 157,
      "score": 119,
      "reward": -959.0,
      "steps": 46,
      "mean_loss": 3058.9161876180897,
      "epsilon": 0.4877250000003284
    },
    {
      "episode": 158,
      "score": 150,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 5888.3258237838745,
      "epsilon": 0.4876770000003297
    },
    {
      "episode": 159,
      "score": 114,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 4916.935088070956,
      "epsilon": 0.4876330000003309
    },
    {
      "episode": 160,
      "score": 139,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 5694.137109507685,
      "epsilon": 0.4875870000003321
    },
    {
      "episode": 161,
      "score": 139,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 4397.406013336182,
      "epsilon": 0.48753700000033345
    },
    {
      "episode": 162,
      "score": 92,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 3621.3429447895774,
      "epsilon": 0.48750000000033444
    },
    {
      "episode": 163,
      "score": 124,
      "reward": -960.0,
      "steps": 49,
      "mean_loss": 6359.426245241749,
      "epsilon": 0.48745100000033575
    },
    {
      "episode": 164,
      "score": 169,
      "reward": -894.0,
      "steps": 47,
      "mean_loss": 6970.457880223051,
      "epsilon": 0.487404000000337
    },
    {
      "episode": 165,
      "score": 179,
      "reward": -904.0,
      "steps": 53,
      "mean_loss": 3942.2253518734337,
      "epsilon": 0.48735100000033843
    },
    {
      "episode": 166,
      "score": 170,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 5273.504473667519,
      "epsilon": 0.4873000000003398
    },
    {
      "episode": 167,
      "score": 154,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 4814.203969726563,
      "epsilon": 0.48725000000034113
    },
    {
      "episode": 168,
      "score": 190,
      "reward": -875.0,
      "steps": 54,
      "mean_loss": 3096.1137888873063,
      "epsilon": 0.4871960000003426
    },
    {
      "episode": 169,
      "score": 215,
      "reward": -872.0,
      "steps": 55,
      "mean_loss": 3851.1319851962003,
      "epsilon": 0.48714100000034405
    },
    {
      "episode": 170,
      "score": 233,
      "reward": -861.0,
      "steps": 60,
      "mean_loss": 4854.33802541097,
      "epsilon": 0.48708100000034565
    },
    {
      "episode": 171,
      "score": 88,
      "reward": -978.0,
      "steps": 40,
      "mean_loss": 6488.455998420715,
      "epsilon": 0.4870410000003467
    },
    {
      "episode": 172,
      "score": 176,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 7191.559490790734,
      "epsilon": 0.4869890000003481
    },
    {
      "episode": 173,
      "score": 164,
      "reward": -916.0,
      "steps": 49,
      "mean_loss": 3830.7626106106504,
      "epsilon": 0.4869400000003494
    },
    {
      "episode": 174,
      "score": 109,
      "reward": -963.0,
      "steps": 44,
      "mean_loss": 5186.582328449596,
      "epsilon": 0.4868960000003506
    },
    {
      "episode": 175,
      "score": 162,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 4487.337818145752,
      "epsilon": 0.48684600000035194
    },
    {
      "episode": 176,
      "score": 152,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 3891.2180838077625,
      "epsilon": 0.4867990000003532
    },
    {
      "episode": 177,
      "score": 133,
      "reward": -937.0,
      "steps": 43,
      "mean_loss": 4472.092754985011,
      "epsilon": 0.48675600000035435
    },
    {
      "episode": 178,
      "score": 88,
      "reward": -981.0,
      "steps": 40,
      "mean_loss": 4557.830875587463,
      "epsilon": 0.4867160000003554
    },
    {
      "episode": 179,
      "score": 219,
      "reward": -872.0,
      "steps": 57,
      "mean_loss": 2838.2804972330728,
      "epsilon": 0.48665900000035694
    },
    {
      "episode": 180,
      "score": 172,
      "reward": -893.0,
      "steps": 46,
      "mean_loss": 3558.0514682272205,
      "epsilon": 0.4866130000003582
    },
    {
      "episode": 181,
      "score": 121,
      "reward": -941.0,
      "steps": 40,
      "mean_loss": 7308.7409399032595,
      "epsilon": 0.48657300000035925
    },
    {
      "episode": 182,
      "score": 122,
      "reward": -942.0,
      "steps": 40,
      "mean_loss": 3530.3024520874023,
      "epsilon": 0.4865330000003603
    },
    {
      "episode": 183,
      "score": 110,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 7603.766594114758,
      "epsilon": 0.48649100000036144
    },
    {
      "episode": 184,
      "score": 91,
      "reward": -967.0,
      "steps": 37,
      "mean_loss": 4437.94633071487,
      "epsilon": 0.48645400000036243
    },
    {
      "episode": 185,
      "score": 122,
      "reward": -955.0,
      "steps": 45,
      "mean_loss": 2477.1082427130805,
      "epsilon": 0.48640900000036363
    },
    {
      "episode": 186,
      "score": 157,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 5320.775111039479,
      "epsilon": 0.4863610000003649
    },
    {
      "episode": 187,
      "score": 139,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 3698.5951685804002,
      "epsilon": 0.4863140000003662
    },
    {
      "episode": 188,
      "score": 171,
      "reward": -899.0,
      "steps": 48,
      "mean_loss": 2569.031863848368,
      "epsilon": 0.48626600000036746
    },
    {
      "episode": 189,
      "score": 103,
      "reward": -961.0,
      "steps": 39,
      "mean_loss": 5353.076154855581,
      "epsilon": 0.4862270000003685
    },
    {
      "episode": 190,
      "score": 160,
      "reward": -924.0,
      "steps": 49,
      "mean_loss": 4979.700466233857,
      "epsilon": 0.4861780000003698
    },
    {
      "episode": 191,
      "score": 139,
      "reward": -935.0,
      "steps": 45,
      "mean_loss": 3387.3621507432727,
      "epsilon": 0.486133000000371
    },
    {
      "episode": 192,
      "score": 53,
      "reward": -999.0,
      "steps": 30,
      "mean_loss": 3591.7372263590496,
      "epsilon": 0.4861030000003718
    },
    {
      "episode": 193,
      "score": 158,
      "reward": -922.0,
      "steps": 49,
      "mean_loss": 3579.082858338648,
      "epsilon": 0.48605400000037313
    },
    {
      "episode": 194,
      "score": 161,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 6094.520578613281,
      "epsilon": 0.48600400000037447
    },
    {
      "episode": 195,
      "score": 106,
      "reward": -975.0,
      "steps": 41,
      "mean_loss": 2849.673773044493,
      "epsilon": 0.48596300000037557
    },
    {
      "episode": 196,
      "score": 140,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 4542.7909682880745,
      "epsilon": 0.48591900000037674
    },
    {
      "episode": 197,
      "score": 156,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 3213.7096911060567,
      "epsilon": 0.48587000000037806
    },
    {
      "episode": 198,
      "score": 138,
      "reward": -922.0,
      "steps": 42,
      "mean_loss": 4523.206109364827,
      "epsilon": 0.4858280000003792
    },
    {
      "episode": 199,
      "score": 165,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 4589.259677581787,
      "epsilon": 0.4857780000003805
    },
    {
      "episode": 200,
      "score": 151,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3585.3701713412415,
      "epsilon": 0.4857270000003819
    },
    {
      "episode": 201,
      "score": 154,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 2309.4161196899413,
      "epsilon": 0.4856770000003832
    },
    {
      "episode": 202,
      "score": 165,
      "reward": -910.0,
      "steps": 47,
      "mean_loss": 4324.518758733222,
      "epsilon": 0.4856300000003845
    },
    {
      "episode": 203,
      "score": 125,
      "reward": -950.0,
      "steps": 45,
      "mean_loss": 4497.696212938097,
      "epsilon": 0.4855850000003857
    },
    {
      "episode": 204,
      "score": 150,
      "reward": -916.0,
      "steps": 44,
      "mean_loss": 3254.4902893413196,
      "epsilon": 0.48554100000038686
    },
    {
      "episode": 205,
      "score": 111,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 5333.9418129693895,
      "epsilon": 0.485499000000388
    },
    {
      "episode": 206,
      "score": 168,
      "reward": -927.0,
      "steps": 51,
      "mean_loss": 2950.6944919660978,
      "epsilon": 0.48544800000038935
    },
    {
      "episode": 207,
      "score": 236,
      "reward": -853.0,
      "steps": 59,
      "mean_loss": 4625.364854327703,
      "epsilon": 0.4853890000003909
    },
    {
      "episode": 208,
      "score": 121,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 4824.707587502219,
      "epsilon": 0.4853450000003921
    },
    {
      "episode": 209,
      "score": 166,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 5251.82821105957,
      "epsilon": 0.48529500000039344
    },
    {
      "episode": 210,
      "score": 109,
      "reward": -951.0,
      "steps": 40,
      "mean_loss": 2675.8590924263,
      "epsilon": 0.4852550000003945
    },
    {
      "episode": 211,
      "score": 201,
      "reward": -873.0,
      "steps": 55,
      "mean_loss": 3801.7744845997204,
      "epsilon": 0.485200000000396
    },
    {
      "episode": 212,
      "score": 129,
      "reward": -942.0,
      "steps": 46,
      "mean_loss": 3852.681467305059,
      "epsilon": 0.4851540000003972
    },
    {
      "episode": 213,
      "score": 155,
      "reward": -920.0,
      "steps": 48,
      "mean_loss": 4899.406517664592,
      "epsilon": 0.4851060000003985
    },
    {
      "episode": 214,
      "score": 150,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 7214.4568308194475,
      "epsilon": 0.4850580000003998
    },
    {
      "episode": 215,
      "score": 154,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 4627.805022735596,
      "epsilon": 0.4850080000004011
    },
    {
      "episode": 216,
      "score": 220,
      "reward": -856.0,
      "steps": 56,
      "mean_loss": 4992.881006922041,
      "epsilon": 0.4849520000004026
    },
    {
      "episode": 217,
      "score": 157,
      "reward": -910.0,
      "steps": 47,
      "mean_loss": 3912.9093157179814,
      "epsilon": 0.4849050000004039
    },
    {
      "episode": 218,
      "score": 160,
      "reward": -911.0,
      "steps": 49,
      "mean_loss": 3698.6238200907806,
      "epsilon": 0.4848560000004052
    },
    {
      "episode": 219,
      "score": 54,
      "reward": -988.0,
      "steps": 29,
      "mean_loss": 3531.54911883124,
      "epsilon": 0.48482700000040596
    },
    {
      "episode": 220,
      "score": 188,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 4635.524664419669,
      "epsilon": 0.4847730000004074
    },
    {
      "episode": 221,
      "score": 114,
      "reward": -954.0,
      "steps": 43,
      "mean_loss": 5081.364823097407,
      "epsilon": 0.48473000000040856
    },
    {
      "episode": 222,
      "score": 167,
      "reward": -919.0,
      "steps": 49,
      "mean_loss": 4335.3572456204165,
      "epsilon": 0.48468100000040987
    },
    {
      "episode": 223,
      "score": 72,
      "reward": -979.0,
      "steps": 32,
      "mean_loss": 3916.8204889297485,
      "epsilon": 0.4846490000004107
    },
    {
      "episode": 224,
      "score": 120,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 3879.659778958275,
      "epsilon": 0.48460700000041185
    },
    {
      "episode": 225,
      "score": 164,
      "reward": -909.0,
      "steps": 51,
      "mean_loss": 5909.889288958381,
      "epsilon": 0.4845560000004132
    },
    {
      "episode": 226,
      "score": 173,
      "reward": -910.0,
      "steps": 51,
      "mean_loss": 5525.774341508454,
      "epsilon": 0.4845050000004146
    },
    {
      "episode": 227,
      "score": 205,
      "reward": -888.0,
      "steps": 57,
      "mean_loss": 6160.5236487137645,
      "epsilon": 0.4844480000004161
    },
    {
      "episode": 228,
      "score": 102,
      "reward": -962.0,
      "steps": 37,
      "mean_loss": 2972.358631649533,
      "epsilon": 0.4844110000004171
    },
    {
      "episode": 229,
      "score": 153,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 4000.427258511807,
      "epsilon": 0.48436400000041835
    },
    {
      "episode": 230,
      "score": 209,
      "reward": -884.0,
      "steps": 57,
      "mean_loss": 5250.147049887139,
      "epsilon": 0.4843070000004199
    },
    {
      "episode": 231,
      "score": 168,
      "reward": -897.0,
      "steps": 50,
      "mean_loss": 2681.081808013916,
      "epsilon": 0.4842570000004212
    },
    {
      "episode": 232,
      "score": 79,
      "reward": -989.0,
      "steps": 37,
      "mean_loss": 5207.962189133103,
      "epsilon": 0.4842200000004222
    },
    {
      "episode": 233,
      "score": 164,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 4363.473739929199,
      "epsilon": 0.48417000000042354
    },
    {
      "episode": 234,
      "score": 108,
      "reward": -957.0,
      "steps": 37,
      "mean_loss": 5532.246589454445,
      "epsilon": 0.48413300000042453
    },
    {
      "episode": 235,
      "score": 79,
      "reward": -983.0,
      "steps": 35,
      "mean_loss": 4458.900782993862,
      "epsilon": 0.48409800000042547
    },
    {
      "episode": 236,
      "score": 106,
      "reward": -974.0,
      "steps": 45,
      "mean_loss": 3213.9310560438366,
      "epsilon": 0.48405300000042667
    },
    {
      "episode": 237,
      "score": 267,
      "reward": -832.0,
      "steps": 67,
      "mean_loss": 4273.389735663115,
      "epsilon": 0.48398600000042846
    },
    {
      "episode": 238,
      "score": 157,
      "reward": -908.0,
      "steps": 47,
      "mean_loss": 4956.821091672207,
      "epsilon": 0.4839390000004297
    },
    {
      "episode": 239,
      "score": 259,
      "reward": -846.0,
      "steps": 63,
      "mean_loss": 6066.572902134487,
      "epsilon": 0.4838760000004314
    },
    {
      "episode": 240,
      "score": 113,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 6328.09180087135,
      "epsilon": 0.48383400000043253
    },
    {
      "episode": 241,
      "score": 180,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 5001.298043177678,
      "epsilon": 0.4837820000004339
    },
    {
      "episode": 242,
      "score": 134,
      "reward": -956.0,
      "steps": 49,
      "mean_loss": 4792.612955832968,
      "epsilon": 0.48373300000043523
    },
    {
      "episode": 243,
      "score": 153,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 4631.243996143341,
      "epsilon": 0.4836850000004365
    },
    {
      "episode": 244,
      "score": 183,
      "reward": -911.0,
      "steps": 53,
      "mean_loss": 6074.919543572192,
      "epsilon": 0.48363200000043793
    },
    {
      "episode": 245,
      "score": 123,
      "reward": -935.0,
      "steps": 39,
      "mean_loss": 6230.0524000510195,
      "epsilon": 0.483593000000439
    },
    {
      "episode": 246,
      "score": 111,
      "reward": -962.0,
      "steps": 41,
      "mean_loss": 3945.1279700674663,
      "epsilon": 0.4835520000004401
    },
    {
      "episode": 247,
      "score": 98,
      "reward": -967.0,
      "steps": 40,
      "mean_loss": 3394.7307155609133,
      "epsilon": 0.48351200000044114
    },
    {
      "episode": 248,
      "score": 95,
      "reward": -970.0,
      "steps": 39,
      "mean_loss": 1590.5827654325044,
      "epsilon": 0.4834730000004422
    },
    {
      "episode": 249,
      "score": 121,
      "reward": -941.0,
      "steps": 41,
      "mean_loss": 4035.7050368146197,
      "epsilon": 0.4834320000004433
    },
    {
      "episode": 250,
      "score": 148,
      "reward": -938.0,
      "steps": 49,
      "mean_loss": 3438.3392427405533,
      "epsilon": 0.4833830000004446
    },
    {
      "episode": 251,
      "score": 215,
      "reward": -877.0,
      "steps": 52,
      "mean_loss": 3894.7233612353984,
      "epsilon": 0.483331000000446
    },
    {
      "episode": 252,
      "score": 101,
      "reward": -958.0,
      "steps": 40,
      "mean_loss": 4449.766156959534,
      "epsilon": 0.48329100000044706
    },
    {
      "episode": 253,
      "score": 134,
      "reward": -932.0,
      "steps": 45,
      "mean_loss": 3655.010685136583,
      "epsilon": 0.48324600000044826
    },
    {
      "episode": 254,
      "score": 220,
      "reward": -886.0,
      "steps": 60,
      "mean_loss": 5147.9986186981205,
      "epsilon": 0.48318600000044987
    },
    {
      "episode": 255,
      "score": 166,
      "reward": -900.0,
      "steps": 49,
      "mean_loss": 6761.791498145279,
      "epsilon": 0.4831370000004512
    },
    {
      "episode": 256,
      "score": 159,
      "reward": -929.0,
      "steps": 49,
      "mean_loss": 3125.652176370426,
      "epsilon": 0.4830880000004525
    },
    {
      "episode": 257,
      "score": 177,
      "reward": -900.0,
      "steps": 52,
      "mean_loss": 5789.390471971952,
      "epsilon": 0.4830360000004539
    },
    {
      "episode": 258,
      "score": 164,
      "reward": -901.0,
      "steps": 47,
      "mean_loss": 2983.409725595028,
      "epsilon": 0.48298900000045514
    },
    {
      "episode": 259,
      "score": 70,
      "reward": -995.0,
      "steps": 37,
      "mean_loss": 6108.708717758591,
      "epsilon": 0.4829520000004561
    },
    {
      "episode": 260,
      "score": 120,
      "reward": -940.0,
      "steps": 40,
      "mean_loss": 5188.414623260498,
      "epsilon": 0.4829120000004572
    },
    {
      "episode": 261,
      "score": 85,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 6323.874067564268,
      "epsilon": 0.4828750000004582
    },
    {
      "episode": 262,
      "score": 137,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3787.315238465654,
      "epsilon": 0.48282800000045945
    },
    {
      "episode": 263,
      "score": 131,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 6449.655758327908,
      "epsilon": 0.48278300000046065
    },
    {
      "episode": 264,
      "score": 106,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 4290.73760136691,
      "epsilon": 0.4827390000004618
    },
    {
      "episode": 265,
      "score": 150,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 5014.890070976095,
      "epsilon": 0.4826920000004631
    },
    {
      "episode": 266,
      "score": 196,
      "reward": -882.0,
      "steps": 55,
      "mean_loss": 3667.139493630149,
      "epsilon": 0.48263700000046456
    },
    {
      "episode": 267,
      "score": 132,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 5998.218848315152,
      "epsilon": 0.48259300000046573
    },
    {
      "episode": 268,
      "score": 183,
      "reward": -908.0,
      "steps": 56,
      "mean_loss": 3747.194920812334,
      "epsilon": 0.48253700000046723
    },
    {
      "episode": 269,
      "score": 132,
      "reward": -943.0,
      "steps": 45,
      "mean_loss": 3755.2276933458115,
      "epsilon": 0.48249200000046844
    },
    {
      "episode": 270,
      "score": 113,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 6232.252172990279,
      "epsilon": 0.4824480000004696
    },
    {
      "episode": 271,
      "score": 272,
      "reward": -834.0,
      "steps": 69,
      "mean_loss": 4214.635736106098,
      "epsilon": 0.48237900000047146
    },
    {
      "episode": 272,
      "score": 230,
      "reward": -875.0,
      "steps": 60,
      "mean_loss": 3413.1810203552245,
      "epsilon": 0.48231900000047306
    },
    {
      "episode": 273,
      "score": 171,
      "reward": -911.0,
      "steps": 51,
      "mean_loss": 3743.8578192766977,
      "epsilon": 0.48226800000047443
    },
    {
      "episode": 274,
      "score": 136,
      "reward": -929.0,
      "steps": 44,
      "mean_loss": 4120.105425921353,
      "epsilon": 0.4822240000004756
    },
    {
      "episode": 275,
      "score": 119,
      "reward": -942.0,
      "steps": 43,
      "mean_loss": 3853.6280828076738,
      "epsilon": 0.48218100000047676
    },
    {
      "episode": 276,
      "score": 179,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 8122.593730779795,
      "epsilon": 0.48212900000047815
    },
    {
      "episode": 277,
      "score": 119,
      "reward": -969.0,
      "steps": 46,
      "mean_loss": 6252.757952151092,
      "epsilon": 0.4820830000004794
    },
    {
      "episode": 278,
      "score": 95,
      "reward": -975.0,
      "steps": 42,
      "mean_loss": 2138.1950274876185,
      "epsilon": 0.4820410000004805
    },
    {
      "episode": 279,
      "score": 140,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 4936.758356051975,
      "epsilon": 0.4819960000004817
    },
    {
      "episode": 280,
      "score": 110,
      "reward": -968.0,
      "steps": 41,
      "mean_loss": 3772.694660279809,
      "epsilon": 0.4819550000004828
    },
    {
      "episode": 281,
      "score": 94,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 3038.3605836404336,
      "epsilon": 0.4819180000004838
    },
    {
      "episode": 282,
      "score": 120,
      "reward": -951.0,
      "steps": 47,
      "mean_loss": 3641.147179786195,
      "epsilon": 0.48187100000048505
    },
    {
      "episode": 283,
      "score": 162,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 5365.634237639758,
      "epsilon": 0.48182200000048636
    },
    {
      "episode": 284,
      "score": 148,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 5360.881251525879,
      "epsilon": 0.48177700000048757
    },
    {
      "episode": 285,
      "score": 114,
      "reward": -933.0,
      "steps": 35,
      "mean_loss": 3168.928109741211,
      "epsilon": 0.4817420000004885
    },
    {
      "episode": 286,
      "score": 164,
      "reward": -916.0,
      "steps": 48,
      "mean_loss": 4203.883852481842,
      "epsilon": 0.4816940000004898
    },
    {
      "episode": 287,
      "score": 164,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 5292.006109359417,
      "epsilon": 0.48164700000049104
    },
    {
      "episode": 288,
      "score": 145,
      "reward": -942.0,
      "steps": 49,
      "mean_loss": 3703.652180885782,
      "epsilon": 0.48159800000049235
    },
    {
      "episode": 289,
      "score": 134,
      "reward": -947.0,
      "steps": 47,
      "mean_loss": 3485.686509477331,
      "epsilon": 0.4815510000004936
    },
    {
      "episode": 290,
      "score": 107,
      "reward": -956.0,
      "steps": 39,
      "mean_loss": 4206.65217590332,
      "epsilon": 0.48151200000049466
    },
    {
      "episode": 291,
      "score": 229,
      "reward": -862.0,
      "steps": 58,
      "mean_loss": 4868.0741025332745,
      "epsilon": 0.4814540000004962
    },
    {
      "episode": 292,
      "score": 96,
      "reward": -976.0,
      "steps": 43,
      "mean_loss": 2910.226843723031,
      "epsilon": 0.48141100000049736
    },
    {
      "episode": 293,
      "score": 118,
      "reward": -937.0,
      "steps": 39,
      "mean_loss": 3927.4358637883115,
      "epsilon": 0.4813720000004984
    },
    {
      "episode": 294,
      "score": 82,
      "reward": -982.0,
      "steps": 39,
      "mean_loss": 4758.006007267879,
      "epsilon": 0.48133300000049944
    },
    {
      "episode": 295,
      "score": 161,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 5842.474824710768,
      "epsilon": 0.48128400000050076
    },
    {
      "episode": 296,
      "score": 146,
      "reward": -937.0,
      "steps": 46,
      "mean_loss": 4243.263921654742,
      "epsilon": 0.481238000000502
    },
    {
      "episode": 297,
      "score": 143,
      "reward": -917.0,
      "steps": 46,
      "mean_loss": 5387.21988794078,
      "epsilon": 0.4811920000005032
    },
    {
      "episode": 298,
      "score": 108,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 4299.09135660311,
      "epsilon": 0.4811510000005043
    },
    {
      "episode": 299,
      "score": 82,
      "reward": -983.0,
      "steps": 36,
      "mean_loss": 4981.832697550456,
      "epsilon": 0.4811150000005053
    },
    {
      "episode": 300,
      "score": 194,
      "reward": -879.0,
      "steps": 54,
      "mean_loss": 3373.749087651571,
      "epsilon": 0.4810610000005067
    },
    {
      "episode": 301,
      "score": 85,
      "reward": -990.0,
      "steps": 38,
      "mean_loss": 2296.481475026984,
      "epsilon": 0.48102300000050774
    },
    {
      "episode": 302,
      "score": 150,
      "reward": -951.0,
      "steps": 49,
      "mean_loss": 1562.7894189017159,
      "epsilon": 0.48097400000050905
    },
    {
      "episode": 303,
      "score": 148,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 3179.409750431142,
      "epsilon": 0.4809270000005103
    },
    {
      "episode": 304,
      "score": 83,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 4043.813670802761,
      "epsilon": 0.4808900000005113
    },
    {
      "episode": 305,
      "score": 143,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3641.804298400879,
      "epsilon": 0.48084300000051255
    },
    {
      "episode": 306,
      "score": 184,
      "reward": -888.0,
      "steps": 48,
      "mean_loss": 5229.6689980824785,
      "epsilon": 0.48079500000051384
    },
    {
      "episode": 307,
      "score": 176,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 1988.2275680841185,
      "epsilon": 0.4807440000005152
    },
    {
      "episode": 308,
      "score": 149,
      "reward": -929.0,
      "steps": 47,
      "mean_loss": 3094.9308643746886,
      "epsilon": 0.48069700000051646
    },
    {
      "episode": 309,
      "score": 171,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 4090.9253695678713,
      "epsilon": 0.4806470000005178
    },
    {
      "episode": 310,
      "score": 156,
      "reward": -927.0,
      "steps": 51,
      "mean_loss": 4294.813720927519,
      "epsilon": 0.48059600000051916
    },
    {
      "episode": 311,
      "score": 125,
      "reward": -947.0,
      "steps": 45,
      "mean_loss": 6076.549392191569,
      "epsilon": 0.48055100000052037
    },
    {
      "episode": 312,
      "score": 119,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 3497.7144608931108,
      "epsilon": 0.48050700000052154
    },
    {
      "episode": 313,
      "score": 140,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 3264.506589592828,
      "epsilon": 0.48046200000052275
    },
    {
      "episode": 314,
      "score": 158,
      "reward": -929.0,
      "steps": 49,
      "mean_loss": 5458.328514099121,
      "epsilon": 0.48041300000052406
    },
    {
      "episode": 315,
      "score": 133,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 2845.716163635254,
      "epsilon": 0.48036900000052524
    },
    {
      "episode": 316,
      "score": 105,
      "reward": -945.0,
      "steps": 40,
      "mean_loss": 3355.2161441802978,
      "epsilon": 0.4803290000005263
    },
    {
      "episode": 317,
      "score": 142,
      "reward": -919.0,
      "steps": 44,
      "mean_loss": 3298.6829110925846,
      "epsilon": 0.4802850000005275
    },
    {
      "episode": 318,
      "score": 193,
      "reward": -887.0,
      "steps": 55,
      "mean_loss": 3497.2180163296784,
      "epsilon": 0.48023000000052896
    },
    {
      "episode": 319,
      "score": 95,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 4388.786712027885,
      "epsilon": 0.48019300000052995
    },
    {
      "episode": 320,
      "score": 56,
      "reward": -998.0,
      "steps": 31,
      "mean_loss": 4731.552207700668,
      "epsilon": 0.4801620000005308
    },
    {
      "episode": 321,
      "score": 111,
      "reward": -950.0,
      "steps": 41,
      "mean_loss": 4108.009058882551,
      "epsilon": 0.4801210000005319
    },
    {
      "episode": 322,
      "score": 80,
      "reward": -988.0,
      "steps": 39,
      "mean_loss": 3706.006586710612,
      "epsilon": 0.4800820000005329
    },
    {
      "episode": 323,
      "score": 168,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 5069.154678344727,
      "epsilon": 0.48003200000053425
    },
    {
      "episode": 324,
      "score": 123,
      "reward": -945.0,
      "steps": 42,
      "mean_loss": 2468.7571436564126,
      "epsilon": 0.4799900000005354
    },
    {
      "episode": 325,
      "score": 133,
      "reward": -951.0,
      "steps": 48,
      "mean_loss": 4461.354512453079,
      "epsilon": 0.47994200000053666
    },
    {
      "episode": 326,
      "score": 142,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 3348.8003339767456,
      "epsilon": 0.47989400000053795
    },
    {
      "episode": 327,
      "score": 85,
      "reward": -969.0,
      "steps": 34,
      "mean_loss": 4542.197827731862,
      "epsilon": 0.47986000000053886
    },
    {
      "episode": 328,
      "score": 196,
      "reward": -873.0,
      "steps": 50,
      "mean_loss": 4555.841391143799,
      "epsilon": 0.4798100000005402
    },
    {
      "episode": 329,
      "score": 149,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 4959.246787872315,
      "epsilon": 0.47976000000054153
    },
    {
      "episode": 330,
      "score": 171,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 4427.123073425293,
      "epsilon": 0.47971000000054287
    },
    {
      "episode": 331,
      "score": 77,
      "reward": -988.0,
      "steps": 38,
      "mean_loss": 2200.0899300826222,
      "epsilon": 0.4796720000005439
    },
    {
      "episode": 332,
      "score": 183,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 1638.289724529914,
      "epsilon": 0.4796190000005453
    },
    {
      "episode": 333,
      "score": 204,
      "reward": -902.0,
      "steps": 57,
      "mean_loss": 3980.618705347965,
      "epsilon": 0.47956200000054683
    },
    {
      "episode": 334,
      "score": 135,
      "reward": -927.0,
      "steps": 44,
      "mean_loss": 6389.394182031805,
      "epsilon": 0.479518000000548
    },
    {
      "episode": 335,
      "score": 191,
      "reward": -869.0,
      "steps": 52,
      "mean_loss": 6652.825478480412,
      "epsilon": 0.4794660000005494
    },
    {
      "episode": 336,
      "score": 140,
      "reward": -917.0,
      "steps": 46,
      "mean_loss": 6794.427317080291,
      "epsilon": 0.47942000000055063
    },
    {
      "episode": 337,
      "score": 88,
      "reward": -961.0,
      "steps": 35,
      "mean_loss": 5199.798301478794,
      "epsilon": 0.47938500000055156
    },
    {
      "episode": 338,
      "score": 155,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 3686.0065077209474,
      "epsilon": 0.4793350000005529
    },
    {
      "episode": 339,
      "score": 163,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 2837.8719602312362,
      "epsilon": 0.4792860000005542
    },
    {
      "episode": 340,
      "score": 176,
      "reward": -910.0,
      "steps": 51,
      "mean_loss": 4316.093307046329,
      "epsilon": 0.4792350000005556
    },
    {
      "episode": 341,
      "score": 172,
      "reward": -921.0,
      "steps": 51,
      "mean_loss": 5329.914876900467,
      "epsilon": 0.47918400000055694
    },
    {
      "episode": 342,
      "score": 164,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 3582.7450832444792,
      "epsilon": 0.47913500000055825
    },
    {
      "episode": 343,
      "score": 159,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 4131.613499450684,
      "epsilon": 0.4790850000005596
    },
    {
      "episode": 344,
      "score": 81,
      "reward": -992.0,
      "steps": 40,
      "mean_loss": 3851.1330377578734,
      "epsilon": 0.47904500000056066
    },
    {
      "episode": 345,
      "score": 137,
      "reward": -930.0,
      "steps": 45,
      "mean_loss": 4499.491267395019,
      "epsilon": 0.47900000000056187
    },
    {
      "episode": 346,
      "score": 139,
      "reward": -929.0,
      "steps": 47,
      "mean_loss": 4718.293852623473,
      "epsilon": 0.4789530000005631
    },
    {
      "episode": 347,
      "score": 141,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 3995.458033135597,
      "epsilon": 0.4789060000005644
    },
    {
      "episode": 348,
      "score": 127,
      "reward": -942.0,
      "steps": 46,
      "mean_loss": 3994.7834154211955,
      "epsilon": 0.4788600000005656
    },
    {
      "episode": 349,
      "score": 212,
      "reward": -879.0,
      "steps": 56,
      "mean_loss": 5659.594874382019,
      "epsilon": 0.4788040000005671
    },
    {
      "episode": 350,
      "score": 181,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 3949.0545380536246,
      "epsilon": 0.4787530000005685
    },
    {
      "episode": 351,
      "score": 155,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 3559.5893218669485,
      "epsilon": 0.47870600000056973
    },
    {
      "episode": 352,
      "score": 197,
      "reward": -876.0,
      "steps": 53,
      "mean_loss": 2785.1211880378005,
      "epsilon": 0.47865300000057115
    },
    {
      "episode": 353,
      "score": 167,
      "reward": -902.0,
      "steps": 49,
      "mean_loss": 4949.019756550691,
      "epsilon": 0.47860400000057246
    },
    {
      "episode": 354,
      "score": 73,
      "reward": -999.0,
      "steps": 38,
      "mean_loss": 5523.415862133628,
      "epsilon": 0.4785660000005735
    },
    {
      "episode": 355,
      "score": 116,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 4668.438435294412,
      "epsilon": 0.47852200000057465
    },
    {
      "episode": 356,
      "score": 170,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 2787.9616250258227,
      "epsilon": 0.47847000000057605
    },
    {
      "episode": 357,
      "score": 156,
      "reward": -934.0,
      "steps": 51,
      "mean_loss": 4101.950847550935,
      "epsilon": 0.4784190000005774
    },
    {
      "episode": 358,
      "score": 121,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 3802.7733821463075,
      "epsilon": 0.47837200000057867
    },
    {
      "episode": 359,
      "score": 111,
      "reward": -965.0,
      "steps": 40,
      "mean_loss": 6236.227268791199,
      "epsilon": 0.47833200000057974
    },
    {
      "episode": 360,
      "score": 87,
      "reward": -983.0,
      "steps": 39,
      "mean_loss": 3043.493323888534,
      "epsilon": 0.4782930000005808
    },
    {
      "episode": 361,
      "score": 121,
      "reward": -966.0,
      "steps": 45,
      "mean_loss": 3336.4411447313096,
      "epsilon": 0.478248000000582
    },
    {
      "episode": 362,
      "score": 121,
      "reward": -952.0,
      "steps": 45,
      "mean_loss": 4699.131174045139,
      "epsilon": 0.4782030000005832
    },
    {
      "episode": 363,
      "score": 160,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 4684.93337504069,
      "epsilon": 0.4781550000005845
    },
    {
      "episode": 364,
      "score": 114,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3874.566482890736,
      "epsilon": 0.47811100000058565
    },
    {
      "episode": 365,
      "score": 153,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 3074.0497721036277,
      "epsilon": 0.47806300000058694
    },
    {
      "episode": 366,
      "score": 177,
      "reward": -893.0,
      "steps": 52,
      "mean_loss": 4116.74599310068,
      "epsilon": 0.4780110000005883
    },
    {
      "episode": 367,
      "score": 112,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 4398.579384422303,
      "epsilon": 0.4779710000005894
    },
    {
      "episode": 368,
      "score": 155,
      "reward": -919.0,
      "steps": 49,
      "mean_loss": 3329.2965617277187,
      "epsilon": 0.4779220000005907
    },
    {
      "episode": 369,
      "score": 180,
      "reward": -898.0,
      "steps": 50,
      "mean_loss": 1598.6714329528809,
      "epsilon": 0.47787200000059205
    },
    {
      "episode": 370,
      "score": 92,
      "reward": -973.0,
      "steps": 35,
      "mean_loss": 2163.9313555036274,
      "epsilon": 0.477837000000593
    },
    {
      "episode": 371,
      "score": 138,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 3575.026063634994,
      "epsilon": 0.47779000000059424
    },
    {
      "episode": 372,
      "score": 117,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 2673.980696938255,
      "epsilon": 0.4777460000005954
    },
    {
      "episode": 373,
      "score": 176,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 3863.824136352539,
      "epsilon": 0.47769600000059675
    },
    {
      "episode": 374,
      "score": 147,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 4587.968124084473,
      "epsilon": 0.4776460000005981
    },
    {
      "episode": 375,
      "score": 205,
      "reward": -876.0,
      "steps": 54,
      "mean_loss": 3497.346396976047,
      "epsilon": 0.47759200000059954
    },
    {
      "episode": 376,
      "score": 178,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 6459.25622852032,
      "epsilon": 0.47754000000060093
    },
    {
      "episode": 377,
      "score": 108,
      "reward": -968.0,
      "steps": 34,
      "mean_loss": 3551.87981190401,
      "epsilon": 0.47750600000060184
    },
    {
      "episode": 378,
      "score": 117,
      "reward": -971.0,
      "steps": 47,
      "mean_loss": 1979.3474182778216,
      "epsilon": 0.4774590000006031
    },
    {
      "episode": 379,
      "score": 99,
      "reward": -960.0,
      "steps": 39,
      "mean_loss": 4589.142968202249,
      "epsilon": 0.47742000000060414
    },
    {
      "episode": 380,
      "score": 197,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 3580.4497563397445,
      "epsilon": 0.4773660000006056
    },
    {
      "episode": 381,
      "score": 127,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 3480.185292677446,
      "epsilon": 0.47732200000060676
    },
    {
      "episode": 382,
      "score": 93,
      "reward": -968.0,
      "steps": 35,
      "mean_loss": 5688.464203316825,
      "epsilon": 0.4772870000006077
    },
    {
      "episode": 383,
      "score": 154,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 3475.0054509589013,
      "epsilon": 0.47724000000060895
    },
    {
      "episode": 384,
      "score": 106,
      "reward": -954.0,
      "steps": 39,
      "mean_loss": 4756.780333103277,
      "epsilon": 0.47720100000061
    },
    {
      "episode": 385,
      "score": 160,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 1859.694658915202,
      "epsilon": 0.4771530000006113
    },
    {
      "episode": 386,
      "score": 95,
      "reward": -975.0,
      "steps": 41,
      "mean_loss": 2109.430472025057,
      "epsilon": 0.4771120000006124
    },
    {
      "episode": 387,
      "score": 114,
      "reward": -951.0,
      "steps": 37,
      "mean_loss": 2906.733140172185,
      "epsilon": 0.47707500000061337
    },
    {
      "episode": 388,
      "score": 139,
      "reward": -919.0,
      "steps": 44,
      "mean_loss": 4948.575849359686,
      "epsilon": 0.47703100000061455
    },
    {
      "episode": 389,
      "score": 46,
      "reward": -1013.0,
      "steps": 31,
      "mean_loss": 2841.801445991762,
      "epsilon": 0.4770000000006154
    },
    {
      "episode": 390,
      "score": 186,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 2849.2310901857772,
      "epsilon": 0.4769470000006168
    },
    {
      "episode": 391,
      "score": 149,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 4198.725483508821,
      "epsilon": 0.47690000000061805
    },
    {
      "episode": 392,
      "score": 211,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 5674.434787608959,
      "epsilon": 0.4768460000006195
    },
    {
      "episode": 393,
      "score": 82,
      "reward": -978.0,
      "steps": 34,
      "mean_loss": 2260.5228946910183,
      "epsilon": 0.4768120000006204
    },
    {
      "episode": 394,
      "score": 220,
      "reward": -890.0,
      "steps": 58,
      "mean_loss": 4487.175930417818,
      "epsilon": 0.47675400000062196
    },
    {
      "episode": 395,
      "score": 144,
      "reward": -947.0,
      "steps": 45,
      "mean_loss": 3371.052000088162,
      "epsilon": 0.47670900000062316
    },
    {
      "episode": 396,
      "score": 133,
      "reward": -933.0,
      "steps": 42,
      "mean_loss": 2478.2270164489746,
      "epsilon": 0.4766670000006243
    },
    {
      "episode": 397,
      "score": 142,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 3669.102325771166,
      "epsilon": 0.4766210000006255
    },
    {
      "episode": 398,
      "score": 79,
      "reward": -986.0,
      "steps": 37,
      "mean_loss": 5310.24504811055,
      "epsilon": 0.4765840000006265
    },
    {
      "episode": 399,
      "score": 120,
      "reward": -950.0,
      "steps": 42,
      "mean_loss": 3894.2520661127,
      "epsilon": 0.47654200000062763
    },
    {
      "episode": 400,
      "score": 113,
      "reward": -963.0,
      "steps": 46,
      "mean_loss": 4786.026164842689,
      "epsilon": 0.47649600000062886
    },
    {
      "episode": 401,
      "score": 92,
      "reward": -994.0,
      "steps": 42,
      "mean_loss": 3390.287448247274,
      "epsilon": 0.47645400000063
    },
    {
      "episode": 402,
      "score": 106,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 5156.014293125698,
      "epsilon": 0.4764120000006311
    },
    {
      "episode": 403,
      "score": 110,
      "reward": -955.0,
      "steps": 40,
      "mean_loss": 3901.8279815673827,
      "epsilon": 0.4763720000006322
    },
    {
      "episode": 404,
      "score": 166,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 4747.300669767419,
      "epsilon": 0.4763230000006335
    },
    {
      "episode": 405,
      "score": 103,
      "reward": -952.0,
      "steps": 37,
      "mean_loss": 4903.739738670555,
      "epsilon": 0.4762860000006345
    },
    {
      "episode": 406,
      "score": 158,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 3510.4584048461916,
      "epsilon": 0.4762360000006358
    },
    {
      "episode": 407,
      "score": 141,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 4331.56155538559,
      "epsilon": 0.4761880000006371
    },
    {
      "episode": 408,
      "score": 101,
      "reward": -949.0,
      "steps": 36,
      "mean_loss": 4680.607425265842,
      "epsilon": 0.47615200000063806
    },
    {
      "episode": 409,
      "score": 119,
      "reward": -940.0,
      "steps": 41,
      "mean_loss": 5897.368142849062,
      "epsilon": 0.47611100000063916
    },
    {
      "episode": 410,
      "score": 111,
      "reward": -958.0,
      "steps": 45,
      "mean_loss": 4138.104291449653,
      "epsilon": 0.47606600000064037
    },
    {
      "episode": 411,
      "score": 116,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 3631.830994345925,
      "epsilon": 0.47602200000064154
    },
    {
      "episode": 412,
      "score": 179,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 3729.66099357605,
      "epsilon": 0.47597000000064293
    },
    {
      "episode": 413,
      "score": 161,
      "reward": -915.0,
      "steps": 48,
      "mean_loss": 3167.9269264539084,
      "epsilon": 0.4759220000006442
    },
    {
      "episode": 414,
      "score": 130,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 3182.8449762517757,
      "epsilon": 0.4758780000006454
    },
    {
      "episode": 415,
      "score": 199,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 2836.4355955857495,
      "epsilon": 0.4758260000006468
    },
    {
      "episode": 416,
      "score": 192,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 4316.388652377658,
      "epsilon": 0.47577200000064823
    },
    {
      "episode": 417,
      "score": 170,
      "reward": -903.0,
      "steps": 53,
      "mean_loss": 3663.7492805337006,
      "epsilon": 0.47571900000064965
    },
    {
      "episode": 418,
      "score": 194,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 2284.0112091347023,
      "epsilon": 0.4756650000006511
    },
    {
      "episode": 419,
      "score": 226,
      "reward": -875.0,
      "steps": 60,
      "mean_loss": 4252.64729385376,
      "epsilon": 0.4756050000006527
    },
    {
      "episode": 420,
      "score": 121,
      "reward": -946.0,
      "steps": 43,
      "mean_loss": 2032.8855610337368,
      "epsilon": 0.47556200000065385
    },
    {
      "episode": 421,
      "score": 142,
      "reward": -926.0,
      "steps": 48,
      "mean_loss": 3420.637435118357,
      "epsilon": 0.47551400000065513
    },
    {
      "episode": 422,
      "score": 213,
      "reward": -893.0,
      "steps": 58,
      "mean_loss": 4226.801610486261,
      "epsilon": 0.4754560000006567
    },
    {
      "episode": 423,
      "score": 99,
      "reward": -970.0,
      "steps": 39,
      "mean_loss": 5769.133355947642,
      "epsilon": 0.47541700000065773
    },
    {
      "episode": 424,
      "score": 170,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 3378.324524823357,
      "epsilon": 0.4753660000006591
    },
    {
      "episode": 425,
      "score": 132,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 2256.987905385543,
      "epsilon": 0.4753170000006604
    },
    {
      "episode": 426,
      "score": 147,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 4460.398989677429,
      "epsilon": 0.4752690000006617
    },
    {
      "episode": 427,
      "score": 78,
      "reward": -983.0,
      "steps": 37,
      "mean_loss": 3950.1444042308913,
      "epsilon": 0.4752320000006627
    },
    {
      "episode": 428,
      "score": 107,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 3268.946339520541,
      "epsilon": 0.47518800000066386
    },
    {
      "episode": 429,
      "score": 174,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 3836.730959085318,
      "epsilon": 0.47513600000066525
    },
    {
      "episode": 430,
      "score": 176,
      "reward": -892.0,
      "steps": 50,
      "mean_loss": 6516.770725097656,
      "epsilon": 0.4750860000006666
    },
    {
      "episode": 431,
      "score": 247,
      "reward": -849.0,
      "steps": 62,
      "mean_loss": 5626.354293577133,
      "epsilon": 0.47502400000066825
    },
    {
      "episode": 432,
      "score": 120,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 3767.987259084528,
      "epsilon": 0.4749800000006694
    },
    {
      "episode": 433,
      "score": 138,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 2197.3488914002764,
      "epsilon": 0.4749330000006707
    },
    {
      "episode": 434,
      "score": 124,
      "reward": -946.0,
      "steps": 42,
      "mean_loss": 3920.6408813113258,
      "epsilon": 0.4748910000006718
    },
    {
      "episode": 435,
      "score": 153,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 3527.927074665926,
      "epsilon": 0.4748420000006731
    },
    {
      "episode": 436,
      "score": 116,
      "reward": -958.0,
      "steps": 43,
      "mean_loss": 3377.979347051576,
      "epsilon": 0.47479900000067427
    },
    {
      "episode": 437,
      "score": 157,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 4966.374254302978,
      "epsilon": 0.4747490000006756
    },
    {
      "episode": 438,
      "score": 149,
      "reward": -921.0,
      "steps": 44,
      "mean_loss": 2820.874958385121,
      "epsilon": 0.4747050000006768
    },
    {
      "episode": 439,
      "score": 117,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 2656.737501864963,
      "epsilon": 0.474660000000678
    },
    {
      "episode": 440,
      "score": 132,
      "reward": -933.0,
      "steps": 42,
      "mean_loss": 4517.229319981167,
      "epsilon": 0.4746180000006791
    },
    {
      "episode": 441,
      "score": 136,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 7799.298499065897,
      "epsilon": 0.47457200000068034
    },
    {
      "episode": 442,
      "score": 143,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 3006.2586423912826,
      "epsilon": 0.47452300000068165
    },
    {
      "episode": 443,
      "score": 166,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 3412.134547424316,
      "epsilon": 0.474473000000683
    },
    {
      "episode": 444,
      "score": 123,
      "reward": -943.0,
      "steps": 40,
      "mean_loss": 5713.295198631286,
      "epsilon": 0.47443300000068406
    },
    {
      "episode": 445,
      "score": 184,
      "reward": -893.0,
      "steps": 54,
      "mean_loss": 4061.4883694118926,
      "epsilon": 0.4743790000006855
    },
    {
      "episode": 446,
      "score": 107,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 2331.0974446738637,
      "epsilon": 0.4743380000006866
    },
    {
      "episode": 447,
      "score": 95,
      "reward": -971.0,
      "steps": 39,
      "mean_loss": 3849.038796449319,
      "epsilon": 0.47429900000068764
    },
    {
      "episode": 448,
      "score": 132,
      "reward": -923.0,
      "steps": 41,
      "mean_loss": 2789.4574062068286,
      "epsilon": 0.47425800000068874
    },
    {
      "episode": 449,
      "score": 92,
      "reward": -967.0,
      "steps": 37,
      "mean_loss": 4851.321310507285,
      "epsilon": 0.47422100000068973
    },
    {
      "episode": 450,
      "score": 103,
      "reward": -973.0,
      "steps": 41,
      "mean_loss": 2833.7954251359147,
      "epsilon": 0.4741800000006908
    },
    {
      "episode": 451,
      "score": 89,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 5603.004597019505,
      "epsilon": 0.4741430000006918
    },
    {
      "episode": 452,
      "score": 112,
      "reward": -944.0,
      "steps": 40,
      "mean_loss": 2407.195088195801,
      "epsilon": 0.4741030000006929
    },
    {
      "episode": 453,
      "score": 68,
      "reward": -993.0,
      "steps": 34,
      "mean_loss": 4558.014084311093,
      "epsilon": 0.4740690000006938
    },
    {
      "episode": 454,
      "score": 174,
      "reward": -916.0,
      "steps": 53,
      "mean_loss": 3437.665675181263,
      "epsilon": 0.4740160000006952
    },
    {
      "episode": 455,
      "score": 166,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 5078.907853070427,
      "epsilon": 0.4739650000006966
    },
    {
      "episode": 456,
      "score": 147,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 3694.978038787842,
      "epsilon": 0.47391800000069784
    },
    {
      "episode": 457,
      "score": 139,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 2753.0786330040464,
      "epsilon": 0.4738710000006991
    },
    {
      "episode": 458,
      "score": 189,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 4982.779073319345,
      "epsilon": 0.4738180000007005
    },
    {
      "episode": 459,
      "score": 55,
      "reward": -985.0,
      "steps": 28,
      "mean_loss": 3376.8941078186035,
      "epsilon": 0.47379000000070126
    },
    {
      "episode": 460,
      "score": 173,
      "reward": -908.0,
      "steps": 54,
      "mean_loss": 3897.8491338094077,
      "epsilon": 0.4737360000007027
    },
    {
      "episode": 461,
      "score": 142,
      "reward": -928.0,
      "steps": 45,
      "mean_loss": 2752.809972805447,
      "epsilon": 0.4736910000007039
    },
    {
      "episode": 462,
      "score": 141,
      "reward": -921.0,
      "steps": 40,
      "mean_loss": 2564.073578262329,
      "epsilon": 0.473651000000705
    },
    {
      "episode": 463,
      "score": 130,
      "reward": -927.0,
      "steps": 41,
      "mean_loss": 1681.5264980037039,
      "epsilon": 0.4736100000007061
    },
    {
      "episode": 464,
      "score": 119,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 3767.6946664289994,
      "epsilon": 0.47356600000070725
    },
    {
      "episode": 465,
      "score": 116,
      "reward": -964.0,
      "steps": 45,
      "mean_loss": 5370.7815282185875,
      "epsilon": 0.47352100000070846
    },
    {
      "episode": 466,
      "score": 176,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 4465.846698320829,
      "epsilon": 0.47346900000070985
    },
    {
      "episode": 467,
      "score": 106,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 5242.586110548539,
      "epsilon": 0.473425000000711
    },
    {
      "episode": 468,
      "score": 102,
      "reward": -967.0,
      "steps": 38,
      "mean_loss": 3012.3101676137826,
      "epsilon": 0.47338700000071204
    },
    {
      "episode": 469,
      "score": 260,
      "reward": -853.0,
      "steps": 68,
      "mean_loss": 3199.6140722386976,
      "epsilon": 0.47331900000071386
    },
    {
      "episode": 470,
      "score": 111,
      "reward": -958.0,
      "steps": 42,
      "mean_loss": 3594.6323305765786,
      "epsilon": 0.473277000000715
    },
    {
      "episode": 471,
      "score": 270,
      "reward": -818.0,
      "steps": 66,
      "mean_loss": 3131.6006334478207,
      "epsilon": 0.47321100000071675
    },
    {
      "episode": 472,
      "score": 111,
      "reward": -963.0,
      "steps": 41,
      "mean_loss": 2307.956001467821,
      "epsilon": 0.47317000000071785
    },
    {
      "episode": 473,
      "score": 175,
      "reward": -905.0,
      "steps": 51,
      "mean_loss": 2920.624307557648,
      "epsilon": 0.4731190000007192
    },
    {
      "episode": 474,
      "score": 183,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 3894.873022079468,
      "epsilon": 0.4730670000007206
    },
    {
      "episode": 475,
      "score": 115,
      "reward": -972.0,
      "steps": 45,
      "mean_loss": 4127.427431572808,
      "epsilon": 0.4730220000007218
    },
    {
      "episode": 476,
      "score": 168,
      "reward": -914.0,
      "steps": 52,
      "mean_loss": 2871.2255080296445,
      "epsilon": 0.4729700000007232
    },
    {
      "episode": 477,
      "score": 153,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 5787.936850865682,
      "epsilon": 0.4729220000007245
    },
    {
      "episode": 478,
      "score": 99,
      "reward": -975.0,
      "steps": 41,
      "mean_loss": 7268.608566656345,
      "epsilon": 0.4728810000007256
    },
    {
      "episode": 479,
      "score": 99,
      "reward": -965.0,
      "steps": 40,
      "mean_loss": 5698.237042999268,
      "epsilon": 0.47284100000072665
    },
    {
      "episode": 480,
      "score": 69,
      "reward": -985.0,
      "steps": 34,
      "mean_loss": 2441.062745262595,
      "epsilon": 0.47280700000072756
    },
    {
      "episode": 481,
      "score": 120,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 2451.7943146445537,
      "epsilon": 0.47276300000072874
    },
    {
      "episode": 482,
      "score": 167,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 3119.64320602417,
      "epsilon": 0.4727130000007301
    },
    {
      "episode": 483,
      "score": 143,
      "reward": -939.0,
      "steps": 43,
      "mean_loss": 2554.90904945551,
      "epsilon": 0.4726700000007312
    },
    {
      "episode": 484,
      "score": 149,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 3818.6125894663287,
      "epsilon": 0.47262100000073254
    },
    {
      "episode": 485,
      "score": 139,
      "reward": -913.0,
      "steps": 40,
      "mean_loss": 2093.049633026123,
      "epsilon": 0.4725810000007336
    },
    {
      "episode": 486,
      "score": 185,
      "reward": -885.0,
      "steps": 53,
      "mean_loss": 1628.639689895342,
      "epsilon": 0.472528000000735
    },
    {
      "episode": 487,
      "score": 147,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 3058.725658961705,
      "epsilon": 0.47247900000073634
    },
    {
      "episode": 488,
      "score": 125,
      "reward": -950.0,
      "steps": 46,
      "mean_loss": 3563.4870240584664,
      "epsilon": 0.47243300000073757
    },
    {
      "episode": 489,
      "score": 185,
      "reward": -898.0,
      "steps": 51,
      "mean_loss": 3911.814360824286,
      "epsilon": 0.47238200000073893
    },
    {
      "episode": 490,
      "score": 167,
      "reward": -893.0,
      "steps": 49,
      "mean_loss": 3248.450311154735,
      "epsilon": 0.47233300000074024
    },
    {
      "episode": 491,
      "score": 97,
      "reward": -959.0,
      "steps": 38,
      "mean_loss": 4046.313947978773,
      "epsilon": 0.47229500000074126
    },
    {
      "episode": 492,
      "score": 107,
      "reward": -964.0,
      "steps": 43,
      "mean_loss": 1242.501802488815,
      "epsilon": 0.4722520000007424
    },
    {
      "episode": 493,
      "score": 123,
      "reward": -949.0,
      "steps": 43,
      "mean_loss": 2554.789203377657,
      "epsilon": 0.47220900000074356
    },
    {
      "episode": 494,
      "score": 109,
      "reward": -961.0,
      "steps": 41,
      "mean_loss": 3706.443226884051,
      "epsilon": 0.47216800000074466
    },
    {
      "episode": 495,
      "score": 169,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 2986.0833674210767,
      "epsilon": 0.47211600000074605
    },
    {
      "episode": 496,
      "score": 131,
      "reward": -924.0,
      "steps": 39,
      "mean_loss": 3675.6924154819585,
      "epsilon": 0.4720770000007471
    },
    {
      "episode": 497,
      "score": 119,
      "reward": -956.0,
      "steps": 42,
      "mean_loss": 6795.565151032947,
      "epsilon": 0.4720350000007482
    },
    {
      "episode": 498,
      "score": 68,
      "reward": -995.0,
      "steps": 34,
      "mean_loss": 4031.7320588055777,
      "epsilon": 0.4720010000007491
    },
    {
      "episode": 499,
      "score": 87,
      "reward": -978.0,
      "steps": 38,
      "mean_loss": 3990.6542559171976,
      "epsilon": 0.47196300000075014
    },
    {
      "episode": 500,
      "score": 202,
      "reward": -894.0,
      "steps": 56,
      "mean_loss": 3880.6421665464127,
      "epsilon": 0.47190700000075164
    },
    {
      "episode": 501,
      "score": 122,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 4924.706461927626,
      "epsilon": 0.47186200000075285
    },
    {
      "episode": 502,
      "score": 131,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 2700.313223361969,
      "epsilon": 0.47181400000075413
    },
    {
      "episode": 503,
      "score": 166,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 1886.1070351114079,
      "epsilon": 0.47176500000075544
    },
    {
      "episode": 504,
      "score": 116,
      "reward": -946.0,
      "steps": 43,
      "mean_loss": 3821.0233338821768,
      "epsilon": 0.4717220000007566
    },
    {
      "episode": 505,
      "score": 148,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 3041.701413154602,
      "epsilon": 0.4716740000007579
    },
    {
      "episode": 506,
      "score": 164,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3424.2833895874023,
      "epsilon": 0.4716240000007592
    },
    {
      "episode": 507,
      "score": 170,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 5773.786775817871,
      "epsilon": 0.47157400000076055
    },
    {
      "episode": 508,
      "score": 151,
      "reward": -934.0,
      "steps": 49,
      "mean_loss": 3801.326639603595,
      "epsilon": 0.47152500000076186
    },
    {
      "episode": 509,
      "score": 182,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 4183.547629089356,
      "epsilon": 0.4714750000007632
    },
    {
      "episode": 510,
      "score": 89,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 2525.2173777399835,
      "epsilon": 0.4714380000007642
    },
    {
      "episode": 511,
      "score": 91,
      "reward": -967.0,
      "steps": 41,
      "mean_loss": 3473.7681910817214,
      "epsilon": 0.4713970000007653
    },
    {
      "episode": 512,
      "score": 168,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 4325.168649380023,
      "epsilon": 0.4713450000007667
    },
    {
      "episode": 513,
      "score": 183,
      "reward": -880.0,
      "steps": 52,
      "mean_loss": 3664.569081086379,
      "epsilon": 0.47129300000076807
    },
    {
      "episode": 514,
      "score": 124,
      "reward": -947.0,
      "steps": 46,
      "mean_loss": 4353.957483042841,
      "epsilon": 0.4712470000007693
    },
    {
      "episode": 515,
      "score": 114,
      "reward": -931.0,
      "steps": 40,
      "mean_loss": 3615.480922317505,
      "epsilon": 0.47120700000077037
    },
    {
      "episode": 516,
      "score": 168,
      "reward": -899.0,
      "steps": 50,
      "mean_loss": 2859.777465362549,
      "epsilon": 0.4711570000007717
    },
    {
      "episode": 517,
      "score": 142,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 4385.152664915045,
      "epsilon": 0.47111000000077297
    },
    {
      "episode": 518,
      "score": 141,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 2731.1461008389792,
      "epsilon": 0.47106200000077425
    },
    {
      "episode": 519,
      "score": 81,
      "reward": -986.0,
      "steps": 38,
      "mean_loss": 3079.4958122654966,
      "epsilon": 0.47102400000077527
    },
    {
      "episode": 520,
      "score": 246,
      "reward": -854.0,
      "steps": 61,
      "mean_loss": 3357.839039161557,
      "epsilon": 0.4709630000007769
    },
    {
      "episode": 521,
      "score": 100,
      "reward": -967.0,
      "steps": 41,
      "mean_loss": 2247.7551258366284,
      "epsilon": 0.470922000000778
    },
    {
      "episode": 522,
      "score": 126,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 1047.661855618159,
      "epsilon": 0.4708740000007793
    },
    {
      "episode": 523,
      "score": 153,
      "reward": -910.0,
      "steps": 46,
      "mean_loss": 3498.612116938052,
      "epsilon": 0.4708280000007805
    },
    {
      "episode": 524,
      "score": 156,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 3912.441791145169,
      "epsilon": 0.4707790000007818
    },
    {
      "episode": 525,
      "score": 117,
      "reward": -945.0,
      "steps": 37,
      "mean_loss": 3183.3308891090187,
      "epsilon": 0.4707420000007828
    },
    {
      "episode": 526,
      "score": 158,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 6836.756540501371,
      "epsilon": 0.47069500000078407
    },
    {
      "episode": 527,
      "score": 89,
      "reward": -977.0,
      "steps": 41,
      "mean_loss": 3835.075109528332,
      "epsilon": 0.47065400000078517
    },
    {
      "episode": 528,
      "score": 92,
      "reward": -988.0,
      "steps": 40,
      "mean_loss": 5764.311950302124,
      "epsilon": 0.47061400000078624
    },
    {
      "episode": 529,
      "score": 243,
      "reward": -847.0,
      "steps": 60,
      "mean_loss": 4169.928806050619,
      "epsilon": 0.47055400000078784
    },
    {
      "episode": 530,
      "score": 111,
      "reward": -952.0,
      "steps": 41,
      "mean_loss": 2702.216411497535,
      "epsilon": 0.47051300000078894
    },
    {
      "episode": 531,
      "score": 120,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 4318.09101768162,
      "epsilon": 0.47046700000079017
    },
    {
      "episode": 532,
      "score": 257,
      "reward": -851.0,
      "steps": 62,
      "mean_loss": 2888.1399481988724,
      "epsilon": 0.47040500000079183
    },
    {
      "episode": 533,
      "score": 238,
      "reward": -866.0,
      "steps": 62,
      "mean_loss": 2467.3228432439987,
      "epsilon": 0.4703430000007935
    },
    {
      "episode": 534,
      "score": 126,
      "reward": -952.0,
      "steps": 47,
      "mean_loss": 3672.7046263674474,
      "epsilon": 0.47029600000079474
    },
    {
      "episode": 535,
      "score": 216,
      "reward": -872.0,
      "steps": 55,
      "mean_loss": 6030.75626151345,
      "epsilon": 0.4702410000007962
    },
    {
      "episode": 536,
      "score": 100,
      "reward": -973.0,
      "steps": 40,
      "mean_loss": 6375.218063354492,
      "epsilon": 0.4702010000007973
    },
    {
      "episode": 537,
      "score": 170,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 3372.417154083252,
      "epsilon": 0.4701510000007986
    },
    {
      "episode": 538,
      "score": 83,
      "reward": -977.0,
      "steps": 36,
      "mean_loss": 5471.981352700128,
      "epsilon": 0.4701150000007996
    },
    {
      "episode": 539,
      "score": 156,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 7637.332081397374,
      "epsilon": 0.47006700000080087
    },
    {
      "episode": 540,
      "score": 205,
      "reward": -884.0,
      "steps": 56,
      "mean_loss": 4212.696243149893,
      "epsilon": 0.47001100000080237
    },
    {
      "episode": 541,
      "score": 59,
      "reward": -983.0,
      "steps": 29,
      "mean_loss": 3400.4667108469994,
      "epsilon": 0.46998200000080315
    },
    {
      "episode": 542,
      "score": 188,
      "reward": -903.0,
      "steps": 54,
      "mean_loss": 2556.9911172654893,
      "epsilon": 0.4699280000008046
    },
    {
      "episode": 543,
      "score": 201,
      "reward": -888.0,
      "steps": 56,
      "mean_loss": 2655.2702655792236,
      "epsilon": 0.4698720000008061
    },
    {
      "episode": 544,
      "score": 108,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 3483.9316531590052,
      "epsilon": 0.4698300000008072
    },
    {
      "episode": 545,
      "score": 142,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 5055.582286337148,
      "epsilon": 0.46978400000080844
    },
    {
      "episode": 546,
      "score": 137,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 4382.355739593506,
      "epsilon": 0.4697380000008097
    },
    {
      "episode": 547,
      "score": 135,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 2290.6091771227248,
      "epsilon": 0.46969100000081093
    },
    {
      "episode": 548,
      "score": 214,
      "reward": -872.0,
      "steps": 56,
      "mean_loss": 3443.9473420551844,
      "epsilon": 0.46963500000081243
    },
    {
      "episode": 549,
      "score": 120,
      "reward": -949.0,
      "steps": 43,
      "mean_loss": 2852.159116700638,
      "epsilon": 0.4695920000008136
    },
    {
      "episode": 550,
      "score": 172,
      "reward": -898.0,
      "steps": 48,
      "mean_loss": 4899.275334199269,
      "epsilon": 0.46954400000081487
    },
    {
      "episode": 551,
      "score": 138,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 4522.314517801458,
      "epsilon": 0.46950000000081604
    },
    {
      "episode": 552,
      "score": 95,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 5243.982660448229,
      "epsilon": 0.46946300000081703
    },
    {
      "episode": 553,
      "score": 133,
      "reward": -949.0,
      "steps": 46,
      "mean_loss": 4067.9906960362973,
      "epsilon": 0.46941700000081826
    },
    {
      "episode": 554,
      "score": 135,
      "reward": -919.0,
      "steps": 44,
      "mean_loss": 2182.604264866222,
      "epsilon": 0.46937300000081944
    },
    {
      "episode": 555,
      "score": 109,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 2102.053766704741,
      "epsilon": 0.46933100000082056
    },
    {
      "episode": 556,
      "score": 137,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 3078.1923958322277,
      "epsilon": 0.4692850000008218
    },
    {
      "episode": 557,
      "score": 129,
      "reward": -954.0,
      "steps": 49,
      "mean_loss": 2346.424620492118,
      "epsilon": 0.4692360000008231
    },
    {
      "episode": 558,
      "score": 99,
      "reward": -954.0,
      "steps": 34,
      "mean_loss": 5362.077675090117,
      "epsilon": 0.469202000000824
    },
    {
      "episode": 559,
      "score": 103,
      "reward": -971.0,
      "steps": 44,
      "mean_loss": 3839.7491723840885,
      "epsilon": 0.4691580000008252
    },
    {
      "episode": 560,
      "score": 140,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 4773.661766529083,
      "epsilon": 0.4691100000008265
    },
    {
      "episode": 561,
      "score": 114,
      "reward": -964.0,
      "steps": 45,
      "mean_loss": 5685.120152791341,
      "epsilon": 0.4690650000008277
    },
    {
      "episode": 562,
      "score": 149,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 4749.476111554085,
      "epsilon": 0.46901800000082894
    },
    {
      "episode": 563,
      "score": 109,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 2855.8239822387695,
      "epsilon": 0.46897700000083004
    },
    {
      "episode": 564,
      "score": 181,
      "reward": -904.0,
      "steps": 51,
      "mean_loss": 2614.8068403356215,
      "epsilon": 0.4689260000008314
    },
    {
      "episode": 565,
      "score": 268,
      "reward": -858.0,
      "steps": 64,
      "mean_loss": 4689.713142871857,
      "epsilon": 0.4688620000008331
    },
    {
      "episode": 566,
      "score": 156,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 4358.949917851663,
      "epsilon": 0.4688130000008344
    },
    {
      "episode": 567,
      "score": 177,
      "reward": -884.0,
      "steps": 51,
      "mean_loss": 4770.846889570647,
      "epsilon": 0.4687620000008358
    },
    {
      "episode": 568,
      "score": 224,
      "reward": -871.0,
      "steps": 58,
      "mean_loss": 3671.0373251027077,
      "epsilon": 0.46870400000083734
    },
    {
      "episode": 569,
      "score": 95,
      "reward": -982.0,
      "steps": 44,
      "mean_loss": 1812.945348219438,
      "epsilon": 0.4686600000008385
    },
    {
      "episode": 570,
      "score": 199,
      "reward": -880.0,
      "steps": 54,
      "mean_loss": 3239.742027000145,
      "epsilon": 0.46860600000083996
    },
    {
      "episode": 571,
      "score": 152,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 6212.578372039795,
      "epsilon": 0.4685560000008413
    },
    {
      "episode": 572,
      "score": 195,
      "reward": -888.0,
      "steps": 53,
      "mean_loss": 3755.255966618376,
      "epsilon": 0.4685030000008427
    },
    {
      "episode": 573,
      "score": 163,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 3607.9762928771975,
      "epsilon": 0.46845300000084406
    },
    {
      "episode": 574,
      "score": 52,
      "reward": -1008.0,
      "steps": 31,
      "mean_loss": 6457.36424304593,
      "epsilon": 0.4684220000008449
    },
    {
      "episode": 575,
      "score": 171,
      "reward": -909.0,
      "steps": 52,
      "mean_loss": 6906.793197044959,
      "epsilon": 0.4683700000008463
    },
    {
      "episode": 576,
      "score": 158,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 5330.897702331543,
      "epsilon": 0.4683200000008476
    },
    {
      "episode": 577,
      "score": 172,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3501.153606719971,
      "epsilon": 0.46827000000084895
    },
    {
      "episode": 578,
      "score": 151,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 4481.74982405682,
      "epsilon": 0.46822100000085026
    },
    {
      "episode": 579,
      "score": 228,
      "reward": -863.0,
      "steps": 56,
      "mean_loss": 5289.617697170803,
      "epsilon": 0.46816500000085176
    },
    {
      "episode": 580,
      "score": 238,
      "reward": -863.0,
      "steps": 61,
      "mean_loss": 3266.883656861352,
      "epsilon": 0.4681040000008534
    },
    {
      "episode": 581,
      "score": 115,
      "reward": -948.0,
      "steps": 43,
      "mean_loss": 4336.113538342853,
      "epsilon": 0.46806100000085454
    },
    {
      "episode": 582,
      "score": 233,
      "reward": -866.0,
      "steps": 58,
      "mean_loss": 5129.441094891778,
      "epsilon": 0.4680030000008561
    },
    {
      "episode": 583,
      "score": 175,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 4297.545091775747,
      "epsilon": 0.4679510000008575
    },
    {
      "episode": 584,
      "score": 135,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 2614.2883536156187,
      "epsilon": 0.46790400000085874
    },
    {
      "episode": 585,
      "score": 129,
      "reward": -946.0,
      "steps": 48,
      "mean_loss": 4092.139420350393,
      "epsilon": 0.46785600000086003
    },
    {
      "episode": 586,
      "score": 77,
      "reward": -985.0,
      "steps": 35,
      "mean_loss": 4146.881790597098,
      "epsilon": 0.46782100000086096
    },
    {
      "episode": 587,
      "score": 150,
      "reward": -912.0,
      "steps": 45,
      "mean_loss": 3837.792443169488,
      "epsilon": 0.46777600000086217
    },
    {
      "episode": 588,
      "score": 168,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 2477.306390075684,
      "epsilon": 0.4677260000008635
    },
    {
      "episode": 589,
      "score": 186,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 1838.31898244222,
      "epsilon": 0.46767200000086495
    },
    {
      "episode": 590,
      "score": 187,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 3406.1058175428857,
      "epsilon": 0.46761900000086637
    },
    {
      "episode": 591,
      "score": 227,
      "reward": -872.0,
      "steps": 56,
      "mean_loss": 2574.3625802993774,
      "epsilon": 0.46756300000086787
    },
    {
      "episode": 592,
      "score": 238,
      "reward": -868.0,
      "steps": 62,
      "mean_loss": 3487.384705943446,
      "epsilon": 0.4675010000008695
    },
    {
      "episode": 593,
      "score": 113,
      "reward": -971.0,
      "steps": 46,
      "mean_loss": 2552.319337596064,
      "epsilon": 0.46745500000087076
    },
    {
      "episode": 594,
      "score": 165,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 4553.375540618897,
      "epsilon": 0.4674050000008721
    },
    {
      "episode": 595,
      "score": 173,
      "reward": -890.0,
      "steps": 48,
      "mean_loss": 6305.2195561726885,
      "epsilon": 0.4673570000008734
    },
    {
      "episode": 596,
      "score": 72,
      "reward": -987.0,
      "steps": 33,
      "mean_loss": 3973.0081500429096,
      "epsilon": 0.46732400000087426
    },
    {
      "episode": 597,
      "score": 199,
      "reward": -884.0,
      "steps": 51,
      "mean_loss": 3597.9017497791965,
      "epsilon": 0.4672730000008756
    },
    {
      "episode": 598,
      "score": 103,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 3087.720303622159,
      "epsilon": 0.4672290000008768
    },
    {
      "episode": 599,
      "score": 135,
      "reward": -963.0,
      "steps": 46,
      "mean_loss": 2807.5373349397078,
      "epsilon": 0.46718300000087803
    },
    {
      "episode": 600,
      "score": 160,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 5016.619061372718,
      "epsilon": 0.46713400000087935
    },
    {
      "episode": 601,
      "score": 137,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 6858.5553263346355,
      "epsilon": 0.46708900000088055
    },
    {
      "episode": 602,
      "score": 146,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 4889.239704365633,
      "epsilon": 0.46704000000088186
    },
    {
      "episode": 603,
      "score": 160,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 3512.4446609203633,
      "epsilon": 0.46698800000088325
    },
    {
      "episode": 604,
      "score": 162,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 3485.2446374159595,
      "epsilon": 0.46693600000088464
    },
    {
      "episode": 605,
      "score": 56,
      "reward": -1009.0,
      "steps": 35,
      "mean_loss": 2400.2852739606583,
      "epsilon": 0.4669010000008856
    },
    {
      "episode": 606,
      "score": 159,
      "reward": -912.0,
      "steps": 44,
      "mean_loss": 4138.083916750821,
      "epsilon": 0.46685700000088676
    },
    {
      "episode": 607,
      "score": 160,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 4415.979048437001,
      "epsilon": 0.46680800000088807
    },
    {
      "episode": 608,
      "score": 117,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 2739.4793535579333,
      "epsilon": 0.46676400000088925
    },
    {
      "episode": 609,
      "score": 152,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 3861.604459645797,
      "epsilon": 0.46671500000089056
    },
    {
      "episode": 610,
      "score": 177,
      "reward": -893.0,
      "steps": 52,
      "mean_loss": 3247.5720826662505,
      "epsilon": 0.46666300000089195
    },
    {
      "episode": 611,
      "score": 113,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 4186.093757915497,
      "epsilon": 0.466623000000893
    },
    {
      "episode": 612,
      "score": 162,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 2913.7652018021563,
      "epsilon": 0.46657400000089433
    },
    {
      "episode": 613,
      "score": 87,
      "reward": -987.0,
      "steps": 40,
      "mean_loss": 2082.1454034805297,
      "epsilon": 0.4665340000008954
    },
    {
      "episode": 614,
      "score": 144,
      "reward": -918.0,
      "steps": 43,
      "mean_loss": 3260.890334373297,
      "epsilon": 0.46649100000089655
    },
    {
      "episode": 615,
      "score": 121,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 4214.803764516657,
      "epsilon": 0.4664470000008977
    },
    {
      "episode": 616,
      "score": 152,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 2818.3883583068846,
      "epsilon": 0.46640200000089893
    },
    {
      "episode": 617,
      "score": 177,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 5538.427640231151,
      "epsilon": 0.46634900000090035
    },
    {
      "episode": 618,
      "score": 141,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 2379.0179349650507,
      "epsilon": 0.4663030000009016
    },
    {
      "episode": 619,
      "score": 256,
      "reward": -842.0,
      "steps": 62,
      "mean_loss": 3834.6715779458323,
      "epsilon": 0.46624100000090324
    },
    {
      "episode": 620,
      "score": 82,
      "reward": -983.0,
      "steps": 37,
      "mean_loss": 3865.878420443148,
      "epsilon": 0.46620400000090423
    },
    {
      "episode": 621,
      "score": 165,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 3858.61521427448,
      "epsilon": 0.4661520000009056
    },
    {
      "episode": 622,
      "score": 88,
      "reward": -977.0,
      "steps": 37,
      "mean_loss": 2831.662476307637,
      "epsilon": 0.4661150000009066
    },
    {
      "episode": 623,
      "score": 132,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 3456.0798868815104,
      "epsilon": 0.4660700000009078
    },
    {
      "episode": 624,
      "score": 119,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 3845.4777701984754,
      "epsilon": 0.466026000000909
    },
    {
      "episode": 625,
      "score": 191,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4030.060947276928,
      "epsilon": 0.46597200000091044
    },
    {
      "episode": 626,
      "score": 153,
      "reward": -964.0,
      "steps": 46,
      "mean_loss": 2649.0197965373163,
      "epsilon": 0.46592600000091167
    },
    {
      "episode": 627,
      "score": 242,
      "reward": -847.0,
      "steps": 61,
      "mean_loss": 4485.409882842518,
      "epsilon": 0.4658650000009133
    },
    {
      "episode": 628,
      "score": 107,
      "reward": -947.0,
      "steps": 36,
      "mean_loss": 3495.4704869588218,
      "epsilon": 0.46582900000091426
    },
    {
      "episode": 629,
      "score": 103,
      "reward": -974.0,
      "steps": 41,
      "mean_loss": 2338.0495335648698,
      "epsilon": 0.46578800000091536
    },
    {
      "episode": 630,
      "score": 170,
      "reward": -912.0,
      "steps": 48,
      "mean_loss": 4431.408344745636,
      "epsilon": 0.46574000000091664
    },
    {
      "episode": 631,
      "score": 145,
      "reward": -936.0,
      "steps": 49,
      "mean_loss": 5127.805951799665,
      "epsilon": 0.46569100000091795
    },
    {
      "episode": 632,
      "score": 156,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 2710.180164794922,
      "epsilon": 0.4656410000009193
    },
    {
      "episode": 633,
      "score": 180,
      "reward": -892.0,
      "steps": 51,
      "mean_loss": 4806.6294177186255,
      "epsilon": 0.46559000000092066
    },
    {
      "episode": 634,
      "score": 142,
      "reward": -935.0,
      "steps": 41,
      "mean_loss": 4196.991017411395,
      "epsilon": 0.46554900000092175
    },
    {
      "episode": 635,
      "score": 252,
      "reward": -866.0,
      "steps": 66,
      "mean_loss": 5542.595586950129,
      "epsilon": 0.4654830000009235
    },
    {
      "episode": 636,
      "score": 118,
      "reward": -965.0,
      "steps": 45,
      "mean_loss": 4328.535358768039,
      "epsilon": 0.4654380000009247
    },
    {
      "episode": 637,
      "score": 101,
      "reward": -956.0,
      "steps": 36,
      "mean_loss": 3133.148279401991,
      "epsilon": 0.4654020000009257
    },
    {
      "episode": 638,
      "score": 168,
      "reward": -912.0,
      "steps": 50,
      "mean_loss": 3572.11146484375,
      "epsilon": 0.465352000000927
    },
    {
      "episode": 639,
      "score": 210,
      "reward": -864.0,
      "steps": 56,
      "mean_loss": 4833.778649057661,
      "epsilon": 0.4652960000009285
    },
    {
      "episode": 640,
      "score": 104,
      "reward": -966.0,
      "steps": 39,
      "mean_loss": 3044.8584667108,
      "epsilon": 0.46525700000092957
    },
    {
      "episode": 641,
      "score": 153,
      "reward": -933.0,
      "steps": 48,
      "mean_loss": 2135.0324540138245,
      "epsilon": 0.46520900000093085
    },
    {
      "episode": 642,
      "score": 112,
      "reward": -962.0,
      "steps": 40,
      "mean_loss": 4618.67313156128,
      "epsilon": 0.4651690000009319
    },
    {
      "episode": 643,
      "score": 142,
      "reward": -914.0,
      "steps": 46,
      "mean_loss": 7091.538312497346,
      "epsilon": 0.46512300000093315
    },
    {
      "episode": 644,
      "score": 143,
      "reward": -922.0,
      "steps": 44,
      "mean_loss": 6307.693102403121,
      "epsilon": 0.46507900000093433
    },
    {
      "episode": 645,
      "score": 113,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 6957.213718934493,
      "epsilon": 0.4650350000009355
    },
    {
      "episode": 646,
      "score": 82,
      "reward": -965.0,
      "steps": 33,
      "mean_loss": 3066.7235199899383,
      "epsilon": 0.4650020000009364
    },
    {
      "episode": 647,
      "score": 176,
      "reward": -884.0,
      "steps": 49,
      "mean_loss": 1887.5151552472796,
      "epsilon": 0.4649530000009377
    },
    {
      "episode": 648,
      "score": 99,
      "reward": -972.0,
      "steps": 43,
      "mean_loss": 6491.8544762189995,
      "epsilon": 0.46491000000093885
    },
    {
      "episode": 649,
      "score": 241,
      "reward": -848.0,
      "steps": 61,
      "mean_loss": 5581.937936126209,
      "epsilon": 0.4648490000009405
    },
    {
      "episode": 650,
      "score": 166,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 1862.46407913208,
      "epsilon": 0.4647990000009418
    },
    {
      "episode": 651,
      "score": 152,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 2281.936627149582,
      "epsilon": 0.4647510000009431
    },
    {
      "episode": 652,
      "score": 106,
      "reward": -948.0,
      "steps": 35,
      "mean_loss": 3759.9807830810546,
      "epsilon": 0.46471600000094404
    },
    {
      "episode": 653,
      "score": 254,
      "reward": -879.0,
      "steps": 66,
      "mean_loss": 2966.6542625427246,
      "epsilon": 0.4646500000009458
    },
    {
      "episode": 654,
      "score": 180,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4321.436947857892,
      "epsilon": 0.46459600000094725
    },
    {
      "episode": 655,
      "score": 102,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 4170.33459594033,
      "epsilon": 0.46455200000094843
    },
    {
      "episode": 656,
      "score": 165,
      "reward": -903.0,
      "steps": 48,
      "mean_loss": 3478.3383251825967,
      "epsilon": 0.4645040000009497
    },
    {
      "episode": 657,
      "score": 144,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3938.3636520872724,
      "epsilon": 0.46445700000095097
    },
    {
      "episode": 658,
      "score": 104,
      "reward": -975.0,
      "steps": 46,
      "mean_loss": 2555.720927114072,
      "epsilon": 0.4644110000009522
    },
    {
      "episode": 659,
      "score": 157,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 4236.932457129161,
      "epsilon": 0.4643630000009535
    },
    {
      "episode": 660,
      "score": 133,
      "reward": -952.0,
      "steps": 48,
      "mean_loss": 4368.426104942958,
      "epsilon": 0.46431500000095477
    },
    {
      "episode": 661,
      "score": 109,
      "reward": -942.0,
      "steps": 37,
      "mean_loss": 4790.382660943109,
      "epsilon": 0.46427800000095576
    },
    {
      "episode": 662,
      "score": 241,
      "reward": -853.0,
      "steps": 61,
      "mean_loss": 3848.7146394760885,
      "epsilon": 0.4642170000009574
    },
    {
      "episode": 663,
      "score": 70,
      "reward": -999.0,
      "steps": 38,
      "mean_loss": 5789.716201581453,
      "epsilon": 0.4641790000009584
    },
    {
      "episode": 664,
      "score": 129,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 3114.108734960141,
      "epsilon": 0.46413300000095964
    },
    {
      "episode": 665,
      "score": 118,
      "reward": -950.0,
      "steps": 46,
      "mean_loss": 5225.394770746646,
      "epsilon": 0.46408700000096087
    },
    {
      "episode": 666,
      "score": 113,
      "reward": -959.0,
      "steps": 41,
      "mean_loss": 5090.53551799495,
      "epsilon": 0.46404600000096197
    },
    {
      "episode": 667,
      "score": 110,
      "reward": -958.0,
      "steps": 41,
      "mean_loss": 3975.9240313274104,
      "epsilon": 0.46400500000096306
    },
    {
      "episode": 668,
      "score": 88,
      "reward": -967.0,
      "steps": 35,
      "mean_loss": 4548.621745736258,
      "epsilon": 0.463970000000964
    },
    {
      "episode": 669,
      "score": 87,
      "reward": -964.0,
      "steps": 35,
      "mean_loss": 4296.93993900844,
      "epsilon": 0.46393500000096494
    },
    {
      "episode": 670,
      "score": 131,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 2425.3564697612414,
      "epsilon": 0.4638910000009661
    },
    {
      "episode": 671,
      "score": 211,
      "reward": -869.0,
      "steps": 54,
      "mean_loss": 4873.130736456977,
      "epsilon": 0.46383700000096756
    },
    {
      "episode": 672,
      "score": 128,
      "reward": -951.0,
      "steps": 49,
      "mean_loss": 3521.2236802237376,
      "epsilon": 0.46378800000096887
    },
    {
      "episode": 673,
      "score": 93,
      "reward": -957.0,
      "steps": 34,
      "mean_loss": 6388.640593136058,
      "epsilon": 0.4637540000009698
    },
    {
      "episode": 674,
      "score": 122,
      "reward": -961.0,
      "steps": 47,
      "mean_loss": 2601.5733142609292,
      "epsilon": 0.46370700000097104
    },
    {
      "episode": 675,
      "score": 138,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 5796.25861193917,
      "epsilon": 0.4636630000009722
    },
    {
      "episode": 676,
      "score": 158,
      "reward": -904.0,
      "steps": 48,
      "mean_loss": 3838.1951710383096,
      "epsilon": 0.4636150000009735
    },
    {
      "episode": 677,
      "score": 116,
      "reward": -965.0,
      "steps": 43,
      "mean_loss": 3773.612382400868,
      "epsilon": 0.46357200000097465
    },
    {
      "episode": 678,
      "score": 135,
      "reward": -927.0,
      "steps": 44,
      "mean_loss": 5556.9462942643595,
      "epsilon": 0.4635280000009758
    },
    {
      "episode": 679,
      "score": 186,
      "reward": -910.0,
      "steps": 54,
      "mean_loss": 5425.415614092792,
      "epsilon": 0.46347400000097727
    },
    {
      "episode": 680,
      "score": 139,
      "reward": -939.0,
      "steps": 49,
      "mean_loss": 4248.683161832849,
      "epsilon": 0.4634250000009786
    },
    {
      "episode": 681,
      "score": 211,
      "reward": -881.0,
      "steps": 60,
      "mean_loss": 4677.404492441813,
      "epsilon": 0.4633650000009802
    },
    {
      "episode": 682,
      "score": 114,
      "reward": -967.0,
      "steps": 46,
      "mean_loss": 3769.481108126433,
      "epsilon": 0.4633190000009814
    },
    {
      "episode": 683,
      "score": 146,
      "reward": -935.0,
      "steps": 47,
      "mean_loss": 3399.3530447127973,
      "epsilon": 0.4632720000009827
    },
    {
      "episode": 684,
      "score": 186,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 3237.465566781851,
      "epsilon": 0.46322000000098407
    },
    {
      "episode": 685,
      "score": 89,
      "reward": -964.0,
      "steps": 34,
      "mean_loss": 5834.5758325913375,
      "epsilon": 0.463186000000985
    },
    {
      "episode": 686,
      "score": 178,
      "reward": -895.0,
      "steps": 52,
      "mean_loss": 4259.102026499235,
      "epsilon": 0.46313400000098637
    },
    {
      "episode": 687,
      "score": 215,
      "reward": -879.0,
      "steps": 54,
      "mean_loss": 5227.729064941406,
      "epsilon": 0.4630800000009878
    },
    {
      "episode": 688,
      "score": 142,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 1898.0063764254253,
      "epsilon": 0.4630320000009891
    },
    {
      "episode": 689,
      "score": 225,
      "reward": -879.0,
      "steps": 58,
      "mean_loss": 3537.5322702342064,
      "epsilon": 0.46297400000099065
    },
    {
      "episode": 690,
      "score": 104,
      "reward": -957.0,
      "steps": 39,
      "mean_loss": 4617.259162707206,
      "epsilon": 0.4629350000009917
    },
    {
      "episode": 691,
      "score": 156,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 4357.478295167287,
      "epsilon": 0.462887000000993
    },
    {
      "episode": 692,
      "score": 164,
      "reward": -905.0,
      "steps": 47,
      "mean_loss": 3571.411870104201,
      "epsilon": 0.46284000000099423
    },
    {
      "episode": 693,
      "score": 144,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 2766.4263282938205,
      "epsilon": 0.4627930000009955
    },
    {
      "episode": 694,
      "score": 119,
      "reward": -954.0,
      "steps": 47,
      "mean_loss": 6809.081813406437,
      "epsilon": 0.46274600000099675
    },
    {
      "episode": 695,
      "score": 178,
      "reward": -901.0,
      "steps": 50,
      "mean_loss": 4419.16388671875,
      "epsilon": 0.4626960000009981
    },
    {
      "episode": 696,
      "score": 171,
      "reward": -895.0,
      "steps": 50,
      "mean_loss": 2765.5917338562012,
      "epsilon": 0.4626460000009994
    },
    {
      "episode": 697,
      "score": 197,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 4764.5116280449765,
      "epsilon": 0.46259200000100087
    },
    {
      "episode": 698,
      "score": 162,
      "reward": -897.0,
      "steps": 46,
      "mean_loss": 2697.628218692282,
      "epsilon": 0.4625460000010021
    },
    {
      "episode": 699,
      "score": 219,
      "reward": -874.0,
      "steps": 59,
      "mean_loss": 5496.201249591375,
      "epsilon": 0.4624870000010037
    },
    {
      "episode": 700,
      "score": 136,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 3108.553742842241,
      "epsilon": 0.46244300000100486
    },
    {
      "episode": 701,
      "score": 90,
      "reward": -967.0,
      "steps": 34,
      "mean_loss": 1031.0230602937586,
      "epsilon": 0.46240900000100577
    },
    {
      "episode": 702,
      "score": 152,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 2991.2039558410643,
      "epsilon": 0.4623590000010071
    },
    {
      "episode": 703,
      "score": 262,
      "reward": -833.0,
      "steps": 63,
      "mean_loss": 3740.647455427382,
      "epsilon": 0.4622960000010088
    },
    {
      "episode": 704,
      "score": 128,
      "reward": -942.0,
      "steps": 45,
      "mean_loss": 3076.6224587334527,
      "epsilon": 0.46225100000101
    },
    {
      "episode": 705,
      "score": 208,
      "reward": -898.0,
      "steps": 58,
      "mean_loss": 3405.7694690309722,
      "epsilon": 0.46219300000101154
    },
    {
      "episode": 706,
      "score": 190,
      "reward": -885.0,
      "steps": 54,
      "mean_loss": 4212.99898204097,
      "epsilon": 0.462139000001013
    },
    {
      "episode": 707,
      "score": 99,
      "reward": -961.0,
      "steps": 39,
      "mean_loss": 2598.3883946736655,
      "epsilon": 0.46210000000101403
    },
    {
      "episode": 708,
      "score": 143,
      "reward": -954.0,
      "steps": 48,
      "mean_loss": 4640.941820859909,
      "epsilon": 0.4620520000010153
    },
    {
      "episode": 709,
      "score": 149,
      "reward": -935.0,
      "steps": 49,
      "mean_loss": 4075.2187867456555,
      "epsilon": 0.46200300000101663
    },
    {
      "episode": 710,
      "score": 64,
      "reward": -987.0,
      "steps": 30,
      "mean_loss": 4026.958983103434,
      "epsilon": 0.46197300000101743
    },
    {
      "episode": 711,
      "score": 139,
      "reward": -922.0,
      "steps": 45,
      "mean_loss": 4170.772295803494,
      "epsilon": 0.46192800000101863
    },
    {
      "episode": 712,
      "score": 140,
      "reward": -912.0,
      "steps": 41,
      "mean_loss": 2223.53526883009,
      "epsilon": 0.46188700000101973
    },
    {
      "episode": 713,
      "score": 114,
      "reward": -946.0,
      "steps": 40,
      "mean_loss": 3743.9552167892457,
      "epsilon": 0.4618470000010208
    },
    {
      "episode": 714,
      "score": 137,
      "reward": -948.0,
      "steps": 49,
      "mean_loss": 3537.0099797151524,
      "epsilon": 0.4617980000010221
    },
    {
      "episode": 715,
      "score": 171,
      "reward": -910.0,
      "steps": 51,
      "mean_loss": 5669.223656448664,
      "epsilon": 0.4617470000010235
    },
    {
      "episode": 716,
      "score": 120,
      "reward": -957.0,
      "steps": 45,
      "mean_loss": 3093.972399224175,
      "epsilon": 0.4617020000010247
    },
    {
      "episode": 717,
      "score": 191,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 3846.12858795166,
      "epsilon": 0.461652000001026
    },
    {
      "episode": 718,
      "score": 157,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 3498.5186845461526,
      "epsilon": 0.4616040000010273
    },
    {
      "episode": 719,
      "score": 133,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 4725.812622748481,
      "epsilon": 0.4615590000010285
    },
    {
      "episode": 720,
      "score": 207,
      "reward": -881.0,
      "steps": 54,
      "mean_loss": 4775.38625519364,
      "epsilon": 0.46150500000102995
    },
    {
      "episode": 721,
      "score": 179,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 4652.618207103801,
      "epsilon": 0.46145200000103137
    },
    {
      "episode": 722,
      "score": 171,
      "reward": -890.0,
      "steps": 49,
      "mean_loss": 3101.2980659640566,
      "epsilon": 0.4614030000010327
    },
    {
      "episode": 723,
      "score": 169,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 4418.586109161377,
      "epsilon": 0.461354000001034
    },
    {
      "episode": 724,
      "score": 115,
      "reward": -952.0,
      "steps": 42,
      "mean_loss": 2981.6887755621046,
      "epsilon": 0.4613120000010351
    },
    {
      "episode": 725,
      "score": 125,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 4812.08910742673,
      "epsilon": 0.4612680000010363
    },
    {
      "episode": 726,
      "score": 120,
      "reward": -963.0,
      "steps": 45,
      "mean_loss": 3415.8491636488175,
      "epsilon": 0.4612230000010375
    },
    {
      "episode": 727,
      "score": 153,
      "reward": -938.0,
      "steps": 51,
      "mean_loss": 5185.703699149338,
      "epsilon": 0.46117200000103886
    },
    {
      "episode": 728,
      "score": 103,
      "reward": -964.0,
      "steps": 40,
      "mean_loss": 3784.1305042266845,
      "epsilon": 0.46113200000103993
    },
    {
      "episode": 729,
      "score": 91,
      "reward": -984.0,
      "steps": 41,
      "mean_loss": 5513.5338741395535,
      "epsilon": 0.46109100000104103
    },
    {
      "episode": 730,
      "score": 120,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 6109.930533495816,
      "epsilon": 0.4610470000010422
    },
    {
      "episode": 731,
      "score": 112,
      "reward": -944.0,
      "steps": 39,
      "mean_loss": 4097.934101789426,
      "epsilon": 0.46100800000104325
    },
    {
      "episode": 732,
      "score": 121,
      "reward": -961.0,
      "steps": 46,
      "mean_loss": 6579.624229679937,
      "epsilon": 0.4609620000010445
    },
    {
      "episode": 733,
      "score": 119,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 4510.29134126143,
      "epsilon": 0.46091800000104566
    },
    {
      "episode": 734,
      "score": 106,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 5505.551767349243,
      "epsilon": 0.46087800000104673
    },
    {
      "episode": 735,
      "score": 110,
      "reward": -947.0,
      "steps": 39,
      "mean_loss": 3089.0490061442056,
      "epsilon": 0.46083900000104777
    },
    {
      "episode": 736,
      "score": 83,
      "reward": -981.0,
      "steps": 36,
      "mean_loss": 3800.188537809584,
      "epsilon": 0.46080300000104873
    },
    {
      "episode": 737,
      "score": 99,
      "reward": -966.0,
      "steps": 44,
      "mean_loss": 2180.92920962247,
      "epsilon": 0.4607590000010499
    },
    {
      "episode": 738,
      "score": 163,
      "reward": -912.0,
      "steps": 49,
      "mean_loss": 4856.412507582684,
      "epsilon": 0.4607100000010512
    },
    {
      "episode": 739,
      "score": 104,
      "reward": -947.0,
      "steps": 36,
      "mean_loss": 4126.190715577867,
      "epsilon": 0.4606740000010522
    },
    {
      "episode": 740,
      "score": 135,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 2497.162251898583,
      "epsilon": 0.46062700000105344
    },
    {
      "episode": 741,
      "score": 90,
      "reward": -959.0,
      "steps": 35,
      "mean_loss": 3007.2140919276644,
      "epsilon": 0.4605920000010544
    },
    {
      "episode": 742,
      "score": 129,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 1948.0099676305597,
      "epsilon": 0.46054800000105556
    },
    {
      "episode": 743,
      "score": 107,
      "reward": -971.0,
      "steps": 43,
      "mean_loss": 2575.4322605576626,
      "epsilon": 0.4605050000010567
    },
    {
      "episode": 744,
      "score": 115,
      "reward": -959.0,
      "steps": 47,
      "mean_loss": 3355.3205493358855,
      "epsilon": 0.46045800000105797
    },
    {
      "episode": 745,
      "score": 105,
      "reward": -967.0,
      "steps": 43,
      "mean_loss": 1485.4530737233717,
      "epsilon": 0.4604150000010591
    },
    {
      "episode": 746,
      "score": 85,
      "reward": -982.0,
      "steps": 36,
      "mean_loss": 4010.0971173180474,
      "epsilon": 0.4603790000010601
    },
    {
      "episode": 747,
      "score": 174,
      "reward": -909.0,
      "steps": 54,
      "mean_loss": 5850.983282018591,
      "epsilon": 0.4603250000010615
    },
    {
      "episode": 748,
      "score": 151,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 3894.7442224820456,
      "epsilon": 0.4602770000010628
    },
    {
      "episode": 749,
      "score": 153,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 7435.552342006138,
      "epsilon": 0.4602280000010641
    },
    {
      "episode": 750,
      "score": 141,
      "reward": -946.0,
      "steps": 49,
      "mean_loss": 3091.6176729786152,
      "epsilon": 0.46017900000106543
    },
    {
      "episode": 751,
      "score": 126,
      "reward": -944.0,
      "steps": 41,
      "mean_loss": 2230.950277002846,
      "epsilon": 0.4601380000010665
    },
    {
      "episode": 752,
      "score": 199,
      "reward": -896.0,
      "steps": 56,
      "mean_loss": 3888.9527854919434,
      "epsilon": 0.460082000001068
    },
    {
      "episode": 753,
      "score": 222,
      "reward": -866.0,
      "steps": 57,
      "mean_loss": 4705.816224483022,
      "epsilon": 0.46002500000106955
    },
    {
      "episode": 754,
      "score": 152,
      "reward": -931.0,
      "steps": 50,
      "mean_loss": 4983.002812652588,
      "epsilon": 0.4599750000010709
    },
    {
      "episode": 755,
      "score": 140,
      "reward": -927.0,
      "steps": 48,
      "mean_loss": 5362.889898935954,
      "epsilon": 0.4599270000010722
    },
    {
      "episode": 756,
      "score": 216,
      "reward": -878.0,
      "steps": 56,
      "mean_loss": 4135.047961643764,
      "epsilon": 0.45987100000107367
    },
    {
      "episode": 757,
      "score": 201,
      "reward": -881.0,
      "steps": 54,
      "mean_loss": 7181.121876045509,
      "epsilon": 0.4598170000010751
    },
    {
      "episode": 758,
      "score": 139,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 4590.883076543393,
      "epsilon": 0.45977100000107635
    },
    {
      "episode": 759,
      "score": 138,
      "reward": -947.0,
      "steps": 48,
      "mean_loss": 3061.325172742208,
      "epsilon": 0.45972300000107763
    },
    {
      "episode": 760,
      "score": 152,
      "reward": -920.0,
      "steps": 48,
      "mean_loss": 2218.8219130833945,
      "epsilon": 0.4596750000010789
    },
    {
      "episode": 761,
      "score": 132,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 4332.422843850177,
      "epsilon": 0.45962900000108015
    },
    {
      "episode": 762,
      "score": 126,
      "reward": -935.0,
      "steps": 43,
      "mean_loss": 7908.183826890103,
      "epsilon": 0.4595860000010813
    },
    {
      "episode": 763,
      "score": 90,
      "reward": -959.0,
      "steps": 35,
      "mean_loss": 3067.646140398298,
      "epsilon": 0.45955100000108223
    },
    {
      "episode": 764,
      "score": 95,
      "reward": -961.0,
      "steps": 35,
      "mean_loss": 5055.7394160679405,
      "epsilon": 0.45951600000108317
    },
    {
      "episode": 765,
      "score": 135,
      "reward": -928.0,
      "steps": 44,
      "mean_loss": 5105.584023215554,
      "epsilon": 0.45947200000108435
    },
    {
      "episode": 766,
      "score": 187,
      "reward": -899.0,
      "steps": 53,
      "mean_loss": 3193.858900250129,
      "epsilon": 0.45941900000108576
    },
    {
      "episode": 767,
      "score": 183,
      "reward": -907.0,
      "steps": 51,
      "mean_loss": 3446.501043731091,
      "epsilon": 0.45936800000108713
    },
    {
      "episode": 768,
      "score": 170,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 2750.3029676584097,
      "epsilon": 0.4593160000010885
    },
    {
      "episode": 769,
      "score": 205,
      "reward": -872.0,
      "steps": 57,
      "mean_loss": 4941.116562023498,
      "epsilon": 0.45925900000109005
    },
    {
      "episode": 770,
      "score": 120,
      "reward": -956.0,
      "steps": 47,
      "mean_loss": 4983.315865374626,
      "epsilon": 0.4592120000010913
    },
    {
      "episode": 771,
      "score": 168,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 4065.000468987685,
      "epsilon": 0.4591600000010927
    },
    {
      "episode": 772,
      "score": 104,
      "reward": -960.0,
      "steps": 42,
      "mean_loss": 3362.4985900152296,
      "epsilon": 0.4591180000010938
    },
    {
      "episode": 773,
      "score": 191,
      "reward": -886.0,
      "steps": 54,
      "mean_loss": 5886.352049792255,
      "epsilon": 0.45906400000109526
    },
    {
      "episode": 774,
      "score": 144,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 4782.0973416592215,
      "epsilon": 0.4590170000010965
    },
    {
      "episode": 775,
      "score": 98,
      "reward": -958.0,
      "steps": 37,
      "mean_loss": 4912.144329792744,
      "epsilon": 0.4589800000010975
    },
    {
      "episode": 776,
      "score": 133,
      "reward": -949.0,
      "steps": 45,
      "mean_loss": 2805.6771842108833,
      "epsilon": 0.4589350000010987
    },
    {
      "episode": 777,
      "score": 215,
      "reward": -877.0,
      "steps": 54,
      "mean_loss": 5671.6490070201735,
      "epsilon": 0.45888100000110016
    },
    {
      "episode": 778,
      "score": 186,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 4241.696825027466,
      "epsilon": 0.45882900000110155
    },
    {
      "episode": 779,
      "score": 253,
      "reward": -840.0,
      "steps": 59,
      "mean_loss": 3465.536041001142,
      "epsilon": 0.45877000000110313
    },
    {
      "episode": 780,
      "score": 182,
      "reward": -891.0,
      "steps": 49,
      "mean_loss": 1312.2384850638252,
      "epsilon": 0.45872100000110444
    },
    {
      "episode": 781,
      "score": 230,
      "reward": -865.0,
      "steps": 60,
      "mean_loss": 2999.0637811024985,
      "epsilon": 0.45866100000110605
    },
    {
      "episode": 782,
      "score": 144,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3594.60465208013,
      "epsilon": 0.4586140000011073
    },
    {
      "episode": 783,
      "score": 105,
      "reward": -962.0,
      "steps": 43,
      "mean_loss": 2934.6878756146098,
      "epsilon": 0.45857100000110845
    },
    {
      "episode": 784,
      "score": 120,
      "reward": -955.0,
      "steps": 46,
      "mean_loss": 3635.718345807946,
      "epsilon": 0.4585250000011097
    },
    {
      "episode": 785,
      "score": 170,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 2716.6552015451284,
      "epsilon": 0.4584730000011111
    },
    {
      "episode": 786,
      "score": 132,
      "reward": -934.0,
      "steps": 46,
      "mean_loss": 3749.2647925667143,
      "epsilon": 0.4584270000011123
    },
    {
      "episode": 787,
      "score": 70,
      "reward": -999.0,
      "steps": 37,
      "mean_loss": 1164.2660391524032,
      "epsilon": 0.4583900000011133
    },
    {
      "episode": 788,
      "score": 131,
      "reward": -930.0,
      "steps": 42,
      "mean_loss": 4015.929063706171,
      "epsilon": 0.4583480000011144
    },
    {
      "episode": 789,
      "score": 155,
      "reward": -916.0,
      "steps": 49,
      "mean_loss": 4513.450039921975,
      "epsilon": 0.45829900000111573
    },
    {
      "episode": 790,
      "score": 191,
      "reward": -914.0,
      "steps": 57,
      "mean_loss": 2596.6755881058543,
      "epsilon": 0.45824200000111726
    },
    {
      "episode": 791,
      "score": 150,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 4475.943078214472,
      "epsilon": 0.45819800000111843
    },
    {
      "episode": 792,
      "score": 184,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 4019.3573602640404,
      "epsilon": 0.45814500000111985
    },
    {
      "episode": 793,
      "score": 154,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 4775.108621558365,
      "epsilon": 0.45809600000112116
    },
    {
      "episode": 794,
      "score": 112,
      "reward": -948.0,
      "steps": 41,
      "mean_loss": 4410.842462679235,
      "epsilon": 0.45805500000112226
    },
    {
      "episode": 795,
      "score": 102,
      "reward": -965.0,
      "steps": 41,
      "mean_loss": 2867.216166984744,
      "epsilon": 0.45801400000112336
    },
    {
      "episode": 796,
      "score": 181,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 5646.583573854887,
      "epsilon": 0.45796200000112475
    },
    {
      "episode": 797,
      "score": 117,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 3902.6888731135878,
      "epsilon": 0.4579190000011259
    },
    {
      "episode": 798,
      "score": 188,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 4428.2156763616595,
      "epsilon": 0.4578660000011273
    },
    {
      "episode": 799,
      "score": 115,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 5847.388064956665,
      "epsilon": 0.4578260000011284
    },
    {
      "episode": 800,
      "score": 121,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 3542.9622740312057,
      "epsilon": 0.45778200000112956
    },
    {
      "episode": 801,
      "score": 99,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 1916.5735532587225,
      "epsilon": 0.45773800000113074
    },
    {
      "episode": 802,
      "score": 145,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 1764.9602770124163,
      "epsilon": 0.45768900000113205
    },
    {
      "episode": 803,
      "score": 281,
      "reward": -831.0,
      "steps": 68,
      "mean_loss": 4338.9673872555,
      "epsilon": 0.45762100000113387
    },
    {
      "episode": 804,
      "score": 163,
      "reward": -892.0,
      "steps": 45,
      "mean_loss": 2263.4836393568253,
      "epsilon": 0.4575760000011351
    },
    {
      "episode": 805,
      "score": 125,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 3479.294573879242,
      "epsilon": 0.45753600000113614
    },
    {
      "episode": 806,
      "score": 72,
      "reward": -981.0,
      "steps": 33,
      "mean_loss": 1677.0409691550515,
      "epsilon": 0.45750300000113703
    },
    {
      "episode": 807,
      "score": 120,
      "reward": -962.0,
      "steps": 45,
      "mean_loss": 4340.828841315375,
      "epsilon": 0.45745800000113823
    },
    {
      "episode": 808,
      "score": 103,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 5288.485763549805,
      "epsilon": 0.4574140000011394
    },
    {
      "episode": 809,
      "score": 153,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 4716.7612657547,
      "epsilon": 0.4573700000011406
    },
    {
      "episode": 810,
      "score": 119,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 5105.732869529724,
      "epsilon": 0.45733000000114166
    },
    {
      "episode": 811,
      "score": 124,
      "reward": -943.0,
      "steps": 43,
      "mean_loss": 4099.053050196448,
      "epsilon": 0.4572870000011428
    },
    {
      "episode": 812,
      "score": 208,
      "reward": -886.0,
      "steps": 57,
      "mean_loss": 5037.556087426972,
      "epsilon": 0.45723000000114433
    },
    {
      "episode": 813,
      "score": 129,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 3037.3386169780383,
      "epsilon": 0.4571860000011455
    },
    {
      "episode": 814,
      "score": 153,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 5322.170682790328,
      "epsilon": 0.4571370000011468
    },
    {
      "episode": 815,
      "score": 124,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 1340.3978822881525,
      "epsilon": 0.457093000001148
    },
    {
      "episode": 816,
      "score": 205,
      "reward": -883.0,
      "steps": 55,
      "mean_loss": 3469.0712449507278,
      "epsilon": 0.45703800000114947
    },
    {
      "episode": 817,
      "score": 183,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 2062.021132271245,
      "epsilon": 0.4569850000011509
    },
    {
      "episode": 818,
      "score": 121,
      "reward": -951.0,
      "steps": 43,
      "mean_loss": 3174.6942910482717,
      "epsilon": 0.45694200000115204
    },
    {
      "episode": 819,
      "score": 194,
      "reward": -877.0,
      "steps": 55,
      "mean_loss": 4986.242871509899,
      "epsilon": 0.4568870000011535
    },
    {
      "episode": 820,
      "score": 159,
      "reward": -911.0,
      "steps": 47,
      "mean_loss": 5230.2398498210505,
      "epsilon": 0.45684000000115477
    },
    {
      "episode": 821,
      "score": 93,
      "reward": -970.0,
      "steps": 41,
      "mean_loss": 3245.6396644406204,
      "epsilon": 0.45679900000115586
    },
    {
      "episode": 822,
      "score": 80,
      "reward": -989.0,
      "steps": 37,
      "mean_loss": 5237.71084079227,
      "epsilon": 0.45676200000115685
    },
    {
      "episode": 823,
      "score": 108,
      "reward": -944.0,
      "steps": 37,
      "mean_loss": 4339.70525937467,
      "epsilon": 0.45672500000115784
    },
    {
      "episode": 824,
      "score": 146,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 3088.687271118164,
      "epsilon": 0.45667700000115913
    },
    {
      "episode": 825,
      "score": 119,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 3575.6085260564632,
      "epsilon": 0.4566330000011603
    },
    {
      "episode": 826,
      "score": 141,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 2902.9462811084504,
      "epsilon": 0.45658600000116156
    },
    {
      "episode": 827,
      "score": 143,
      "reward": -926.0,
      "steps": 45,
      "mean_loss": 2677.27794096205,
      "epsilon": 0.45654100000116277
    },
    {
      "episode": 828,
      "score": 139,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 2619.802278559259,
      "epsilon": 0.456494000001164
    },
    {
      "episode": 829,
      "score": 146,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 5043.507345275879,
      "epsilon": 0.45644400000116536
    },
    {
      "episode": 830,
      "score": 149,
      "reward": -926.0,
      "steps": 48,
      "mean_loss": 3510.576655069987,
      "epsilon": 0.45639600000116665
    },
    {
      "episode": 831,
      "score": 146,
      "reward": -916.0,
      "steps": 45,
      "mean_loss": 3929.5902099609375,
      "epsilon": 0.45635100000116785
    },
    {
      "episode": 832,
      "score": 153,
      "reward": -908.0,
      "steps": 47,
      "mean_loss": 2996.1773856954374,
      "epsilon": 0.4563040000011691
    },
    {
      "episode": 833,
      "score": 121,
      "reward": -959.0,
      "steps": 47,
      "mean_loss": 3690.5510187351956,
      "epsilon": 0.45625700000117037
    },
    {
      "episode": 834,
      "score": 170,
      "reward": -910.0,
      "steps": 48,
      "mean_loss": 4512.547905286153,
      "epsilon": 0.45620900000117165
    },
    {
      "episode": 835,
      "score": 126,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 2878.4549321713653,
      "epsilon": 0.4561630000011729
    },
    {
      "episode": 836,
      "score": 241,
      "reward": -859.0,
      "steps": 63,
      "mean_loss": 3123.5140279134116,
      "epsilon": 0.45610000000117457
    },
    {
      "episode": 837,
      "score": 175,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 4555.844452637893,
      "epsilon": 0.45604800000117596
    },
    {
      "episode": 838,
      "score": 142,
      "reward": -931.0,
      "steps": 50,
      "mean_loss": 1249.4632754516601,
      "epsilon": 0.4559980000011773
    },
    {
      "episode": 839,
      "score": 158,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 4972.428081512451,
      "epsilon": 0.45594800000117863
    },
    {
      "episode": 840,
      "score": 209,
      "reward": -881.0,
      "steps": 56,
      "mean_loss": 3384.855858394078,
      "epsilon": 0.45589200000118013
    },
    {
      "episode": 841,
      "score": 93,
      "reward": -974.0,
      "steps": 39,
      "mean_loss": 4297.9208743755635,
      "epsilon": 0.4558530000011812
    },
    {
      "episode": 842,
      "score": 199,
      "reward": -881.0,
      "steps": 55,
      "mean_loss": 2417.854085887562,
      "epsilon": 0.45579800000118265
    },
    {
      "episode": 843,
      "score": 124,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 2656.5859074694044,
      "epsilon": 0.4557510000011839
    },
    {
      "episode": 844,
      "score": 171,
      "reward": -893.0,
      "steps": 50,
      "mean_loss": 3555.781568450928,
      "epsilon": 0.45570100000118524
    },
    {
      "episode": 845,
      "score": 89,
      "reward": -979.0,
      "steps": 42,
      "mean_loss": 3262.6717478434243,
      "epsilon": 0.45565900000118637
    },
    {
      "episode": 846,
      "score": 96,
      "reward": -977.0,
      "steps": 39,
      "mean_loss": 2457.555787893442,
      "epsilon": 0.4556200000011874
    },
    {
      "episode": 847,
      "score": 127,
      "reward": -950.0,
      "steps": 48,
      "mean_loss": 2335.2926318645477,
      "epsilon": 0.4555720000011887
    },
    {
      "episode": 848,
      "score": 151,
      "reward": -916.0,
      "steps": 44,
      "mean_loss": 3020.181510578502,
      "epsilon": 0.45552800000118987
    },
    {
      "episode": 849,
      "score": 122,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 2844.111448981545,
      "epsilon": 0.45548400000119105
    },
    {
      "episode": 850,
      "score": 145,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 2988.9267983728528,
      "epsilon": 0.45543500000119236
    },
    {
      "episode": 851,
      "score": 51,
      "reward": -1002.0,
      "steps": 31,
      "mean_loss": 2702.3031488233996,
      "epsilon": 0.4554040000011932
    },
    {
      "episode": 852,
      "score": 144,
      "reward": -921.0,
      "steps": 43,
      "mean_loss": 3000.0324799293694,
      "epsilon": 0.45536100000119434
    },
    {
      "episode": 853,
      "score": 87,
      "reward": -986.0,
      "steps": 40,
      "mean_loss": 6149.373492240906,
      "epsilon": 0.4553210000011954
    },
    {
      "episode": 854,
      "score": 93,
      "reward": -960.0,
      "steps": 35,
      "mean_loss": 2427.056042480469,
      "epsilon": 0.45528600000119634
    },
    {
      "episode": 855,
      "score": 155,
      "reward": -930.0,
      "steps": 51,
      "mean_loss": 2731.07165332869,
      "epsilon": 0.4552350000011977
    },
    {
      "episode": 856,
      "score": 215,
      "reward": -889.0,
      "steps": 58,
      "mean_loss": 3653.193992088581,
      "epsilon": 0.45517700000119926
    },
    {
      "episode": 857,
      "score": 109,
      "reward": -955.0,
      "steps": 40,
      "mean_loss": 3381.562814617157,
      "epsilon": 0.45513700000120033
    },
    {
      "episode": 858,
      "score": 117,
      "reward": -950.0,
      "steps": 42,
      "mean_loss": 3499.816614968436,
      "epsilon": 0.45509500000120146
    },
    {
      "episode": 859,
      "score": 182,
      "reward": -901.0,
      "steps": 53,
      "mean_loss": 3377.7167397265166,
      "epsilon": 0.4550420000012029
    },
    {
      "episode": 860,
      "score": 90,
      "reward": -972.0,
      "steps": 40,
      "mean_loss": 4264.298383331299,
      "epsilon": 0.45500200000120394
    },
    {
      "episode": 861,
      "score": 203,
      "reward": -880.0,
      "steps": 57,
      "mean_loss": 2890.584313911304,
      "epsilon": 0.45494500000120547
    },
    {
      "episode": 862,
      "score": 150,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 5651.480247192383,
      "epsilon": 0.4548950000012068
    },
    {
      "episode": 863,
      "score": 146,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 3820.277936732515,
      "epsilon": 0.45484800000120806
    },
    {
      "episode": 864,
      "score": 244,
      "reward": -855.0,
      "steps": 62,
      "mean_loss": 3070.6669040802985,
      "epsilon": 0.4547860000012097
    },
    {
      "episode": 865,
      "score": 135,
      "reward": -929.0,
      "steps": 45,
      "mean_loss": 5308.488066609701,
      "epsilon": 0.4547410000012109
    },
    {
      "episode": 866,
      "score": 100,
      "reward": -978.0,
      "steps": 42,
      "mean_loss": 6252.042376018706,
      "epsilon": 0.45469900000121205
    },
    {
      "episode": 867,
      "score": 148,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 4048.2711450327997,
      "epsilon": 0.4546530000012133
    },
    {
      "episode": 868,
      "score": 151,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 4110.48962340063,
      "epsilon": 0.4546040000012146
    },
    {
      "episode": 869,
      "score": 156,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 3686.8536327443226,
      "epsilon": 0.45455700000121585
    },
    {
      "episode": 870,
      "score": 158,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 4870.439971549838,
      "epsilon": 0.4545060000012172
    },
    {
      "episode": 871,
      "score": 150,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 2757.521025737127,
      "epsilon": 0.4544580000012185
    },
    {
      "episode": 872,
      "score": 167,
      "reward": -902.0,
      "steps": 49,
      "mean_loss": 2018.3605486811423,
      "epsilon": 0.4544090000012198
    },
    {
      "episode": 873,
      "score": 214,
      "reward": -874.0,
      "steps": 54,
      "mean_loss": 2784.7646699834754,
      "epsilon": 0.45435500000122125
    },
    {
      "episode": 874,
      "score": 92,
      "reward": -978.0,
      "steps": 37,
      "mean_loss": 3677.647060909787,
      "epsilon": 0.45431800000122224
    },
    {
      "episode": 875,
      "score": 155,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 1810.076080159938,
      "epsilon": 0.4542710000012235
    },
    {
      "episode": 876,
      "score": 104,
      "reward": -979.0,
      "steps": 44,
      "mean_loss": 2562.503855791959,
      "epsilon": 0.4542270000012247
    },
    {
      "episode": 877,
      "score": 229,
      "reward": -867.0,
      "steps": 59,
      "mean_loss": 3544.9491575208763,
      "epsilon": 0.45416800000122626
    },
    {
      "episode": 878,
      "score": 179,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 3434.1736767108623,
      "epsilon": 0.45411600000122765
    },
    {
      "episode": 879,
      "score": 169,
      "reward": -902.0,
      "steps": 48,
      "mean_loss": 3490.1176931858063,
      "epsilon": 0.45406800000122893
    },
    {
      "episode": 880,
      "score": 171,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 1523.8449624633788,
      "epsilon": 0.45401800000123027
    },
    {
      "episode": 881,
      "score": 116,
      "reward": -941.0,
      "steps": 39,
      "mean_loss": 5578.350198501195,
      "epsilon": 0.4539790000012313
    },
    {
      "episode": 882,
      "score": 155,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 4175.437903442383,
      "epsilon": 0.45392900000123265
    },
    {
      "episode": 883,
      "score": 90,
      "reward": -983.0,
      "steps": 41,
      "mean_loss": 5174.088340387112,
      "epsilon": 0.45388800000123375
    },
    {
      "episode": 884,
      "score": 56,
      "reward": -989.0,
      "steps": 28,
      "mean_loss": 5794.894722802298,
      "epsilon": 0.4538600000012345
    },
    {
      "episode": 885,
      "score": 150,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 3405.2527961730957,
      "epsilon": 0.45381400000123573
    },
    {
      "episode": 886,
      "score": 154,
      "reward": -918.0,
      "steps": 46,
      "mean_loss": 4507.695479185685,
      "epsilon": 0.45376800000123696
    },
    {
      "episode": 887,
      "score": 89,
      "reward": -972.0,
      "steps": 36,
      "mean_loss": 3628.538144429525,
      "epsilon": 0.4537320000012379
    },
    {
      "episode": 888,
      "score": 181,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4308.119102619313,
      "epsilon": 0.45367800000123937
    },
    {
      "episode": 889,
      "score": 83,
      "reward": -978.0,
      "steps": 35,
      "mean_loss": 2817.6021719796317,
      "epsilon": 0.4536430000012403
    },
    {
      "episode": 890,
      "score": 144,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 2741.3030637953016,
      "epsilon": 0.4535980000012415
    },
    {
      "episode": 891,
      "score": 145,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 2924.3263885974884,
      "epsilon": 0.4535500000012428
    },
    {
      "episode": 892,
      "score": 118,
      "reward": -948.0,
      "steps": 42,
      "mean_loss": 3147.741981869652,
      "epsilon": 0.4535080000012439
    },
    {
      "episode": 893,
      "score": 72,
      "reward": -980.0,
      "steps": 34,
      "mean_loss": 3814.9721087287453,
      "epsilon": 0.4534740000012448
    },
    {
      "episode": 894,
      "score": 123,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 3433.6319558037653,
      "epsilon": 0.45342900000124603
    },
    {
      "episode": 895,
      "score": 108,
      "reward": -966.0,
      "steps": 43,
      "mean_loss": 4357.395052532817,
      "epsilon": 0.4533860000012472
    },
    {
      "episode": 896,
      "score": 105,
      "reward": -954.0,
      "steps": 36,
      "mean_loss": 3058.2634635501436,
      "epsilon": 0.45335000000124814
    },
    {
      "episode": 897,
      "score": 142,
      "reward": -914.0,
      "steps": 41,
      "mean_loss": 5220.68807890357,
      "epsilon": 0.45330900000124924
    },
    {
      "episode": 898,
      "score": 114,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 2436.8355648734355,
      "epsilon": 0.4532650000012504
    },
    {
      "episode": 899,
      "score": 160,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 2661.996174870705,
      "epsilon": 0.45321600000125173
    },
    {
      "episode": 900,
      "score": 193,
      "reward": -905.0,
      "steps": 55,
      "mean_loss": 3936.6312563809483,
      "epsilon": 0.4531610000012532
    },
    {
      "episode": 901,
      "score": 133,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 3333.301133338441,
      "epsilon": 0.45311400000125446
    },
    {
      "episode": 902,
      "score": 234,
      "reward": -865.0,
      "steps": 60,
      "mean_loss": 4085.5703969955443,
      "epsilon": 0.45305400000125606
    },
    {
      "episode": 903,
      "score": 147,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 4832.129493879235,
      "epsilon": 0.4530080000012573
    },
    {
      "episode": 904,
      "score": 101,
      "reward": -976.0,
      "steps": 42,
      "mean_loss": 3825.3827954246885,
      "epsilon": 0.4529660000012584
    },
    {
      "episode": 905,
      "score": 144,
      "reward": -935.0,
      "steps": 47,
      "mean_loss": 3677.4855581242987,
      "epsilon": 0.4529190000012597
    },
    {
      "episode": 906,
      "score": 198,
      "reward": -880.0,
      "steps": 55,
      "mean_loss": 2824.5865941827947,
      "epsilon": 0.45286400000126115
    },
    {
      "episode": 907,
      "score": 143,
      "reward": -909.0,
      "steps": 44,
      "mean_loss": 2851.9848628477616,
      "epsilon": 0.4528200000012623
    },
    {
      "episode": 908,
      "score": 156,
      "reward": -903.0,
      "steps": 45,
      "mean_loss": 2535.0838402642144,
      "epsilon": 0.45277500000126353
    },
    {
      "episode": 909,
      "score": 136,
      "reward": -936.0,
      "steps": 45,
      "mean_loss": 5499.49789513482,
      "epsilon": 0.45273000000126473
    },
    {
      "episode": 910,
      "score": 91,
      "reward": -962.0,
      "steps": 38,
      "mean_loss": 4034.303444912559,
      "epsilon": 0.45269200000126575
    },
    {
      "episode": 911,
      "score": 165,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 4755.511539160037,
      "epsilon": 0.4526410000012671
    },
    {
      "episode": 912,
      "score": 160,
      "reward": -902.0,
      "steps": 47,
      "mean_loss": 2256.692300674763,
      "epsilon": 0.45259400000126837
    },
    {
      "episode": 913,
      "score": 148,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 4495.593093709743,
      "epsilon": 0.45254700000126963
    },
    {
      "episode": 914,
      "score": 161,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3297.395392773198,
      "epsilon": 0.452496000001271
    },
    {
      "episode": 915,
      "score": 186,
      "reward": -893.0,
      "steps": 53,
      "mean_loss": 3855.1474369696853,
      "epsilon": 0.4524430000012724
    },
    {
      "episode": 916,
      "score": 152,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 2095.124685974121,
      "epsilon": 0.45239300000127375
    },
    {
      "episode": 917,
      "score": 162,
      "reward": -931.0,
      "steps": 50,
      "mean_loss": 1576.815425262451,
      "epsilon": 0.4523430000012751
    },
    {
      "episode": 918,
      "score": 157,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 3934.5944459533694,
      "epsilon": 0.4522930000012764
    },
    {
      "episode": 919,
      "score": 111,
      "reward": -968.0,
      "steps": 44,
      "mean_loss": 4801.826131820679,
      "epsilon": 0.4522490000012776
    },
    {
      "episode": 920,
      "score": 141,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 5739.261013923808,
      "epsilon": 0.45220200000127886
    },
    {
      "episode": 921,
      "score": 181,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 2542.115651589853,
      "epsilon": 0.4521480000012803
    },
    {
      "episode": 922,
      "score": 96,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 4103.552991169255,
      "epsilon": 0.4521070000012814
    },
    {
      "episode": 923,
      "score": 95,
      "reward": -984.0,
      "steps": 44,
      "mean_loss": 5246.1922841505575,
      "epsilon": 0.4520630000012826
    },
    {
      "episode": 924,
      "score": 220,
      "reward": -880.0,
      "steps": 59,
      "mean_loss": 4593.692610271906,
      "epsilon": 0.45200400000128416
    },
    {
      "episode": 925,
      "score": 123,
      "reward": -947.0,
      "steps": 45,
      "mean_loss": 3927.1553175184463,
      "epsilon": 0.45195900000128536
    },
    {
      "episode": 926,
      "score": 155,
      "reward": -922.0,
      "steps": 48,
      "mean_loss": 4458.179573218028,
      "epsilon": 0.45191100000128664
    },
    {
      "episode": 927,
      "score": 173,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 5313.708930382361,
      "epsilon": 0.45185900000128804
    },
    {
      "episode": 928,
      "score": 123,
      "reward": -934.0,
      "steps": 38,
      "mean_loss": 4899.059390620181,
      "epsilon": 0.45182100000128905
    },
    {
      "episode": 929,
      "score": 127,
      "reward": -957.0,
      "steps": 45,
      "mean_loss": 4500.542218865288,
      "epsilon": 0.45177600000129026
    },
    {
      "episode": 930,
      "score": 87,
      "reward": -969.0,
      "steps": 37,
      "mean_loss": 2508.386115615432,
      "epsilon": 0.45173900000129125
    },
    {
      "episode": 931,
      "score": 181,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 4981.718201270471,
      "epsilon": 0.45168700000129264
    },
    {
      "episode": 932,
      "score": 107,
      "reward": -973.0,
      "steps": 42,
      "mean_loss": 5210.5183337983635,
      "epsilon": 0.45164500000129376
    },
    {
      "episode": 933,
      "score": 101,
      "reward": -946.0,
      "steps": 34,
      "mean_loss": 5779.778886234059,
      "epsilon": 0.45161100000129467
    },
    {
      "episode": 934,
      "score": 176,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 5472.580140075684,
      "epsilon": 0.451561000001296
    },
    {
      "episode": 935,
      "score": 171,
      "reward": -915.0,
      "steps": 52,
      "mean_loss": 2375.2794777063223,
      "epsilon": 0.4515090000012974
    },
    {
      "episode": 936,
      "score": 119,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 2963.654596675526,
      "epsilon": 0.4514650000012986
    },
    {
      "episode": 937,
      "score": 109,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 3720.68985748291,
      "epsilon": 0.45142100000129975
    },
    {
      "episode": 938,
      "score": 182,
      "reward": -906.0,
      "steps": 51,
      "mean_loss": 3490.4246725942576,
      "epsilon": 0.4513700000013011
    },
    {
      "episode": 939,
      "score": 148,
      "reward": -915.0,
      "steps": 44,
      "mean_loss": 1200.0284498388116,
      "epsilon": 0.4513260000013023
    },
    {
      "episode": 940,
      "score": 197,
      "reward": -880.0,
      "steps": 55,
      "mean_loss": 2917.0143400018865,
      "epsilon": 0.45127100000130377
    },
    {
      "episode": 941,
      "score": 168,
      "reward": -893.0,
      "steps": 48,
      "mean_loss": 4043.881162325541,
      "epsilon": 0.45122300000130505
    },
    {
      "episode": 942,
      "score": 80,
      "reward": -986.0,
      "steps": 37,
      "mean_loss": 5836.432528933963,
      "epsilon": 0.45118600000130604
    },
    {
      "episode": 943,
      "score": 157,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 4742.154709952219,
      "epsilon": 0.45113700000130735
    },
    {
      "episode": 944,
      "score": 184,
      "reward": -897.0,
      "steps": 54,
      "mean_loss": 2599.630802154541,
      "epsilon": 0.4510830000013088
    },
    {
      "episode": 945,
      "score": 178,
      "reward": -894.0,
      "steps": 53,
      "mean_loss": 4631.873683569566,
      "epsilon": 0.4510300000013102
    },
    {
      "episode": 946,
      "score": 135,
      "reward": -928.0,
      "steps": 45,
      "mean_loss": 2409.571199713813,
      "epsilon": 0.4509850000013114
    },
    {
      "episode": 947,
      "score": 158,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 4722.646242102798,
      "epsilon": 0.45093600000131273
    },
    {
      "episode": 948,
      "score": 182,
      "reward": -885.0,
      "steps": 51,
      "mean_loss": 4529.772102655149,
      "epsilon": 0.4508850000013141
    },
    {
      "episode": 949,
      "score": 72,
      "reward": -996.0,
      "steps": 35,
      "mean_loss": 2928.3377233232773,
      "epsilon": 0.45085000000131503
    },
    {
      "episode": 950,
      "score": 185,
      "reward": -895.0,
      "steps": 52,
      "mean_loss": 5216.966211612408,
      "epsilon": 0.4507980000013164
    },
    {
      "episode": 951,
      "score": 140,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 5582.533514065212,
      "epsilon": 0.4507530000013176
    },
    {
      "episode": 952,
      "score": 175,
      "reward": -920.0,
      "steps": 54,
      "mean_loss": 4436.658025388365,
      "epsilon": 0.4506990000013191
    },
    {
      "episode": 953,
      "score": 240,
      "reward": -855.0,
      "steps": 61,
      "mean_loss": 2663.96079904525,
      "epsilon": 0.4506380000013207
    },
    {
      "episode": 954,
      "score": 130,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 3138.7028032668095,
      "epsilon": 0.45059100000132196
    },
    {
      "episode": 955,
      "score": 118,
      "reward": -964.0,
      "steps": 40,
      "mean_loss": 4075.83678188324,
      "epsilon": 0.45055100000132303
    },
    {
      "episode": 956,
      "score": 117,
      "reward": -954.0,
      "steps": 40,
      "mean_loss": 6109.778061485291,
      "epsilon": 0.4505110000013241
    },
    {
      "episode": 957,
      "score": 251,
      "reward": -839.0,
      "steps": 62,
      "mean_loss": 4089.4857394310734,
      "epsilon": 0.45044900000132576
    },
    {
      "episode": 958,
      "score": 76,
      "reward": -979.0,
      "steps": 35,
      "mean_loss": 1715.7868532453265,
      "epsilon": 0.4504140000013267
    },
    {
      "episode": 959,
      "score": 226,
      "reward": -860.0,
      "steps": 56,
      "mean_loss": 1945.7446927343096,
      "epsilon": 0.4503580000013282
    },
    {
      "episode": 960,
      "score": 63,
      "reward": -997.0,
      "steps": 33,
      "mean_loss": 1082.3799794514973,
      "epsilon": 0.4503250000013291
    },
    {
      "episode": 961,
      "score": 211,
      "reward": -870.0,
      "steps": 55,
      "mean_loss": 1939.0056286898525,
      "epsilon": 0.45027000000133055
    },
    {
      "episode": 962,
      "score": 172,
      "reward": -928.0,
      "steps": 52,
      "mean_loss": 3295.8386251743023,
      "epsilon": 0.45021800000133194
    },
    {
      "episode": 963,
      "score": 159,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 3145.352159387925,
      "epsilon": 0.4501670000013333
    },
    {
      "episode": 964,
      "score": 102,
      "reward": -971.0,
      "steps": 41,
      "mean_loss": 2899.046604156494,
      "epsilon": 0.4501260000013344
    },
    {
      "episode": 965,
      "score": 153,
      "reward": -949.0,
      "steps": 46,
      "mean_loss": 2421.980491306471,
      "epsilon": 0.45008000000133563
    },
    {
      "episode": 966,
      "score": 107,
      "reward": -959.0,
      "steps": 39,
      "mean_loss": 4686.695995037372,
      "epsilon": 0.4500410000013367
    },
    {
      "episode": 967,
      "score": 182,
      "reward": -902.0,
      "steps": 51,
      "mean_loss": 5083.954757840026,
      "epsilon": 0.44999000000133804
    },
    {
      "episode": 968,
      "score": 191,
      "reward": -900.0,
      "steps": 56,
      "mean_loss": 5121.964691707066,
      "epsilon": 0.44993400000133954
    },
    {
      "episode": 969,
      "score": 164,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 4734.412962154466,
      "epsilon": 0.44988500000134085
    },
    {
      "episode": 970,
      "score": 168,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 2923.6848885779286,
      "epsilon": 0.4498340000013422
    },
    {
      "episode": 971,
      "score": 232,
      "reward": -882.0,
      "steps": 62,
      "mean_loss": 2128.7835135921355,
      "epsilon": 0.4497720000013439
    },
    {
      "episode": 972,
      "score": 144,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 5558.277241333672,
      "epsilon": 0.4497260000013451
    },
    {
      "episode": 973,
      "score": 165,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 3419.4228341674807,
      "epsilon": 0.44967600000134644
    },
    {
      "episode": 974,
      "score": 75,
      "reward": -986.0,
      "steps": 34,
      "mean_loss": 1913.7520921370563,
      "epsilon": 0.44964200000134735
    },
    {
      "episode": 975,
      "score": 64,
      "reward": -987.0,
      "steps": 30,
      "mean_loss": 3177.2799072265625,
      "epsilon": 0.44961200000134816
    },
    {
      "episode": 976,
      "score": 207,
      "reward": -876.0,
      "steps": 54,
      "mean_loss": 4065.1507213733817,
      "epsilon": 0.4495580000013496
    },
    {
      "episode": 977,
      "score": 91,
      "reward": -981.0,
      "steps": 38,
      "mean_loss": 3171.4966245952405,
      "epsilon": 0.4495200000013506
    },
    {
      "episode": 978,
      "score": 113,
      "reward": -954.0,
      "steps": 42,
      "mean_loss": 4355.679216203235,
      "epsilon": 0.44947800000135174
    },
    {
      "episode": 979,
      "score": 96,
      "reward": -989.0,
      "steps": 44,
      "mean_loss": 2849.4691890369763,
      "epsilon": 0.4494340000013529
    },
    {
      "episode": 980,
      "score": 211,
      "reward": -871.0,
      "steps": 58,
      "mean_loss": 4233.929267225594,
      "epsilon": 0.44937600000135447
    },
    {
      "episode": 981,
      "score": 201,
      "reward": -906.0,
      "steps": 56,
      "mean_loss": 4140.09820665632,
      "epsilon": 0.44932000000135597
    },
    {
      "episode": 982,
      "score": 119,
      "reward": -948.0,
      "steps": 42,
      "mean_loss": 3167.514424551101,
      "epsilon": 0.4492780000013571
    },
    {
      "episode": 983,
      "score": 267,
      "reward": -832.0,
      "steps": 69,
      "mean_loss": 3727.1940753218055,
      "epsilon": 0.44920900000135894
    },
    {
      "episode": 984,
      "score": 139,
      "reward": -935.0,
      "steps": 45,
      "mean_loss": 2716.82702738444,
      "epsilon": 0.44916400000136014
    },
    {
      "episode": 985,
      "score": 162,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 3600.601114078444,
      "epsilon": 0.44911500000136145
    },
    {
      "episode": 986,
      "score": 153,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 4205.6859813017,
      "epsilon": 0.4490640000013628
    },
    {
      "episode": 987,
      "score": 131,
      "reward": -930.0,
      "steps": 37,
      "mean_loss": 2087.7271264565957,
      "epsilon": 0.4490270000013638
    },
    {
      "episode": 988,
      "score": 122,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 3214.709340875799,
      "epsilon": 0.448983000001365
    },
    {
      "episode": 989,
      "score": 127,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 5278.926944039084,
      "epsilon": 0.44893900000136616
    },
    {
      "episode": 990,
      "score": 137,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 1462.8735823935651,
      "epsilon": 0.4488920000013674
    },
    {
      "episode": 991,
      "score": 103,
      "reward": -951.0,
      "steps": 38,
      "mean_loss": 3373.6961478183143,
      "epsilon": 0.44885400000136844
    },
    {
      "episode": 992,
      "score": 128,
      "reward": -943.0,
      "steps": 45,
      "mean_loss": 2630.804628245036,
      "epsilon": 0.44880900000136964
    },
    {
      "episode": 993,
      "score": 126,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 3718.9248202853732,
      "epsilon": 0.44876400000137084
    },
    {
      "episode": 994,
      "score": 106,
      "reward": -963.0,
      "steps": 36,
      "mean_loss": 4999.5667986339995,
      "epsilon": 0.4487280000013718
    },
    {
      "episode": 995,
      "score": 182,
      "reward": -908.0,
      "steps": 51,
      "mean_loss": 3543.7145444084617,
      "epsilon": 0.44867700000137317
    },
    {
      "episode": 996,
      "score": 135,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 4603.776260213649,
      "epsilon": 0.44863000000137443
    },
    {
      "episode": 997,
      "score": 152,
      "reward": -911.0,
      "steps": 47,
      "mean_loss": 4486.548074113562,
      "epsilon": 0.4485830000013757
    },
    {
      "episode": 998,
      "score": 201,
      "reward": -909.0,
      "steps": 55,
      "mean_loss": 4558.230891695889,
      "epsilon": 0.44852800000137716
    },
    {
      "episode": 999,
      "score": 183,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 6190.912505538376,
      "epsilon": 0.4484740000013786
    },
    {
      "episode": 1000,
      "score": 207,
      "reward": -876.0,
      "steps": 58,
      "mean_loss": 4530.771585793331,
      "epsilon": 0.44841600000138016
    },
    {
      "episode": 1001,
      "score": 156,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 2597.735600897606,
      "epsilon": 0.4483690000013814
    },
    {
      "episode": 1002,
      "score": 127,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 2684.4799985018644,
      "epsilon": 0.4483250000013826
    },
    {
      "episode": 1003,
      "score": 121,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 4605.847195538608,
      "epsilon": 0.44828100000138377
    },
    {
      "episode": 1004,
      "score": 82,
      "reward": -967.0,
      "steps": 33,
      "mean_loss": 5245.681202975186,
      "epsilon": 0.44824800000138465
    },
    {
      "episode": 1005,
      "score": 162,
      "reward": -914.0,
      "steps": 48,
      "mean_loss": 3553.597059249878,
      "epsilon": 0.44820000000138593
    },
    {
      "episode": 1006,
      "score": 170,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 5651.59139251709,
      "epsilon": 0.44815100000138725
    },
    {
      "episode": 1007,
      "score": 87,
      "reward": -988.0,
      "steps": 41,
      "mean_loss": 3294.0130901801876,
      "epsilon": 0.44811000000138834
    },
    {
      "episode": 1008,
      "score": 187,
      "reward": -895.0,
      "steps": 54,
      "mean_loss": 3200.662671830919,
      "epsilon": 0.4480560000013898
    },
    {
      "episode": 1009,
      "score": 201,
      "reward": -885.0,
      "steps": 54,
      "mean_loss": 4153.896550496419,
      "epsilon": 0.44800200000139123
    },
    {
      "episode": 1010,
      "score": 129,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 3642.1272113106465,
      "epsilon": 0.4479580000013924
    },
    {
      "episode": 1011,
      "score": 126,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 4036.0751297690654,
      "epsilon": 0.4479140000013936
    },
    {
      "episode": 1012,
      "score": 110,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 4627.019309811476,
      "epsilon": 0.4478730000013947
    },
    {
      "episode": 1013,
      "score": 141,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 3454.8603897094727,
      "epsilon": 0.44782600000139594
    },
    {
      "episode": 1014,
      "score": 160,
      "reward": -890.0,
      "steps": 45,
      "mean_loss": 3279.9529627482098,
      "epsilon": 0.44778100000139714
    },
    {
      "episode": 1015,
      "score": 103,
      "reward": -973.0,
      "steps": 43,
      "mean_loss": 3414.181676021842,
      "epsilon": 0.4477380000013983
    },
    {
      "episode": 1016,
      "score": 157,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 2165.3899111066544,
      "epsilon": 0.4476890000013996
    },
    {
      "episode": 1017,
      "score": 156,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 4940.436135312344,
      "epsilon": 0.44764200000140086
    },
    {
      "episode": 1018,
      "score": 210,
      "reward": -864.0,
      "steps": 56,
      "mean_loss": 3767.986683368683,
      "epsilon": 0.44758600000140236
    },
    {
      "episode": 1019,
      "score": 107,
      "reward": -973.0,
      "steps": 43,
      "mean_loss": 4052.6020827182506,
      "epsilon": 0.4475430000014035
    },
    {
      "episode": 1020,
      "score": 118,
      "reward": -937.0,
      "steps": 39,
      "mean_loss": 3723.4961057809683,
      "epsilon": 0.44750400000140456
    },
    {
      "episode": 1021,
      "score": 143,
      "reward": -921.0,
      "steps": 46,
      "mean_loss": 6137.5805274299955,
      "epsilon": 0.4474580000014058
    },
    {
      "episode": 1022,
      "score": 115,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 6317.156463623047,
      "epsilon": 0.44741400000140696
    },
    {
      "episode": 1023,
      "score": 81,
      "reward": -991.0,
      "steps": 37,
      "mean_loss": 6448.1426441089525,
      "epsilon": 0.44737700000140795
    },
    {
      "episode": 1024,
      "score": 129,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 3289.0059349060057,
      "epsilon": 0.44733200000140916
    },
    {
      "episode": 1025,
      "score": 110,
      "reward": -956.0,
      "steps": 42,
      "mean_loss": 3353.056636083694,
      "epsilon": 0.4472900000014103
    },
    {
      "episode": 1026,
      "score": 88,
      "reward": -979.0,
      "steps": 40,
      "mean_loss": 3633.0603387832643,
      "epsilon": 0.44725000000141135
    },
    {
      "episode": 1027,
      "score": 114,
      "reward": -959.0,
      "steps": 45,
      "mean_loss": 5060.142156304253,
      "epsilon": 0.44720500000141256
    },
    {
      "episode": 1028,
      "score": 129,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 6487.071381632487,
      "epsilon": 0.44716000000141376
    },
    {
      "episode": 1029,
      "score": 174,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 1532.9945654239295,
      "epsilon": 0.4471070000014152
    },
    {
      "episode": 1030,
      "score": 228,
      "reward": -863.0,
      "steps": 61,
      "mean_loss": 3619.090609441038,
      "epsilon": 0.4470460000014168
    },
    {
      "episode": 1031,
      "score": 189,
      "reward": -897.0,
      "steps": 51,
      "mean_loss": 5398.192658368279,
      "epsilon": 0.4469950000014182
    },
    {
      "episode": 1032,
      "score": 162,
      "reward": -928.0,
      "steps": 51,
      "mean_loss": 2121.8452432669847,
      "epsilon": 0.44694400000141954
    },
    {
      "episode": 1033,
      "score": 116,
      "reward": -949.0,
      "steps": 36,
      "mean_loss": 4260.974265840318,
      "epsilon": 0.4469080000014205
    },
    {
      "episode": 1034,
      "score": 122,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 5671.810105831065,
      "epsilon": 0.44686100000142176
    },
    {
      "episode": 1035,
      "score": 115,
      "reward": -973.0,
      "steps": 45,
      "mean_loss": 2284.06357421875,
      "epsilon": 0.44681600000142296
    },
    {
      "episode": 1036,
      "score": 199,
      "reward": -901.0,
      "steps": 56,
      "mean_loss": 4623.247278213501,
      "epsilon": 0.44676000000142446
    },
    {
      "episode": 1037,
      "score": 282,
      "reward": -827.0,
      "steps": 68,
      "mean_loss": 6113.91340339885,
      "epsilon": 0.4466920000014263
    },
    {
      "episode": 1038,
      "score": 92,
      "reward": -982.0,
      "steps": 40,
      "mean_loss": 3519.322801208496,
      "epsilon": 0.44665200000142735
    },
    {
      "episode": 1039,
      "score": 159,
      "reward": -904.0,
      "steps": 47,
      "mean_loss": 4520.439918842721,
      "epsilon": 0.4466050000014286
    },
    {
      "episode": 1040,
      "score": 150,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 2903.3035030754245,
      "epsilon": 0.4465560000014299
    },
    {
      "episode": 1041,
      "score": 161,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 3432.4683410046146,
      "epsilon": 0.4465050000014313
    },
    {
      "episode": 1042,
      "score": 144,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 5528.956514773162,
      "epsilon": 0.4464590000014325
    },
    {
      "episode": 1043,
      "score": 177,
      "reward": -897.0,
      "steps": 51,
      "mean_loss": 5313.661585489909,
      "epsilon": 0.4464080000014339
    },
    {
      "episode": 1044,
      "score": 198,
      "reward": -890.0,
      "steps": 57,
      "mean_loss": 2927.048018137614,
      "epsilon": 0.4463510000014354
    },
    {
      "episode": 1045,
      "score": 242,
      "reward": -863.0,
      "steps": 62,
      "mean_loss": 3311.3450793604698,
      "epsilon": 0.44628900000143706
    },
    {
      "episode": 1046,
      "score": 110,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 3077.2580701654606,
      "epsilon": 0.44624500000143824
    },
    {
      "episode": 1047,
      "score": 168,
      "reward": -915.0,
      "steps": 54,
      "mean_loss": 4872.258486500493,
      "epsilon": 0.4461910000014397
    },
    {
      "episode": 1048,
      "score": 148,
      "reward": -923.0,
      "steps": 47,
      "mean_loss": 4857.925411427274,
      "epsilon": 0.44614400000144094
    },
    {
      "episode": 1049,
      "score": 195,
      "reward": -893.0,
      "steps": 53,
      "mean_loss": 4403.486412192291,
      "epsilon": 0.44609100000144236
    },
    {
      "episode": 1050,
      "score": 121,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 4585.453041943637,
      "epsilon": 0.44604700000144354
    },
    {
      "episode": 1051,
      "score": 60,
      "reward": -1011.0,
      "steps": 36,
      "mean_loss": 4443.472378836737,
      "epsilon": 0.4460110000014445
    },
    {
      "episode": 1052,
      "score": 95,
      "reward": -974.0,
      "steps": 38,
      "mean_loss": 3605.59613328231,
      "epsilon": 0.4459730000014455
    },
    {
      "episode": 1053,
      "score": 112,
      "reward": -952.0,
      "steps": 39,
      "mean_loss": 6146.572936131404,
      "epsilon": 0.44593400000144656
    },
    {
      "episode": 1054,
      "score": 196,
      "reward": -897.0,
      "steps": 56,
      "mean_loss": 6136.511187825884,
      "epsilon": 0.44587800000144806
    },
    {
      "episode": 1055,
      "score": 210,
      "reward": -870.0,
      "steps": 56,
      "mean_loss": 4502.908240727016,
      "epsilon": 0.44582200000144956
    },
    {
      "episode": 1056,
      "score": 125,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 2196.7622507268734,
      "epsilon": 0.44577800000145074
    },
    {
      "episode": 1057,
      "score": 137,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 5813.131157895352,
      "epsilon": 0.445731000001452
    },
    {
      "episode": 1058,
      "score": 143,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 4232.981052745472,
      "epsilon": 0.44568700000145317
    },
    {
      "episode": 1059,
      "score": 79,
      "reward": -976.0,
      "steps": 35,
      "mean_loss": 2841.965018572126,
      "epsilon": 0.4456520000014541
    },
    {
      "episode": 1060,
      "score": 193,
      "reward": -893.0,
      "steps": 55,
      "mean_loss": 4281.268872070313,
      "epsilon": 0.4455970000014556
    },
    {
      "episode": 1061,
      "score": 127,
      "reward": -927.0,
      "steps": 40,
      "mean_loss": 4021.2166179656983,
      "epsilon": 0.44555700000145665
    },
    {
      "episode": 1062,
      "score": 184,
      "reward": -905.0,
      "steps": 52,
      "mean_loss": 3816.8219529665434,
      "epsilon": 0.44550500000145804
    },
    {
      "episode": 1063,
      "score": 124,
      "reward": -936.0,
      "steps": 39,
      "mean_loss": 4822.680446037879,
      "epsilon": 0.4454660000014591
    },
    {
      "episode": 1064,
      "score": 128,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 3803.1546065590596,
      "epsilon": 0.44542200000146026
    },
    {
      "episode": 1065,
      "score": 240,
      "reward": -862.0,
      "steps": 60,
      "mean_loss": 2511.368087005615,
      "epsilon": 0.44536200000146187
    },
    {
      "episode": 1066,
      "score": 126,
      "reward": -935.0,
      "steps": 44,
      "mean_loss": 3256.396878675981,
      "epsilon": 0.44531800000146304
    },
    {
      "episode": 1067,
      "score": 151,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 4698.190001446268,
      "epsilon": 0.4452720000014643
    },
    {
      "episode": 1068,
      "score": 100,
      "reward": -973.0,
      "steps": 41,
      "mean_loss": 2354.909486165861,
      "epsilon": 0.44523100000146537
    },
    {
      "episode": 1069,
      "score": 110,
      "reward": -967.0,
      "steps": 45,
      "mean_loss": 4805.767912462023,
      "epsilon": 0.4451860000014666
    },
    {
      "episode": 1070,
      "score": 109,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 3037.7583977092395,
      "epsilon": 0.44514200000146775
    },
    {
      "episode": 1071,
      "score": 176,
      "reward": -912.0,
      "steps": 53,
      "mean_loss": 4706.428185229031,
      "epsilon": 0.44508900000146917
    },
    {
      "episode": 1072,
      "score": 183,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 3634.077910105387,
      "epsilon": 0.4450350000014706
    },
    {
      "episode": 1073,
      "score": 192,
      "reward": -866.0,
      "steps": 49,
      "mean_loss": 5354.511545920858,
      "epsilon": 0.4449860000014719
    },
    {
      "episode": 1074,
      "score": 106,
      "reward": -966.0,
      "steps": 42,
      "mean_loss": 5099.218871162051,
      "epsilon": 0.44494400000147305
    },
    {
      "episode": 1075,
      "score": 91,
      "reward": -982.0,
      "steps": 40,
      "mean_loss": 4246.431121826172,
      "epsilon": 0.4449040000014741
    },
    {
      "episode": 1076,
      "score": 129,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 4433.09745684537,
      "epsilon": 0.4448600000014753
    },
    {
      "episode": 1077,
      "score": 82,
      "reward": -977.0,
      "steps": 38,
      "mean_loss": 2570.0209216067665,
      "epsilon": 0.4448220000014763
    },
    {
      "episode": 1078,
      "score": 226,
      "reward": -882.0,
      "steps": 60,
      "mean_loss": 2881.442033513387,
      "epsilon": 0.4447620000014779
    },
    {
      "episode": 1079,
      "score": 96,
      "reward": -976.0,
      "steps": 44,
      "mean_loss": 5822.604897238992,
      "epsilon": 0.4447180000014791
    },
    {
      "episode": 1080,
      "score": 164,
      "reward": -916.0,
      "steps": 51,
      "mean_loss": 1970.1008798935834,
      "epsilon": 0.44466700000148046
    },
    {
      "episode": 1081,
      "score": 135,
      "reward": -948.0,
      "steps": 49,
      "mean_loss": 3889.886949811663,
      "epsilon": 0.4446180000014818
    },
    {
      "episode": 1082,
      "score": 144,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 2683.7432129230906,
      "epsilon": 0.44457100000148303
    },
    {
      "episode": 1083,
      "score": 139,
      "reward": -925.0,
      "steps": 40,
      "mean_loss": 3371.5618286132812,
      "epsilon": 0.4445310000014841
    },
    {
      "episode": 1084,
      "score": 253,
      "reward": -859.0,
      "steps": 62,
      "mean_loss": 5724.396635117069,
      "epsilon": 0.44446900000148576
    },
    {
      "episode": 1085,
      "score": 203,
      "reward": -872.0,
      "steps": 53,
      "mean_loss": 3046.7060758482735,
      "epsilon": 0.4444160000014872
    },
    {
      "episode": 1086,
      "score": 183,
      "reward": -894.0,
      "steps": 52,
      "mean_loss": 4835.362878946157,
      "epsilon": 0.44436400000148857
    },
    {
      "episode": 1087,
      "score": 137,
      "reward": -944.0,
      "steps": 46,
      "mean_loss": 3085.8203463347063,
      "epsilon": 0.4443180000014898
    },
    {
      "episode": 1088,
      "score": 185,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 2918.9639361454892,
      "epsilon": 0.4442660000014912
    },
    {
      "episode": 1089,
      "score": 159,
      "reward": -927.0,
      "steps": 51,
      "mean_loss": 3102.9641961490406,
      "epsilon": 0.44421500000149255
    },
    {
      "episode": 1090,
      "score": 138,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 4067.4342431413365,
      "epsilon": 0.4441680000014938
    },
    {
      "episode": 1091,
      "score": 96,
      "reward": -968.0,
      "steps": 39,
      "mean_loss": 2307.4072224543643,
      "epsilon": 0.44412900000149486
    },
    {
      "episode": 1092,
      "score": 103,
      "reward": -968.0,
      "steps": 38,
      "mean_loss": 6877.009925039191,
      "epsilon": 0.4440910000014959
    },
    {
      "episode": 1093,
      "score": 213,
      "reward": -867.0,
      "steps": 53,
      "mean_loss": 3225.1273186161834,
      "epsilon": 0.4440380000014973
    },
    {
      "episode": 1094,
      "score": 95,
      "reward": -974.0,
      "steps": 43,
      "mean_loss": 6677.196054857831,
      "epsilon": 0.44399500000149844
    },
    {
      "episode": 1095,
      "score": 185,
      "reward": -888.0,
      "steps": 49,
      "mean_loss": 5196.088882134885,
      "epsilon": 0.44394600000149975
    },
    {
      "episode": 1096,
      "score": 151,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 8146.8519582545505,
      "epsilon": 0.443899000001501
    },
    {
      "episode": 1097,
      "score": 146,
      "reward": -920.0,
      "steps": 47,
      "mean_loss": 4692.185829487253,
      "epsilon": 0.44385200000150227
    },
    {
      "episode": 1098,
      "score": 210,
      "reward": -872.0,
      "steps": 57,
      "mean_loss": 3550.2959159717225,
      "epsilon": 0.4437950000015038
    },
    {
      "episode": 1099,
      "score": 135,
      "reward": -929.0,
      "steps": 45,
      "mean_loss": 2288.695451778836,
      "epsilon": 0.443750000001505
    },
    {
      "episode": 1100,
      "score": 117,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 2998.7059483961625,
      "epsilon": 0.4437060000015062
    },
    {
      "episode": 1101,
      "score": 159,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 4092.331241226196,
      "epsilon": 0.4436560000015075
    },
    {
      "episode": 1102,
      "score": 124,
      "reward": -955.0,
      "steps": 45,
      "mean_loss": 3906.4086401197646,
      "epsilon": 0.4436110000015087
    },
    {
      "episode": 1103,
      "score": 225,
      "reward": -880.0,
      "steps": 59,
      "mean_loss": 3504.2445187326207,
      "epsilon": 0.4435520000015103
    },
    {
      "episode": 1104,
      "score": 172,
      "reward": -926.0,
      "steps": 53,
      "mean_loss": 4309.283794331101,
      "epsilon": 0.4434990000015117
    },
    {
      "episode": 1105,
      "score": 246,
      "reward": -846.0,
      "steps": 63,
      "mean_loss": 5120.202290368458,
      "epsilon": 0.4434360000015134
    },
    {
      "episode": 1106,
      "score": 256,
      "reward": -840.0,
      "steps": 63,
      "mean_loss": 4025.6456926133897,
      "epsilon": 0.4433730000015151
    },
    {
      "episode": 1107,
      "score": 99,
      "reward": -953.0,
      "steps": 37,
      "mean_loss": 4614.265434471336,
      "epsilon": 0.4433360000015161
    },
    {
      "episode": 1108,
      "score": 259,
      "reward": -853.0,
      "steps": 64,
      "mean_loss": 4077.0778485536575,
      "epsilon": 0.4432720000015178
    },
    {
      "episode": 1109,
      "score": 126,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 5417.898929249157,
      "epsilon": 0.44322800000151896
    },
    {
      "episode": 1110,
      "score": 136,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 2806.25597485629,
      "epsilon": 0.44318400000152014
    },
    {
      "episode": 1111,
      "score": 53,
      "reward": -1003.0,
      "steps": 31,
      "mean_loss": 2804.6037756396877,
      "epsilon": 0.44315300000152097
    },
    {
      "episode": 1112,
      "score": 237,
      "reward": -862.0,
      "steps": 61,
      "mean_loss": 5393.1981588895205,
      "epsilon": 0.4430920000015226
    },
    {
      "episode": 1113,
      "score": 179,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 2366.4169757080076,
      "epsilon": 0.44304200000152394
    },
    {
      "episode": 1114,
      "score": 189,
      "reward": -888.0,
      "steps": 51,
      "mean_loss": 3804.0333461387486,
      "epsilon": 0.4429910000015253
    },
    {
      "episode": 1115,
      "score": 153,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 3246.9587770843505,
      "epsilon": 0.44294100000152664
    },
    {
      "episode": 1116,
      "score": 140,
      "reward": -912.0,
      "steps": 44,
      "mean_loss": 3766.286794315685,
      "epsilon": 0.4428970000015278
    },
    {
      "episode": 1117,
      "score": 173,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 3863.0559331453765,
      "epsilon": 0.4428450000015292
    },
    {
      "episode": 1118,
      "score": 138,
      "reward": -927.0,
      "steps": 44,
      "mean_loss": 3919.447190111334,
      "epsilon": 0.4428010000015304
    },
    {
      "episode": 1119,
      "score": 183,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 2814.061624820416,
      "epsilon": 0.4427490000015318
    },
    {
      "episode": 1120,
      "score": 162,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 5348.63906829834,
      "epsilon": 0.4426990000015331
    },
    {
      "episode": 1121,
      "score": 136,
      "reward": -945.0,
      "steps": 47,
      "mean_loss": 4272.729814732328,
      "epsilon": 0.4426520000015344
    },
    {
      "episode": 1122,
      "score": 246,
      "reward": -854.0,
      "steps": 65,
      "mean_loss": 3247.5328946040227,
      "epsilon": 0.4425870000015361
    },
    {
      "episode": 1123,
      "score": 100,
      "reward": -969.0,
      "steps": 40,
      "mean_loss": 4875.569030570984,
      "epsilon": 0.4425470000015372
    },
    {
      "episode": 1124,
      "score": 90,
      "reward": -981.0,
      "steps": 36,
      "mean_loss": 3250.7999159495034,
      "epsilon": 0.44251100000153815
    },
    {
      "episode": 1125,
      "score": 241,
      "reward": -867.0,
      "steps": 62,
      "mean_loss": 3377.3583163599815,
      "epsilon": 0.4424490000015398
    },
    {
      "episode": 1126,
      "score": 100,
      "reward": -953.0,
      "steps": 36,
      "mean_loss": 4042.720456653171,
      "epsilon": 0.44241300000154077
    },
    {
      "episode": 1127,
      "score": 153,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 4309.715830588827,
      "epsilon": 0.4423640000015421
    },
    {
      "episode": 1128,
      "score": 184,
      "reward": -901.0,
      "steps": 53,
      "mean_loss": 4210.073556288234,
      "epsilon": 0.4423110000015435
    },
    {
      "episode": 1129,
      "score": 141,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 3280.187486012777,
      "epsilon": 0.4422630000015448
    },
    {
      "episode": 1130,
      "score": 144,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 5071.8792828499,
      "epsilon": 0.44221600000154604
    },
    {
      "episode": 1131,
      "score": 110,
      "reward": -956.0,
      "steps": 43,
      "mean_loss": 2864.8270506747936,
      "epsilon": 0.4421730000015472
    },
    {
      "episode": 1132,
      "score": 165,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 3794.260803604126,
      "epsilon": 0.4421230000015485
    },
    {
      "episode": 1133,
      "score": 163,
      "reward": -914.0,
      "steps": 47,
      "mean_loss": 3283.753210189495,
      "epsilon": 0.4420760000015498
    },
    {
      "episode": 1134,
      "score": 274,
      "reward": -822.0,
      "steps": 65,
      "mean_loss": 5333.0141114455,
      "epsilon": 0.4420110000015515
    },
    {
      "episode": 1135,
      "score": 151,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 3154.5965826156294,
      "epsilon": 0.4419640000015528
    },
    {
      "episode": 1136,
      "score": 145,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 6387.38233483356,
      "epsilon": 0.441918000001554
    },
    {
      "episode": 1137,
      "score": 263,
      "reward": -841.0,
      "steps": 64,
      "mean_loss": 7979.500864863396,
      "epsilon": 0.4418540000015557
    },
    {
      "episode": 1138,
      "score": 116,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 3509.4398996179752,
      "epsilon": 0.4418100000015569
    },
    {
      "episode": 1139,
      "score": 176,
      "reward": -885.0,
      "steps": 48,
      "mean_loss": 4447.524076461792,
      "epsilon": 0.4417620000015582
    },
    {
      "episode": 1140,
      "score": 136,
      "reward": -935.0,
      "steps": 44,
      "mean_loss": 2044.8234351765025,
      "epsilon": 0.44171800000155936
    },
    {
      "episode": 1141,
      "score": 153,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 2994.86464553833,
      "epsilon": 0.4416680000015607
    },
    {
      "episode": 1142,
      "score": 155,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 1726.8084301238364,
      "epsilon": 0.44162100000156196
    },
    {
      "episode": 1143,
      "score": 109,
      "reward": -967.0,
      "steps": 42,
      "mean_loss": 4860.578309831165,
      "epsilon": 0.4415790000015631
    },
    {
      "episode": 1144,
      "score": 167,
      "reward": -902.0,
      "steps": 49,
      "mean_loss": 2867.746401183459,
      "epsilon": 0.4415300000015644
    },
    {
      "episode": 1145,
      "score": 259,
      "reward": -849.0,
      "steps": 67,
      "mean_loss": 2816.2552187336023,
      "epsilon": 0.4414630000015662
    },
    {
      "episode": 1146,
      "score": 174,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 4728.727738290463,
      "epsilon": 0.4414100000015676
    },
    {
      "episode": 1147,
      "score": 115,
      "reward": -951.0,
      "steps": 43,
      "mean_loss": 3445.6886903629747,
      "epsilon": 0.44136700000156875
    },
    {
      "episode": 1148,
      "score": 126,
      "reward": -955.0,
      "steps": 45,
      "mean_loss": 1578.099358622233,
      "epsilon": 0.44132200000156996
    },
    {
      "episode": 1149,
      "score": 185,
      "reward": -904.0,
      "steps": 55,
      "mean_loss": 2198.4535163185815,
      "epsilon": 0.44126700000157143
    },
    {
      "episode": 1150,
      "score": 153,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 2949.380885996717,
      "epsilon": 0.4412200000015727
    },
    {
      "episode": 1151,
      "score": 158,
      "reward": -920.0,
      "steps": 51,
      "mean_loss": 2138.3868010277843,
      "epsilon": 0.44116900000157405
    },
    {
      "episode": 1152,
      "score": 77,
      "reward": -986.0,
      "steps": 36,
      "mean_loss": 3702.7956635157266,
      "epsilon": 0.441133000001575
    },
    {
      "episode": 1153,
      "score": 200,
      "reward": -899.0,
      "steps": 56,
      "mean_loss": 4630.305005822863,
      "epsilon": 0.4410770000015765
    },
    {
      "episode": 1154,
      "score": 195,
      "reward": -878.0,
      "steps": 54,
      "mean_loss": 4565.476180465133,
      "epsilon": 0.44102300000157796
    },
    {
      "episode": 1155,
      "score": 162,
      "reward": -900.0,
      "steps": 47,
      "mean_loss": 2742.969733299093,
      "epsilon": 0.4409760000015792
    },
    {
      "episode": 1156,
      "score": 158,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 1983.56239402771,
      "epsilon": 0.44092600000158055
    },
    {
      "episode": 1157,
      "score": 91,
      "reward": -987.0,
      "steps": 42,
      "mean_loss": 1601.6547700791132,
      "epsilon": 0.4408840000015817
    },
    {
      "episode": 1158,
      "score": 77,
      "reward": -989.0,
      "steps": 37,
      "mean_loss": 6867.348708487846,
      "epsilon": 0.44084700000158267
    },
    {
      "episode": 1159,
      "score": 125,
      "reward": -947.0,
      "steps": 46,
      "mean_loss": 1823.9264845640762,
      "epsilon": 0.4408010000015839
    },
    {
      "episode": 1160,
      "score": 220,
      "reward": -865.0,
      "steps": 59,
      "mean_loss": 4072.273836685439,
      "epsilon": 0.4407420000015855
    },
    {
      "episode": 1161,
      "score": 87,
      "reward": -986.0,
      "steps": 37,
      "mean_loss": 5166.092362687395,
      "epsilon": 0.44070500000158647
    },
    {
      "episode": 1162,
      "score": 81,
      "reward": -991.0,
      "steps": 36,
      "mean_loss": 6089.740763770209,
      "epsilon": 0.44066900000158743
    },
    {
      "episode": 1163,
      "score": 97,
      "reward": -971.0,
      "steps": 40,
      "mean_loss": 5961.8118885040285,
      "epsilon": 0.4406290000015885
    },
    {
      "episode": 1164,
      "score": 136,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 4124.70592157046,
      "epsilon": 0.4405810000015898
    },
    {
      "episode": 1165,
      "score": 161,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3221.7350930606617,
      "epsilon": 0.44053000000159115
    },
    {
      "episode": 1166,
      "score": 74,
      "reward": -986.0,
      "steps": 35,
      "mean_loss": 2778.072318812779,
      "epsilon": 0.4404950000015921
    },
    {
      "episode": 1167,
      "score": 139,
      "reward": -935.0,
      "steps": 40,
      "mean_loss": 5405.090345954895,
      "epsilon": 0.44045500000159316
    },
    {
      "episode": 1168,
      "score": 240,
      "reward": -865.0,
      "steps": 63,
      "mean_loss": 2924.0313078865174,
      "epsilon": 0.44039200000159484
    },
    {
      "episode": 1169,
      "score": 147,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 3258.2259257569604,
      "epsilon": 0.44034300000159615
    },
    {
      "episode": 1170,
      "score": 96,
      "reward": -965.0,
      "steps": 41,
      "mean_loss": 4472.983577076981,
      "epsilon": 0.44030200000159725
    },
    {
      "episode": 1171,
      "score": 94,
      "reward": -972.0,
      "steps": 39,
      "mean_loss": 1162.3951924641926,
      "epsilon": 0.4402630000015983
    },
    {
      "episode": 1172,
      "score": 82,
      "reward": -988.0,
      "steps": 39,
      "mean_loss": 3456.2724646543843,
      "epsilon": 0.44022400000159934
    },
    {
      "episode": 1173,
      "score": 90,
      "reward": -966.0,
      "steps": 40,
      "mean_loss": 5412.495971298218,
      "epsilon": 0.4401840000016004
    },
    {
      "episode": 1174,
      "score": 186,
      "reward": -880.0,
      "steps": 51,
      "mean_loss": 3673.635810253667,
      "epsilon": 0.44013300000160177
    },
    {
      "episode": 1175,
      "score": 97,
      "reward": -971.0,
      "steps": 42,
      "mean_loss": 3052.72726949056,
      "epsilon": 0.4400910000016029
    },
    {
      "episode": 1176,
      "score": 171,
      "reward": -899.0,
      "steps": 51,
      "mean_loss": 1987.494800642425,
      "epsilon": 0.44004000000160426
    },
    {
      "episode": 1177,
      "score": 198,
      "reward": -902.0,
      "steps": 55,
      "mean_loss": 3322.402410749956,
      "epsilon": 0.43998500000160573
    },
    {
      "episode": 1178,
      "score": 99,
      "reward": -971.0,
      "steps": 41,
      "mean_loss": 7584.53203806063,
      "epsilon": 0.4399440000016068
    },
    {
      "episode": 1179,
      "score": 159,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 2977.8606558819206,
      "epsilon": 0.43989500000160814
    },
    {
      "episode": 1180,
      "score": 215,
      "reward": -879.0,
      "steps": 57,
      "mean_loss": 4387.049142670213,
      "epsilon": 0.43983800000160966
    },
    {
      "episode": 1181,
      "score": 147,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 5228.220047619878,
      "epsilon": 0.439789000001611
    },
    {
      "episode": 1182,
      "score": 146,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 5109.146610736847,
      "epsilon": 0.43974100000161226
    },
    {
      "episode": 1183,
      "score": 148,
      "reward": -924.0,
      "steps": 42,
      "mean_loss": 4910.977483840215,
      "epsilon": 0.4396990000016134
    },
    {
      "episode": 1184,
      "score": 77,
      "reward": -985.0,
      "steps": 36,
      "mean_loss": 7831.1004026201035,
      "epsilon": 0.43966300000161435
    },
    {
      "episode": 1185,
      "score": 110,
      "reward": -954.0,
      "steps": 41,
      "mean_loss": 4966.170440673828,
      "epsilon": 0.43962200000161544
    },
    {
      "episode": 1186,
      "score": 93,
      "reward": -968.0,
      "steps": 38,
      "mean_loss": 4591.11162868299,
      "epsilon": 0.43958400000161646
    },
    {
      "episode": 1187,
      "score": 268,
      "reward": -825.0,
      "steps": 66,
      "mean_loss": 5044.7402528705015,
      "epsilon": 0.4395180000016182
    },
    {
      "episode": 1188,
      "score": 136,
      "reward": -929.0,
      "steps": 47,
      "mean_loss": 3761.2936747124854,
      "epsilon": 0.4394710000016195
    },
    {
      "episode": 1189,
      "score": 142,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 3910.5533959524973,
      "epsilon": 0.4394220000016208
    },
    {
      "episode": 1190,
      "score": 112,
      "reward": -943.0,
      "steps": 40,
      "mean_loss": 6376.256435012818,
      "epsilon": 0.43938200000162186
    },
    {
      "episode": 1191,
      "score": 201,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 4919.953172454834,
      "epsilon": 0.4393320000016232
    },
    {
      "episode": 1192,
      "score": 257,
      "reward": -868.0,
      "steps": 67,
      "mean_loss": 3799.3761294920055,
      "epsilon": 0.439265000001625
    },
    {
      "episode": 1193,
      "score": 145,
      "reward": -935.0,
      "steps": 48,
      "mean_loss": 3337.4189915657043,
      "epsilon": 0.4392170000016263
    },
    {
      "episode": 1194,
      "score": 153,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 3443.54425282381,
      "epsilon": 0.4391680000016276
    },
    {
      "episode": 1195,
      "score": 45,
      "reward": -994.0,
      "steps": 25,
      "mean_loss": 7533.716109008789,
      "epsilon": 0.43914300000162826
    },
    {
      "episode": 1196,
      "score": 142,
      "reward": -919.0,
      "steps": 40,
      "mean_loss": 3024.6301168441773,
      "epsilon": 0.43910300000162933
    },
    {
      "episode": 1197,
      "score": 149,
      "reward": -944.0,
      "steps": 50,
      "mean_loss": 6739.907874908447,
      "epsilon": 0.43905300000163067
    },
    {
      "episode": 1198,
      "score": 231,
      "reward": -870.0,
      "steps": 58,
      "mean_loss": 4725.218694884202,
      "epsilon": 0.4389950000016322
    },
    {
      "episode": 1199,
      "score": 148,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 3074.6007772528606,
      "epsilon": 0.43894900000163345
    },
    {
      "episode": 1200,
      "score": 172,
      "reward": -912.0,
      "steps": 50,
      "mean_loss": 3525.0101736068727,
      "epsilon": 0.4388990000016348
    },
    {
      "episode": 1201,
      "score": 157,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 3350.7227702238124,
      "epsilon": 0.4388500000016361
    },
    {
      "episode": 1202,
      "score": 134,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 2171.169829185973,
      "epsilon": 0.43880300000163736
    },
    {
      "episode": 1203,
      "score": 87,
      "reward": -962.0,
      "steps": 33,
      "mean_loss": 5493.928841793176,
      "epsilon": 0.43877000000163824
    },
    {
      "episode": 1204,
      "score": 131,
      "reward": -944.0,
      "steps": 41,
      "mean_loss": 2561.957527253686,
      "epsilon": 0.43872900000163934
    },
    {
      "episode": 1205,
      "score": 113,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 6498.113414578322,
      "epsilon": 0.43868800000164043
    },
    {
      "episode": 1206,
      "score": 152,
      "reward": -920.0,
      "steps": 45,
      "mean_loss": 3465.0042165120444,
      "epsilon": 0.43864300000164164
    },
    {
      "episode": 1207,
      "score": 166,
      "reward": -921.0,
      "steps": 51,
      "mean_loss": 4174.360243404612,
      "epsilon": 0.438592000001643
    },
    {
      "episode": 1208,
      "score": 160,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 4178.398953496194,
      "epsilon": 0.4385430000016443
    },
    {
      "episode": 1209,
      "score": 91,
      "reward": -984.0,
      "steps": 43,
      "mean_loss": 3987.5778602777527,
      "epsilon": 0.43850000000164546
    },
    {
      "episode": 1210,
      "score": 50,
      "reward": -1011.0,
      "steps": 32,
      "mean_loss": 5016.418266296387,
      "epsilon": 0.4384680000016463
    },
    {
      "episode": 1211,
      "score": 117,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 2947.0475620269776,
      "epsilon": 0.4384280000016474
    },
    {
      "episode": 1212,
      "score": 61,
      "reward": -1009.0,
      "steps": 37,
      "mean_loss": 2850.8512437150284,
      "epsilon": 0.4383910000016484
    },
    {
      "episode": 1213,
      "score": 124,
      "reward": -947.0,
      "steps": 46,
      "mean_loss": 3739.141464482183,
      "epsilon": 0.4383450000016496
    },
    {
      "episode": 1214,
      "score": 66,
      "reward": -994.0,
      "steps": 33,
      "mean_loss": 3350.711175167199,
      "epsilon": 0.4383120000016505
    },
    {
      "episode": 1215,
      "score": 151,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 5338.026934035281,
      "epsilon": 0.43826500000165175
    },
    {
      "episode": 1216,
      "score": 150,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 4750.65018264107,
      "epsilon": 0.438219000001653
    },
    {
      "episode": 1217,
      "score": 94,
      "reward": -972.0,
      "steps": 39,
      "mean_loss": 7920.100106263772,
      "epsilon": 0.438180000001654
    },
    {
      "episode": 1218,
      "score": 155,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 3704.187226640417,
      "epsilon": 0.4381330000016553
    },
    {
      "episode": 1219,
      "score": 123,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 2806.0254152987864,
      "epsilon": 0.43808600000165654
    },
    {
      "episode": 1220,
      "score": 91,
      "reward": -977.0,
      "steps": 36,
      "mean_loss": 5537.1071008046465,
      "epsilon": 0.4380500000016575
    },
    {
      "episode": 1221,
      "score": 192,
      "reward": -903.0,
      "steps": 55,
      "mean_loss": 5406.915468389338,
      "epsilon": 0.437995000001659
    },
    {
      "episode": 1222,
      "score": 167,
      "reward": -902.0,
      "steps": 47,
      "mean_loss": 4999.056234806142,
      "epsilon": 0.43794800000166023
    },
    {
      "episode": 1223,
      "score": 162,
      "reward": -912.0,
      "steps": 48,
      "mean_loss": 3984.8238763809204,
      "epsilon": 0.4379000000016615
    },
    {
      "episode": 1224,
      "score": 138,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 5391.672074027683,
      "epsilon": 0.43785400000166275
    },
    {
      "episode": 1225,
      "score": 140,
      "reward": -950.0,
      "steps": 46,
      "mean_loss": 6396.345123788585,
      "epsilon": 0.437808000001664
    },
    {
      "episode": 1226,
      "score": 98,
      "reward": -976.0,
      "steps": 43,
      "mean_loss": 5660.892266916674,
      "epsilon": 0.4377650000016651
    },
    {
      "episode": 1227,
      "score": 231,
      "reward": -876.0,
      "steps": 61,
      "mean_loss": 3743.4401510269918,
      "epsilon": 0.43770400000166676
    },
    {
      "episode": 1228,
      "score": 142,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 4454.336986956389,
      "epsilon": 0.437658000001668
    },
    {
      "episode": 1229,
      "score": 111,
      "reward": -959.0,
      "steps": 41,
      "mean_loss": 2380.887624973204,
      "epsilon": 0.4376170000016691
    },
    {
      "episode": 1230,
      "score": 122,
      "reward": -939.0,
      "steps": 43,
      "mean_loss": 1558.824761058009,
      "epsilon": 0.43757400000167024
    },
    {
      "episode": 1231,
      "score": 121,
      "reward": -927.0,
      "steps": 41,
      "mean_loss": 4544.656009953196,
      "epsilon": 0.43753300000167133
    },
    {
      "episode": 1232,
      "score": 241,
      "reward": -863.0,
      "steps": 61,
      "mean_loss": 4633.327013109551,
      "epsilon": 0.43747200000167297
    },
    {
      "episode": 1233,
      "score": 176,
      "reward": -898.0,
      "steps": 51,
      "mean_loss": 2661.059669868619,
      "epsilon": 0.43742100000167433
    },
    {
      "episode": 1234,
      "score": 124,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 5521.62830768932,
      "epsilon": 0.4373770000016755
    },
    {
      "episode": 1235,
      "score": 134,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 7225.99614218007,
      "epsilon": 0.43733100000167674
    },
    {
      "episode": 1236,
      "score": 120,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 5873.668346405029,
      "epsilon": 0.4372870000016779
    },
    {
      "episode": 1237,
      "score": 102,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 4235.217741966248,
      "epsilon": 0.4372430000016791
    },
    {
      "episode": 1238,
      "score": 173,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 4218.674714601957,
      "epsilon": 0.4371910000016805
    },
    {
      "episode": 1239,
      "score": 178,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 3540.556882019043,
      "epsilon": 0.4371410000016818
    },
    {
      "episode": 1240,
      "score": 104,
      "reward": -958.0,
      "steps": 40,
      "mean_loss": 1969.138976097107,
      "epsilon": 0.4371010000016829
    },
    {
      "episode": 1241,
      "score": 247,
      "reward": -842.0,
      "steps": 62,
      "mean_loss": 4168.047284157045,
      "epsilon": 0.43703900000168455
    },
    {
      "episode": 1242,
      "score": 144,
      "reward": -943.0,
      "steps": 49,
      "mean_loss": 4606.326043109504,
      "epsilon": 0.43699000000168586
    },
    {
      "episode": 1243,
      "score": 109,
      "reward": -969.0,
      "steps": 40,
      "mean_loss": 3931.4517766952513,
      "epsilon": 0.43695000000168693
    },
    {
      "episode": 1244,
      "score": 90,
      "reward": -981.0,
      "steps": 37,
      "mean_loss": 5535.646033828323,
      "epsilon": 0.4369130000016879
    },
    {
      "episode": 1245,
      "score": 100,
      "reward": -981.0,
      "steps": 44,
      "mean_loss": 5828.630093314431,
      "epsilon": 0.4368690000016891
    },
    {
      "episode": 1246,
      "score": 160,
      "reward": -934.0,
      "steps": 50,
      "mean_loss": 3993.9940076446533,
      "epsilon": 0.43681900000169044
    },
    {
      "episode": 1247,
      "score": 88,
      "reward": -960.0,
      "steps": 33,
      "mean_loss": 4852.670206012148,
      "epsilon": 0.4367860000016913
    },
    {
      "episode": 1248,
      "score": 92,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 2732.3040711686417,
      "epsilon": 0.4367490000016923
    },
    {
      "episode": 1249,
      "score": 121,
      "reward": -947.0,
      "steps": 41,
      "mean_loss": 5366.132774911276,
      "epsilon": 0.4367080000016934
    },
    {
      "episode": 1250,
      "score": 118,
      "reward": -962.0,
      "steps": 46,
      "mean_loss": 3915.5895875018577,
      "epsilon": 0.43666200000169464
    },
    {
      "episode": 1251,
      "score": 199,
      "reward": -893.0,
      "steps": 57,
      "mean_loss": 5314.592075816372,
      "epsilon": 0.43660500000169616
    },
    {
      "episode": 1252,
      "score": 80,
      "reward": -985.0,
      "steps": 36,
      "mean_loss": 1809.523511674669,
      "epsilon": 0.4365690000016971
    },
    {
      "episode": 1253,
      "score": 118,
      "reward": -969.0,
      "steps": 46,
      "mean_loss": 5136.511718086575,
      "epsilon": 0.43652300000169836
    },
    {
      "episode": 1254,
      "score": 167,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 2792.402552947998,
      "epsilon": 0.4364730000016997
    },
    {
      "episode": 1255,
      "score": 138,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 3553.3400361434274,
      "epsilon": 0.4364270000017009
    },
    {
      "episode": 1256,
      "score": 99,
      "reward": -963.0,
      "steps": 38,
      "mean_loss": 2692.554548163163,
      "epsilon": 0.43638900000170194
    },
    {
      "episode": 1257,
      "score": 91,
      "reward": -972.0,
      "steps": 40,
      "mean_loss": 3251.240396118164,
      "epsilon": 0.436349000001703
    },
    {
      "episode": 1258,
      "score": 100,
      "reward": -961.0,
      "steps": 41,
      "mean_loss": 2750.70766076809,
      "epsilon": 0.4363080000017041
    },
    {
      "episode": 1259,
      "score": 76,
      "reward": -992.0,
      "steps": 37,
      "mean_loss": 6907.260373708365,
      "epsilon": 0.4362710000017051
    },
    {
      "episode": 1260,
      "score": 225,
      "reward": -858.0,
      "steps": 57,
      "mean_loss": 2218.7381749738724,
      "epsilon": 0.4362140000017066
    },
    {
      "episode": 1261,
      "score": 150,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 5298.505867640178,
      "epsilon": 0.4361660000017079
    },
    {
      "episode": 1262,
      "score": 164,
      "reward": -912.0,
      "steps": 49,
      "mean_loss": 6017.1013678725885,
      "epsilon": 0.4361170000017092
    },
    {
      "episode": 1263,
      "score": 115,
      "reward": -957.0,
      "steps": 42,
      "mean_loss": 2114.5493053254627,
      "epsilon": 0.43607500000171034
    },
    {
      "episode": 1264,
      "score": 146,
      "reward": -915.0,
      "steps": 44,
      "mean_loss": 3433.5867619947953,
      "epsilon": 0.4360310000017115
    },
    {
      "episode": 1265,
      "score": 60,
      "reward": -1003.0,
      "steps": 34,
      "mean_loss": 3911.0808696746826,
      "epsilon": 0.43599700000171243
    },
    {
      "episode": 1266,
      "score": 116,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 3730.357535275546,
      "epsilon": 0.4359530000017136
    },
    {
      "episode": 1267,
      "score": 149,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 5521.931750277256,
      "epsilon": 0.43590600000171487
    },
    {
      "episode": 1268,
      "score": 110,
      "reward": -970.0,
      "steps": 40,
      "mean_loss": 5095.73119506836,
      "epsilon": 0.43586600000171594
    },
    {
      "episode": 1269,
      "score": 103,
      "reward": -964.0,
      "steps": 43,
      "mean_loss": 5566.67446305031,
      "epsilon": 0.4358230000017171
    },
    {
      "episode": 1270,
      "score": 181,
      "reward": -878.0,
      "steps": 49,
      "mean_loss": 3244.8678464305644,
      "epsilon": 0.4357740000017184
    },
    {
      "episode": 1271,
      "score": 122,
      "reward": -934.0,
      "steps": 39,
      "mean_loss": 3468.2746544862407,
      "epsilon": 0.43573500000171944
    },
    {
      "episode": 1272,
      "score": 91,
      "reward": -967.0,
      "steps": 34,
      "mean_loss": 3958.2827129364014,
      "epsilon": 0.43570100000172035
    },
    {
      "episode": 1273,
      "score": 143,
      "reward": -944.0,
      "steps": 49,
      "mean_loss": 3220.6821651847995,
      "epsilon": 0.43565200000172166
    },
    {
      "episode": 1274,
      "score": 172,
      "reward": -896.0,
      "steps": 51,
      "mean_loss": 5273.392216027952,
      "epsilon": 0.435601000001723
    },
    {
      "episode": 1275,
      "score": 168,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 2732.2504960573638,
      "epsilon": 0.4355490000017244
    },
    {
      "episode": 1276,
      "score": 126,
      "reward": -964.0,
      "steps": 48,
      "mean_loss": 5193.051085789998,
      "epsilon": 0.4355010000017257
    },
    {
      "episode": 1277,
      "score": 94,
      "reward": -966.0,
      "steps": 39,
      "mean_loss": 2643.360343346229,
      "epsilon": 0.43546200000172675
    },
    {
      "episode": 1278,
      "score": 156,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 4246.3666609160755,
      "epsilon": 0.43541300000172806
    },
    {
      "episode": 1279,
      "score": 175,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 6245.221428665461,
      "epsilon": 0.4353620000017294
    },
    {
      "episode": 1280,
      "score": 160,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 5296.616324462891,
      "epsilon": 0.43531200000173076
    },
    {
      "episode": 1281,
      "score": 151,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 4131.466788609822,
      "epsilon": 0.43526400000173204
    },
    {
      "episode": 1282,
      "score": 118,
      "reward": -943.0,
      "steps": 45,
      "mean_loss": 2530.460067240397,
      "epsilon": 0.43521900000173325
    },
    {
      "episode": 1283,
      "score": 144,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 2926.5832090986537,
      "epsilon": 0.4351720000017345
    },
    {
      "episode": 1284,
      "score": 171,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 3366.767752532959,
      "epsilon": 0.43512200000173584
    },
    {
      "episode": 1285,
      "score": 157,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3898.4542668660483,
      "epsilon": 0.4350710000017372
    },
    {
      "episode": 1286,
      "score": 156,
      "reward": -918.0,
      "steps": 48,
      "mean_loss": 5367.638987541199,
      "epsilon": 0.4350230000017385
    },
    {
      "episode": 1287,
      "score": 170,
      "reward": -899.0,
      "steps": 48,
      "mean_loss": 3461.7129214604697,
      "epsilon": 0.4349750000017398
    },
    {
      "episode": 1288,
      "score": 199,
      "reward": -887.0,
      "steps": 57,
      "mean_loss": 3842.3544346324184,
      "epsilon": 0.4349180000017413
    },
    {
      "episode": 1289,
      "score": 60,
      "reward": -986.0,
      "steps": 30,
      "mean_loss": 1917.9455279032388,
      "epsilon": 0.4348880000017421
    },
    {
      "episode": 1290,
      "score": 68,
      "reward": -992.0,
      "steps": 31,
      "mean_loss": 5410.613817030384,
      "epsilon": 0.43485700000174293
    },
    {
      "episode": 1291,
      "score": 78,
      "reward": -980.0,
      "steps": 36,
      "mean_loss": 2238.6369739108613,
      "epsilon": 0.4348210000017439
    },
    {
      "episode": 1292,
      "score": 143,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 3602.719911813736,
      "epsilon": 0.4347730000017452
    },
    {
      "episode": 1293,
      "score": 175,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 3488.1274256896972,
      "epsilon": 0.4347230000017465
    },
    {
      "episode": 1294,
      "score": 208,
      "reward": -872.0,
      "steps": 54,
      "mean_loss": 2344.688865661621,
      "epsilon": 0.43466900000174796
    },
    {
      "episode": 1295,
      "score": 126,
      "reward": -949.0,
      "steps": 41,
      "mean_loss": 4735.313429483554,
      "epsilon": 0.43462800000174906
    },
    {
      "episode": 1296,
      "score": 93,
      "reward": -973.0,
      "steps": 35,
      "mean_loss": 2555.1702610560824,
      "epsilon": 0.43459300000175
    },
    {
      "episode": 1297,
      "score": 113,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 7761.897519832704,
      "epsilon": 0.4345520000017511
    },
    {
      "episode": 1298,
      "score": 170,
      "reward": -894.0,
      "steps": 49,
      "mean_loss": 5545.3231936084985,
      "epsilon": 0.4345030000017524
    },
    {
      "episode": 1299,
      "score": 119,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 3515.6308444630017,
      "epsilon": 0.4344590000017536
    },
    {
      "episode": 1300,
      "score": 142,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 2482.082773844401,
      "epsilon": 0.4344140000017548
    },
    {
      "episode": 1301,
      "score": 238,
      "reward": -847.0,
      "steps": 58,
      "mean_loss": 2273.515994433699,
      "epsilon": 0.43435600000175634
    },
    {
      "episode": 1302,
      "score": 132,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 3975.075626546686,
      "epsilon": 0.4343120000017575
    },
    {
      "episode": 1303,
      "score": 178,
      "reward": -898.0,
      "steps": 54,
      "mean_loss": 3596.0334598399972,
      "epsilon": 0.43425800000175896
    },
    {
      "episode": 1304,
      "score": 156,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 4353.858382492065,
      "epsilon": 0.4342080000017603
    },
    {
      "episode": 1305,
      "score": 164,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 2434.342757729923,
      "epsilon": 0.43415700000176166
    },
    {
      "episode": 1306,
      "score": 106,
      "reward": -956.0,
      "steps": 37,
      "mean_loss": 5141.280364577835,
      "epsilon": 0.43412000000176265
    },
    {
      "episode": 1307,
      "score": 137,
      "reward": -962.0,
      "steps": 46,
      "mean_loss": 2962.490107826565,
      "epsilon": 0.4340740000017639
    },
    {
      "episode": 1308,
      "score": 122,
      "reward": -932.0,
      "steps": 41,
      "mean_loss": 4898.953182499583,
      "epsilon": 0.434033000001765
    },
    {
      "episode": 1309,
      "score": 141,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3667.6423594697994,
      "epsilon": 0.43398600000176624
    },
    {
      "episode": 1310,
      "score": 146,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 3345.69227950427,
      "epsilon": 0.43393700000176755
    },
    {
      "episode": 1311,
      "score": 85,
      "reward": -978.0,
      "steps": 38,
      "mean_loss": 3702.6629736047043,
      "epsilon": 0.43389900000176856
    },
    {
      "episode": 1312,
      "score": 151,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3320.23859048397,
      "epsilon": 0.4338520000017698
    },
    {
      "episode": 1313,
      "score": 220,
      "reward": -877.0,
      "steps": 58,
      "mean_loss": 2263.4982155109274,
      "epsilon": 0.4337940000017714
    },
    {
      "episode": 1314,
      "score": 116,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 7769.3496659744615,
      "epsilon": 0.4337510000017725
    },
    {
      "episode": 1315,
      "score": 120,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 3228.203629580411,
      "epsilon": 0.4337070000017737
    },
    {
      "episode": 1316,
      "score": 121,
      "reward": -936.0,
      "steps": 43,
      "mean_loss": 3582.692360279172,
      "epsilon": 0.43366400000177485
    },
    {
      "episode": 1317,
      "score": 171,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 4296.409414951618,
      "epsilon": 0.43361200000177624
    },
    {
      "episode": 1318,
      "score": 147,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 2649.9782507523246,
      "epsilon": 0.4335660000017775
    },
    {
      "episode": 1319,
      "score": 127,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 3868.263880666097,
      "epsilon": 0.4335210000017787
    },
    {
      "episode": 1320,
      "score": 263,
      "reward": -846.0,
      "steps": 68,
      "mean_loss": 3387.24339316873,
      "epsilon": 0.4334530000017805
    },
    {
      "episode": 1321,
      "score": 171,
      "reward": -920.0,
      "steps": 52,
      "mean_loss": 5054.066302739657,
      "epsilon": 0.4334010000017819
    },
    {
      "episode": 1322,
      "score": 190,
      "reward": -895.0,
      "steps": 54,
      "mean_loss": 2116.2873902497467,
      "epsilon": 0.43334700000178333
    },
    {
      "episode": 1323,
      "score": 184,
      "reward": -886.0,
      "steps": 49,
      "mean_loss": 4368.944716628717,
      "epsilon": 0.43329800000178464
    },
    {
      "episode": 1324,
      "score": 75,
      "reward": -986.0,
      "steps": 35,
      "mean_loss": 4445.828079223633,
      "epsilon": 0.4332630000017856
    },
    {
      "episode": 1325,
      "score": 156,
      "reward": -912.0,
      "steps": 49,
      "mean_loss": 3425.6562264890085,
      "epsilon": 0.4332140000017869
    },
    {
      "episode": 1326,
      "score": 170,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 5535.154139885535,
      "epsilon": 0.4331620000017883
    },
    {
      "episode": 1327,
      "score": 266,
      "reward": -837.0,
      "steps": 67,
      "mean_loss": 5333.343485590237,
      "epsilon": 0.4330950000017901
    },
    {
      "episode": 1328,
      "score": 117,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 4365.743741382252,
      "epsilon": 0.43305100000179125
    },
    {
      "episode": 1329,
      "score": 116,
      "reward": -955.0,
      "steps": 42,
      "mean_loss": 3402.1802218300954,
      "epsilon": 0.4330090000017924
    },
    {
      "episode": 1330,
      "score": 168,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 3759.969916490408,
      "epsilon": 0.43295700000179377
    },
    {
      "episode": 1331,
      "score": 198,
      "reward": -893.0,
      "steps": 54,
      "mean_loss": 1832.1926727294922,
      "epsilon": 0.4329030000017952
    },
    {
      "episode": 1332,
      "score": 126,
      "reward": -960.0,
      "steps": 48,
      "mean_loss": 4883.976313432057,
      "epsilon": 0.4328550000017965
    },
    {
      "episode": 1333,
      "score": 105,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 4856.99683414806,
      "epsilon": 0.4328110000017977
    },
    {
      "episode": 1334,
      "score": 169,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 2881.510512656354,
      "epsilon": 0.43276400000179893
    },
    {
      "episode": 1335,
      "score": 163,
      "reward": -914.0,
      "steps": 48,
      "mean_loss": 4038.7822802861533,
      "epsilon": 0.4327160000018002
    },
    {
      "episode": 1336,
      "score": 140,
      "reward": -914.0,
      "steps": 44,
      "mean_loss": 5766.39144117182,
      "epsilon": 0.4326720000018014
    },
    {
      "episode": 1337,
      "score": 165,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 4496.029048321294,
      "epsilon": 0.43262100000180276
    },
    {
      "episode": 1338,
      "score": 142,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 3236.3505389436764,
      "epsilon": 0.432574000001804
    },
    {
      "episode": 1339,
      "score": 62,
      "reward": -985.0,
      "steps": 31,
      "mean_loss": 8209.041728850334,
      "epsilon": 0.43254300000180484
    },
    {
      "episode": 1340,
      "score": 164,
      "reward": -909.0,
      "steps": 52,
      "mean_loss": 3436.9412360558144,
      "epsilon": 0.43249100000180624
    },
    {
      "episode": 1341,
      "score": 164,
      "reward": -925.0,
      "steps": 52,
      "mean_loss": 1394.0709674541768,
      "epsilon": 0.4324390000018076
    },
    {
      "episode": 1342,
      "score": 129,
      "reward": -937.0,
      "steps": 43,
      "mean_loss": 2462.1870967066566,
      "epsilon": 0.4323960000018088
    },
    {
      "episode": 1343,
      "score": 150,
      "reward": -921.0,
      "steps": 45,
      "mean_loss": 6171.793314107259,
      "epsilon": 0.43235100000181
    },
    {
      "episode": 1344,
      "score": 140,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 3353.2155043284097,
      "epsilon": 0.43230300000181127
    },
    {
      "episode": 1345,
      "score": 131,
      "reward": -951.0,
      "steps": 48,
      "mean_loss": 3550.98526541392,
      "epsilon": 0.43225500000181255
    },
    {
      "episode": 1346,
      "score": 105,
      "reward": -969.0,
      "steps": 42,
      "mean_loss": 6378.220131647019,
      "epsilon": 0.4322130000018137
    },
    {
      "episode": 1347,
      "score": 112,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 4591.504436683655,
      "epsilon": 0.43217300000181474
    },
    {
      "episode": 1348,
      "score": 114,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 2444.9589340573266,
      "epsilon": 0.43213100000181587
    },
    {
      "episode": 1349,
      "score": 195,
      "reward": -892.0,
      "steps": 54,
      "mean_loss": 5795.481034455476,
      "epsilon": 0.4320770000018173
    },
    {
      "episode": 1350,
      "score": 175,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 4080.7200581477236,
      "epsilon": 0.4320250000018187
    },
    {
      "episode": 1351,
      "score": 168,
      "reward": -927.0,
      "steps": 53,
      "mean_loss": 1725.8860119513745,
      "epsilon": 0.4319720000018201
    },
    {
      "episode": 1352,
      "score": 169,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 3387.5318102264405,
      "epsilon": 0.43192200000182146
    },
    {
      "episode": 1353,
      "score": 144,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 4096.675253868103,
      "epsilon": 0.43187400000182274
    },
    {
      "episode": 1354,
      "score": 120,
      "reward": -954.0,
      "steps": 45,
      "mean_loss": 2087.8813547770183,
      "epsilon": 0.43182900000182395
    },
    {
      "episode": 1355,
      "score": 132,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 1938.7245576736775,
      "epsilon": 0.4317820000018252
    },
    {
      "episode": 1356,
      "score": 263,
      "reward": -856.0,
      "steps": 62,
      "mean_loss": 5510.080134791712,
      "epsilon": 0.43172000000182686
    },
    {
      "episode": 1357,
      "score": 178,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 3098.520854803232,
      "epsilon": 0.43166800000182826
    },
    {
      "episode": 1358,
      "score": 65,
      "reward": -988.0,
      "steps": 31,
      "mean_loss": 6410.589165472215,
      "epsilon": 0.4316370000018291
    },
    {
      "episode": 1359,
      "score": 185,
      "reward": -901.0,
      "steps": 55,
      "mean_loss": 3706.351033297452,
      "epsilon": 0.43158200000183056
    },
    {
      "episode": 1360,
      "score": 126,
      "reward": -928.0,
      "steps": 42,
      "mean_loss": 4103.6429930187405,
      "epsilon": 0.4315400000018317
    },
    {
      "episode": 1361,
      "score": 191,
      "reward": -907.0,
      "steps": 54,
      "mean_loss": 3963.8676931593154,
      "epsilon": 0.4314860000018331
    },
    {
      "episode": 1362,
      "score": 172,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 5709.261125240686,
      "epsilon": 0.43143300000183454
    },
    {
      "episode": 1363,
      "score": 200,
      "reward": -878.0,
      "steps": 55,
      "mean_loss": 4531.411331800981,
      "epsilon": 0.431378000001836
    },
    {
      "episode": 1364,
      "score": 97,
      "reward": -968.0,
      "steps": 39,
      "mean_loss": 4760.3343556722,
      "epsilon": 0.43133900000183706
    },
    {
      "episode": 1365,
      "score": 180,
      "reward": -897.0,
      "steps": 49,
      "mean_loss": 3580.920938297194,
      "epsilon": 0.43129000000183837
    },
    {
      "episode": 1366,
      "score": 99,
      "reward": -970.0,
      "steps": 38,
      "mean_loss": 3846.637841676411,
      "epsilon": 0.4312520000018394
    },
    {
      "episode": 1367,
      "score": 135,
      "reward": -976.0,
      "steps": 44,
      "mean_loss": 3378.4229264692826,
      "epsilon": 0.43120800000184056
    },
    {
      "episode": 1368,
      "score": 145,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 5103.801173189853,
      "epsilon": 0.4311610000018418
    },
    {
      "episode": 1369,
      "score": 143,
      "reward": -950.0,
      "steps": 50,
      "mean_loss": 3685.8032460021973,
      "epsilon": 0.43111100000184316
    },
    {
      "episode": 1370,
      "score": 60,
      "reward": -985.0,
      "steps": 31,
      "mean_loss": 3882.8658457110005,
      "epsilon": 0.431080000001844
    },
    {
      "episode": 1371,
      "score": 139,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 4115.061450163524,
      "epsilon": 0.4310320000018453
    },
    {
      "episode": 1372,
      "score": 116,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 6167.889832756736,
      "epsilon": 0.43098800000184645
    },
    {
      "episode": 1373,
      "score": 169,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 2913.766737246046,
      "epsilon": 0.4309370000018478
    },
    {
      "episode": 1374,
      "score": 122,
      "reward": -940.0,
      "steps": 40,
      "mean_loss": 3949.7163208007814,
      "epsilon": 0.4308970000018489
    },
    {
      "episode": 1375,
      "score": 161,
      "reward": -934.0,
      "steps": 51,
      "mean_loss": 2168.9967254937865,
      "epsilon": 0.43084600000185025
    },
    {
      "episode": 1376,
      "score": 95,
      "reward": -965.0,
      "steps": 39,
      "mean_loss": 2539.8173297979893,
      "epsilon": 0.4308070000018513
    },
    {
      "episode": 1377,
      "score": 58,
      "reward": -1011.0,
      "steps": 34,
      "mean_loss": 5428.6353304245895,
      "epsilon": 0.4307730000018522
    },
    {
      "episode": 1378,
      "score": 86,
      "reward": -960.0,
      "steps": 33,
      "mean_loss": 5422.608607436671,
      "epsilon": 0.4307400000018531
    },
    {
      "episode": 1379,
      "score": 71,
      "reward": -989.0,
      "steps": 34,
      "mean_loss": 3683.498285405776,
      "epsilon": 0.430706000001854
    },
    {
      "episode": 1380,
      "score": 160,
      "reward": -920.0,
      "steps": 52,
      "mean_loss": 2955.4280955974873,
      "epsilon": 0.4306540000018554
    },
    {
      "episode": 1381,
      "score": 133,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 3053.6338907877603,
      "epsilon": 0.4306090000018566
    },
    {
      "episode": 1382,
      "score": 186,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 2838.1408109664917,
      "epsilon": 0.430557000001858
    },
    {
      "episode": 1383,
      "score": 113,
      "reward": -965.0,
      "steps": 43,
      "mean_loss": 3944.245637050895,
      "epsilon": 0.43051400000185913
    },
    {
      "episode": 1384,
      "score": 201,
      "reward": -886.0,
      "steps": 56,
      "mean_loss": 3784.503417832511,
      "epsilon": 0.43045800000186063
    },
    {
      "episode": 1385,
      "score": 109,
      "reward": -965.0,
      "steps": 45,
      "mean_loss": 3076.0118053860133,
      "epsilon": 0.43041300000186183
    },
    {
      "episode": 1386,
      "score": 164,
      "reward": -919.0,
      "steps": 49,
      "mean_loss": 2884.2613128350704,
      "epsilon": 0.43036400000186315
    },
    {
      "episode": 1387,
      "score": 115,
      "reward": -950.0,
      "steps": 43,
      "mean_loss": 5728.64713961579,
      "epsilon": 0.4303210000018643
    },
    {
      "episode": 1388,
      "score": 139,
      "reward": -948.0,
      "steps": 49,
      "mean_loss": 2824.986690754793,
      "epsilon": 0.4302720000018656
    },
    {
      "episode": 1389,
      "score": 127,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 3561.3597818721423,
      "epsilon": 0.4302280000018668
    },
    {
      "episode": 1390,
      "score": 164,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 6260.280543159036,
      "epsilon": 0.43017700000186815
    },
    {
      "episode": 1391,
      "score": 111,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 2763.8569783297453,
      "epsilon": 0.4301330000018693
    },
    {
      "episode": 1392,
      "score": 140,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 2539.0911320845285,
      "epsilon": 0.4300850000018706
    },
    {
      "episode": 1393,
      "score": 107,
      "reward": -962.0,
      "steps": 41,
      "mean_loss": 4569.157398875167,
      "epsilon": 0.4300440000018717
    },
    {
      "episode": 1394,
      "score": 172,
      "reward": -918.0,
      "steps": 53,
      "mean_loss": 4368.684310337283,
      "epsilon": 0.4299910000018731
    },
    {
      "episode": 1395,
      "score": 144,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 4298.499030599789,
      "epsilon": 0.42994200000187444
    },
    {
      "episode": 1396,
      "score": 127,
      "reward": -962.0,
      "steps": 47,
      "mean_loss": 5533.419453073056,
      "epsilon": 0.4298950000018757
    },
    {
      "episode": 1397,
      "score": 101,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 6174.039578177712,
      "epsilon": 0.42985100000187687
    },
    {
      "episode": 1398,
      "score": 113,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 4021.3741918291366,
      "epsilon": 0.429809000001878
    },
    {
      "episode": 1399,
      "score": 185,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 5301.9123935339585,
      "epsilon": 0.4297560000018794
    },
    {
      "episode": 1400,
      "score": 153,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 5460.494794616699,
      "epsilon": 0.42970600000188075
    },
    {
      "episode": 1401,
      "score": 144,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 2294.5128151102267,
      "epsilon": 0.429659000001882
    },
    {
      "episode": 1402,
      "score": 114,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 4304.13318902796,
      "epsilon": 0.4296150000018832
    },
    {
      "episode": 1403,
      "score": 123,
      "reward": -949.0,
      "steps": 43,
      "mean_loss": 4742.722618635311,
      "epsilon": 0.42957200000188434
    },
    {
      "episode": 1404,
      "score": 195,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 3251.737023106328,
      "epsilon": 0.4295180000018858
    },
    {
      "episode": 1405,
      "score": 252,
      "reward": -833.0,
      "steps": 63,
      "mean_loss": 5892.388326856825,
      "epsilon": 0.42945500000188747
    },
    {
      "episode": 1406,
      "score": 68,
      "reward": -996.0,
      "steps": 37,
      "mean_loss": 1521.0124002405114,
      "epsilon": 0.42941800000188846
    },
    {
      "episode": 1407,
      "score": 226,
      "reward": -874.0,
      "steps": 62,
      "mean_loss": 3744.223933496783,
      "epsilon": 0.4293560000018901
    },
    {
      "episode": 1408,
      "score": 84,
      "reward": -976.0,
      "steps": 37,
      "mean_loss": 5664.982392182222,
      "epsilon": 0.4293190000018911
    },
    {
      "episode": 1409,
      "score": 129,
      "reward": -951.0,
      "steps": 48,
      "mean_loss": 4872.296524365743,
      "epsilon": 0.4292710000018924
    },
    {
      "episode": 1410,
      "score": 256,
      "reward": -841.0,
      "steps": 63,
      "mean_loss": 5619.5663978939965,
      "epsilon": 0.4292080000018941
    },
    {
      "episode": 1411,
      "score": 114,
      "reward": -963.0,
      "steps": 39,
      "mean_loss": 2635.6566416422525,
      "epsilon": 0.4291690000018951
    },
    {
      "episode": 1412,
      "score": 193,
      "reward": -888.0,
      "steps": 54,
      "mean_loss": 4193.257479208487,
      "epsilon": 0.42911500000189656
    },
    {
      "episode": 1413,
      "score": 138,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 2888.6973504153166,
      "epsilon": 0.42907100000189774
    },
    {
      "episode": 1414,
      "score": 189,
      "reward": -893.0,
      "steps": 52,
      "mean_loss": 2674.3291268715493,
      "epsilon": 0.42901900000189913
    },
    {
      "episode": 1415,
      "score": 136,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 2457.8591437961745,
      "epsilon": 0.42897300000190036
    },
    {
      "episode": 1416,
      "score": 114,
      "reward": -967.0,
      "steps": 46,
      "mean_loss": 3950.797875114109,
      "epsilon": 0.4289270000019016
    },
    {
      "episode": 1417,
      "score": 155,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 3298.0606810387144,
      "epsilon": 0.42888000000190285
    },
    {
      "episode": 1418,
      "score": 113,
      "reward": -952.0,
      "steps": 41,
      "mean_loss": 4065.162494008134,
      "epsilon": 0.42883900000190395
    },
    {
      "episode": 1419,
      "score": 175,
      "reward": -912.0,
      "steps": 53,
      "mean_loss": 2754.8718266037276,
      "epsilon": 0.42878600000190537
    },
    {
      "episode": 1420,
      "score": 141,
      "reward": -943.0,
      "steps": 48,
      "mean_loss": 5042.2805703481035,
      "epsilon": 0.42873800000190665
    },
    {
      "episode": 1421,
      "score": 138,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 4542.811321339709,
      "epsilon": 0.4286910000019079
    },
    {
      "episode": 1422,
      "score": 133,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 3501.516549151877,
      "epsilon": 0.42864500000190914
    },
    {
      "episode": 1423,
      "score": 146,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 4533.6520347595215,
      "epsilon": 0.42859900000191037
    },
    {
      "episode": 1424,
      "score": 83,
      "reward": -974.0,
      "steps": 38,
      "mean_loss": 4576.272990176552,
      "epsilon": 0.4285610000019114
    },
    {
      "episode": 1425,
      "score": 113,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 4957.537779273056,
      "epsilon": 0.4285200000019125
    },
    {
      "episode": 1426,
      "score": 108,
      "reward": -964.0,
      "steps": 44,
      "mean_loss": 2930.167646581476,
      "epsilon": 0.42847600000191366
    },
    {
      "episode": 1427,
      "score": 108,
      "reward": -964.0,
      "steps": 44,
      "mean_loss": 3148.703331340443,
      "epsilon": 0.42843200000191484
    },
    {
      "episode": 1428,
      "score": 127,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 6741.6616814136505,
      "epsilon": 0.4283840000019161
    },
    {
      "episode": 1429,
      "score": 129,
      "reward": -951.0,
      "steps": 48,
      "mean_loss": 4906.048327128093,
      "epsilon": 0.4283360000019174
    },
    {
      "episode": 1430,
      "score": 93,
      "reward": -977.0,
      "steps": 42,
      "mean_loss": 5264.184380667551,
      "epsilon": 0.42829400000191853
    },
    {
      "episode": 1431,
      "score": 102,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 4644.706846583973,
      "epsilon": 0.4282500000019197
    },
    {
      "episode": 1432,
      "score": 119,
      "reward": -955.0,
      "steps": 42,
      "mean_loss": 3127.4981144496373,
      "epsilon": 0.42820800000192083
    },
    {
      "episode": 1433,
      "score": 71,
      "reward": -998.0,
      "steps": 35,
      "mean_loss": 2742.849113900321,
      "epsilon": 0.42817300000192177
    },
    {
      "episode": 1434,
      "score": 169,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 2074.8343442021583,
      "epsilon": 0.4281240000019231
    },
    {
      "episode": 1435,
      "score": 83,
      "reward": -972.0,
      "steps": 35,
      "mean_loss": 2852.5719506399973,
      "epsilon": 0.428089000001924
    },
    {
      "episode": 1436,
      "score": 154,
      "reward": -928.0,
      "steps": 52,
      "mean_loss": 3753.7845237438496,
      "epsilon": 0.4280370000019254
    },
    {
      "episode": 1437,
      "score": 91,
      "reward": -980.0,
      "steps": 42,
      "mean_loss": 2641.010078702654,
      "epsilon": 0.42799500000192653
    },
    {
      "episode": 1438,
      "score": 183,
      "reward": -889.0,
      "steps": 53,
      "mean_loss": 5844.427163178066,
      "epsilon": 0.42794200000192795
    },
    {
      "episode": 1439,
      "score": 165,
      "reward": -903.0,
      "steps": 47,
      "mean_loss": 4850.3074098952275,
      "epsilon": 0.4278950000019292
    },
    {
      "episode": 1440,
      "score": 235,
      "reward": -868.0,
      "steps": 61,
      "mean_loss": 3373.0216943084215,
      "epsilon": 0.42783400000193084
    },
    {
      "episode": 1441,
      "score": 172,
      "reward": -886.0,
      "steps": 51,
      "mean_loss": 3114.7378406898647,
      "epsilon": 0.4277830000019322
    },
    {
      "episode": 1442,
      "score": 111,
      "reward": -960.0,
      "steps": 43,
      "mean_loss": 4421.493338828863,
      "epsilon": 0.42774000000193335
    },
    {
      "episode": 1443,
      "score": 151,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4040.1326659844844,
      "epsilon": 0.42769100000193466
    },
    {
      "episode": 1444,
      "score": 112,
      "reward": -951.0,
      "steps": 40,
      "mean_loss": 3960.9730175018312,
      "epsilon": 0.42765100000193573
    },
    {
      "episode": 1445,
      "score": 92,
      "reward": -984.0,
      "steps": 41,
      "mean_loss": 4011.9714052153795,
      "epsilon": 0.42761000000193683
    },
    {
      "episode": 1446,
      "score": 125,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 5722.18611647866,
      "epsilon": 0.427566000001938
    },
    {
      "episode": 1447,
      "score": 103,
      "reward": -973.0,
      "steps": 41,
      "mean_loss": 4914.91832649417,
      "epsilon": 0.4275250000019391
    },
    {
      "episode": 1448,
      "score": 85,
      "reward": -981.0,
      "steps": 36,
      "mean_loss": 2718.013210084703,
      "epsilon": 0.42748900000194007
    },
    {
      "episode": 1449,
      "score": 124,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 4227.46801459271,
      "epsilon": 0.4274430000019413
    },
    {
      "episode": 1450,
      "score": 117,
      "reward": -957.0,
      "steps": 42,
      "mean_loss": 6514.169117972964,
      "epsilon": 0.4274010000019424
    },
    {
      "episode": 1451,
      "score": 98,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 3717.961843299866,
      "epsilon": 0.4273610000019435
    },
    {
      "episode": 1452,
      "score": 235,
      "reward": -865.0,
      "steps": 61,
      "mean_loss": 4887.229482213004,
      "epsilon": 0.4273000000019451
    },
    {
      "episode": 1453,
      "score": 205,
      "reward": -874.0,
      "steps": 56,
      "mean_loss": 3572.034794534956,
      "epsilon": 0.4272440000019466
    },
    {
      "episode": 1454,
      "score": 121,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 4027.992836518721,
      "epsilon": 0.4272000000019478
    },
    {
      "episode": 1455,
      "score": 189,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 4114.924613952637,
      "epsilon": 0.42714900000194916
    },
    {
      "episode": 1456,
      "score": 96,
      "reward": -965.0,
      "steps": 41,
      "mean_loss": 2241.963259068931,
      "epsilon": 0.42710800000195026
    },
    {
      "episode": 1457,
      "score": 75,
      "reward": -981.0,
      "steps": 35,
      "mean_loss": 6085.712718963623,
      "epsilon": 0.4270730000019512
    },
    {
      "episode": 1458,
      "score": 167,
      "reward": -919.0,
      "steps": 52,
      "mean_loss": 4629.022907110361,
      "epsilon": 0.4270210000019526
    },
    {
      "episode": 1459,
      "score": 153,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 6400.1988749402635,
      "epsilon": 0.42697400000195385
    },
    {
      "episode": 1460,
      "score": 175,
      "reward": -908.0,
      "steps": 47,
      "mean_loss": 3229.5798341467025,
      "epsilon": 0.4269270000019551
    },
    {
      "episode": 1461,
      "score": 262,
      "reward": -848.0,
      "steps": 62,
      "mean_loss": 4423.918747686571,
      "epsilon": 0.42686500000195676
    },
    {
      "episode": 1462,
      "score": 151,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 5364.463807264964,
      "epsilon": 0.42681700000195805
    },
    {
      "episode": 1463,
      "score": 215,
      "reward": -877.0,
      "steps": 54,
      "mean_loss": 3284.318823637786,
      "epsilon": 0.4267630000019595
    },
    {
      "episode": 1464,
      "score": 116,
      "reward": -946.0,
      "steps": 39,
      "mean_loss": 3246.581309783153,
      "epsilon": 0.42672400000196054
    },
    {
      "episode": 1465,
      "score": 141,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 2566.3574471473694,
      "epsilon": 0.4266760000019618
    },
    {
      "episode": 1466,
      "score": 178,
      "reward": -906.0,
      "steps": 51,
      "mean_loss": 4688.210141499837,
      "epsilon": 0.4266250000019632
    },
    {
      "episode": 1467,
      "score": 158,
      "reward": -933.0,
      "steps": 48,
      "mean_loss": 4406.071374257405,
      "epsilon": 0.42657700000196447
    },
    {
      "episode": 1468,
      "score": 235,
      "reward": -869.0,
      "steps": 61,
      "mean_loss": 2804.3004726347376,
      "epsilon": 0.4265160000019661
    },
    {
      "episode": 1469,
      "score": 118,
      "reward": -939.0,
      "steps": 41,
      "mean_loss": 1942.9375294010813,
      "epsilon": 0.4264750000019672
    },
    {
      "episode": 1470,
      "score": 157,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 2381.461071792914,
      "epsilon": 0.4264260000019685
    },
    {
      "episode": 1471,
      "score": 200,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 5498.031037577876,
      "epsilon": 0.42637200000196995
    },
    {
      "episode": 1472,
      "score": 75,
      "reward": -985.0,
      "steps": 33,
      "mean_loss": 3903.3476678096886,
      "epsilon": 0.42633900000197084
    },
    {
      "episode": 1473,
      "score": 142,
      "reward": -920.0,
      "steps": 41,
      "mean_loss": 4787.6925147452,
      "epsilon": 0.42629800000197193
    },
    {
      "episode": 1474,
      "score": 103,
      "reward": -977.0,
      "steps": 42,
      "mean_loss": 5109.868810744512,
      "epsilon": 0.42625600000197306
    },
    {
      "episode": 1475,
      "score": 126,
      "reward": -932.0,
      "steps": 38,
      "mean_loss": 1659.661635950992,
      "epsilon": 0.4262180000019741
    },
    {
      "episode": 1476,
      "score": 265,
      "reward": -844.0,
      "steps": 64,
      "mean_loss": 3567.811058819294,
      "epsilon": 0.4261540000019758
    },
    {
      "episode": 1477,
      "score": 111,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 5944.4969504963265,
      "epsilon": 0.42611000000197696
    },
    {
      "episode": 1478,
      "score": 158,
      "reward": -913.0,
      "steps": 49,
      "mean_loss": 1952.7366530749262,
      "epsilon": 0.4260610000019783
    },
    {
      "episode": 1479,
      "score": 139,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 5367.903055605681,
      "epsilon": 0.4260150000019795
    },
    {
      "episode": 1480,
      "score": 277,
      "reward": -841.0,
      "steps": 69,
      "mean_loss": 4328.465522379115,
      "epsilon": 0.42594600000198135
    },
    {
      "episode": 1481,
      "score": 253,
      "reward": -839.0,
      "steps": 63,
      "mean_loss": 2303.0427707490467,
      "epsilon": 0.42588300000198304
    },
    {
      "episode": 1482,
      "score": 118,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 2603.2458591867003,
      "epsilon": 0.4258360000019843
    },
    {
      "episode": 1483,
      "score": 141,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 3513.4092948747716,
      "epsilon": 0.4257900000019855
    },
    {
      "episode": 1484,
      "score": 53,
      "reward": -1004.0,
      "steps": 33,
      "mean_loss": 4698.573417432381,
      "epsilon": 0.4257570000019864
    },
    {
      "episode": 1485,
      "score": 231,
      "reward": -869.0,
      "steps": 59,
      "mean_loss": 3111.42343837932,
      "epsilon": 0.425698000001988
    },
    {
      "episode": 1486,
      "score": 92,
      "reward": -969.0,
      "steps": 35,
      "mean_loss": 8779.94420187814,
      "epsilon": 0.4256630000019889
    },
    {
      "episode": 1487,
      "score": 231,
      "reward": -875.0,
      "steps": 59,
      "mean_loss": 4155.302075014276,
      "epsilon": 0.4256040000019905
    },
    {
      "episode": 1488,
      "score": 157,
      "reward": -920.0,
      "steps": 48,
      "mean_loss": 4930.652463754018,
      "epsilon": 0.4255560000019918
    },
    {
      "episode": 1489,
      "score": 148,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 6110.112638595257,
      "epsilon": 0.42550900000199304
    },
    {
      "episode": 1490,
      "score": 206,
      "reward": -885.0,
      "steps": 54,
      "mean_loss": 4921.496425911232,
      "epsilon": 0.4254550000019945
    },
    {
      "episode": 1491,
      "score": 147,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 1920.3604177633922,
      "epsilon": 0.42540700000199577
    },
    {
      "episode": 1492,
      "score": 162,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 3742.3323912620544,
      "epsilon": 0.42535900000199706
    },
    {
      "episode": 1493,
      "score": 111,
      "reward": -973.0,
      "steps": 43,
      "mean_loss": 3014.425115008687,
      "epsilon": 0.4253160000019982
    },
    {
      "episode": 1494,
      "score": 115,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 2219.65057555112,
      "epsilon": 0.4252720000019994
    },
    {
      "episode": 1495,
      "score": 259,
      "reward": -843.0,
      "steps": 67,
      "mean_loss": 2653.725394120857,
      "epsilon": 0.4252050000020012
    },
    {
      "episode": 1496,
      "score": 119,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 4091.9650109030986,
      "epsilon": 0.42516100000200235
    },
    {
      "episode": 1497,
      "score": 124,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 3250.426589792425,
      "epsilon": 0.42511700000200353
    },
    {
      "episode": 1498,
      "score": 154,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 4304.744478723277,
      "epsilon": 0.42507100000200476
    },
    {
      "episode": 1499,
      "score": 164,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 4049.586093201929,
      "epsilon": 0.4250220000020061
    },
    {
      "episode": 1500,
      "score": 129,
      "reward": -952.0,
      "steps": 51,
      "mean_loss": 6170.296369216021,
      "epsilon": 0.42497100000200744
    },
    {
      "episode": 1501,
      "score": 162,
      "reward": -922.0,
      "steps": 53,
      "mean_loss": 4683.787446651819,
      "epsilon": 0.42491800000200886
    },
    {
      "episode": 1502,
      "score": 112,
      "reward": -949.0,
      "steps": 36,
      "mean_loss": 4447.443827311198,
      "epsilon": 0.4248820000020098
    },
    {
      "episode": 1503,
      "score": 89,
      "reward": -989.0,
      "steps": 41,
      "mean_loss": 3589.944701776272,
      "epsilon": 0.4248410000020109
    },
    {
      "episode": 1504,
      "score": 75,
      "reward": -992.0,
      "steps": 39,
      "mean_loss": 3833.0838736509663,
      "epsilon": 0.42480200000201196
    },
    {
      "episode": 1505,
      "score": 171,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 4115.680119084377,
      "epsilon": 0.4247510000020133
    },
    {
      "episode": 1506,
      "score": 97,
      "reward": -963.0,
      "steps": 39,
      "mean_loss": 3732.837507003393,
      "epsilon": 0.42471200000201437
    },
    {
      "episode": 1507,
      "score": 181,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 4104.2203499720645,
      "epsilon": 0.42466000000201576
    },
    {
      "episode": 1508,
      "score": 277,
      "reward": -837.0,
      "steps": 68,
      "mean_loss": 4946.533913892858,
      "epsilon": 0.4245920000020176
    },
    {
      "episode": 1509,
      "score": 118,
      "reward": -952.0,
      "steps": 45,
      "mean_loss": 4065.4465689765084,
      "epsilon": 0.4245470000020188
    },
    {
      "episode": 1510,
      "score": 140,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 6203.759271579319,
      "epsilon": 0.42450200000202
    },
    {
      "episode": 1511,
      "score": 104,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 1713.209537159313,
      "epsilon": 0.42445800000202116
    },
    {
      "episode": 1512,
      "score": 56,
      "reward": -994.0,
      "steps": 30,
      "mean_loss": 1900.894756825765,
      "epsilon": 0.42442800000202197
    },
    {
      "episode": 1513,
      "score": 223,
      "reward": -876.0,
      "steps": 55,
      "mean_loss": 2349.4006587635386,
      "epsilon": 0.42437300000202344
    },
    {
      "episode": 1514,
      "score": 263,
      "reward": -841.0,
      "steps": 67,
      "mean_loss": 4643.718725973101,
      "epsilon": 0.42430600000202523
    },
    {
      "episode": 1515,
      "score": 117,
      "reward": -940.0,
      "steps": 40,
      "mean_loss": 4786.114493942261,
      "epsilon": 0.4242660000020263
    },
    {
      "episode": 1516,
      "score": 166,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 3529.7211619785853,
      "epsilon": 0.4242170000020276
    },
    {
      "episode": 1517,
      "score": 161,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 3781.1873391591585,
      "epsilon": 0.424165000002029
    },
    {
      "episode": 1518,
      "score": 128,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 3544.856162591414,
      "epsilon": 0.4241210000020302
    },
    {
      "episode": 1519,
      "score": 154,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 3504.5055649128367,
      "epsilon": 0.42407400000203144
    },
    {
      "episode": 1520,
      "score": 170,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 4571.805451466487,
      "epsilon": 0.42402200000203283
    },
    {
      "episode": 1521,
      "score": 103,
      "reward": -966.0,
      "steps": 40,
      "mean_loss": 3810.8491622924803,
      "epsilon": 0.4239820000020339
    },
    {
      "episode": 1522,
      "score": 196,
      "reward": -899.0,
      "steps": 55,
      "mean_loss": 4312.252262739702,
      "epsilon": 0.42392700000203537
    },
    {
      "episode": 1523,
      "score": 156,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 3378.2416282816134,
      "epsilon": 0.4238800000020366
    },
    {
      "episode": 1524,
      "score": 121,
      "reward": -950.0,
      "steps": 43,
      "mean_loss": 2177.557440913001,
      "epsilon": 0.4238370000020378
    },
    {
      "episode": 1525,
      "score": 105,
      "reward": -967.0,
      "steps": 41,
      "mean_loss": 2073.984687619093,
      "epsilon": 0.4237960000020389
    },
    {
      "episode": 1526,
      "score": 180,
      "reward": -890.0,
      "steps": 53,
      "mean_loss": 2288.638382317885,
      "epsilon": 0.4237430000020403
    },
    {
      "episode": 1527,
      "score": 153,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 3094.922591094971,
      "epsilon": 0.42369300000204163
    },
    {
      "episode": 1528,
      "score": 153,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 3615.053264923096,
      "epsilon": 0.42364300000204297
    },
    {
      "episode": 1529,
      "score": 64,
      "reward": -971.0,
      "steps": 29,
      "mean_loss": 6450.508937441069,
      "epsilon": 0.42361400000204374
    },
    {
      "episode": 1530,
      "score": 167,
      "reward": -908.0,
      "steps": 49,
      "mean_loss": 4433.30668577856,
      "epsilon": 0.42356500000204506
    },
    {
      "episode": 1531,
      "score": 167,
      "reward": -934.0,
      "steps": 52,
      "mean_loss": 4939.590871517475,
      "epsilon": 0.42351300000204645
    },
    {
      "episode": 1532,
      "score": 139,
      "reward": -926.0,
      "steps": 41,
      "mean_loss": 3348.0580903960436,
      "epsilon": 0.42347200000204754
    },
    {
      "episode": 1533,
      "score": 117,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 5663.212274876047,
      "epsilon": 0.4234250000020488
    },
    {
      "episode": 1534,
      "score": 167,
      "reward": -886.0,
      "steps": 46,
      "mean_loss": 2708.8034147179646,
      "epsilon": 0.42337900000205003
    },
    {
      "episode": 1535,
      "score": 162,
      "reward": -905.0,
      "steps": 47,
      "mean_loss": 6572.572253125779,
      "epsilon": 0.4233320000020513
    },
    {
      "episode": 1536,
      "score": 192,
      "reward": -891.0,
      "steps": 52,
      "mean_loss": 3765.114539073064,
      "epsilon": 0.4232800000020527
    },
    {
      "episode": 1537,
      "score": 100,
      "reward": -961.0,
      "steps": 38,
      "mean_loss": 2327.897307747289,
      "epsilon": 0.4232420000020537
    },
    {
      "episode": 1538,
      "score": 115,
      "reward": -955.0,
      "steps": 41,
      "mean_loss": 4150.699780533953,
      "epsilon": 0.4232010000020548
    },
    {
      "episode": 1539,
      "score": 100,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 4889.468899681455,
      "epsilon": 0.4231590000020559
    },
    {
      "episode": 1540,
      "score": 159,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 3237.416596270622,
      "epsilon": 0.4231120000020572
    },
    {
      "episode": 1541,
      "score": 101,
      "reward": -973.0,
      "steps": 44,
      "mean_loss": 5927.424254244024,
      "epsilon": 0.42306800000205835
    },
    {
      "episode": 1542,
      "score": 152,
      "reward": -930.0,
      "steps": 51,
      "mean_loss": 4441.94379679362,
      "epsilon": 0.4230170000020597
    },
    {
      "episode": 1543,
      "score": 236,
      "reward": -872.0,
      "steps": 61,
      "mean_loss": 3081.214225393827,
      "epsilon": 0.42295600000206135
    },
    {
      "episode": 1544,
      "score": 118,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3590.6412058743563,
      "epsilon": 0.4229120000020625
    },
    {
      "episode": 1545,
      "score": 144,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 4513.919861857096,
      "epsilon": 0.42286700000206373
    },
    {
      "episode": 1546,
      "score": 159,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 5695.594434232128,
      "epsilon": 0.42281800000206504
    },
    {
      "episode": 1547,
      "score": 109,
      "reward": -975.0,
      "steps": 44,
      "mean_loss": 3792.8018694790926,
      "epsilon": 0.4227740000020662
    },
    {
      "episode": 1548,
      "score": 103,
      "reward": -967.0,
      "steps": 40,
      "mean_loss": 3942.8987188339233,
      "epsilon": 0.4227340000020673
    },
    {
      "episode": 1549,
      "score": 193,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4398.825205485026,
      "epsilon": 0.42268000000206873
    },
    {
      "episode": 1550,
      "score": 124,
      "reward": -940.0,
      "steps": 41,
      "mean_loss": 2561.499717154154,
      "epsilon": 0.42263900000206983
    },
    {
      "episode": 1551,
      "score": 127,
      "reward": -935.0,
      "steps": 41,
      "mean_loss": 1749.5298020897842,
      "epsilon": 0.42259800000207093
    },
    {
      "episode": 1552,
      "score": 110,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 3493.952360788981,
      "epsilon": 0.42255600000207205
    },
    {
      "episode": 1553,
      "score": 112,
      "reward": -955.0,
      "steps": 42,
      "mean_loss": 4469.856572287424,
      "epsilon": 0.4225140000020732
    },
    {
      "episode": 1554,
      "score": 135,
      "reward": -945.0,
      "steps": 49,
      "mean_loss": 2929.7841786754375,
      "epsilon": 0.4224650000020745
    },
    {
      "episode": 1555,
      "score": 166,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 1987.3140367889405,
      "epsilon": 0.4224150000020758
    },
    {
      "episode": 1556,
      "score": 116,
      "reward": -971.0,
      "steps": 47,
      "mean_loss": 1707.075398221929,
      "epsilon": 0.4223680000020771
    },
    {
      "episode": 1557,
      "score": 141,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 6839.202089025619,
      "epsilon": 0.42232100000207834
    },
    {
      "episode": 1558,
      "score": 79,
      "reward": -979.0,
      "steps": 33,
      "mean_loss": 5069.959204009085,
      "epsilon": 0.4222880000020792
    },
    {
      "episode": 1559,
      "score": 235,
      "reward": -860.0,
      "steps": 59,
      "mean_loss": 5671.88740849899,
      "epsilon": 0.4222290000020808
    },
    {
      "episode": 1560,
      "score": 243,
      "reward": -859.0,
      "steps": 62,
      "mean_loss": 4193.356564737135,
      "epsilon": 0.42216700000208246
    },
    {
      "episode": 1561,
      "score": 160,
      "reward": -932.0,
      "steps": 50,
      "mean_loss": 5179.62224319458,
      "epsilon": 0.4221170000020838
    },
    {
      "episode": 1562,
      "score": 70,
      "reward": -991.0,
      "steps": 37,
      "mean_loss": 4046.9631966255806,
      "epsilon": 0.4220800000020848
    },
    {
      "episode": 1563,
      "score": 85,
      "reward": -984.0,
      "steps": 39,
      "mean_loss": 2005.8209177652996,
      "epsilon": 0.42204100000208583
    },
    {
      "episode": 1564,
      "score": 136,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 4874.58114528656,
      "epsilon": 0.421997000002087
    },
    {
      "episode": 1565,
      "score": 147,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 4721.77639559482,
      "epsilon": 0.42195000000208827
    },
    {
      "episode": 1566,
      "score": 88,
      "reward": -981.0,
      "steps": 39,
      "mean_loss": 3457.9745488289077,
      "epsilon": 0.4219110000020893
    },
    {
      "episode": 1567,
      "score": 88,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 5932.623011717925,
      "epsilon": 0.4218740000020903
    },
    {
      "episode": 1568,
      "score": 153,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 3228.0132525697045,
      "epsilon": 0.4218250000020916
    },
    {
      "episode": 1569,
      "score": 86,
      "reward": -998.0,
      "steps": 39,
      "mean_loss": 3920.6991860805415,
      "epsilon": 0.42178600000209265
    },
    {
      "episode": 1570,
      "score": 119,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 3814.389405337247,
      "epsilon": 0.42174200000209383
    },
    {
      "episode": 1571,
      "score": 201,
      "reward": -868.0,
      "steps": 53,
      "mean_loss": 4922.7526309895065,
      "epsilon": 0.42168900000209525
    },
    {
      "episode": 1572,
      "score": 120,
      "reward": -936.0,
      "steps": 41,
      "mean_loss": 3801.064522533882,
      "epsilon": 0.42164800000209635
    },
    {
      "episode": 1573,
      "score": 208,
      "reward": -919.0,
      "steps": 54,
      "mean_loss": 3555.0067808363174,
      "epsilon": 0.4215940000020978
    },
    {
      "episode": 1574,
      "score": 169,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 4515.061973026821,
      "epsilon": 0.4215450000020991
    },
    {
      "episode": 1575,
      "score": 258,
      "reward": -833.0,
      "steps": 65,
      "mean_loss": 4307.038953164908,
      "epsilon": 0.42148000000210084
    },
    {
      "episode": 1576,
      "score": 79,
      "reward": -973.0,
      "steps": 35,
      "mean_loss": 4856.085841805594,
      "epsilon": 0.4214450000021018
    },
    {
      "episode": 1577,
      "score": 159,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 4020.887196699778,
      "epsilon": 0.42139700000210306
    },
    {
      "episode": 1578,
      "score": 215,
      "reward": -894.0,
      "steps": 57,
      "mean_loss": 2073.4903759872705,
      "epsilon": 0.4213400000021046
    },
    {
      "episode": 1579,
      "score": 148,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 8074.915043043054,
      "epsilon": 0.4212940000021058
    },
    {
      "episode": 1580,
      "score": 244,
      "reward": -859.0,
      "steps": 62,
      "mean_loss": 3259.576271057129,
      "epsilon": 0.4212320000021075
    },
    {
      "episode": 1581,
      "score": 325,
      "reward": -795.0,
      "steps": 71,
      "mean_loss": 3502.069699462031,
      "epsilon": 0.4211610000021094
    },
    {
      "episode": 1582,
      "score": 158,
      "reward": -929.0,
      "steps": 51,
      "mean_loss": 2896.7499554951987,
      "epsilon": 0.42111000000211074
    },
    {
      "episode": 1583,
      "score": 256,
      "reward": -846.0,
      "steps": 64,
      "mean_loss": 2650.687601029873,
      "epsilon": 0.42104600000211245
    },
    {
      "episode": 1584,
      "score": 179,
      "reward": -894.0,
      "steps": 48,
      "mean_loss": 4727.987278461456,
      "epsilon": 0.42099800000211374
    },
    {
      "episode": 1585,
      "score": 155,
      "reward": -943.0,
      "steps": 50,
      "mean_loss": 4632.185068664551,
      "epsilon": 0.4209480000021151
    },
    {
      "episode": 1586,
      "score": 192,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 6267.651439450822,
      "epsilon": 0.4208950000021165
    },
    {
      "episode": 1587,
      "score": 94,
      "reward": -985.0,
      "steps": 41,
      "mean_loss": 3463.444225962569,
      "epsilon": 0.4208540000021176
    },
    {
      "episode": 1588,
      "score": 151,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 5062.040759339625,
      "epsilon": 0.4208050000021189
    },
    {
      "episode": 1589,
      "score": 121,
      "reward": -961.0,
      "steps": 46,
      "mean_loss": 4464.1346054906435,
      "epsilon": 0.42075900000212013
    },
    {
      "episode": 1590,
      "score": 137,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 4292.3623338037605,
      "epsilon": 0.42071000000212144
    },
    {
      "episode": 1591,
      "score": 128,
      "reward": -924.0,
      "steps": 36,
      "mean_loss": 2662.3051304287383,
      "epsilon": 0.4206740000021224
    },
    {
      "episode": 1592,
      "score": 235,
      "reward": -839.0,
      "steps": 58,
      "mean_loss": 3263.8503113450674,
      "epsilon": 0.42061600000212396
    },
    {
      "episode": 1593,
      "score": 105,
      "reward": -958.0,
      "steps": 40,
      "mean_loss": 2653.2596155166625,
      "epsilon": 0.42057600000212503
    },
    {
      "episode": 1594,
      "score": 270,
      "reward": -837.0,
      "steps": 64,
      "mean_loss": 4631.488667070866,
      "epsilon": 0.42051200000212674
    },
    {
      "episode": 1595,
      "score": 145,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 6885.547201603017,
      "epsilon": 0.420465000002128
    },
    {
      "episode": 1596,
      "score": 115,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 4885.158723571084,
      "epsilon": 0.4204210000021292
    },
    {
      "episode": 1597,
      "score": 173,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 3255.4951937693468,
      "epsilon": 0.4203680000021306
    },
    {
      "episode": 1598,
      "score": 151,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 5042.288405609131,
      "epsilon": 0.42031800000213193
    },
    {
      "episode": 1599,
      "score": 82,
      "reward": -989.0,
      "steps": 37,
      "mean_loss": 3651.6811853357262,
      "epsilon": 0.4202810000021329
    },
    {
      "episode": 1600,
      "score": 159,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 3871.2274034818015,
      "epsilon": 0.4202330000021342
    },
    {
      "episode": 1601,
      "score": 97,
      "reward": -971.0,
      "steps": 39,
      "mean_loss": 7412.939093467517,
      "epsilon": 0.42019400000213525
    },
    {
      "episode": 1602,
      "score": 194,
      "reward": -894.0,
      "steps": 53,
      "mean_loss": 5228.553830776575,
      "epsilon": 0.42014100000213667
    },
    {
      "episode": 1603,
      "score": 228,
      "reward": -890.0,
      "steps": 61,
      "mean_loss": 4904.475716450175,
      "epsilon": 0.4200800000021383
    },
    {
      "episode": 1604,
      "score": 165,
      "reward": -928.0,
      "steps": 52,
      "mean_loss": 5606.6941645695615,
      "epsilon": 0.4200280000021397
    },
    {
      "episode": 1605,
      "score": 140,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 3618.7297909259796,
      "epsilon": 0.419980000002141
    },
    {
      "episode": 1606,
      "score": 218,
      "reward": -861.0,
      "steps": 55,
      "mean_loss": 5112.878597467596,
      "epsilon": 0.41992500000214245
    },
    {
      "episode": 1607,
      "score": 122,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 2967.484164758162,
      "epsilon": 0.4198810000021436
    },
    {
      "episode": 1608,
      "score": 101,
      "reward": -969.0,
      "steps": 39,
      "mean_loss": 4111.0639239580205,
      "epsilon": 0.41984200000214467
    },
    {
      "episode": 1609,
      "score": 139,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 3250.7069472399626,
      "epsilon": 0.41979800000214584
    },
    {
      "episode": 1610,
      "score": 119,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 5757.886540476481,
      "epsilon": 0.41975300000214705
    },
    {
      "episode": 1611,
      "score": 80,
      "reward": -980.0,
      "steps": 35,
      "mean_loss": 4577.4168258667,
      "epsilon": 0.419718000002148
    },
    {
      "episode": 1612,
      "score": 171,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 2941.999372599076,
      "epsilon": 0.4196690000021493
    },
    {
      "episode": 1613,
      "score": 243,
      "reward": -885.0,
      "steps": 67,
      "mean_loss": 3316.1674746613003,
      "epsilon": 0.4196020000021511
    },
    {
      "episode": 1614,
      "score": 184,
      "reward": -906.0,
      "steps": 54,
      "mean_loss": 3966.500493791368,
      "epsilon": 0.41954800000215253
    },
    {
      "episode": 1615,
      "score": 103,
      "reward": -965.0,
      "steps": 40,
      "mean_loss": 5799.847731494903,
      "epsilon": 0.4195080000021536
    },
    {
      "episode": 1616,
      "score": 176,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 5636.366291779738,
      "epsilon": 0.419456000002155
    },
    {
      "episode": 1617,
      "score": 143,
      "reward": -924.0,
      "steps": 49,
      "mean_loss": 6819.010638334314,
      "epsilon": 0.4194070000021563
    },
    {
      "episode": 1618,
      "score": 157,
      "reward": -925.0,
      "steps": 46,
      "mean_loss": 4421.686734075131,
      "epsilon": 0.41936100000215754
    },
    {
      "episode": 1619,
      "score": 129,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 3178.538378455422,
      "epsilon": 0.4193170000021587
    },
    {
      "episode": 1620,
      "score": 108,
      "reward": -963.0,
      "steps": 43,
      "mean_loss": 2697.9638028699296,
      "epsilon": 0.41927400000215986
    },
    {
      "episode": 1621,
      "score": 125,
      "reward": -944.0,
      "steps": 42,
      "mean_loss": 4011.003738221668,
      "epsilon": 0.419232000002161
    },
    {
      "episode": 1622,
      "score": 200,
      "reward": -883.0,
      "steps": 57,
      "mean_loss": 2648.4828527350173,
      "epsilon": 0.4191750000021625
    },
    {
      "episode": 1623,
      "score": 156,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 4168.212575250743,
      "epsilon": 0.4191260000021638
    },
    {
      "episode": 1624,
      "score": 127,
      "reward": -951.0,
      "steps": 45,
      "mean_loss": 5290.152244906955,
      "epsilon": 0.419081000002165
    },
    {
      "episode": 1625,
      "score": 167,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 3776.4180576558015,
      "epsilon": 0.41903200000216634
    },
    {
      "episode": 1626,
      "score": 162,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 4250.952304077148,
      "epsilon": 0.4189820000021677
    },
    {
      "episode": 1627,
      "score": 195,
      "reward": -883.0,
      "steps": 55,
      "mean_loss": 5734.479436354203,
      "epsilon": 0.41892700000216915
    },
    {
      "episode": 1628,
      "score": 218,
      "reward": -869.0,
      "steps": 58,
      "mean_loss": 4383.495303844584,
      "epsilon": 0.4188690000021707
    },
    {
      "episode": 1629,
      "score": 126,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 3727.446675726708,
      "epsilon": 0.41882200000217196
    },
    {
      "episode": 1630,
      "score": 107,
      "reward": -962.0,
      "steps": 39,
      "mean_loss": 5305.888370220478,
      "epsilon": 0.418783000002173
    },
    {
      "episode": 1631,
      "score": 193,
      "reward": -890.0,
      "steps": 53,
      "mean_loss": 3729.6906920379065,
      "epsilon": 0.4187300000021744
    },
    {
      "episode": 1632,
      "score": 184,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 5226.344692014299,
      "epsilon": 0.41867700000217584
    },
    {
      "episode": 1633,
      "score": 159,
      "reward": -910.0,
      "steps": 48,
      "mean_loss": 5167.993789831798,
      "epsilon": 0.4186290000021771
    },
    {
      "episode": 1634,
      "score": 236,
      "reward": -864.0,
      "steps": 57,
      "mean_loss": 3947.7827303033127,
      "epsilon": 0.41857200000217865
    },
    {
      "episode": 1635,
      "score": 167,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 5251.414423217773,
      "epsilon": 0.41852200000218
    },
    {
      "episode": 1636,
      "score": 147,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 3071.048525174459,
      "epsilon": 0.41847400000218127
    },
    {
      "episode": 1637,
      "score": 153,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 5713.427527348201,
      "epsilon": 0.41842600000218255
    },
    {
      "episode": 1638,
      "score": 110,
      "reward": -964.0,
      "steps": 45,
      "mean_loss": 4262.20045759413,
      "epsilon": 0.41838100000218376
    },
    {
      "episode": 1639,
      "score": 118,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 3640.7478456285266,
      "epsilon": 0.41833600000218496
    },
    {
      "episode": 1640,
      "score": 123,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 3734.2546390035877,
      "epsilon": 0.4182900000021862
    },
    {
      "episode": 1641,
      "score": 116,
      "reward": -951.0,
      "steps": 37,
      "mean_loss": 3800.569614101101,
      "epsilon": 0.4182530000021872
    },
    {
      "episode": 1642,
      "score": 122,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 3940.932099082253,
      "epsilon": 0.41820900000218836
    },
    {
      "episode": 1643,
      "score": 129,
      "reward": -923.0,
      "steps": 37,
      "mean_loss": 2359.7210973791175,
      "epsilon": 0.41817200000218935
    },
    {
      "episode": 1644,
      "score": 179,
      "reward": -904.0,
      "steps": 53,
      "mean_loss": 3883.581142929365,
      "epsilon": 0.41811900000219077
    },
    {
      "episode": 1645,
      "score": 105,
      "reward": -934.0,
      "steps": 34,
      "mean_loss": 5228.092790715835,
      "epsilon": 0.4180850000021917
    },
    {
      "episode": 1646,
      "score": 192,
      "reward": -888.0,
      "steps": 52,
      "mean_loss": 4288.041402376615,
      "epsilon": 0.41803300000219307
    },
    {
      "episode": 1647,
      "score": 163,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 3635.6832230237064,
      "epsilon": 0.4179840000021944
    },
    {
      "episode": 1648,
      "score": 139,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 5227.898927891508,
      "epsilon": 0.41793700000219564
    },
    {
      "episode": 1649,
      "score": 113,
      "reward": -942.0,
      "steps": 37,
      "mean_loss": 4110.558452090701,
      "epsilon": 0.4179000000021966
    },
    {
      "episode": 1650,
      "score": 268,
      "reward": -855.0,
      "steps": 64,
      "mean_loss": 2867.610767006874,
      "epsilon": 0.41783600000219834
    },
    {
      "episode": 1651,
      "score": 143,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 6056.555763742198,
      "epsilon": 0.41779000000219957
    },
    {
      "episode": 1652,
      "score": 198,
      "reward": -894.0,
      "steps": 54,
      "mean_loss": 4054.9485092163086,
      "epsilon": 0.417736000002201
    },
    {
      "episode": 1653,
      "score": 100,
      "reward": -980.0,
      "steps": 43,
      "mean_loss": 3694.9060871212982,
      "epsilon": 0.41769300000220216
    },
    {
      "episode": 1654,
      "score": 151,
      "reward": -945.0,
      "steps": 49,
      "mean_loss": 4888.434087792221,
      "epsilon": 0.4176440000022035
    },
    {
      "episode": 1655,
      "score": 146,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 4822.871152918389,
      "epsilon": 0.41759700000220473
    },
    {
      "episode": 1656,
      "score": 158,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 5296.828903587497,
      "epsilon": 0.41754800000220604
    },
    {
      "episode": 1657,
      "score": 122,
      "reward": -954.0,
      "steps": 45,
      "mean_loss": 6367.622409735785,
      "epsilon": 0.41750300000220725
    },
    {
      "episode": 1658,
      "score": 129,
      "reward": -956.0,
      "steps": 48,
      "mean_loss": 4284.749317963918,
      "epsilon": 0.41745500000220853
    },
    {
      "episode": 1659,
      "score": 98,
      "reward": -964.0,
      "steps": 40,
      "mean_loss": 5126.786825656891,
      "epsilon": 0.4174150000022096
    },
    {
      "episode": 1660,
      "score": 161,
      "reward": -918.0,
      "steps": 47,
      "mean_loss": 5404.838343681173,
      "epsilon": 0.41736800000221086
    },
    {
      "episode": 1661,
      "score": 103,
      "reward": -976.0,
      "steps": 42,
      "mean_loss": 7749.745855058943,
      "epsilon": 0.417326000002212
    },
    {
      "episode": 1662,
      "score": 182,
      "reward": -904.0,
      "steps": 53,
      "mean_loss": 5169.845160430333,
      "epsilon": 0.4172730000022134
    },
    {
      "episode": 1663,
      "score": 152,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 4679.154717072197,
      "epsilon": 0.41722700000221463
    },
    {
      "episode": 1664,
      "score": 124,
      "reward": -957.0,
      "steps": 46,
      "mean_loss": 2577.0067742389183,
      "epsilon": 0.41718100000221586
    },
    {
      "episode": 1665,
      "score": 121,
      "reward": -959.0,
      "steps": 46,
      "mean_loss": 3619.215351353521,
      "epsilon": 0.4171350000022171
    },
    {
      "episode": 1666,
      "score": 177,
      "reward": -889.0,
      "steps": 51,
      "mean_loss": 4887.965806400075,
      "epsilon": 0.41708400000221846
    },
    {
      "episode": 1667,
      "score": 113,
      "reward": -953.0,
      "steps": 38,
      "mean_loss": 6254.752145466052,
      "epsilon": 0.4170460000022195
    },
    {
      "episode": 1668,
      "score": 79,
      "reward": -976.0,
      "steps": 34,
      "mean_loss": 3783.3418579101562,
      "epsilon": 0.4170120000022204
    },
    {
      "episode": 1669,
      "score": 141,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 5002.383664557275,
      "epsilon": 0.41696500000222164
    },
    {
      "episode": 1670,
      "score": 103,
      "reward": -971.0,
      "steps": 40,
      "mean_loss": 3225.300131225586,
      "epsilon": 0.4169250000022227
    },
    {
      "episode": 1671,
      "score": 140,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 4975.705537245009,
      "epsilon": 0.4168800000022239
    },
    {
      "episode": 1672,
      "score": 177,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 4821.99081348923,
      "epsilon": 0.41682700000222533
    },
    {
      "episode": 1673,
      "score": 129,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 4485.995265007019,
      "epsilon": 0.4167790000022266
    },
    {
      "episode": 1674,
      "score": 174,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 4798.701941172282,
      "epsilon": 0.4167310000022279
    },
    {
      "episode": 1675,
      "score": 156,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 4199.528536289296,
      "epsilon": 0.41668400000222916
    },
    {
      "episode": 1676,
      "score": 129,
      "reward": -937.0,
      "steps": 45,
      "mean_loss": 3437.0033393012154,
      "epsilon": 0.41663900000223036
    },
    {
      "episode": 1677,
      "score": 168,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 5863.652762756347,
      "epsilon": 0.4165890000022317
    },
    {
      "episode": 1678,
      "score": 178,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 5686.217790310199,
      "epsilon": 0.4165370000022331
    },
    {
      "episode": 1679,
      "score": 122,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 5916.2239246774225,
      "epsilon": 0.41649000000223435
    },
    {
      "episode": 1680,
      "score": 114,
      "reward": -938.0,
      "steps": 35,
      "mean_loss": 2502.402263532366,
      "epsilon": 0.4164550000022353
    },
    {
      "episode": 1681,
      "score": 126,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 5331.020126776261,
      "epsilon": 0.41641100000223646
    },
    {
      "episode": 1682,
      "score": 130,
      "reward": -935.0,
      "steps": 39,
      "mean_loss": 4838.455716451009,
      "epsilon": 0.4163720000022375
    },
    {
      "episode": 1683,
      "score": 131,
      "reward": -959.0,
      "steps": 46,
      "mean_loss": 3299.1035011954928,
      "epsilon": 0.41632600000223874
    },
    {
      "episode": 1684,
      "score": 143,
      "reward": -933.0,
      "steps": 48,
      "mean_loss": 2668.723304748535,
      "epsilon": 0.41627800000224
    },
    {
      "episode": 1685,
      "score": 107,
      "reward": -959.0,
      "steps": 41,
      "mean_loss": 3201.201512592595,
      "epsilon": 0.4162370000022411
    },
    {
      "episode": 1686,
      "score": 172,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 4185.207884568435,
      "epsilon": 0.4161850000022425
    },
    {
      "episode": 1687,
      "score": 169,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 2334.5629494849672,
      "epsilon": 0.41613800000224377
    },
    {
      "episode": 1688,
      "score": 159,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 2242.0139581298827,
      "epsilon": 0.4160880000022451
    },
    {
      "episode": 1689,
      "score": 164,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 5234.31641494751,
      "epsilon": 0.41603800000224644
    },
    {
      "episode": 1690,
      "score": 100,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 3159.3895312983814,
      "epsilon": 0.41599700000224754
    },
    {
      "episode": 1691,
      "score": 179,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 4608.5354341360235,
      "epsilon": 0.41594500000224893
    },
    {
      "episode": 1692,
      "score": 173,
      "reward": -899.0,
      "steps": 50,
      "mean_loss": 3315.646754074097,
      "epsilon": 0.41589500000225027
    },
    {
      "episode": 1693,
      "score": 174,
      "reward": -911.0,
      "steps": 49,
      "mean_loss": 4044.472661543866,
      "epsilon": 0.4158460000022516
    },
    {
      "episode": 1694,
      "score": 78,
      "reward": -978.0,
      "steps": 34,
      "mean_loss": 2566.3137844310086,
      "epsilon": 0.4158120000022525
    },
    {
      "episode": 1695,
      "score": 152,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 3267.855020840963,
      "epsilon": 0.4157640000022538
    },
    {
      "episode": 1696,
      "score": 151,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4676.452344388378,
      "epsilon": 0.4157150000022551
    },
    {
      "episode": 1697,
      "score": 126,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 4333.266521370929,
      "epsilon": 0.4156690000022563
    },
    {
      "episode": 1698,
      "score": 106,
      "reward": -943.0,
      "steps": 35,
      "mean_loss": 3560.2270411900113,
      "epsilon": 0.41563400000225725
    },
    {
      "episode": 1699,
      "score": 128,
      "reward": -945.0,
      "steps": 42,
      "mean_loss": 3555.3654789697557,
      "epsilon": 0.4155920000022584
    },
    {
      "episode": 1700,
      "score": 211,
      "reward": -886.0,
      "steps": 57,
      "mean_loss": 4085.3770654243335,
      "epsilon": 0.4155350000022599
    },
    {
      "episode": 1701,
      "score": 43,
      "reward": -1002.0,
      "steps": 27,
      "mean_loss": 5604.129420810275,
      "epsilon": 0.4155080000022606
    },
    {
      "episode": 1702,
      "score": 105,
      "reward": -976.0,
      "steps": 42,
      "mean_loss": 5903.467355455671,
      "epsilon": 0.41546600000226175
    },
    {
      "episode": 1703,
      "score": 98,
      "reward": -960.0,
      "steps": 37,
      "mean_loss": 9730.175317506533,
      "epsilon": 0.41542900000226274
    },
    {
      "episode": 1704,
      "score": 195,
      "reward": -893.0,
      "steps": 53,
      "mean_loss": 3736.061124693673,
      "epsilon": 0.41537600000226416
    },
    {
      "episode": 1705,
      "score": 122,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 3901.311281464317,
      "epsilon": 0.41533200000226533
    },
    {
      "episode": 1706,
      "score": 103,
      "reward": -953.0,
      "steps": 35,
      "mean_loss": 2286.1426176888604,
      "epsilon": 0.41529700000226627
    },
    {
      "episode": 1707,
      "score": 103,
      "reward": -961.0,
      "steps": 38,
      "mean_loss": 4878.172543375115,
      "epsilon": 0.4152590000022673
    },
    {
      "episode": 1708,
      "score": 137,
      "reward": -927.0,
      "steps": 45,
      "mean_loss": 4028.6632973564997,
      "epsilon": 0.4152140000022685
    },
    {
      "episode": 1709,
      "score": 126,
      "reward": -945.0,
      "steps": 45,
      "mean_loss": 3544.2705777486167,
      "epsilon": 0.4151690000022697
    },
    {
      "episode": 1710,
      "score": 161,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 3562.6707589076113,
      "epsilon": 0.4151170000022711
    },
    {
      "episode": 1711,
      "score": 161,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 3403.6867609405517,
      "epsilon": 0.4150670000022724
    },
    {
      "episode": 1712,
      "score": 157,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 4886.89129809944,
      "epsilon": 0.41501800000227373
    },
    {
      "episode": 1713,
      "score": 149,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 3470.1657612080476,
      "epsilon": 0.41496900000227505
    },
    {
      "episode": 1714,
      "score": 239,
      "reward": -857.0,
      "steps": 62,
      "mean_loss": 4401.277161136751,
      "epsilon": 0.4149070000022767
    },
    {
      "episode": 1715,
      "score": 150,
      "reward": -921.0,
      "steps": 48,
      "mean_loss": 5258.87993812561,
      "epsilon": 0.414859000002278
    },
    {
      "episode": 1716,
      "score": 104,
      "reward": -968.0,
      "steps": 42,
      "mean_loss": 1988.9278831481934,
      "epsilon": 0.4148170000022791
    },
    {
      "episode": 1717,
      "score": 121,
      "reward": -929.0,
      "steps": 35,
      "mean_loss": 2513.308680289132,
      "epsilon": 0.41478200000228005
    },
    {
      "episode": 1718,
      "score": 123,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 6430.388860702515,
      "epsilon": 0.4147380000022812
    },
    {
      "episode": 1719,
      "score": 105,
      "reward": -967.0,
      "steps": 43,
      "mean_loss": 4457.4908446822055,
      "epsilon": 0.4146950000022824
    },
    {
      "episode": 1720,
      "score": 171,
      "reward": -918.0,
      "steps": 47,
      "mean_loss": 4064.413954227529,
      "epsilon": 0.41464800000228363
    },
    {
      "episode": 1721,
      "score": 140,
      "reward": -932.0,
      "steps": 46,
      "mean_loss": 4933.389502981435,
      "epsilon": 0.41460200000228487
    },
    {
      "episode": 1722,
      "score": 176,
      "reward": -919.0,
      "steps": 53,
      "mean_loss": 7419.313853281848,
      "epsilon": 0.4145490000022863
    },
    {
      "episode": 1723,
      "score": 133,
      "reward": -932.0,
      "steps": 46,
      "mean_loss": 3289.7479354194975,
      "epsilon": 0.4145030000022875
    },
    {
      "episode": 1724,
      "score": 140,
      "reward": -932.0,
      "steps": 48,
      "mean_loss": 6977.924358050029,
      "epsilon": 0.4144550000022888
    },
    {
      "episode": 1725,
      "score": 203,
      "reward": -876.0,
      "steps": 55,
      "mean_loss": 7116.652170632102,
      "epsilon": 0.41440000000229027
    },
    {
      "episode": 1726,
      "score": 134,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 3241.912212371826,
      "epsilon": 0.41435200000229155
    },
    {
      "episode": 1727,
      "score": 243,
      "reward": -851.0,
      "steps": 60,
      "mean_loss": 6391.4196985880535,
      "epsilon": 0.41429200000229316
    },
    {
      "episode": 1728,
      "score": 68,
      "reward": -998.0,
      "steps": 36,
      "mean_loss": 3315.665217929416,
      "epsilon": 0.4142560000022941
    },
    {
      "episode": 1729,
      "score": 114,
      "reward": -950.0,
      "steps": 40,
      "mean_loss": 4620.327183532715,
      "epsilon": 0.4142160000022952
    },
    {
      "episode": 1730,
      "score": 85,
      "reward": -979.0,
      "steps": 37,
      "mean_loss": 4356.984957102182,
      "epsilon": 0.4141790000022962
    },
    {
      "episode": 1731,
      "score": 103,
      "reward": -974.0,
      "steps": 44,
      "mean_loss": 4348.249743201516,
      "epsilon": 0.41413500000229736
    },
    {
      "episode": 1732,
      "score": 95,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 4887.298335719753,
      "epsilon": 0.41409800000229835
    },
    {
      "episode": 1733,
      "score": 167,
      "reward": -908.0,
      "steps": 51,
      "mean_loss": 1841.8148291344737,
      "epsilon": 0.4140470000022997
    },
    {
      "episode": 1734,
      "score": 107,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 3182.430782058022,
      "epsilon": 0.4140030000023009
    },
    {
      "episode": 1735,
      "score": 131,
      "reward": -946.0,
      "steps": 47,
      "mean_loss": 6803.924264948419,
      "epsilon": 0.41395600000230215
    },
    {
      "episode": 1736,
      "score": 225,
      "reward": -872.0,
      "steps": 58,
      "mean_loss": 5766.302683468522,
      "epsilon": 0.4138980000023037
    },
    {
      "episode": 1737,
      "score": 189,
      "reward": -898.0,
      "steps": 52,
      "mean_loss": 2965.4839151822603,
      "epsilon": 0.4138460000023051
    },
    {
      "episode": 1738,
      "score": 117,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 5002.558072090149,
      "epsilon": 0.41380200000230627
    },
    {
      "episode": 1739,
      "score": 76,
      "reward": -965.0,
      "steps": 31,
      "mean_loss": 3864.5517159738847,
      "epsilon": 0.4137710000023071
    },
    {
      "episode": 1740,
      "score": 125,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 4750.756446174953,
      "epsilon": 0.41372500000230833
    },
    {
      "episode": 1741,
      "score": 116,
      "reward": -945.0,
      "steps": 39,
      "mean_loss": 5310.873524201222,
      "epsilon": 0.4136860000023094
    },
    {
      "episode": 1742,
      "score": 130,
      "reward": -945.0,
      "steps": 47,
      "mean_loss": 3711.2023830007997,
      "epsilon": 0.41363900000231063
    },
    {
      "episode": 1743,
      "score": 117,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 3712.773932977156,
      "epsilon": 0.4135950000023118
    },
    {
      "episode": 1744,
      "score": 95,
      "reward": -951.0,
      "steps": 34,
      "mean_loss": 2979.66224973342,
      "epsilon": 0.4135610000023127
    },
    {
      "episode": 1745,
      "score": 125,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 3674.736055042433,
      "epsilon": 0.41351500000231395
    },
    {
      "episode": 1746,
      "score": 158,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 4100.083109140396,
      "epsilon": 0.41346700000231523
    },
    {
      "episode": 1747,
      "score": 145,
      "reward": -919.0,
      "steps": 45,
      "mean_loss": 4669.775957319472,
      "epsilon": 0.41342200000231644
    },
    {
      "episode": 1748,
      "score": 138,
      "reward": -938.0,
      "steps": 45,
      "mean_loss": 5135.085229153104,
      "epsilon": 0.41337700000231764
    },
    {
      "episode": 1749,
      "score": 77,
      "reward": -986.0,
      "steps": 37,
      "mean_loss": 5187.357322589771,
      "epsilon": 0.41334000000231863
    },
    {
      "episode": 1750,
      "score": 190,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 2350.9129892985025,
      "epsilon": 0.4132860000023201
    },
    {
      "episode": 1751,
      "score": 159,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 3862.339068042989,
      "epsilon": 0.4132370000023214
    },
    {
      "episode": 1752,
      "score": 128,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 4784.802204471164,
      "epsilon": 0.4131920000023226
    },
    {
      "episode": 1753,
      "score": 123,
      "reward": -927.0,
      "steps": 40,
      "mean_loss": 4751.593950271606,
      "epsilon": 0.41315200000232366
    },
    {
      "episode": 1754,
      "score": 212,
      "reward": -899.0,
      "steps": 59,
      "mean_loss": 3749.811224985931,
      "epsilon": 0.41309300000232524
    },
    {
      "episode": 1755,
      "score": 90,
      "reward": -977.0,
      "steps": 39,
      "mean_loss": 3185.1058611747544,
      "epsilon": 0.4130540000023263
    },
    {
      "episode": 1756,
      "score": 87,
      "reward": -985.0,
      "steps": 40,
      "mean_loss": 3228.153476333618,
      "epsilon": 0.41301400000232735
    },
    {
      "episode": 1757,
      "score": 133,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 4541.259243878451,
      "epsilon": 0.41297000000232853
    },
    {
      "episode": 1758,
      "score": 83,
      "reward": -981.0,
      "steps": 38,
      "mean_loss": 3733.075048547042,
      "epsilon": 0.41293200000232955
    },
    {
      "episode": 1759,
      "score": 168,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 3447.0573759812573,
      "epsilon": 0.41288000000233094
    },
    {
      "episode": 1760,
      "score": 153,
      "reward": -912.0,
      "steps": 48,
      "mean_loss": 2858.0957402388253,
      "epsilon": 0.4128320000023322
    },
    {
      "episode": 1761,
      "score": 82,
      "reward": -959.0,
      "steps": 31,
      "mean_loss": 2404.956821072486,
      "epsilon": 0.41280100000233305
    },
    {
      "episode": 1762,
      "score": 117,
      "reward": -936.0,
      "steps": 43,
      "mean_loss": 3379.576771403468,
      "epsilon": 0.4127580000023342
    },
    {
      "episode": 1763,
      "score": 98,
      "reward": -969.0,
      "steps": 43,
      "mean_loss": 6138.375244495481,
      "epsilon": 0.41271500000233535
    },
    {
      "episode": 1764,
      "score": 156,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 5665.540136108399,
      "epsilon": 0.4126650000023367
    },
    {
      "episode": 1765,
      "score": 90,
      "reward": -988.0,
      "steps": 42,
      "mean_loss": 3842.8379640125095,
      "epsilon": 0.4126230000023378
    },
    {
      "episode": 1766,
      "score": 146,
      "reward": -935.0,
      "steps": 49,
      "mean_loss": 6086.703850103884,
      "epsilon": 0.4125740000023391
    },
    {
      "episode": 1767,
      "score": 142,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 3955.837700055993,
      "epsilon": 0.41252800000234036
    },
    {
      "episode": 1768,
      "score": 83,
      "reward": -966.0,
      "steps": 33,
      "mean_loss": 4799.427053624933,
      "epsilon": 0.41249500000234124
    },
    {
      "episode": 1769,
      "score": 129,
      "reward": -959.0,
      "steps": 47,
      "mean_loss": 7754.632515684088,
      "epsilon": 0.4124480000023425
    },
    {
      "episode": 1770,
      "score": 93,
      "reward": -962.0,
      "steps": 38,
      "mean_loss": 6405.065916764109,
      "epsilon": 0.4124100000023435
    },
    {
      "episode": 1771,
      "score": 173,
      "reward": -893.0,
      "steps": 50,
      "mean_loss": 4289.421808624267,
      "epsilon": 0.41236000000234485
    },
    {
      "episode": 1772,
      "score": 147,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 5983.256266492478,
      "epsilon": 0.4123130000023461
    },
    {
      "episode": 1773,
      "score": 175,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 4010.06462258559,
      "epsilon": 0.4122610000023475
    },
    {
      "episode": 1774,
      "score": 128,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 3075.409542170438,
      "epsilon": 0.4122170000023487
    },
    {
      "episode": 1775,
      "score": 226,
      "reward": -871.0,
      "steps": 55,
      "mean_loss": 3235.079583601518,
      "epsilon": 0.41216200000235015
    },
    {
      "episode": 1776,
      "score": 128,
      "reward": -952.0,
      "steps": 45,
      "mean_loss": 4402.709223429362,
      "epsilon": 0.41211700000235135
    },
    {
      "episode": 1777,
      "score": 153,
      "reward": -906.0,
      "steps": 45,
      "mean_loss": 7307.199369133843,
      "epsilon": 0.41207200000235256
    },
    {
      "episode": 1778,
      "score": 106,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 4651.3650620200415,
      "epsilon": 0.41202800000235373
    },
    {
      "episode": 1779,
      "score": 234,
      "reward": -861.0,
      "steps": 58,
      "mean_loss": 5098.892873040561,
      "epsilon": 0.4119700000023553
    },
    {
      "episode": 1780,
      "score": 154,
      "reward": -919.0,
      "steps": 45,
      "mean_loss": 4524.204190995958,
      "epsilon": 0.4119250000023565
    },
    {
      "episode": 1781,
      "score": 168,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3148.0654028320314,
      "epsilon": 0.4118750000023578
    },
    {
      "episode": 1782,
      "score": 275,
      "reward": -831.0,
      "steps": 63,
      "mean_loss": 3049.0115111820282,
      "epsilon": 0.4118120000023595
    },
    {
      "episode": 1783,
      "score": 153,
      "reward": -914.0,
      "steps": 46,
      "mean_loss": 4347.870063615882,
      "epsilon": 0.41176600000236074
    },
    {
      "episode": 1784,
      "score": 195,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 2964.6886728074815,
      "epsilon": 0.4117120000023622
    },
    {
      "episode": 1785,
      "score": 174,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 4596.296784494438,
      "epsilon": 0.41166100000236355
    },
    {
      "episode": 1786,
      "score": 112,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 5136.3733398800805,
      "epsilon": 0.4116190000023647
    },
    {
      "episode": 1787,
      "score": 163,
      "reward": -913.0,
      "steps": 49,
      "mean_loss": 3236.068368172159,
      "epsilon": 0.411570000002366
    },
    {
      "episode": 1788,
      "score": 130,
      "reward": -956.0,
      "steps": 47,
      "mean_loss": 4769.2571206600105,
      "epsilon": 0.41152300000236725
    },
    {
      "episode": 1789,
      "score": 143,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 3170.3912893136344,
      "epsilon": 0.41147500000236853
    },
    {
      "episode": 1790,
      "score": 74,
      "reward": -993.0,
      "steps": 34,
      "mean_loss": 3968.934050055111,
      "epsilon": 0.41144100000236944
    },
    {
      "episode": 1791,
      "score": 118,
      "reward": -941.0,
      "steps": 36,
      "mean_loss": 4242.375076293945,
      "epsilon": 0.4114050000023704
    },
    {
      "episode": 1792,
      "score": 134,
      "reward": -918.0,
      "steps": 41,
      "mean_loss": 2791.7310403963415,
      "epsilon": 0.4113640000023715
    },
    {
      "episode": 1793,
      "score": 168,
      "reward": -907.0,
      "steps": 51,
      "mean_loss": 2087.8531542011337,
      "epsilon": 0.41131300000237286
    },
    {
      "episode": 1794,
      "score": 152,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 5380.132444381714,
      "epsilon": 0.4112630000023742
    },
    {
      "episode": 1795,
      "score": 131,
      "reward": -931.0,
      "steps": 42,
      "mean_loss": 1353.3078438895088,
      "epsilon": 0.4112210000023753
    },
    {
      "episode": 1796,
      "score": 202,
      "reward": -873.0,
      "steps": 54,
      "mean_loss": 5504.135516979076,
      "epsilon": 0.41116700000237677
    },
    {
      "episode": 1797,
      "score": 87,
      "reward": -976.0,
      "steps": 39,
      "mean_loss": 5930.199591416579,
      "epsilon": 0.4111280000023778
    },
    {
      "episode": 1798,
      "score": 73,
      "reward": -971.0,
      "steps": 31,
      "mean_loss": 5671.328340099704,
      "epsilon": 0.41109700000237864
    },
    {
      "episode": 1799,
      "score": 121,
      "reward": -959.0,
      "steps": 46,
      "mean_loss": 3187.17648945684,
      "epsilon": 0.4110510000023799
    },
    {
      "episode": 1800,
      "score": 141,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 2157.8563195069632,
      "epsilon": 0.41100300000238116
    },
    {
      "episode": 1801,
      "score": 171,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 6250.300036112468,
      "epsilon": 0.4109520000023825
    },
    {
      "episode": 1802,
      "score": 75,
      "reward": -980.0,
      "steps": 34,
      "mean_loss": 3443.088399550494,
      "epsilon": 0.41091800000238343
    },
    {
      "episode": 1803,
      "score": 110,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 4224.169454993271,
      "epsilon": 0.41087700000238453
    },
    {
      "episode": 1804,
      "score": 160,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 5119.429746780395,
      "epsilon": 0.41082700000238587
    },
    {
      "episode": 1805,
      "score": 67,
      "reward": -1003.0,
      "steps": 36,
      "mean_loss": 1811.4493021435208,
      "epsilon": 0.41079100000238683
    },
    {
      "episode": 1806,
      "score": 119,
      "reward": -946.0,
      "steps": 41,
      "mean_loss": 6850.520529956352,
      "epsilon": 0.4107500000023879
    },
    {
      "episode": 1807,
      "score": 126,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 2655.2135114255157,
      "epsilon": 0.41070400000238916
    },
    {
      "episode": 1808,
      "score": 99,
      "reward": -967.0,
      "steps": 39,
      "mean_loss": 7622.361827361278,
      "epsilon": 0.4106650000023902
    },
    {
      "episode": 1809,
      "score": 143,
      "reward": -917.0,
      "steps": 43,
      "mean_loss": 6807.217330932617,
      "epsilon": 0.41062200000239135
    },
    {
      "episode": 1810,
      "score": 126,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 2345.8550836389713,
      "epsilon": 0.41057800000239253
    },
    {
      "episode": 1811,
      "score": 92,
      "reward": -980.0,
      "steps": 40,
      "mean_loss": 5233.680037689209,
      "epsilon": 0.4105380000023936
    },
    {
      "episode": 1812,
      "score": 124,
      "reward": -950.0,
      "steps": 45,
      "mean_loss": 3404.086126200358,
      "epsilon": 0.4104930000023948
    },
    {
      "episode": 1813,
      "score": 147,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 2737.6508444081182,
      "epsilon": 0.41044700000239603
    },
    {
      "episode": 1814,
      "score": 113,
      "reward": -974.0,
      "steps": 44,
      "mean_loss": 4140.997207554904,
      "epsilon": 0.4104030000023972
    },
    {
      "episode": 1815,
      "score": 119,
      "reward": -956.0,
      "steps": 46,
      "mean_loss": 3547.127715981525,
      "epsilon": 0.41035700000239844
    },
    {
      "episode": 1816,
      "score": 63,
      "reward": -990.0,
      "steps": 32,
      "mean_loss": 2007.5367193222046,
      "epsilon": 0.4103250000023993
    },
    {
      "episode": 1817,
      "score": 142,
      "reward": -955.0,
      "steps": 48,
      "mean_loss": 3656.129071076711,
      "epsilon": 0.4102770000024006
    },
    {
      "episode": 1818,
      "score": 125,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 5140.030500498685,
      "epsilon": 0.41023300000240176
    },
    {
      "episode": 1819,
      "score": 90,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 4150.883996087152,
      "epsilon": 0.41019600000240275
    },
    {
      "episode": 1820,
      "score": 79,
      "reward": -969.0,
      "steps": 33,
      "mean_loss": 3486.6432997963643,
      "epsilon": 0.41016300000240363
    },
    {
      "episode": 1821,
      "score": 200,
      "reward": -885.0,
      "steps": 56,
      "mean_loss": 5050.048819405692,
      "epsilon": 0.41010700000240513
    },
    {
      "episode": 1822,
      "score": 139,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 3096.494480609894,
      "epsilon": 0.4100590000024064
    },
    {
      "episode": 1823,
      "score": 105,
      "reward": -957.0,
      "steps": 42,
      "mean_loss": 4064.0848755609422,
      "epsilon": 0.41001700000240754
    },
    {
      "episode": 1824,
      "score": 65,
      "reward": -1003.0,
      "steps": 34,
      "mean_loss": 3630.959575653076,
      "epsilon": 0.40998300000240845
    },
    {
      "episode": 1825,
      "score": 172,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 4847.571905330736,
      "epsilon": 0.40993400000240976
    },
    {
      "episode": 1826,
      "score": 138,
      "reward": -934.0,
      "steps": 46,
      "mean_loss": 4588.866163336713,
      "epsilon": 0.409888000002411
    },
    {
      "episode": 1827,
      "score": 148,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 1574.3230361143749,
      "epsilon": 0.4098400000024123
    },
    {
      "episode": 1828,
      "score": 91,
      "reward": -955.0,
      "steps": 35,
      "mean_loss": 4689.579402923584,
      "epsilon": 0.4098050000024132
    },
    {
      "episode": 1829,
      "score": 151,
      "reward": -914.0,
      "steps": 45,
      "mean_loss": 5439.058757146199,
      "epsilon": 0.4097600000024144
    },
    {
      "episode": 1830,
      "score": 122,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 2960.4374913735824,
      "epsilon": 0.4097160000024156
    },
    {
      "episode": 1831,
      "score": 93,
      "reward": -960.0,
      "steps": 35,
      "mean_loss": 3949.3146730695453,
      "epsilon": 0.40968100000241653
    },
    {
      "episode": 1832,
      "score": 97,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 3967.0146717908906,
      "epsilon": 0.4096400000024176
    },
    {
      "episode": 1833,
      "score": 102,
      "reward": -971.0,
      "steps": 44,
      "mean_loss": 6996.263553619385,
      "epsilon": 0.4095960000024188
    },
    {
      "episode": 1834,
      "score": 158,
      "reward": -918.0,
      "steps": 46,
      "mean_loss": 3156.176140329112,
      "epsilon": 0.40955000000242003
    },
    {
      "episode": 1835,
      "score": 207,
      "reward": -881.0,
      "steps": 58,
      "mean_loss": 4830.140945039946,
      "epsilon": 0.4094920000024216
    },
    {
      "episode": 1836,
      "score": 94,
      "reward": -977.0,
      "steps": 37,
      "mean_loss": 5777.113423527898,
      "epsilon": 0.4094550000024226
    },
    {
      "episode": 1837,
      "score": 162,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 4826.336384887695,
      "epsilon": 0.4094050000024239
    },
    {
      "episode": 1838,
      "score": 114,
      "reward": -966.0,
      "steps": 45,
      "mean_loss": 3565.2589953952365,
      "epsilon": 0.4093600000024251
    },
    {
      "episode": 1839,
      "score": 124,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 5480.351513602517,
      "epsilon": 0.4093160000024263
    },
    {
      "episode": 1840,
      "score": 214,
      "reward": -880.0,
      "steps": 57,
      "mean_loss": 5780.3117754752175,
      "epsilon": 0.4092590000024278
    },
    {
      "episode": 1841,
      "score": 84,
      "reward": -973.0,
      "steps": 34,
      "mean_loss": 3186.4373210458193,
      "epsilon": 0.40922500000242873
    },
    {
      "episode": 1842,
      "score": 122,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 4870.74976643649,
      "epsilon": 0.4091810000024299
    },
    {
      "episode": 1843,
      "score": 113,
      "reward": -969.0,
      "steps": 45,
      "mean_loss": 5813.110529666476,
      "epsilon": 0.4091360000024311
    },
    {
      "episode": 1844,
      "score": 158,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 2948.756978750229,
      "epsilon": 0.4090880000024324
    },
    {
      "episode": 1845,
      "score": 107,
      "reward": -949.0,
      "steps": 38,
      "mean_loss": 4959.608980781154,
      "epsilon": 0.4090500000024334
    },
    {
      "episode": 1846,
      "score": 116,
      "reward": -940.0,
      "steps": 36,
      "mean_loss": 4403.054333262973,
      "epsilon": 0.4090140000024344
    },
    {
      "episode": 1847,
      "score": 159,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 4404.610862731934,
      "epsilon": 0.4089640000024357
    },
    {
      "episode": 1848,
      "score": 126,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 4160.499545184049,
      "epsilon": 0.4089200000024369
    },
    {
      "episode": 1849,
      "score": 100,
      "reward": -978.0,
      "steps": 42,
      "mean_loss": 2861.9372907366073,
      "epsilon": 0.408878000002438
    },
    {
      "episode": 1850,
      "score": 247,
      "reward": -858.0,
      "steps": 63,
      "mean_loss": 5230.296506609236,
      "epsilon": 0.4088150000024397
    },
    {
      "episode": 1851,
      "score": 133,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 2947.441188812256,
      "epsilon": 0.4087710000024409
    },
    {
      "episode": 1852,
      "score": 243,
      "reward": -849.0,
      "steps": 61,
      "mean_loss": 5341.226505217005,
      "epsilon": 0.4087100000024425
    },
    {
      "episode": 1853,
      "score": 98,
      "reward": -957.0,
      "steps": 37,
      "mean_loss": 4681.458250715926,
      "epsilon": 0.4086730000024435
    },
    {
      "episode": 1854,
      "score": 106,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 2042.2902737129025,
      "epsilon": 0.4086320000024446
    },
    {
      "episode": 1855,
      "score": 161,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 5908.784857089703,
      "epsilon": 0.408580000002446
    },
    {
      "episode": 1856,
      "score": 199,
      "reward": -881.0,
      "steps": 54,
      "mean_loss": 5159.478275581642,
      "epsilon": 0.40852600000244743
    },
    {
      "episode": 1857,
      "score": 133,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 4192.483891426249,
      "epsilon": 0.4084790000024487
    },
    {
      "episode": 1858,
      "score": 137,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 4896.873357192329,
      "epsilon": 0.4084330000024499
    },
    {
      "episode": 1859,
      "score": 136,
      "reward": -924.0,
      "steps": 43,
      "mean_loss": 4090.884184016738,
      "epsilon": 0.40839000000245107
    },
    {
      "episode": 1860,
      "score": 110,
      "reward": -952.0,
      "steps": 36,
      "mean_loss": 3439.9168649249605,
      "epsilon": 0.40835400000245203
    },
    {
      "episode": 1861,
      "score": 91,
      "reward": -984.0,
      "steps": 40,
      "mean_loss": 4853.273135566711,
      "epsilon": 0.4083140000024531
    },
    {
      "episode": 1862,
      "score": 130,
      "reward": -949.0,
      "steps": 43,
      "mean_loss": 4516.460361037143,
      "epsilon": 0.40827100000245425
    },
    {
      "episode": 1863,
      "score": 90,
      "reward": -958.0,
      "steps": 35,
      "mean_loss": 2369.9025205339703,
      "epsilon": 0.4082360000024552
    },
    {
      "episode": 1864,
      "score": 231,
      "reward": -870.0,
      "steps": 58,
      "mean_loss": 4607.980214612237,
      "epsilon": 0.40817800000245674
    },
    {
      "episode": 1865,
      "score": 90,
      "reward": -975.0,
      "steps": 38,
      "mean_loss": 4698.237973363776,
      "epsilon": 0.40814000000245776
    },
    {
      "episode": 1866,
      "score": 126,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 1912.6361725547097,
      "epsilon": 0.40809600000245894
    },
    {
      "episode": 1867,
      "score": 148,
      "reward": -921.0,
      "steps": 46,
      "mean_loss": 4833.894307260928,
      "epsilon": 0.40805000000246017
    },
    {
      "episode": 1868,
      "score": 129,
      "reward": -956.0,
      "steps": 46,
      "mean_loss": 4193.789532951687,
      "epsilon": 0.4080040000024614
    },
    {
      "episode": 1869,
      "score": 141,
      "reward": -924.0,
      "steps": 46,
      "mean_loss": 3515.112931624703,
      "epsilon": 0.40795800000246263
    },
    {
      "episode": 1870,
      "score": 247,
      "reward": -851.0,
      "steps": 62,
      "mean_loss": 5426.726292640932,
      "epsilon": 0.4078960000024643
    },
    {
      "episode": 1871,
      "score": 116,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 3643.6021383376346,
      "epsilon": 0.4078540000024654
    },
    {
      "episode": 1872,
      "score": 173,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 3386.567811126709,
      "epsilon": 0.40780400000246675
    },
    {
      "episode": 1873,
      "score": 114,
      "reward": -955.0,
      "steps": 40,
      "mean_loss": 4626.782185268402,
      "epsilon": 0.4077640000024678
    },
    {
      "episode": 1874,
      "score": 136,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3691.6234199036944,
      "epsilon": 0.4077170000024691
    },
    {
      "episode": 1875,
      "score": 111,
      "reward": -963.0,
      "steps": 45,
      "mean_loss": 4469.983245171441,
      "epsilon": 0.4076720000024703
    },
    {
      "episode": 1876,
      "score": 162,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 4658.546758124169,
      "epsilon": 0.40762500000247154
    },
    {
      "episode": 1877,
      "score": 215,
      "reward": -877.0,
      "steps": 57,
      "mean_loss": 2352.168737511886,
      "epsilon": 0.40756800000247306
    },
    {
      "episode": 1878,
      "score": 100,
      "reward": -965.0,
      "steps": 38,
      "mean_loss": 3596.6494130586325,
      "epsilon": 0.4075300000024741
    },
    {
      "episode": 1879,
      "score": 203,
      "reward": -894.0,
      "steps": 51,
      "mean_loss": 3979.251611821792,
      "epsilon": 0.40747900000247544
    },
    {
      "episode": 1880,
      "score": 137,
      "reward": -917.0,
      "steps": 44,
      "mean_loss": 2788.872331272472,
      "epsilon": 0.4074350000024766
    },
    {
      "episode": 1881,
      "score": 119,
      "reward": -959.0,
      "steps": 41,
      "mean_loss": 2932.814997231088,
      "epsilon": 0.4073940000024777
    },
    {
      "episode": 1882,
      "score": 220,
      "reward": -876.0,
      "steps": 57,
      "mean_loss": 3932.5553784286767,
      "epsilon": 0.40733700000247924
    },
    {
      "episode": 1883,
      "score": 197,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 6050.597251468234,
      "epsilon": 0.4072830000024807
    },
    {
      "episode": 1884,
      "score": 127,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 5432.076488329017,
      "epsilon": 0.4072370000024819
    },
    {
      "episode": 1885,
      "score": 88,
      "reward": -971.0,
      "steps": 35,
      "mean_loss": 2649.25339617048,
      "epsilon": 0.40720200000248286
    },
    {
      "episode": 1886,
      "score": 159,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 3628.714236577352,
      "epsilon": 0.40715400000248414
    },
    {
      "episode": 1887,
      "score": 120,
      "reward": -938.0,
      "steps": 43,
      "mean_loss": 1643.4356849138128,
      "epsilon": 0.4071110000024853
    },
    {
      "episode": 1888,
      "score": 166,
      "reward": -898.0,
      "steps": 45,
      "mean_loss": 3161.787717013889,
      "epsilon": 0.4070660000024865
    },
    {
      "episode": 1889,
      "score": 122,
      "reward": -960.0,
      "steps": 46,
      "mean_loss": 3870.832430134649,
      "epsilon": 0.4070200000024877
    },
    {
      "episode": 1890,
      "score": 145,
      "reward": -917.0,
      "steps": 46,
      "mean_loss": 4550.212257716967,
      "epsilon": 0.40697400000248896
    },
    {
      "episode": 1891,
      "score": 249,
      "reward": -846.0,
      "steps": 63,
      "mean_loss": 4573.564707317049,
      "epsilon": 0.40691100000249064
    },
    {
      "episode": 1892,
      "score": 117,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 1770.519645690918,
      "epsilon": 0.4068670000024918
    },
    {
      "episode": 1893,
      "score": 146,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 2624.0465854008994,
      "epsilon": 0.4068190000024931
    },
    {
      "episode": 1894,
      "score": 172,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 2745.060903842633,
      "epsilon": 0.4067670000024945
    },
    {
      "episode": 1895,
      "score": 132,
      "reward": -944.0,
      "steps": 47,
      "mean_loss": 3258.472089402219,
      "epsilon": 0.40672000000249575
    },
    {
      "episode": 1896,
      "score": 184,
      "reward": -918.0,
      "steps": 52,
      "mean_loss": 3042.291202178368,
      "epsilon": 0.40666800000249714
    },
    {
      "episode": 1897,
      "score": 133,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 2704.2015443884807,
      "epsilon": 0.4066220000024984
    },
    {
      "episode": 1898,
      "score": 132,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 3475.243481594583,
      "epsilon": 0.4065760000024996
    },
    {
      "episode": 1899,
      "score": 142,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 3352.481054554815,
      "epsilon": 0.40653000000250084
    },
    {
      "episode": 1900,
      "score": 193,
      "reward": -894.0,
      "steps": 52,
      "mean_loss": 1952.7820909940278,
      "epsilon": 0.4064780000025022
    },
    {
      "episode": 1901,
      "score": 130,
      "reward": -927.0,
      "steps": 40,
      "mean_loss": 3517.2435583114625,
      "epsilon": 0.4064380000025033
    },
    {
      "episode": 1902,
      "score": 183,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4547.87460122285,
      "epsilon": 0.40638400000250474
    },
    {
      "episode": 1903,
      "score": 90,
      "reward": -974.0,
      "steps": 35,
      "mean_loss": 1603.0873445783343,
      "epsilon": 0.4063490000025057
    },
    {
      "episode": 1904,
      "score": 149,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 2629.4568786621094,
      "epsilon": 0.4063030000025069
    },
    {
      "episode": 1905,
      "score": 155,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 4315.839854888916,
      "epsilon": 0.40625300000250825
    },
    {
      "episode": 1906,
      "score": 250,
      "reward": -853.0,
      "steps": 63,
      "mean_loss": 6089.614128688025,
      "epsilon": 0.40619000000250993
    },
    {
      "episode": 1907,
      "score": 90,
      "reward": -971.0,
      "steps": 33,
      "mean_loss": 4661.365397597804,
      "epsilon": 0.4061570000025108
    },
    {
      "episode": 1908,
      "score": 101,
      "reward": -959.0,
      "steps": 39,
      "mean_loss": 4487.982514405862,
      "epsilon": 0.40611800000251186
    },
    {
      "episode": 1909,
      "score": 180,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 3902.3505613620464,
      "epsilon": 0.40606600000251325
    },
    {
      "episode": 1910,
      "score": 149,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 6473.842725587928,
      "epsilon": 0.4060200000025145
    },
    {
      "episode": 1911,
      "score": 95,
      "reward": -972.0,
      "steps": 38,
      "mean_loss": 3859.245209442942,
      "epsilon": 0.4059820000025155
    },
    {
      "episode": 1912,
      "score": 146,
      "reward": -936.0,
      "steps": 49,
      "mean_loss": 4430.704562284509,
      "epsilon": 0.4059330000025168
    },
    {
      "episode": 1913,
      "score": 64,
      "reward": -1003.0,
      "steps": 33,
      "mean_loss": 4140.207523114754,
      "epsilon": 0.4059000000025177
    },
    {
      "episode": 1914,
      "score": 109,
      "reward": -951.0,
      "steps": 41,
      "mean_loss": 2586.075243787068,
      "epsilon": 0.4058590000025188
    },
    {
      "episode": 1915,
      "score": 124,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 2324.623254055447,
      "epsilon": 0.40581400000252
    },
    {
      "episode": 1916,
      "score": 169,
      "reward": -911.0,
      "steps": 49,
      "mean_loss": 3051.265517721371,
      "epsilon": 0.4057650000025213
    },
    {
      "episode": 1917,
      "score": 153,
      "reward": -944.0,
      "steps": 50,
      "mean_loss": 4396.278271179199,
      "epsilon": 0.40571500000252264
    },
    {
      "episode": 1918,
      "score": 103,
      "reward": -968.0,
      "steps": 42,
      "mean_loss": 2640.2160191308885,
      "epsilon": 0.40567300000252376
    },
    {
      "episode": 1919,
      "score": 210,
      "reward": -877.0,
      "steps": 52,
      "mean_loss": 6300.559305631197,
      "epsilon": 0.40562100000252516
    },
    {
      "episode": 1920,
      "score": 234,
      "reward": -874.0,
      "steps": 60,
      "mean_loss": 4063.2302649180097,
      "epsilon": 0.40556100000252676
    },
    {
      "episode": 1921,
      "score": 170,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 5041.4042086792,
      "epsilon": 0.4055110000025281
    },
    {
      "episode": 1922,
      "score": 168,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 3302.4690550261853,
      "epsilon": 0.40546000000252946
    },
    {
      "episode": 1923,
      "score": 114,
      "reward": -953.0,
      "steps": 41,
      "mean_loss": 3023.026406544011,
      "epsilon": 0.40541900000253056
    },
    {
      "episode": 1924,
      "score": 148,
      "reward": -924.0,
      "steps": 49,
      "mean_loss": 4003.146567986936,
      "epsilon": 0.40537000000253187
    },
    {
      "episode": 1925,
      "score": 151,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 3059.5853459040322,
      "epsilon": 0.40532200000253316
    },
    {
      "episode": 1926,
      "score": 92,
      "reward": -971.0,
      "steps": 41,
      "mean_loss": 3371.4570092922304,
      "epsilon": 0.40528100000253425
    },
    {
      "episode": 1927,
      "score": 157,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 3978.810375914282,
      "epsilon": 0.40523200000253556
    },
    {
      "episode": 1928,
      "score": 103,
      "reward": -961.0,
      "steps": 40,
      "mean_loss": 1923.1221469879151,
      "epsilon": 0.40519200000253663
    },
    {
      "episode": 1929,
      "score": 122,
      "reward": -956.0,
      "steps": 47,
      "mean_loss": 3059.232030584457,
      "epsilon": 0.4051450000025379
    },
    {
      "episode": 1930,
      "score": 105,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 1225.531020373833,
      "epsilon": 0.405104000002539
    },
    {
      "episode": 1931,
      "score": 198,
      "reward": -890.0,
      "steps": 57,
      "mean_loss": 3402.535300137704,
      "epsilon": 0.4050470000025405
    },
    {
      "episode": 1932,
      "score": 176,
      "reward": -895.0,
      "steps": 49,
      "mean_loss": 3521.1945501833547,
      "epsilon": 0.4049980000025418
    },
    {
      "episode": 1933,
      "score": 150,
      "reward": -945.0,
      "steps": 50,
      "mean_loss": 2209.192123718262,
      "epsilon": 0.40494800000254316
    },
    {
      "episode": 1934,
      "score": 178,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 3393.5618301703007,
      "epsilon": 0.4048990000025445
    },
    {
      "episode": 1935,
      "score": 114,
      "reward": -961.0,
      "steps": 42,
      "mean_loss": 3382.6501351311094,
      "epsilon": 0.4048570000025456
    },
    {
      "episode": 1936,
      "score": 117,
      "reward": -924.0,
      "steps": 35,
      "mean_loss": 3834.158183288574,
      "epsilon": 0.40482200000254653
    },
    {
      "episode": 1937,
      "score": 149,
      "reward": -920.0,
      "steps": 44,
      "mean_loss": 5823.555759950118,
      "epsilon": 0.4047780000025477
    },
    {
      "episode": 1938,
      "score": 120,
      "reward": -941.0,
      "steps": 43,
      "mean_loss": 2305.0401669879293,
      "epsilon": 0.40473500000254886
    },
    {
      "episode": 1939,
      "score": 84,
      "reward": -986.0,
      "steps": 39,
      "mean_loss": 5953.385744339381,
      "epsilon": 0.4046960000025499
    },
    {
      "episode": 1940,
      "score": 128,
      "reward": -933.0,
      "steps": 39,
      "mean_loss": 3587.6780577439526,
      "epsilon": 0.40465700000255095
    },
    {
      "episode": 1941,
      "score": 129,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 4550.792707483819,
      "epsilon": 0.4046100000025522
    },
    {
      "episode": 1942,
      "score": 148,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 5377.354723179594,
      "epsilon": 0.40456300000255346
    },
    {
      "episode": 1943,
      "score": 175,
      "reward": -919.0,
      "steps": 54,
      "mean_loss": 4343.691916854294,
      "epsilon": 0.4045090000025549
    },
    {
      "episode": 1944,
      "score": 175,
      "reward": -895.0,
      "steps": 50,
      "mean_loss": 3862.73730758667,
      "epsilon": 0.40445900000255625
    },
    {
      "episode": 1945,
      "score": 129,
      "reward": -939.0,
      "steps": 42,
      "mean_loss": 5557.626467023577,
      "epsilon": 0.40441700000255737
    },
    {
      "episode": 1946,
      "score": 283,
      "reward": -830.0,
      "steps": 68,
      "mean_loss": 4157.144041734583,
      "epsilon": 0.4043490000025592
    },
    {
      "episode": 1947,
      "score": 139,
      "reward": -927.0,
      "steps": 40,
      "mean_loss": 4419.878770256042,
      "epsilon": 0.40430900000256026
    },
    {
      "episode": 1948,
      "score": 143,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 5513.593910650773,
      "epsilon": 0.40426500000256144
    },
    {
      "episode": 1949,
      "score": 90,
      "reward": -972.0,
      "steps": 37,
      "mean_loss": 3781.4560869577767,
      "epsilon": 0.4042280000025624
    },
    {
      "episode": 1950,
      "score": 157,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 2552.7461777545036,
      "epsilon": 0.4041810000025637
    },
    {
      "episode": 1951,
      "score": 123,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 5053.180159308694,
      "epsilon": 0.40413700000256486
    },
    {
      "episode": 1952,
      "score": 147,
      "reward": -926.0,
      "steps": 48,
      "mean_loss": 2177.1001530488334,
      "epsilon": 0.40408900000256615
    },
    {
      "episode": 1953,
      "score": 185,
      "reward": -909.0,
      "steps": 55,
      "mean_loss": 4009.2107482910155,
      "epsilon": 0.4040340000025676
    },
    {
      "episode": 1954,
      "score": 83,
      "reward": -979.0,
      "steps": 40,
      "mean_loss": 2625.2615279197694,
      "epsilon": 0.4039940000025687
    },
    {
      "episode": 1955,
      "score": 109,
      "reward": -971.0,
      "steps": 45,
      "mean_loss": 4413.1122683207195,
      "epsilon": 0.4039490000025699
    },
    {
      "episode": 1956,
      "score": 146,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 5438.389715700733,
      "epsilon": 0.4039000000025712
    },
    {
      "episode": 1957,
      "score": 180,
      "reward": -890.0,
      "steps": 49,
      "mean_loss": 2481.4534429433393,
      "epsilon": 0.4038510000025725
    },
    {
      "episode": 1958,
      "score": 124,
      "reward": -946.0,
      "steps": 42,
      "mean_loss": 2223.697117215111,
      "epsilon": 0.40380900000257364
    },
    {
      "episode": 1959,
      "score": 138,
      "reward": -924.0,
      "steps": 44,
      "mean_loss": 6222.519996816462,
      "epsilon": 0.4037650000025748
    },
    {
      "episode": 1960,
      "score": 105,
      "reward": -960.0,
      "steps": 41,
      "mean_loss": 1388.0381451118283,
      "epsilon": 0.4037240000025759
    },
    {
      "episode": 1961,
      "score": 193,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 6164.011360608614,
      "epsilon": 0.4036720000025773
    },
    {
      "episode": 1962,
      "score": 247,
      "reward": -865.0,
      "steps": 62,
      "mean_loss": 6579.15202282321,
      "epsilon": 0.40361000000257896
    },
    {
      "episode": 1963,
      "score": 191,
      "reward": -874.0,
      "steps": 47,
      "mean_loss": 3038.8120105824573,
      "epsilon": 0.4035630000025802
    },
    {
      "episode": 1964,
      "score": 163,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 2150.705784606934,
      "epsilon": 0.40351300000258156
    },
    {
      "episode": 1965,
      "score": 141,
      "reward": -935.0,
      "steps": 46,
      "mean_loss": 3380.160812543786,
      "epsilon": 0.4034670000025828
    },
    {
      "episode": 1966,
      "score": 105,
      "reward": -962.0,
      "steps": 38,
      "mean_loss": 6794.198593641582,
      "epsilon": 0.4034290000025838
    },
    {
      "episode": 1967,
      "score": 176,
      "reward": -891.0,
      "steps": 49,
      "mean_loss": 7462.654169510822,
      "epsilon": 0.4033800000025851
    },
    {
      "episode": 1968,
      "score": 104,
      "reward": -932.0,
      "steps": 33,
      "mean_loss": 4509.48127746582,
      "epsilon": 0.403347000002586
    },
    {
      "episode": 1969,
      "score": 128,
      "reward": -934.0,
      "steps": 40,
      "mean_loss": 5320.526958084107,
      "epsilon": 0.40330700000258707
    },
    {
      "episode": 1970,
      "score": 166,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 4607.408403583601,
      "epsilon": 0.40325600000258843
    },
    {
      "episode": 1971,
      "score": 132,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 3131.3249893188477,
      "epsilon": 0.4032090000025897
    },
    {
      "episode": 1972,
      "score": 74,
      "reward": -994.0,
      "steps": 35,
      "mean_loss": 3329.8614324297223,
      "epsilon": 0.4031740000025906
    },
    {
      "episode": 1973,
      "score": 154,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 4816.464162577753,
      "epsilon": 0.40312800000259186
    },
    {
      "episode": 1974,
      "score": 122,
      "reward": -934.0,
      "steps": 42,
      "mean_loss": 3141.1541203998386,
      "epsilon": 0.403086000002593
    },
    {
      "episode": 1975,
      "score": 231,
      "reward": -866.0,
      "steps": 60,
      "mean_loss": 3428.099063873291,
      "epsilon": 0.4030260000025946
    },
    {
      "episode": 1976,
      "score": 127,
      "reward": -944.0,
      "steps": 42,
      "mean_loss": 2706.9071638924734,
      "epsilon": 0.4029840000025957
    },
    {
      "episode": 1977,
      "score": 192,
      "reward": -895.0,
      "steps": 56,
      "mean_loss": 3585.4336468832835,
      "epsilon": 0.4029280000025972
    },
    {
      "episode": 1978,
      "score": 121,
      "reward": -947.0,
      "steps": 41,
      "mean_loss": 3809.23211744355,
      "epsilon": 0.4028870000025983
    },
    {
      "episode": 1979,
      "score": 83,
      "reward": -963.0,
      "steps": 34,
      "mean_loss": 3249.25134972965,
      "epsilon": 0.4028530000025992
    },
    {
      "episode": 1980,
      "score": 142,
      "reward": -918.0,
      "steps": 44,
      "mean_loss": 4336.835108930414,
      "epsilon": 0.4028090000026004
    },
    {
      "episode": 1981,
      "score": 162,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3108.5990534973143,
      "epsilon": 0.40275900000260173
    },
    {
      "episode": 1982,
      "score": 276,
      "reward": -829.0,
      "steps": 68,
      "mean_loss": 3300.5825044407566,
      "epsilon": 0.40269100000260355
    },
    {
      "episode": 1983,
      "score": 134,
      "reward": -934.0,
      "steps": 46,
      "mean_loss": 3560.472186378811,
      "epsilon": 0.4026450000026048
    },
    {
      "episode": 1984,
      "score": 299,
      "reward": -813.0,
      "steps": 70,
      "mean_loss": 6131.988008989607,
      "epsilon": 0.40257500000260665
    },
    {
      "episode": 1985,
      "score": 198,
      "reward": -890.0,
      "steps": 55,
      "mean_loss": 2540.16864825162,
      "epsilon": 0.4025200000026081
    },
    {
      "episode": 1986,
      "score": 193,
      "reward": -906.0,
      "steps": 56,
      "mean_loss": 2912.9611594336375,
      "epsilon": 0.4024640000026096
    },
    {
      "episode": 1987,
      "score": 106,
      "reward": -963.0,
      "steps": 43,
      "mean_loss": 3187.2576130711755,
      "epsilon": 0.4024210000026108
    },
    {
      "episode": 1988,
      "score": 110,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 4591.435304187593,
      "epsilon": 0.4023790000026119
    },
    {
      "episode": 1989,
      "score": 95,
      "reward": -961.0,
      "steps": 34,
      "mean_loss": 4723.281559214873,
      "epsilon": 0.4023450000026128
    },
    {
      "episode": 1990,
      "score": 132,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 4634.756969282362,
      "epsilon": 0.402300000002614
    },
    {
      "episode": 1991,
      "score": 99,
      "reward": -940.0,
      "steps": 34,
      "mean_loss": 3064.512389687931,
      "epsilon": 0.4022660000026149
    },
    {
      "episode": 1992,
      "score": 185,
      "reward": -892.0,
      "steps": 54,
      "mean_loss": 5345.703389626962,
      "epsilon": 0.40221200000261637
    },
    {
      "episode": 1993,
      "score": 136,
      "reward": -946.0,
      "steps": 47,
      "mean_loss": 5097.263775115318,
      "epsilon": 0.4021650000026176
    },
    {
      "episode": 1994,
      "score": 235,
      "reward": -880.0,
      "steps": 63,
      "mean_loss": 5615.026629735553,
      "epsilon": 0.4021020000026193
    },
    {
      "episode": 1995,
      "score": 101,
      "reward": -960.0,
      "steps": 43,
      "mean_loss": 3538.6759345476016,
      "epsilon": 0.40205900000262046
    },
    {
      "episode": 1996,
      "score": 51,
      "reward": -1005.0,
      "steps": 30,
      "mean_loss": 4381.293788019816,
      "epsilon": 0.40202900000262126
    },
    {
      "episode": 1997,
      "score": 231,
      "reward": -869.0,
      "steps": 62,
      "mean_loss": 5517.344629103138,
      "epsilon": 0.4019670000026229
    },
    {
      "episode": 1998,
      "score": 113,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 5829.941692872481,
      "epsilon": 0.4019230000026241
    },
    {
      "episode": 1999,
      "score": 113,
      "reward": -934.0,
      "steps": 37,
      "mean_loss": 2492.5111834551835,
      "epsilon": 0.4018860000026251
    },
    {
      "episode": 2000,
      "score": 104,
      "reward": -952.0,
      "steps": 36,
      "mean_loss": 2467.369519021776,
      "epsilon": 0.40185000000262605
    },
    {
      "episode": 2001,
      "score": 102,
      "reward": -975.0,
      "steps": 41,
      "mean_loss": 3113.5805217463794,
      "epsilon": 0.40180900000262715
    },
    {
      "episode": 2002,
      "score": 131,
      "reward": -944.0,
      "steps": 47,
      "mean_loss": 6149.857415868881,
      "epsilon": 0.4017620000026284
    },
    {
      "episode": 2003,
      "score": 169,
      "reward": -924.0,
      "steps": 51,
      "mean_loss": 6471.660545423919,
      "epsilon": 0.40171100000262977
    },
    {
      "episode": 2004,
      "score": 142,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 5071.176020663717,
      "epsilon": 0.401665000002631
    },
    {
      "episode": 2005,
      "score": 94,
      "reward": -978.0,
      "steps": 42,
      "mean_loss": 3351.121825581505,
      "epsilon": 0.4016230000026321
    },
    {
      "episode": 2006,
      "score": 179,
      "reward": -894.0,
      "steps": 51,
      "mean_loss": 1630.7854340497186,
      "epsilon": 0.4015720000026335
    },
    {
      "episode": 2007,
      "score": 202,
      "reward": -894.0,
      "steps": 55,
      "mean_loss": 5950.271102766557,
      "epsilon": 0.40151700000263496
    },
    {
      "episode": 2008,
      "score": 175,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 2815.019648132324,
      "epsilon": 0.4014670000026363
    },
    {
      "episode": 2009,
      "score": 132,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 3610.149569193522,
      "epsilon": 0.4014190000026376
    },
    {
      "episode": 2010,
      "score": 149,
      "reward": -932.0,
      "steps": 48,
      "mean_loss": 4545.9377215703325,
      "epsilon": 0.40137100000263887
    },
    {
      "episode": 2011,
      "score": 235,
      "reward": -859.0,
      "steps": 57,
      "mean_loss": 2752.9836862129077,
      "epsilon": 0.4013140000026404
    },
    {
      "episode": 2012,
      "score": 157,
      "reward": -927.0,
      "steps": 53,
      "mean_loss": 3414.1033084077653,
      "epsilon": 0.4012610000026418
    },
    {
      "episode": 2013,
      "score": 103,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 1647.4473879814147,
      "epsilon": 0.4012210000026429
    },
    {
      "episode": 2014,
      "score": 163,
      "reward": -918.0,
      "steps": 46,
      "mean_loss": 3815.5563364443574,
      "epsilon": 0.4011750000026441
    },
    {
      "episode": 2015,
      "score": 145,
      "reward": -924.0,
      "steps": 46,
      "mean_loss": 2840.3105502750564,
      "epsilon": 0.40112900000264534
    },
    {
      "episode": 2016,
      "score": 119,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 4135.870932752436,
      "epsilon": 0.4010850000026465
    },
    {
      "episode": 2017,
      "score": 101,
      "reward": -981.0,
      "steps": 42,
      "mean_loss": 2167.7123186928884,
      "epsilon": 0.40104300000264764
    },
    {
      "episode": 2018,
      "score": 184,
      "reward": -901.0,
      "steps": 55,
      "mean_loss": 3301.3540365739304,
      "epsilon": 0.4009880000026491
    },
    {
      "episode": 2019,
      "score": 113,
      "reward": -946.0,
      "steps": 40,
      "mean_loss": 2323.1452478408814,
      "epsilon": 0.4009480000026502
    },
    {
      "episode": 2020,
      "score": 198,
      "reward": -889.0,
      "steps": 57,
      "mean_loss": 2954.9188362924674,
      "epsilon": 0.4008910000026517
    },
    {
      "episode": 2021,
      "score": 92,
      "reward": -966.0,
      "steps": 37,
      "mean_loss": 4990.232967273609,
      "epsilon": 0.4008540000026527
    },
    {
      "episode": 2022,
      "score": 177,
      "reward": -880.0,
      "steps": 52,
      "mean_loss": 6345.466379605807,
      "epsilon": 0.4008020000026541
    },
    {
      "episode": 2023,
      "score": 159,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 5830.98452480634,
      "epsilon": 0.4007540000026554
    },
    {
      "episode": 2024,
      "score": 136,
      "reward": -934.0,
      "steps": 44,
      "mean_loss": 1962.1751815622504,
      "epsilon": 0.40071000000265655
    },
    {
      "episode": 2025,
      "score": 213,
      "reward": -865.0,
      "steps": 57,
      "mean_loss": 3950.799081635057,
      "epsilon": 0.4006530000026581
    },
    {
      "episode": 2026,
      "score": 150,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 3452.4818921661376,
      "epsilon": 0.4006030000026594
    },
    {
      "episode": 2027,
      "score": 167,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 4663.844442764918,
      "epsilon": 0.4005550000026607
    },
    {
      "episode": 2028,
      "score": 162,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 5546.304534454346,
      "epsilon": 0.40050500000266204
    },
    {
      "episode": 2029,
      "score": 148,
      "reward": -932.0,
      "steps": 48,
      "mean_loss": 2369.6225924491882,
      "epsilon": 0.4004570000026633
    },
    {
      "episode": 2030,
      "score": 147,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 5400.71376435653,
      "epsilon": 0.40041100000266455
    },
    {
      "episode": 2031,
      "score": 171,
      "reward": -898.0,
      "steps": 50,
      "mean_loss": 6408.724940948487,
      "epsilon": 0.4003610000026659
    },
    {
      "episode": 2032,
      "score": 138,
      "reward": -935.0,
      "steps": 44,
      "mean_loss": 3200.0368567380037,
      "epsilon": 0.40031700000266707
    },
    {
      "episode": 2033,
      "score": 90,
      "reward": -984.0,
      "steps": 41,
      "mean_loss": 2038.8467816608709,
      "epsilon": 0.40027600000266816
    },
    {
      "episode": 2034,
      "score": 238,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 3989.6343881707444,
      "epsilon": 0.4002190000026697
    },
    {
      "episode": 2035,
      "score": 196,
      "reward": -886.0,
      "steps": 55,
      "mean_loss": 5449.194838021018,
      "epsilon": 0.40016400000267116
    },
    {
      "episode": 2036,
      "score": 145,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 5840.012858671301,
      "epsilon": 0.4001130000026725
    },
    {
      "episode": 2037,
      "score": 131,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 5616.731909318404,
      "epsilon": 0.4000690000026737
    },
    {
      "episode": 2038,
      "score": 98,
      "reward": -951.0,
      "steps": 34,
      "mean_loss": 4318.606049257166,
      "epsilon": 0.4000350000026746
    },
    {
      "episode": 2039,
      "score": 111,
      "reward": -963.0,
      "steps": 47,
      "mean_loss": 5246.275887184955,
      "epsilon": 0.39998800000267587
    },
    {
      "episode": 2040,
      "score": 150,
      "reward": -907.0,
      "steps": 44,
      "mean_loss": 4766.362511374734,
      "epsilon": 0.39994400000267705
    },
    {
      "episode": 2041,
      "score": 107,
      "reward": -938.0,
      "steps": 35,
      "mean_loss": 3958.758383178711,
      "epsilon": 0.399909000002678
    },
    {
      "episode": 2042,
      "score": 166,
      "reward": -920.0,
      "steps": 53,
      "mean_loss": 2993.4200869146384,
      "epsilon": 0.3998560000026794
    },
    {
      "episode": 2043,
      "score": 78,
      "reward": -976.0,
      "steps": 33,
      "mean_loss": 1236.883341702548,
      "epsilon": 0.3998230000026803
    },
    {
      "episode": 2044,
      "score": 134,
      "reward": -955.0,
      "steps": 46,
      "mean_loss": 4112.757431693699,
      "epsilon": 0.3997770000026815
    },
    {
      "episode": 2045,
      "score": 260,
      "reward": -844.0,
      "steps": 63,
      "mean_loss": 4744.3454764835415,
      "epsilon": 0.3997140000026832
    },
    {
      "episode": 2046,
      "score": 109,
      "reward": -954.0,
      "steps": 40,
      "mean_loss": 5059.137468528747,
      "epsilon": 0.39967400000268427
    },
    {
      "episode": 2047,
      "score": 100,
      "reward": -970.0,
      "steps": 42,
      "mean_loss": 4401.078782671973,
      "epsilon": 0.3996320000026854
    },
    {
      "episode": 2048,
      "score": 63,
      "reward": -989.0,
      "steps": 29,
      "mean_loss": 4350.18290684141,
      "epsilon": 0.39960300000268617
    },
    {
      "episode": 2049,
      "score": 157,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 5329.713531255722,
      "epsilon": 0.39955500000268745
    },
    {
      "episode": 2050,
      "score": 134,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 4468.03610758348,
      "epsilon": 0.39951100000268863
    },
    {
      "episode": 2051,
      "score": 218,
      "reward": -869.0,
      "steps": 54,
      "mean_loss": 3324.229280118589,
      "epsilon": 0.3994570000026901
    },
    {
      "episode": 2052,
      "score": 252,
      "reward": -851.0,
      "steps": 64,
      "mean_loss": 3525.2734259963036,
      "epsilon": 0.3993930000026918
    },
    {
      "episode": 2053,
      "score": 193,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 3675.7267131098993,
      "epsilon": 0.39933900000269323
    },
    {
      "episode": 2054,
      "score": 157,
      "reward": -914.0,
      "steps": 47,
      "mean_loss": 3518.6747828544453,
      "epsilon": 0.3992920000026945
    },
    {
      "episode": 2055,
      "score": 129,
      "reward": -940.0,
      "steps": 45,
      "mean_loss": 2334.7174241807725,
      "epsilon": 0.3992470000026957
    },
    {
      "episode": 2056,
      "score": 128,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 4036.661000272061,
      "epsilon": 0.39920000000269695
    },
    {
      "episode": 2057,
      "score": 144,
      "reward": -917.0,
      "steps": 46,
      "mean_loss": 5897.988531941953,
      "epsilon": 0.3991540000026982
    },
    {
      "episode": 2058,
      "score": 150,
      "reward": -946.0,
      "steps": 48,
      "mean_loss": 5728.717712720235,
      "epsilon": 0.39910600000269947
    },
    {
      "episode": 2059,
      "score": 253,
      "reward": -860.0,
      "steps": 65,
      "mean_loss": 4119.104517892691,
      "epsilon": 0.3990410000027012
    },
    {
      "episode": 2060,
      "score": 163,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 8109.184462694021,
      "epsilon": 0.3989890000027026
    },
    {
      "episode": 2061,
      "score": 134,
      "reward": -948.0,
      "steps": 45,
      "mean_loss": 4138.033364698622,
      "epsilon": 0.3989440000027038
    },
    {
      "episode": 2062,
      "score": 220,
      "reward": -872.0,
      "steps": 58,
      "mean_loss": 4835.0111118185105,
      "epsilon": 0.39888600000270535
    },
    {
      "episode": 2063,
      "score": 173,
      "reward": -908.0,
      "steps": 49,
      "mean_loss": 4144.066576198656,
      "epsilon": 0.39883700000270667
    },
    {
      "episode": 2064,
      "score": 151,
      "reward": -926.0,
      "steps": 48,
      "mean_loss": 3480.619715770086,
      "epsilon": 0.39878900000270795
    },
    {
      "episode": 2065,
      "score": 113,
      "reward": -941.0,
      "steps": 41,
      "mean_loss": 4464.521280242176,
      "epsilon": 0.39874800000270905
    },
    {
      "episode": 2066,
      "score": 114,
      "reward": -964.0,
      "steps": 43,
      "mean_loss": 4204.72594718046,
      "epsilon": 0.3987050000027102
    },
    {
      "episode": 2067,
      "score": 163,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 3541.0858705139162,
      "epsilon": 0.39865500000271153
    },
    {
      "episode": 2068,
      "score": 173,
      "reward": -884.0,
      "steps": 48,
      "mean_loss": 2042.7462992668152,
      "epsilon": 0.3986070000027128
    },
    {
      "episode": 2069,
      "score": 157,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 2773.434033296546,
      "epsilon": 0.39855800000271413
    },
    {
      "episode": 2070,
      "score": 185,
      "reward": -901.0,
      "steps": 53,
      "mean_loss": 6729.623027513612,
      "epsilon": 0.39850500000271555
    },
    {
      "episode": 2071,
      "score": 153,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 5258.253258285523,
      "epsilon": 0.3984550000027169
    },
    {
      "episode": 2072,
      "score": 109,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 4558.923630809784,
      "epsilon": 0.39841500000271796
    },
    {
      "episode": 2073,
      "score": 162,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 3206.6163526916503,
      "epsilon": 0.3983650000027193
    },
    {
      "episode": 2074,
      "score": 99,
      "reward": -961.0,
      "steps": 38,
      "mean_loss": 807.1928050392553,
      "epsilon": 0.3983270000027203
    },
    {
      "episode": 2075,
      "score": 159,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 3969.0829727497508,
      "epsilon": 0.39828000000272157
    },
    {
      "episode": 2076,
      "score": 154,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 2779.9976529060527,
      "epsilon": 0.3982330000027228
    },
    {
      "episode": 2077,
      "score": 117,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 4653.07119586251,
      "epsilon": 0.398189000002724
    },
    {
      "episode": 2078,
      "score": 81,
      "reward": -985.0,
      "steps": 37,
      "mean_loss": 6477.2573807175095,
      "epsilon": 0.398152000002725
    },
    {
      "episode": 2079,
      "score": 167,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 7010.897564926147,
      "epsilon": 0.39810200000272633
    },
    {
      "episode": 2080,
      "score": 103,
      "reward": -951.0,
      "steps": 38,
      "mean_loss": 2574.2461155339292,
      "epsilon": 0.39806400000272735
    },
    {
      "episode": 2081,
      "score": 174,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 1902.1413368225099,
      "epsilon": 0.3980140000027287
    },
    {
      "episode": 2082,
      "score": 196,
      "reward": -873.0,
      "steps": 55,
      "mean_loss": 6358.309661865234,
      "epsilon": 0.39795900000273016
    },
    {
      "episode": 2083,
      "score": 113,
      "reward": -953.0,
      "steps": 41,
      "mean_loss": 3763.056375643102,
      "epsilon": 0.39791800000273125
    },
    {
      "episode": 2084,
      "score": 132,
      "reward": -949.0,
      "steps": 46,
      "mean_loss": 2626.941288491954,
      "epsilon": 0.3978720000027325
    },
    {
      "episode": 2085,
      "score": 161,
      "reward": -908.0,
      "steps": 50,
      "mean_loss": 6716.461773376464,
      "epsilon": 0.3978220000027338
    },
    {
      "episode": 2086,
      "score": 96,
      "reward": -977.0,
      "steps": 41,
      "mean_loss": 3202.8160102658157,
      "epsilon": 0.3977810000027349
    },
    {
      "episode": 2087,
      "score": 127,
      "reward": -960.0,
      "steps": 49,
      "mean_loss": 2048.7436656951904,
      "epsilon": 0.39773200000273623
    },
    {
      "episode": 2088,
      "score": 106,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 1870.5833346957252,
      "epsilon": 0.39769000000273735
    },
    {
      "episode": 2089,
      "score": 136,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 5304.822727122205,
      "epsilon": 0.3976430000027386
    },
    {
      "episode": 2090,
      "score": 180,
      "reward": -911.0,
      "steps": 54,
      "mean_loss": 3616.577441180194,
      "epsilon": 0.39758900000274006
    },
    {
      "episode": 2091,
      "score": 192,
      "reward": -895.0,
      "steps": 56,
      "mean_loss": 4523.677641323635,
      "epsilon": 0.39753300000274155
    },
    {
      "episode": 2092,
      "score": 127,
      "reward": -946.0,
      "steps": 43,
      "mean_loss": 3620.844170503838,
      "epsilon": 0.3974900000027427
    },
    {
      "episode": 2093,
      "score": 242,
      "reward": -866.0,
      "steps": 62,
      "mean_loss": 3605.539822424612,
      "epsilon": 0.39742800000274436
    },
    {
      "episode": 2094,
      "score": 159,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 2929.799123077393,
      "epsilon": 0.3973780000027457
    },
    {
      "episode": 2095,
      "score": 131,
      "reward": -947.0,
      "steps": 47,
      "mean_loss": 4519.110172352893,
      "epsilon": 0.39733100000274696
    },
    {
      "episode": 2096,
      "score": 124,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 2947.4443801533093,
      "epsilon": 0.39728700000274814
    },
    {
      "episode": 2097,
      "score": 130,
      "reward": -942.0,
      "steps": 43,
      "mean_loss": 3367.113401013751,
      "epsilon": 0.3972440000027493
    },
    {
      "episode": 2098,
      "score": 166,
      "reward": -915.0,
      "steps": 48,
      "mean_loss": 6602.583455880483,
      "epsilon": 0.39719600000275057
    },
    {
      "episode": 2099,
      "score": 232,
      "reward": -865.0,
      "steps": 59,
      "mean_loss": 4651.693469710269,
      "epsilon": 0.39713700000275215
    },
    {
      "episode": 2100,
      "score": 134,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 6033.126107257345,
      "epsilon": 0.3970910000027534
    },
    {
      "episode": 2101,
      "score": 141,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 7130.4911113652315,
      "epsilon": 0.39704700000275456
    },
    {
      "episode": 2102,
      "score": 126,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 3460.094257651435,
      "epsilon": 0.39700200000275576
    },
    {
      "episode": 2103,
      "score": 122,
      "reward": -933.0,
      "steps": 39,
      "mean_loss": 5755.635639288486,
      "epsilon": 0.3969630000027568
    },
    {
      "episode": 2104,
      "score": 129,
      "reward": -930.0,
      "steps": 42,
      "mean_loss": 5558.892921311514,
      "epsilon": 0.39692100000275793
    },
    {
      "episode": 2105,
      "score": 133,
      "reward": -950.0,
      "steps": 48,
      "mean_loss": 3805.878278652827,
      "epsilon": 0.3968730000027592
    },
    {
      "episode": 2106,
      "score": 72,
      "reward": -994.0,
      "steps": 34,
      "mean_loss": 6240.1111302095305,
      "epsilon": 0.3968390000027601
    },
    {
      "episode": 2107,
      "score": 265,
      "reward": -835.0,
      "steps": 65,
      "mean_loss": 5078.552300086389,
      "epsilon": 0.39677400000276186
    },
    {
      "episode": 2108,
      "score": 170,
      "reward": -901.0,
      "steps": 51,
      "mean_loss": 3291.4651326198205,
      "epsilon": 0.3967230000027632
    },
    {
      "episode": 2109,
      "score": 225,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 3650.6752492001183,
      "epsilon": 0.39666600000276475
    },
    {
      "episode": 2110,
      "score": 170,
      "reward": -908.0,
      "steps": 51,
      "mean_loss": 5804.859158983418,
      "epsilon": 0.3966150000027661
    },
    {
      "episode": 2111,
      "score": 131,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 3933.613120626896,
      "epsilon": 0.3965680000027674
    },
    {
      "episode": 2112,
      "score": 150,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 1202.0552645338344,
      "epsilon": 0.39652100000276863
    },
    {
      "episode": 2113,
      "score": 156,
      "reward": -903.0,
      "steps": 43,
      "mean_loss": 3853.7435366608374,
      "epsilon": 0.3964780000027698
    },
    {
      "episode": 2114,
      "score": 187,
      "reward": -918.0,
      "steps": 55,
      "mean_loss": 4564.604114046963,
      "epsilon": 0.39642300000277125
    },
    {
      "episode": 2115,
      "score": 155,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 3255.4937663175624,
      "epsilon": 0.39637400000277256
    },
    {
      "episode": 2116,
      "score": 159,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 5404.764905770619,
      "epsilon": 0.39632600000277385
    },
    {
      "episode": 2117,
      "score": 121,
      "reward": -944.0,
      "steps": 42,
      "mean_loss": 4235.887016205561,
      "epsilon": 0.39628400000277497
    },
    {
      "episode": 2118,
      "score": 170,
      "reward": -895.0,
      "steps": 48,
      "mean_loss": 6193.317854245503,
      "epsilon": 0.39623600000277626
    },
    {
      "episode": 2119,
      "score": 161,
      "reward": -918.0,
      "steps": 48,
      "mean_loss": 3228.39569513003,
      "epsilon": 0.39618800000277754
    },
    {
      "episode": 2120,
      "score": 113,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 5559.550180521878,
      "epsilon": 0.3961440000027787
    },
    {
      "episode": 2121,
      "score": 87,
      "reward": -977.0,
      "steps": 39,
      "mean_loss": 2714.9282867236016,
      "epsilon": 0.39610500000277976
    },
    {
      "episode": 2122,
      "score": 117,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 3505.0581082430754,
      "epsilon": 0.39606100000278094
    },
    {
      "episode": 2123,
      "score": 116,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 3642.1259436713326,
      "epsilon": 0.39601600000278214
    },
    {
      "episode": 2124,
      "score": 158,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 3268.0374528566995,
      "epsilon": 0.3959680000027834
    },
    {
      "episode": 2125,
      "score": 133,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3358.8614885046127,
      "epsilon": 0.3959210000027847
    },
    {
      "episode": 2126,
      "score": 234,
      "reward": -848.0,
      "steps": 58,
      "mean_loss": 3808.132964824808,
      "epsilon": 0.39586300000278624
    },
    {
      "episode": 2127,
      "score": 169,
      "reward": -897.0,
      "steps": 49,
      "mean_loss": 3637.053517477853,
      "epsilon": 0.39581400000278755
    },
    {
      "episode": 2128,
      "score": 137,
      "reward": -923.0,
      "steps": 41,
      "mean_loss": 1547.6013674852325,
      "epsilon": 0.39577300000278864
    },
    {
      "episode": 2129,
      "score": 185,
      "reward": -912.0,
      "steps": 55,
      "mean_loss": 5050.975575256348,
      "epsilon": 0.3957180000027901
    },
    {
      "episode": 2130,
      "score": 164,
      "reward": -911.0,
      "steps": 46,
      "mean_loss": 3938.828055091526,
      "epsilon": 0.39567200000279135
    },
    {
      "episode": 2131,
      "score": 122,
      "reward": -959.0,
      "steps": 43,
      "mean_loss": 3697.8526141144507,
      "epsilon": 0.3956290000027925
    },
    {
      "episode": 2132,
      "score": 132,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 3490.2608439127603,
      "epsilon": 0.3955810000027938
    },
    {
      "episode": 2133,
      "score": 152,
      "reward": -945.0,
      "steps": 49,
      "mean_loss": 4778.860131322122,
      "epsilon": 0.3955320000027951
    },
    {
      "episode": 2134,
      "score": 261,
      "reward": -846.0,
      "steps": 58,
      "mean_loss": 5354.04673675011,
      "epsilon": 0.39547400000279664
    },
    {
      "episode": 2135,
      "score": 128,
      "reward": -950.0,
      "steps": 41,
      "mean_loss": 2334.3951121074397,
      "epsilon": 0.39543300000279774
    },
    {
      "episode": 2136,
      "score": 195,
      "reward": -889.0,
      "steps": 54,
      "mean_loss": 4530.661732355754,
      "epsilon": 0.3953790000027992
    },
    {
      "episode": 2137,
      "score": 155,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 3004.738872909546,
      "epsilon": 0.3953290000028005
    },
    {
      "episode": 2138,
      "score": 189,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 2920.1130456190845,
      "epsilon": 0.3952770000028019
    },
    {
      "episode": 2139,
      "score": 182,
      "reward": -909.0,
      "steps": 55,
      "mean_loss": 4844.460883539373,
      "epsilon": 0.3952220000028034
    },
    {
      "episode": 2140,
      "score": 105,
      "reward": -952.0,
      "steps": 38,
      "mean_loss": 3416.076869763826,
      "epsilon": 0.3951840000028044
    },
    {
      "episode": 2141,
      "score": 188,
      "reward": -877.0,
      "steps": 53,
      "mean_loss": 2881.64375254793,
      "epsilon": 0.3951310000028058
    },
    {
      "episode": 2142,
      "score": 174,
      "reward": -909.0,
      "steps": 48,
      "mean_loss": 3917.18203830719,
      "epsilon": 0.3950830000028071
    },
    {
      "episode": 2143,
      "score": 126,
      "reward": -939.0,
      "steps": 42,
      "mean_loss": 3756.917863845825,
      "epsilon": 0.39504100000280823
    },
    {
      "episode": 2144,
      "score": 132,
      "reward": -933.0,
      "steps": 45,
      "mean_loss": 2852.109999423557,
      "epsilon": 0.39499600000280943
    },
    {
      "episode": 2145,
      "score": 236,
      "reward": -885.0,
      "steps": 60,
      "mean_loss": 4485.860769271851,
      "epsilon": 0.39493600000281104
    },
    {
      "episode": 2146,
      "score": 151,
      "reward": -920.0,
      "steps": 48,
      "mean_loss": 2766.990271727244,
      "epsilon": 0.3948880000028123
    },
    {
      "episode": 2147,
      "score": 119,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 3959.996490565213,
      "epsilon": 0.3948440000028135
    },
    {
      "episode": 2148,
      "score": 131,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 2821.82903324474,
      "epsilon": 0.3948000000028147
    },
    {
      "episode": 2149,
      "score": 210,
      "reward": -876.0,
      "steps": 56,
      "mean_loss": 3347.176525797163,
      "epsilon": 0.3947440000028162
    },
    {
      "episode": 2150,
      "score": 113,
      "reward": -952.0,
      "steps": 42,
      "mean_loss": 6470.938953218006,
      "epsilon": 0.3947020000028173
    },
    {
      "episode": 2151,
      "score": 149,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 3129.911096613458,
      "epsilon": 0.39465500000281856
    },
    {
      "episode": 2152,
      "score": 215,
      "reward": -882.0,
      "steps": 58,
      "mean_loss": 2880.627170036579,
      "epsilon": 0.3945970000028201
    },
    {
      "episode": 2153,
      "score": 141,
      "reward": -948.0,
      "steps": 46,
      "mean_loss": 1680.4697358504586,
      "epsilon": 0.39455100000282134
    },
    {
      "episode": 2154,
      "score": 135,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 5825.135367697858,
      "epsilon": 0.3945040000028226
    },
    {
      "episode": 2155,
      "score": 107,
      "reward": -973.0,
      "steps": 44,
      "mean_loss": 3093.9486751556396,
      "epsilon": 0.3944600000028238
    },
    {
      "episode": 2156,
      "score": 178,
      "reward": -909.0,
      "steps": 54,
      "mean_loss": 4076.2522664953162,
      "epsilon": 0.3944060000028252
    },
    {
      "episode": 2157,
      "score": 154,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 4018.232543487549,
      "epsilon": 0.39435600000282656
    },
    {
      "episode": 2158,
      "score": 200,
      "reward": -902.0,
      "steps": 56,
      "mean_loss": 2705.6078382560186,
      "epsilon": 0.39430000000282805
    },
    {
      "episode": 2159,
      "score": 94,
      "reward": -964.0,
      "steps": 37,
      "mean_loss": 3411.124013127507,
      "epsilon": 0.39426300000282904
    },
    {
      "episode": 2160,
      "score": 147,
      "reward": -924.0,
      "steps": 46,
      "mean_loss": 3484.7431272423787,
      "epsilon": 0.3942170000028303
    },
    {
      "episode": 2161,
      "score": 124,
      "reward": -943.0,
      "steps": 43,
      "mean_loss": 4941.614407561546,
      "epsilon": 0.3941740000028314
    },
    {
      "episode": 2162,
      "score": 110,
      "reward": -952.0,
      "steps": 39,
      "mean_loss": 4604.385173699795,
      "epsilon": 0.39413500000283247
    },
    {
      "episode": 2163,
      "score": 225,
      "reward": -874.0,
      "steps": 61,
      "mean_loss": 5065.658893710277,
      "epsilon": 0.3940740000028341
    },
    {
      "episode": 2164,
      "score": 155,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 4429.7722827911375,
      "epsilon": 0.39402400000283544
    },
    {
      "episode": 2165,
      "score": 139,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 3355.5697242418923,
      "epsilon": 0.3939760000028367
    },
    {
      "episode": 2166,
      "score": 162,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 1886.4828654270545,
      "epsilon": 0.3939250000028381
    },
    {
      "episode": 2167,
      "score": 107,
      "reward": -965.0,
      "steps": 39,
      "mean_loss": 2952.9215895823945,
      "epsilon": 0.39388600000283913
    },
    {
      "episode": 2168,
      "score": 180,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 2617.441957987272,
      "epsilon": 0.3938340000028405
    },
    {
      "episode": 2169,
      "score": 139,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 3406.5657128043795,
      "epsilon": 0.39378800000284175
    },
    {
      "episode": 2170,
      "score": 87,
      "reward": -978.0,
      "steps": 39,
      "mean_loss": 3459.4354251959385,
      "epsilon": 0.3937490000028428
    },
    {
      "episode": 2171,
      "score": 215,
      "reward": -874.0,
      "steps": 53,
      "mean_loss": 1527.820881825573,
      "epsilon": 0.3936960000028442
    },
    {
      "episode": 2172,
      "score": 143,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 4771.135003110196,
      "epsilon": 0.3936490000028455
    },
    {
      "episode": 2173,
      "score": 119,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 4520.000728260387,
      "epsilon": 0.39360500000284665
    },
    {
      "episode": 2174,
      "score": 135,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 4440.021440463596,
      "epsilon": 0.39356000000284785
    },
    {
      "episode": 2175,
      "score": 181,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 4434.025665740966,
      "epsilon": 0.3935100000028492
    },
    {
      "episode": 2176,
      "score": 223,
      "reward": -863.0,
      "steps": 57,
      "mean_loss": 2504.591668647632,
      "epsilon": 0.3934530000028507
    },
    {
      "episode": 2177,
      "score": 164,
      "reward": -927.0,
      "steps": 51,
      "mean_loss": 6594.996587940291,
      "epsilon": 0.3934020000028521
    },
    {
      "episode": 2178,
      "score": 162,
      "reward": -920.0,
      "steps": 52,
      "mean_loss": 4969.816805472741,
      "epsilon": 0.3933500000028535
    },
    {
      "episode": 2179,
      "score": 123,
      "reward": -947.0,
      "steps": 45,
      "mean_loss": 4494.340202670627,
      "epsilon": 0.3933050000028547
    },
    {
      "episode": 2180,
      "score": 175,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 4926.353630652795,
      "epsilon": 0.39325300000285607
    },
    {
      "episode": 2181,
      "score": 205,
      "reward": -884.0,
      "steps": 52,
      "mean_loss": 6074.553262490493,
      "epsilon": 0.39320100000285746
    },
    {
      "episode": 2182,
      "score": 68,
      "reward": -1003.0,
      "steps": 34,
      "mean_loss": 6423.302717096665,
      "epsilon": 0.39316700000285837
    },
    {
      "episode": 2183,
      "score": 151,
      "reward": -913.0,
      "steps": 44,
      "mean_loss": 2797.9247954975476,
      "epsilon": 0.39312300000285955
    },
    {
      "episode": 2184,
      "score": 93,
      "reward": -974.0,
      "steps": 39,
      "mean_loss": 4703.293863296509,
      "epsilon": 0.3930840000028606
    },
    {
      "episode": 2185,
      "score": 142,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 4441.744322035048,
      "epsilon": 0.3930390000028618
    },
    {
      "episode": 2186,
      "score": 125,
      "reward": -958.0,
      "steps": 45,
      "mean_loss": 3830.2203436109753,
      "epsilon": 0.392994000002863
    },
    {
      "episode": 2187,
      "score": 156,
      "reward": -917.0,
      "steps": 46,
      "mean_loss": 2705.911492306253,
      "epsilon": 0.39294800000286423
    },
    {
      "episode": 2188,
      "score": 165,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 2213.573070370421,
      "epsilon": 0.39289900000286554
    },
    {
      "episode": 2189,
      "score": 204,
      "reward": -910.0,
      "steps": 58,
      "mean_loss": 4608.152471476587,
      "epsilon": 0.3928410000028671
    },
    {
      "episode": 2190,
      "score": 119,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 4676.539371956719,
      "epsilon": 0.3927960000028683
    },
    {
      "episode": 2191,
      "score": 173,
      "reward": -914.0,
      "steps": 52,
      "mean_loss": 4149.615042979901,
      "epsilon": 0.3927440000028697
    },
    {
      "episode": 2192,
      "score": 148,
      "reward": -927.0,
      "steps": 48,
      "mean_loss": 4241.470369180043,
      "epsilon": 0.39269600000287097
    },
    {
      "episode": 2193,
      "score": 138,
      "reward": -937.0,
      "steps": 46,
      "mean_loss": 6988.912394150444,
      "epsilon": 0.3926500000028722
    },
    {
      "episode": 2194,
      "score": 164,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 3003.7083407032246,
      "epsilon": 0.3926010000028735
    },
    {
      "episode": 2195,
      "score": 104,
      "reward": -968.0,
      "steps": 44,
      "mean_loss": 4948.962186639959,
      "epsilon": 0.3925570000028747
    },
    {
      "episode": 2196,
      "score": 127,
      "reward": -942.0,
      "steps": 45,
      "mean_loss": 2829.172976854112,
      "epsilon": 0.3925120000028759
    },
    {
      "episode": 2197,
      "score": 186,
      "reward": -903.0,
      "steps": 54,
      "mean_loss": 5260.469375115854,
      "epsilon": 0.39245800000287734
    },
    {
      "episode": 2198,
      "score": 105,
      "reward": -968.0,
      "steps": 42,
      "mean_loss": 4359.085469927107,
      "epsilon": 0.39241600000287846
    },
    {
      "episode": 2199,
      "score": 257,
      "reward": -851.0,
      "steps": 66,
      "mean_loss": 3146.3600879437995,
      "epsilon": 0.39235000000288023
    },
    {
      "episode": 2200,
      "score": 121,
      "reward": -945.0,
      "steps": 45,
      "mean_loss": 3239.5188349405926,
      "epsilon": 0.39230500000288143
    },
    {
      "episode": 2201,
      "score": 153,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 4089.0417765353586,
      "epsilon": 0.3922580000028827
    },
    {
      "episode": 2202,
      "score": 146,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 5356.444988250732,
      "epsilon": 0.392209000002884
    },
    {
      "episode": 2203,
      "score": 155,
      "reward": -922.0,
      "steps": 47,
      "mean_loss": 5262.216932743154,
      "epsilon": 0.39216200000288526
    },
    {
      "episode": 2204,
      "score": 204,
      "reward": -880.0,
      "steps": 55,
      "mean_loss": 5043.596608179266,
      "epsilon": 0.39210700000288673
    },
    {
      "episode": 2205,
      "score": 240,
      "reward": -875.0,
      "steps": 61,
      "mean_loss": 4470.969338338883,
      "epsilon": 0.39204600000288836
    },
    {
      "episode": 2206,
      "score": 97,
      "reward": -985.0,
      "steps": 45,
      "mean_loss": 4541.540535142687,
      "epsilon": 0.39200100000288957
    },
    {
      "episode": 2207,
      "score": 197,
      "reward": -882.0,
      "steps": 54,
      "mean_loss": 2454.9374647493714,
      "epsilon": 0.391947000002891
    },
    {
      "episode": 2208,
      "score": 110,
      "reward": -958.0,
      "steps": 41,
      "mean_loss": 2319.7073918086726,
      "epsilon": 0.3919060000028921
    },
    {
      "episode": 2209,
      "score": 93,
      "reward": -971.0,
      "steps": 41,
      "mean_loss": 5077.707876345006,
      "epsilon": 0.3918650000028932
    },
    {
      "episode": 2210,
      "score": 81,
      "reward": -984.0,
      "steps": 37,
      "mean_loss": 7585.802770459974,
      "epsilon": 0.3918280000028942
    },
    {
      "episode": 2211,
      "score": 116,
      "reward": -940.0,
      "steps": 41,
      "mean_loss": 4426.220131385617,
      "epsilon": 0.3917870000028953
    },
    {
      "episode": 2212,
      "score": 75,
      "reward": -973.0,
      "steps": 33,
      "mean_loss": 4460.753303990219,
      "epsilon": 0.3917540000028962
    },
    {
      "episode": 2213,
      "score": 235,
      "reward": -862.0,
      "steps": 58,
      "mean_loss": 2947.87874044221,
      "epsilon": 0.3916960000028977
    },
    {
      "episode": 2214,
      "score": 165,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 5899.728867492676,
      "epsilon": 0.39164600000289906
    },
    {
      "episode": 2215,
      "score": 75,
      "reward": -995.0,
      "steps": 37,
      "mean_loss": 3718.45463190852,
      "epsilon": 0.39160900000290005
    },
    {
      "episode": 2216,
      "score": 107,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 3860.4131882985434,
      "epsilon": 0.3915670000029012
    },
    {
      "episode": 2217,
      "score": 114,
      "reward": -950.0,
      "steps": 39,
      "mean_loss": 3961.8897379361665,
      "epsilon": 0.3915280000029022
    },
    {
      "episode": 2218,
      "score": 198,
      "reward": -886.0,
      "steps": 54,
      "mean_loss": 2780.2762141051116,
      "epsilon": 0.39147400000290367
    },
    {
      "episode": 2219,
      "score": 114,
      "reward": -966.0,
      "steps": 43,
      "mean_loss": 5721.130492099496,
      "epsilon": 0.3914310000029048
    },
    {
      "episode": 2220,
      "score": 151,
      "reward": -931.0,
      "steps": 50,
      "mean_loss": 1913.6619096374511,
      "epsilon": 0.39138100000290615
    },
    {
      "episode": 2221,
      "score": 144,
      "reward": -929.0,
      "steps": 49,
      "mean_loss": 3571.8997202503438,
      "epsilon": 0.39133200000290747
    },
    {
      "episode": 2222,
      "score": 126,
      "reward": -954.0,
      "steps": 48,
      "mean_loss": 4971.24708712101,
      "epsilon": 0.39128400000290875
    },
    {
      "episode": 2223,
      "score": 188,
      "reward": -917.0,
      "steps": 55,
      "mean_loss": 3106.613534303145,
      "epsilon": 0.3912290000029102
    },
    {
      "episode": 2224,
      "score": 137,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 3517.0547383896846,
      "epsilon": 0.3911820000029115
    },
    {
      "episode": 2225,
      "score": 244,
      "reward": -857.0,
      "steps": 62,
      "mean_loss": 4589.887307382399,
      "epsilon": 0.39112000000291314
    },
    {
      "episode": 2226,
      "score": 143,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 6314.62681511773,
      "epsilon": 0.39107500000291434
    },
    {
      "episode": 2227,
      "score": 196,
      "reward": -872.0,
      "steps": 49,
      "mean_loss": 6072.625018294977,
      "epsilon": 0.39102600000291565
    },
    {
      "episode": 2228,
      "score": 77,
      "reward": -982.0,
      "steps": 36,
      "mean_loss": 4034.916523827447,
      "epsilon": 0.3909900000029166
    },
    {
      "episode": 2229,
      "score": 89,
      "reward": -976.0,
      "steps": 37,
      "mean_loss": 2722.5462174286713,
      "epsilon": 0.3909530000029176
    },
    {
      "episode": 2230,
      "score": 159,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 3802.407875855764,
      "epsilon": 0.3909050000029189
    },
    {
      "episode": 2231,
      "score": 162,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 2797.3094414520265,
      "epsilon": 0.3908550000029202
    },
    {
      "episode": 2232,
      "score": 201,
      "reward": -899.0,
      "steps": 56,
      "mean_loss": 2009.2488008907862,
      "epsilon": 0.3907990000029217
    },
    {
      "episode": 2233,
      "score": 192,
      "reward": -888.0,
      "steps": 51,
      "mean_loss": 5666.7554620481005,
      "epsilon": 0.3907480000029231
    },
    {
      "episode": 2234,
      "score": 135,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 1558.0630770144255,
      "epsilon": 0.3907020000029243
    },
    {
      "episode": 2235,
      "score": 74,
      "reward": -982.0,
      "steps": 33,
      "mean_loss": 4449.424031922312,
      "epsilon": 0.3906690000029252
    },
    {
      "episode": 2236,
      "score": 236,
      "reward": -877.0,
      "steps": 62,
      "mean_loss": 2300.913267873949,
      "epsilon": 0.39060700000292686
    },
    {
      "episode": 2237,
      "score": 114,
      "reward": -956.0,
      "steps": 43,
      "mean_loss": 734.9278970762741,
      "epsilon": 0.390564000002928
    },
    {
      "episode": 2238,
      "score": 118,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 6337.179213192152,
      "epsilon": 0.39051800000292924
    },
    {
      "episode": 2239,
      "score": 104,
      "reward": -970.0,
      "steps": 40,
      "mean_loss": 5702.78683013916,
      "epsilon": 0.3904780000029303
    },
    {
      "episode": 2240,
      "score": 184,
      "reward": -902.0,
      "steps": 56,
      "mean_loss": 4547.333318642208,
      "epsilon": 0.3904220000029318
    },
    {
      "episode": 2241,
      "score": 121,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 3122.147536892361,
      "epsilon": 0.390377000002933
    },
    {
      "episode": 2242,
      "score": 132,
      "reward": -931.0,
      "steps": 41,
      "mean_loss": 5144.997443222418,
      "epsilon": 0.3903360000029341
    },
    {
      "episode": 2243,
      "score": 164,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 5675.757078365404,
      "epsilon": 0.3902870000029354
    },
    {
      "episode": 2244,
      "score": 138,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 1317.7993313259549,
      "epsilon": 0.39024200000293663
    },
    {
      "episode": 2245,
      "score": 110,
      "reward": -952.0,
      "steps": 36,
      "mean_loss": 3563.163967662387,
      "epsilon": 0.3902060000029376
    },
    {
      "episode": 2246,
      "score": 98,
      "reward": -981.0,
      "steps": 42,
      "mean_loss": 5898.826074781872,
      "epsilon": 0.3901640000029387
    },
    {
      "episode": 2247,
      "score": 214,
      "reward": -869.0,
      "steps": 58,
      "mean_loss": 2147.8292309662393,
      "epsilon": 0.39010600000294027
    },
    {
      "episode": 2248,
      "score": 138,
      "reward": -929.0,
      "steps": 44,
      "mean_loss": 3141.9839546030216,
      "epsilon": 0.39006200000294144
    },
    {
      "episode": 2249,
      "score": 179,
      "reward": -891.0,
      "steps": 47,
      "mean_loss": 4403.318091372226,
      "epsilon": 0.3900150000029427
    },
    {
      "episode": 2250,
      "score": 196,
      "reward": -896.0,
      "steps": 56,
      "mean_loss": 3370.145540543965,
      "epsilon": 0.3899590000029442
    },
    {
      "episode": 2251,
      "score": 119,
      "reward": -960.0,
      "steps": 45,
      "mean_loss": 3443.7336379157173,
      "epsilon": 0.3899140000029454
    },
    {
      "episode": 2252,
      "score": 105,
      "reward": -974.0,
      "steps": 45,
      "mean_loss": 3841.727014160156,
      "epsilon": 0.3898690000029466
    },
    {
      "episode": 2253,
      "score": 127,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 3305.4445367896037,
      "epsilon": 0.38982300000294784
    },
    {
      "episode": 2254,
      "score": 203,
      "reward": -890.0,
      "steps": 55,
      "mean_loss": 7300.696792793274,
      "epsilon": 0.3897680000029493
    },
    {
      "episode": 2255,
      "score": 101,
      "reward": -962.0,
      "steps": 39,
      "mean_loss": 3811.309741484813,
      "epsilon": 0.38972900000295035
    },
    {
      "episode": 2256,
      "score": 141,
      "reward": -925.0,
      "steps": 46,
      "mean_loss": 2848.6612776051397,
      "epsilon": 0.3896830000029516
    },
    {
      "episode": 2257,
      "score": 158,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 2493.015915336609,
      "epsilon": 0.3896330000029529
    },
    {
      "episode": 2258,
      "score": 144,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 1697.0771799290435,
      "epsilon": 0.3895860000029542
    },
    {
      "episode": 2259,
      "score": 131,
      "reward": -944.0,
      "steps": 46,
      "mean_loss": 4158.498298064522,
      "epsilon": 0.3895400000029554
    },
    {
      "episode": 2260,
      "score": 187,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 3006.498426154808,
      "epsilon": 0.38948600000295686
    },
    {
      "episode": 2261,
      "score": 103,
      "reward": -954.0,
      "steps": 37,
      "mean_loss": 1780.18888122971,
      "epsilon": 0.38944900000295785
    },
    {
      "episode": 2262,
      "score": 107,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 3773.743543857481,
      "epsilon": 0.38940800000295894
    },
    {
      "episode": 2263,
      "score": 111,
      "reward": -971.0,
      "steps": 45,
      "mean_loss": 3012.7147956000435,
      "epsilon": 0.38936300000296015
    },
    {
      "episode": 2264,
      "score": 228,
      "reward": -870.0,
      "steps": 58,
      "mean_loss": 4471.699607322956,
      "epsilon": 0.3893050000029617
    },
    {
      "episode": 2265,
      "score": 122,
      "reward": -954.0,
      "steps": 47,
      "mean_loss": 3693.184474701577,
      "epsilon": 0.38925800000296296
    },
    {
      "episode": 2266,
      "score": 156,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 1903.0605699920654,
      "epsilon": 0.3892080000029643
    },
    {
      "episode": 2267,
      "score": 109,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 3156.2616647508407,
      "epsilon": 0.3891630000029655
    },
    {
      "episode": 2268,
      "score": 165,
      "reward": -891.0,
      "steps": 45,
      "mean_loss": 2836.5368525187173,
      "epsilon": 0.3891180000029667
    },
    {
      "episode": 2269,
      "score": 160,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 3486.9903718536975,
      "epsilon": 0.38906700000296807
    },
    {
      "episode": 2270,
      "score": 127,
      "reward": -944.0,
      "steps": 46,
      "mean_loss": 3150.4924788267717,
      "epsilon": 0.3890210000029693
    },
    {
      "episode": 2271,
      "score": 124,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 2052.0205517221007,
      "epsilon": 0.38897400000297055
    },
    {
      "episode": 2272,
      "score": 199,
      "reward": -893.0,
      "steps": 54,
      "mean_loss": 4563.850880587543,
      "epsilon": 0.388920000002972
    },
    {
      "episode": 2273,
      "score": 224,
      "reward": -872.0,
      "steps": 59,
      "mean_loss": 3543.6440312013788,
      "epsilon": 0.3888610000029736
    },
    {
      "episode": 2274,
      "score": 125,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 2162.0126578157597,
      "epsilon": 0.38881700000297476
    },
    {
      "episode": 2275,
      "score": 160,
      "reward": -899.0,
      "steps": 47,
      "mean_loss": 7687.709175759173,
      "epsilon": 0.388770000002976
    },
    {
      "episode": 2276,
      "score": 151,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 3865.9951147525867,
      "epsilon": 0.38872300000297727
    },
    {
      "episode": 2277,
      "score": 145,
      "reward": -930.0,
      "steps": 45,
      "mean_loss": 6270.8792477077905,
      "epsilon": 0.3886780000029785
    },
    {
      "episode": 2278,
      "score": 158,
      "reward": -910.0,
      "steps": 47,
      "mean_loss": 4039.0904453358753,
      "epsilon": 0.38863100000297973
    },
    {
      "episode": 2279,
      "score": 251,
      "reward": -838.0,
      "steps": 61,
      "mean_loss": 3495.620575263852,
      "epsilon": 0.38857000000298136
    },
    {
      "episode": 2280,
      "score": 290,
      "reward": -812.0,
      "steps": 70,
      "mean_loss": 4216.955335017613,
      "epsilon": 0.38850000000298324
    },
    {
      "episode": 2281,
      "score": 118,
      "reward": -956.0,
      "steps": 42,
      "mean_loss": 4051.91789045788,
      "epsilon": 0.38845800000298436
    },
    {
      "episode": 2282,
      "score": 243,
      "reward": -839.0,
      "steps": 62,
      "mean_loss": 3164.8809660019415,
      "epsilon": 0.388396000002986
    },
    {
      "episode": 2283,
      "score": 191,
      "reward": -888.0,
      "steps": 54,
      "mean_loss": 2948.9176669650606,
      "epsilon": 0.38834200000298746
    },
    {
      "episode": 2284,
      "score": 263,
      "reward": -854.0,
      "steps": 68,
      "mean_loss": 5369.781210787156,
      "epsilon": 0.3882740000029893
    },
    {
      "episode": 2285,
      "score": 172,
      "reward": -901.0,
      "steps": 51,
      "mean_loss": 2535.3840219834274,
      "epsilon": 0.38822300000299065
    },
    {
      "episode": 2286,
      "score": 112,
      "reward": -974.0,
      "steps": 45,
      "mean_loss": 4590.6845948961045,
      "epsilon": 0.38817800000299185
    },
    {
      "episode": 2287,
      "score": 199,
      "reward": -883.0,
      "steps": 56,
      "mean_loss": 4674.916588783264,
      "epsilon": 0.38812200000299335
    },
    {
      "episode": 2288,
      "score": 81,
      "reward": -990.0,
      "steps": 39,
      "mean_loss": 2507.4625992408164,
      "epsilon": 0.3880830000029944
    },
    {
      "episode": 2289,
      "score": 158,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3519.2812451171876,
      "epsilon": 0.38803300000299573
    },
    {
      "episode": 2290,
      "score": 88,
      "reward": -970.0,
      "steps": 38,
      "mean_loss": 3470.531870892173,
      "epsilon": 0.38799500000299675
    },
    {
      "episode": 2291,
      "score": 149,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 3476.2822384935744,
      "epsilon": 0.387948000002998
    },
    {
      "episode": 2292,
      "score": 199,
      "reward": -866.0,
      "steps": 54,
      "mean_loss": 3516.4660525851777,
      "epsilon": 0.38789400000299945
    },
    {
      "episode": 2293,
      "score": 113,
      "reward": -938.0,
      "steps": 36,
      "mean_loss": 3862.814638561673,
      "epsilon": 0.3878580000030004
    },
    {
      "episode": 2294,
      "score": 156,
      "reward": -914.0,
      "steps": 47,
      "mean_loss": 3117.9935062489612,
      "epsilon": 0.38781100000300167
    },
    {
      "episode": 2295,
      "score": 246,
      "reward": -847.0,
      "steps": 62,
      "mean_loss": 5265.243116747948,
      "epsilon": 0.38774900000300333
    },
    {
      "episode": 2296,
      "score": 162,
      "reward": -900.0,
      "steps": 49,
      "mean_loss": 4317.275190392319,
      "epsilon": 0.38770000000300464
    },
    {
      "episode": 2297,
      "score": 132,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 3834.9805521965027,
      "epsilon": 0.3876520000030059
    },
    {
      "episode": 2298,
      "score": 123,
      "reward": -953.0,
      "steps": 46,
      "mean_loss": 4025.640738943349,
      "epsilon": 0.38760600000300716
    },
    {
      "episode": 2299,
      "score": 121,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 4327.642405726693,
      "epsilon": 0.38756200000300833
    },
    {
      "episode": 2300,
      "score": 110,
      "reward": -964.0,
      "steps": 43,
      "mean_loss": 2527.704942925032,
      "epsilon": 0.3875190000030095
    },
    {
      "episode": 2301,
      "score": 87,
      "reward": -978.0,
      "steps": 36,
      "mean_loss": 2838.858146243625,
      "epsilon": 0.38748300000301045
    },
    {
      "episode": 2302,
      "score": 267,
      "reward": -833.0,
      "steps": 67,
      "mean_loss": 4901.148012303594,
      "epsilon": 0.38741600000301224
    },
    {
      "episode": 2303,
      "score": 114,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 4692.772025715221,
      "epsilon": 0.3873720000030134
    },
    {
      "episode": 2304,
      "score": 187,
      "reward": -880.0,
      "steps": 50,
      "mean_loss": 3855.1659423065184,
      "epsilon": 0.38732200000301475
    },
    {
      "episode": 2305,
      "score": 194,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 3722.3211044164805,
      "epsilon": 0.38727000000301615
    },
    {
      "episode": 2306,
      "score": 115,
      "reward": -956.0,
      "steps": 43,
      "mean_loss": 3347.2187196598497,
      "epsilon": 0.3872270000030173
    },
    {
      "episode": 2307,
      "score": 165,
      "reward": -906.0,
      "steps": 46,
      "mean_loss": 3215.0842719700026,
      "epsilon": 0.3871810000030185
    },
    {
      "episode": 2308,
      "score": 151,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 1900.9187334442138,
      "epsilon": 0.38713100000301987
    },
    {
      "episode": 2309,
      "score": 129,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 2600.0436273657756,
      "epsilon": 0.3870850000030211
    },
    {
      "episode": 2310,
      "score": 186,
      "reward": -886.0,
      "steps": 52,
      "mean_loss": 2117.4634170532227,
      "epsilon": 0.3870330000030225
    },
    {
      "episode": 2311,
      "score": 148,
      "reward": -932.0,
      "steps": 48,
      "mean_loss": 3194.401427666346,
      "epsilon": 0.38698500000302377
    },
    {
      "episode": 2312,
      "score": 237,
      "reward": -865.0,
      "steps": 62,
      "mean_loss": 4964.211871977775,
      "epsilon": 0.38692300000302543
    },
    {
      "episode": 2313,
      "score": 228,
      "reward": -871.0,
      "steps": 58,
      "mean_loss": 3077.558794482001,
      "epsilon": 0.386865000003027
    },
    {
      "episode": 2314,
      "score": 192,
      "reward": -896.0,
      "steps": 55,
      "mean_loss": 3767.285994200273,
      "epsilon": 0.38681000000302845
    },
    {
      "episode": 2315,
      "score": 126,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 2908.116937463934,
      "epsilon": 0.38676600000302963
    },
    {
      "episode": 2316,
      "score": 99,
      "reward": -973.0,
      "steps": 38,
      "mean_loss": 6585.115611628482,
      "epsilon": 0.38672800000303065
    },
    {
      "episode": 2317,
      "score": 107,
      "reward": -968.0,
      "steps": 44,
      "mean_loss": 3724.298510984941,
      "epsilon": 0.3866840000030318
    },
    {
      "episode": 2318,
      "score": 172,
      "reward": -915.0,
      "steps": 52,
      "mean_loss": 4865.547727621519,
      "epsilon": 0.3866320000030332
    },
    {
      "episode": 2319,
      "score": 173,
      "reward": -927.0,
      "steps": 53,
      "mean_loss": 4732.258475033742,
      "epsilon": 0.38657900000303463
    },
    {
      "episode": 2320,
      "score": 91,
      "reward": -983.0,
      "steps": 43,
      "mean_loss": 6332.304609964061,
      "epsilon": 0.3865360000030358
    },
    {
      "episode": 2321,
      "score": 101,
      "reward": -974.0,
      "steps": 44,
      "mean_loss": 5131.36895309795,
      "epsilon": 0.38649200000303696
    },
    {
      "episode": 2322,
      "score": 115,
      "reward": -951.0,
      "steps": 40,
      "mean_loss": 2297.2346102714537,
      "epsilon": 0.38645200000303803
    },
    {
      "episode": 2323,
      "score": 182,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 3172.7313760610728,
      "epsilon": 0.3864000000030394
    },
    {
      "episode": 2324,
      "score": 173,
      "reward": -911.0,
      "steps": 53,
      "mean_loss": 2622.6331044323038,
      "epsilon": 0.38634700000304084
    },
    {
      "episode": 2325,
      "score": 86,
      "reward": -961.0,
      "steps": 34,
      "mean_loss": 5114.377650765811,
      "epsilon": 0.38631300000304175
    },
    {
      "episode": 2326,
      "score": 166,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 2878.4179578294943,
      "epsilon": 0.3862620000030431
    },
    {
      "episode": 2327,
      "score": 122,
      "reward": -958.0,
      "steps": 48,
      "mean_loss": 5551.107050418854,
      "epsilon": 0.3862140000030444
    },
    {
      "episode": 2328,
      "score": 108,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 2930.9695809971204,
      "epsilon": 0.3861700000030456
    },
    {
      "episode": 2329,
      "score": 108,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 3472.209562475031,
      "epsilon": 0.38612600000304675
    },
    {
      "episode": 2330,
      "score": 148,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 2543.657608191172,
      "epsilon": 0.38607800000304804
    },
    {
      "episode": 2331,
      "score": 150,
      "reward": -932.0,
      "steps": 51,
      "mean_loss": 3451.9733394548007,
      "epsilon": 0.3860270000030494
    },
    {
      "episode": 2332,
      "score": 134,
      "reward": -936.0,
      "steps": 43,
      "mean_loss": 4461.049294227778,
      "epsilon": 0.38598400000305055
    },
    {
      "episode": 2333,
      "score": 134,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 5322.00390791893,
      "epsilon": 0.38593600000305184
    },
    {
      "episode": 2334,
      "score": 57,
      "reward": -1018.0,
      "steps": 36,
      "mean_loss": 4836.475727293227,
      "epsilon": 0.3859000000030528
    },
    {
      "episode": 2335,
      "score": 193,
      "reward": -913.0,
      "steps": 54,
      "mean_loss": 6267.110414999503,
      "epsilon": 0.38584600000305425
    },
    {
      "episode": 2336,
      "score": 89,
      "reward": -980.0,
      "steps": 38,
      "mean_loss": 3933.310982202229,
      "epsilon": 0.38580800000305526
    },
    {
      "episode": 2337,
      "score": 103,
      "reward": -970.0,
      "steps": 39,
      "mean_loss": 3850.204778426733,
      "epsilon": 0.3857690000030563
    },
    {
      "episode": 2338,
      "score": 144,
      "reward": -945.0,
      "steps": 47,
      "mean_loss": 4455.377813623307,
      "epsilon": 0.38572200000305756
    },
    {
      "episode": 2339,
      "score": 158,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 4543.638191382091,
      "epsilon": 0.38567400000305885
    },
    {
      "episode": 2340,
      "score": 99,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 5943.8715457008,
      "epsilon": 0.38563200000305997
    },
    {
      "episode": 2341,
      "score": 180,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 1920.4365984843328,
      "epsilon": 0.38558000000306136
    },
    {
      "episode": 2342,
      "score": 226,
      "reward": -880.0,
      "steps": 54,
      "mean_loss": 1785.924638748169,
      "epsilon": 0.3855260000030628
    },
    {
      "episode": 2343,
      "score": 84,
      "reward": -977.0,
      "steps": 37,
      "mean_loss": 4742.110026694633,
      "epsilon": 0.3854890000030638
    },
    {
      "episode": 2344,
      "score": 169,
      "reward": -916.0,
      "steps": 53,
      "mean_loss": 5873.181630980293,
      "epsilon": 0.3854360000030652
    },
    {
      "episode": 2345,
      "score": 181,
      "reward": -901.0,
      "steps": 50,
      "mean_loss": 4381.410121688843,
      "epsilon": 0.38538600000306655
    },
    {
      "episode": 2346,
      "score": 161,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 4931.481848385869,
      "epsilon": 0.38533700000306786
    },
    {
      "episode": 2347,
      "score": 185,
      "reward": -901.0,
      "steps": 56,
      "mean_loss": 4361.812064443316,
      "epsilon": 0.38528100000306936
    },
    {
      "episode": 2348,
      "score": 144,
      "reward": -934.0,
      "steps": 51,
      "mean_loss": 6921.364947300332,
      "epsilon": 0.3852300000030707
    },
    {
      "episode": 2349,
      "score": 176,
      "reward": -916.0,
      "steps": 55,
      "mean_loss": 2974.684465859153,
      "epsilon": 0.3851750000030722
    },
    {
      "episode": 2350,
      "score": 250,
      "reward": -849.0,
      "steps": 61,
      "mean_loss": 5097.141788670274,
      "epsilon": 0.38511400000307383
    },
    {
      "episode": 2351,
      "score": 136,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 2780.898383120273,
      "epsilon": 0.3850670000030751
    },
    {
      "episode": 2352,
      "score": 60,
      "reward": -995.0,
      "steps": 33,
      "mean_loss": 1197.1446882305722,
      "epsilon": 0.38503400000307597
    },
    {
      "episode": 2353,
      "score": 164,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 5567.667165976304,
      "epsilon": 0.38498200000307736
    },
    {
      "episode": 2354,
      "score": 192,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 2921.0042238588685,
      "epsilon": 0.3849280000030788
    },
    {
      "episode": 2355,
      "score": 234,
      "reward": -864.0,
      "steps": 61,
      "mean_loss": 4631.428006906978,
      "epsilon": 0.38486700000308044
    },
    {
      "episode": 2356,
      "score": 156,
      "reward": -911.0,
      "steps": 49,
      "mean_loss": 3850.4210958675462,
      "epsilon": 0.38481800000308175
    },
    {
      "episode": 2357,
      "score": 184,
      "reward": -907.0,
      "steps": 54,
      "mean_loss": 5254.351804591991,
      "epsilon": 0.3847640000030832
    },
    {
      "episode": 2358,
      "score": 139,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 2282.4300359643025,
      "epsilon": 0.3847180000030844
    },
    {
      "episode": 2359,
      "score": 163,
      "reward": -920.0,
      "steps": 52,
      "mean_loss": 3127.0359924756563,
      "epsilon": 0.3846660000030858
    },
    {
      "episode": 2360,
      "score": 275,
      "reward": -853.0,
      "steps": 68,
      "mean_loss": 2696.861042920281,
      "epsilon": 0.38459800000308764
    },
    {
      "episode": 2361,
      "score": 203,
      "reward": -879.0,
      "steps": 55,
      "mean_loss": 4288.670354739103,
      "epsilon": 0.3845430000030891
    },
    {
      "episode": 2362,
      "score": 166,
      "reward": -895.0,
      "steps": 48,
      "mean_loss": 3968.2997698783875,
      "epsilon": 0.3844950000030904
    },
    {
      "episode": 2363,
      "score": 129,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 2543.7891098996424,
      "epsilon": 0.38444800000309165
    },
    {
      "episode": 2364,
      "score": 219,
      "reward": -860.0,
      "steps": 58,
      "mean_loss": 4574.45579673504,
      "epsilon": 0.3843900000030932
    },
    {
      "episode": 2365,
      "score": 122,
      "reward": -941.0,
      "steps": 44,
      "mean_loss": 3526.0633195530286,
      "epsilon": 0.3843460000030944
    },
    {
      "episode": 2366,
      "score": 150,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 2720.100210342407,
      "epsilon": 0.3842960000030957
    },
    {
      "episode": 2367,
      "score": 166,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 3396.1893530273437,
      "epsilon": 0.38424600000309705
    },
    {
      "episode": 2368,
      "score": 156,
      "reward": -911.0,
      "steps": 48,
      "mean_loss": 4014.416335105896,
      "epsilon": 0.38419800000309834
    },
    {
      "episode": 2369,
      "score": 184,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 4213.475360430204,
      "epsilon": 0.38414600000309973
    },
    {
      "episode": 2370,
      "score": 124,
      "reward": -940.0,
      "steps": 39,
      "mean_loss": 3241.047435271434,
      "epsilon": 0.3841070000031008
    },
    {
      "episode": 2371,
      "score": 185,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 3721.5887968981706,
      "epsilon": 0.3840530000031022
    },
    {
      "episode": 2372,
      "score": 198,
      "reward": -882.0,
      "steps": 52,
      "mean_loss": 2319.144285788903,
      "epsilon": 0.3840010000031036
    },
    {
      "episode": 2373,
      "score": 138,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 4287.445081296174,
      "epsilon": 0.38395500000310484
    },
    {
      "episode": 2374,
      "score": 104,
      "reward": -966.0,
      "steps": 40,
      "mean_loss": 2132.559523391724,
      "epsilon": 0.3839150000031059
    },
    {
      "episode": 2375,
      "score": 140,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 1524.7273280931556,
      "epsilon": 0.38386900000310714
    },
    {
      "episode": 2376,
      "score": 140,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 5020.557964974261,
      "epsilon": 0.3838220000031084
    },
    {
      "episode": 2377,
      "score": 222,
      "reward": -873.0,
      "steps": 62,
      "mean_loss": 5093.187854274626,
      "epsilon": 0.38376000000311006
    },
    {
      "episode": 2378,
      "score": 140,
      "reward": -934.0,
      "steps": 43,
      "mean_loss": 3209.7383646410567,
      "epsilon": 0.3837170000031112
    },
    {
      "episode": 2379,
      "score": 141,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 2212.4214260020153,
      "epsilon": 0.38367000000311247
    },
    {
      "episode": 2380,
      "score": 71,
      "reward": -996.0,
      "steps": 35,
      "mean_loss": 5998.657214682443,
      "epsilon": 0.3836350000031134
    },
    {
      "episode": 2381,
      "score": 135,
      "reward": -937.0,
      "steps": 45,
      "mean_loss": 2241.861492199368,
      "epsilon": 0.3835900000031146
    },
    {
      "episode": 2382,
      "score": 231,
      "reward": -873.0,
      "steps": 62,
      "mean_loss": 2127.4537619313887,
      "epsilon": 0.38352800000311627
    },
    {
      "episode": 2383,
      "score": 169,
      "reward": -900.0,
      "steps": 46,
      "mean_loss": 1504.354915826217,
      "epsilon": 0.3834820000031175
    },
    {
      "episode": 2384,
      "score": 103,
      "reward": -965.0,
      "steps": 43,
      "mean_loss": 2848.5919905374217,
      "epsilon": 0.38343900000311865
    },
    {
      "episode": 2385,
      "score": 150,
      "reward": -915.0,
      "steps": 44,
      "mean_loss": 1959.1938069083474,
      "epsilon": 0.3833950000031198
    },
    {
      "episode": 2386,
      "score": 110,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 3501.4323657642713,
      "epsilon": 0.383351000003121
    },
    {
      "episode": 2387,
      "score": 139,
      "reward": -946.0,
      "steps": 48,
      "mean_loss": 2600.5469711621604,
      "epsilon": 0.3833030000031223
    },
    {
      "episode": 2388,
      "score": 159,
      "reward": -934.0,
      "steps": 52,
      "mean_loss": 3829.3230469410237,
      "epsilon": 0.3832510000031237
    },
    {
      "episode": 2389,
      "score": 229,
      "reward": -859.0,
      "steps": 59,
      "mean_loss": 3338.5615236961235,
      "epsilon": 0.38319200000312525
    },
    {
      "episode": 2390,
      "score": 208,
      "reward": -888.0,
      "steps": 56,
      "mean_loss": 4021.600902897971,
      "epsilon": 0.38313600000312675
    },
    {
      "episode": 2391,
      "score": 125,
      "reward": -928.0,
      "steps": 43,
      "mean_loss": 4950.011845610862,
      "epsilon": 0.3830930000031279
    },
    {
      "episode": 2392,
      "score": 147,
      "reward": -920.0,
      "steps": 46,
      "mean_loss": 4182.523758266283,
      "epsilon": 0.38304700000312913
    },
    {
      "episode": 2393,
      "score": 188,
      "reward": -877.0,
      "steps": 51,
      "mean_loss": 3196.8298009984633,
      "epsilon": 0.3829960000031305
    },
    {
      "episode": 2394,
      "score": 193,
      "reward": -874.0,
      "steps": 53,
      "mean_loss": 3664.556904630841,
      "epsilon": 0.3829430000031319
    },
    {
      "episode": 2395,
      "score": 96,
      "reward": -965.0,
      "steps": 34,
      "mean_loss": 8229.603451672723,
      "epsilon": 0.3829090000031328
    },
    {
      "episode": 2396,
      "score": 131,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 3779.794386291504,
      "epsilon": 0.38286400000313403
    },
    {
      "episode": 2397,
      "score": 166,
      "reward": -902.0,
      "steps": 50,
      "mean_loss": 3952.13669631958,
      "epsilon": 0.38281400000313537
    },
    {
      "episode": 2398,
      "score": 262,
      "reward": -840.0,
      "steps": 67,
      "mean_loss": 4027.591242320502,
      "epsilon": 0.38274700000313716
    },
    {
      "episode": 2399,
      "score": 171,
      "reward": -898.0,
      "steps": 50,
      "mean_loss": 3105.144519119263,
      "epsilon": 0.3826970000031385
    },
    {
      "episode": 2400,
      "score": 85,
      "reward": -977.0,
      "steps": 40,
      "mean_loss": 5302.130021095276,
      "epsilon": 0.38265700000313957
    },
    {
      "episode": 2401,
      "score": 158,
      "reward": -901.0,
      "steps": 46,
      "mean_loss": 2787.8990907254424,
      "epsilon": 0.3826110000031408
    },
    {
      "episode": 2402,
      "score": 114,
      "reward": -960.0,
      "steps": 46,
      "mean_loss": 2002.1558109781017,
      "epsilon": 0.38256500000314203
    },
    {
      "episode": 2403,
      "score": 103,
      "reward": -967.0,
      "steps": 42,
      "mean_loss": 3049.69849159604,
      "epsilon": 0.38252300000314315
    },
    {
      "episode": 2404,
      "score": 141,
      "reward": -939.0,
      "steps": 48,
      "mean_loss": 2828.1422809759774,
      "epsilon": 0.38247500000314444
    },
    {
      "episode": 2405,
      "score": 144,
      "reward": -936.0,
      "steps": 49,
      "mean_loss": 3083.248957575584,
      "epsilon": 0.38242600000314575
    },
    {
      "episode": 2406,
      "score": 137,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 5648.465003252029,
      "epsilon": 0.38237800000314703
    },
    {
      "episode": 2407,
      "score": 109,
      "reward": -978.0,
      "steps": 45,
      "mean_loss": 2708.278957790799,
      "epsilon": 0.38233300000314824
    },
    {
      "episode": 2408,
      "score": 186,
      "reward": -918.0,
      "steps": 55,
      "mean_loss": 2867.0314518321643,
      "epsilon": 0.3822780000031497
    },
    {
      "episode": 2409,
      "score": 243,
      "reward": -846.0,
      "steps": 61,
      "mean_loss": 5163.795014678455,
      "epsilon": 0.38221700000315134
    },
    {
      "episode": 2410,
      "score": 175,
      "reward": -892.0,
      "steps": 51,
      "mean_loss": 4559.867503820681,
      "epsilon": 0.3821660000031527
    },
    {
      "episode": 2411,
      "score": 50,
      "reward": -1007.0,
      "steps": 32,
      "mean_loss": 3790.2852606773376,
      "epsilon": 0.38213400000315356
    },
    {
      "episode": 2412,
      "score": 169,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 3126.33711826558,
      "epsilon": 0.3820850000031549
    },
    {
      "episode": 2413,
      "score": 193,
      "reward": -895.0,
      "steps": 52,
      "mean_loss": 3561.4693363629854,
      "epsilon": 0.38203300000315626
    },
    {
      "episode": 2414,
      "score": 166,
      "reward": -905.0,
      "steps": 49,
      "mean_loss": 3149.4612380047233,
      "epsilon": 0.3819840000031576
    },
    {
      "episode": 2415,
      "score": 130,
      "reward": -950.0,
      "steps": 46,
      "mean_loss": 4038.509169537088,
      "epsilon": 0.3819380000031588
    },
    {
      "episode": 2416,
      "score": 165,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 3403.512422027588,
      "epsilon": 0.38188800000316014
    },
    {
      "episode": 2417,
      "score": 107,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 4513.9618570236935,
      "epsilon": 0.38184600000316127
    },
    {
      "episode": 2418,
      "score": 105,
      "reward": -966.0,
      "steps": 43,
      "mean_loss": 2826.7893347629283,
      "epsilon": 0.3818030000031624
    },
    {
      "episode": 2419,
      "score": 126,
      "reward": -936.0,
      "steps": 45,
      "mean_loss": 4352.942078399658,
      "epsilon": 0.3817580000031636
    },
    {
      "episode": 2420,
      "score": 156,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 3163.0609597186653,
      "epsilon": 0.38170900000316493
    },
    {
      "episode": 2421,
      "score": 146,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 2675.592806471155,
      "epsilon": 0.3816620000031662
    },
    {
      "episode": 2422,
      "score": 160,
      "reward": -905.0,
      "steps": 49,
      "mean_loss": 4528.381774201685,
      "epsilon": 0.3816130000031675
    },
    {
      "episode": 2423,
      "score": 183,
      "reward": -908.0,
      "steps": 55,
      "mean_loss": 4928.112994246049,
      "epsilon": 0.381558000003169
    },
    {
      "episode": 2424,
      "score": 131,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 5232.757224704908,
      "epsilon": 0.3815120000031702
    },
    {
      "episode": 2425,
      "score": 125,
      "reward": -963.0,
      "steps": 46,
      "mean_loss": 5042.595989641936,
      "epsilon": 0.38146600000317143
    },
    {
      "episode": 2426,
      "score": 116,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 2258.411320512945,
      "epsilon": 0.3814220000031726
    },
    {
      "episode": 2427,
      "score": 96,
      "reward": -953.0,
      "steps": 37,
      "mean_loss": 2832.2303566803803,
      "epsilon": 0.3813850000031736
    },
    {
      "episode": 2428,
      "score": 171,
      "reward": -905.0,
      "steps": 51,
      "mean_loss": 4305.470855039709,
      "epsilon": 0.38133400000317497
    },
    {
      "episode": 2429,
      "score": 120,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 4299.759995990329,
      "epsilon": 0.38128900000317617
    },
    {
      "episode": 2430,
      "score": 210,
      "reward": -881.0,
      "steps": 57,
      "mean_loss": 4101.289891761646,
      "epsilon": 0.3812320000031777
    },
    {
      "episode": 2431,
      "score": 78,
      "reward": -967.0,
      "steps": 33,
      "mean_loss": 2982.737845102946,
      "epsilon": 0.3811990000031786
    },
    {
      "episode": 2432,
      "score": 150,
      "reward": -939.0,
      "steps": 50,
      "mean_loss": 5201.335365142822,
      "epsilon": 0.3811490000031799
    },
    {
      "episode": 2433,
      "score": 119,
      "reward": -951.0,
      "steps": 45,
      "mean_loss": 7056.150140550401,
      "epsilon": 0.3811040000031811
    },
    {
      "episode": 2434,
      "score": 143,
      "reward": -952.0,
      "steps": 50,
      "mean_loss": 3538.5836262893677,
      "epsilon": 0.38105400000318246
    },
    {
      "episode": 2435,
      "score": 181,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 3678.1900544166565,
      "epsilon": 0.38100200000318385
    },
    {
      "episode": 2436,
      "score": 105,
      "reward": -952.0,
      "steps": 42,
      "mean_loss": 2090.791761125837,
      "epsilon": 0.380960000003185
    },
    {
      "episode": 2437,
      "score": 95,
      "reward": -979.0,
      "steps": 43,
      "mean_loss": 3790.48986514779,
      "epsilon": 0.3809170000031861
    },
    {
      "episode": 2438,
      "score": 98,
      "reward": -959.0,
      "steps": 39,
      "mean_loss": 2748.4099369538135,
      "epsilon": 0.38087800000318717
    },
    {
      "episode": 2439,
      "score": 142,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 4561.437397176569,
      "epsilon": 0.38083400000318834
    },
    {
      "episode": 2440,
      "score": 181,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 3376.825059585571,
      "epsilon": 0.3807840000031897
    },
    {
      "episode": 2441,
      "score": 120,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 4756.477331811731,
      "epsilon": 0.38074000000319086
    },
    {
      "episode": 2442,
      "score": 184,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 4513.230054745307,
      "epsilon": 0.38068800000319225
    },
    {
      "episode": 2443,
      "score": 192,
      "reward": -913.0,
      "steps": 51,
      "mean_loss": 3706.2094179041246,
      "epsilon": 0.3806370000031936
    },
    {
      "episode": 2444,
      "score": 172,
      "reward": -911.0,
      "steps": 48,
      "mean_loss": 3145.287196358045,
      "epsilon": 0.3805890000031949
    },
    {
      "episode": 2445,
      "score": 87,
      "reward": -957.0,
      "steps": 33,
      "mean_loss": 2338.2892160126657,
      "epsilon": 0.3805560000031958
    },
    {
      "episode": 2446,
      "score": 164,
      "reward": -909.0,
      "steps": 48,
      "mean_loss": 2775.0337376594543,
      "epsilon": 0.38050800000319707
    },
    {
      "episode": 2447,
      "score": 158,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 4174.218797805462,
      "epsilon": 0.3804610000031983
    },
    {
      "episode": 2448,
      "score": 88,
      "reward": -977.0,
      "steps": 38,
      "mean_loss": 2434.666407685531,
      "epsilon": 0.38042300000319934
    },
    {
      "episode": 2449,
      "score": 157,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 7164.756476898194,
      "epsilon": 0.3803730000032007
    },
    {
      "episode": 2450,
      "score": 88,
      "reward": -973.0,
      "steps": 41,
      "mean_loss": 5469.028136369659,
      "epsilon": 0.3803320000032018
    },
    {
      "episode": 2451,
      "score": 165,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 4347.774265289307,
      "epsilon": 0.38028100000320314
    },
    {
      "episode": 2452,
      "score": 138,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 6567.098134751015,
      "epsilon": 0.3802340000032044
    },
    {
      "episode": 2453,
      "score": 188,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 3363.268340917734,
      "epsilon": 0.3801820000032058
    },
    {
      "episode": 2454,
      "score": 198,
      "reward": -877.0,
      "steps": 54,
      "mean_loss": 4629.357112743236,
      "epsilon": 0.38012800000320723
    },
    {
      "episode": 2455,
      "score": 231,
      "reward": -870.0,
      "steps": 60,
      "mean_loss": 4383.030170313517,
      "epsilon": 0.38006800000320884
    },
    {
      "episode": 2456,
      "score": 153,
      "reward": -949.0,
      "steps": 50,
      "mean_loss": 4498.895058059692,
      "epsilon": 0.3800180000032102
    },
    {
      "episode": 2457,
      "score": 122,
      "reward": -954.0,
      "steps": 45,
      "mean_loss": 4301.663673951891,
      "epsilon": 0.3799730000032114
    },
    {
      "episode": 2458,
      "score": 158,
      "reward": -920.0,
      "steps": 47,
      "mean_loss": 1706.5731136240859,
      "epsilon": 0.37992600000321264
    },
    {
      "episode": 2459,
      "score": 118,
      "reward": -952.0,
      "steps": 43,
      "mean_loss": 4348.269238937733,
      "epsilon": 0.3798830000032138
    },
    {
      "episode": 2460,
      "score": 228,
      "reward": -879.0,
      "steps": 61,
      "mean_loss": 3596.646183201524,
      "epsilon": 0.3798220000032154
    },
    {
      "episode": 2461,
      "score": 105,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 4619.512746204029,
      "epsilon": 0.3797780000032166
    },
    {
      "episode": 2462,
      "score": 89,
      "reward": -967.0,
      "steps": 37,
      "mean_loss": 5523.098217319798,
      "epsilon": 0.3797410000032176
    },
    {
      "episode": 2463,
      "score": 128,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 2234.35720638699,
      "epsilon": 0.3796960000032188
    },
    {
      "episode": 2464,
      "score": 160,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 3501.562559736536,
      "epsilon": 0.37964900000322005
    },
    {
      "episode": 2465,
      "score": 105,
      "reward": -973.0,
      "steps": 44,
      "mean_loss": 5890.487903074784,
      "epsilon": 0.3796050000032212
    },
    {
      "episode": 2466,
      "score": 95,
      "reward": -953.0,
      "steps": 35,
      "mean_loss": 1941.0926660810198,
      "epsilon": 0.37957000000322216
    },
    {
      "episode": 2467,
      "score": 124,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 2920.0971704036633,
      "epsilon": 0.3795230000032234
    },
    {
      "episode": 2468,
      "score": 177,
      "reward": -916.0,
      "steps": 54,
      "mean_loss": 5222.319396124945,
      "epsilon": 0.37946900000322487
    },
    {
      "episode": 2469,
      "score": 171,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 1844.8415531011728,
      "epsilon": 0.37941700000322626
    },
    {
      "episode": 2470,
      "score": 107,
      "reward": -956.0,
      "steps": 43,
      "mean_loss": 4074.839026783788,
      "epsilon": 0.3793740000032274
    },
    {
      "episode": 2471,
      "score": 165,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 4331.117662811279,
      "epsilon": 0.37932400000322875
    },
    {
      "episode": 2472,
      "score": 106,
      "reward": -977.0,
      "steps": 45,
      "mean_loss": 3564.648514811198,
      "epsilon": 0.37927900000322995
    },
    {
      "episode": 2473,
      "score": 256,
      "reward": -853.0,
      "steps": 67,
      "mean_loss": 4196.606990301787,
      "epsilon": 0.37921200000323174
    },
    {
      "episode": 2474,
      "score": 148,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 3385.4290183385215,
      "epsilon": 0.379164000003233
    },
    {
      "episode": 2475,
      "score": 147,
      "reward": -935.0,
      "steps": 47,
      "mean_loss": 3607.4912202713335,
      "epsilon": 0.3791170000032343
    },
    {
      "episode": 2476,
      "score": 125,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 3192.337865034739,
      "epsilon": 0.37906900000323557
    },
    {
      "episode": 2477,
      "score": 87,
      "reward": -976.0,
      "steps": 40,
      "mean_loss": 3766.6117107391356,
      "epsilon": 0.37902900000323664
    },
    {
      "episode": 2478,
      "score": 133,
      "reward": -947.0,
      "steps": 47,
      "mean_loss": 4399.293837324102,
      "epsilon": 0.3789820000032379
    },
    {
      "episode": 2479,
      "score": 172,
      "reward": -901.0,
      "steps": 50,
      "mean_loss": 7222.538525390625,
      "epsilon": 0.37893200000323923
    },
    {
      "episode": 2480,
      "score": 100,
      "reward": -974.0,
      "steps": 42,
      "mean_loss": 2862.402602150327,
      "epsilon": 0.37889000000324036
    },
    {
      "episode": 2481,
      "score": 133,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 2384.139650628922,
      "epsilon": 0.3788430000032416
    },
    {
      "episode": 2482,
      "score": 226,
      "reward": -861.0,
      "steps": 60,
      "mean_loss": 3818.241641108195,
      "epsilon": 0.3787830000032432
    },
    {
      "episode": 2483,
      "score": 213,
      "reward": -865.0,
      "steps": 55,
      "mean_loss": 4028.3540024497293,
      "epsilon": 0.3787280000032447
    },
    {
      "episode": 2484,
      "score": 103,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 3163.8076480683826,
      "epsilon": 0.3786860000032458
    },
    {
      "episode": 2485,
      "score": 188,
      "reward": -883.0,
      "steps": 54,
      "mean_loss": 2235.4164417408133,
      "epsilon": 0.37863200000324726
    },
    {
      "episode": 2486,
      "score": 179,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 3486.522082646688,
      "epsilon": 0.3785780000032487
    },
    {
      "episode": 2487,
      "score": 170,
      "reward": -900.0,
      "steps": 48,
      "mean_loss": 4505.730026086171,
      "epsilon": 0.37853000000325
    },
    {
      "episode": 2488,
      "score": 97,
      "reward": -978.0,
      "steps": 44,
      "mean_loss": 1369.1782963492653,
      "epsilon": 0.37848600000325117
    },
    {
      "episode": 2489,
      "score": 209,
      "reward": -883.0,
      "steps": 58,
      "mean_loss": 4069.0872682374097,
      "epsilon": 0.3784280000032527
    },
    {
      "episode": 2490,
      "score": 135,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 4438.246331850688,
      "epsilon": 0.378380000003254
    },
    {
      "episode": 2491,
      "score": 84,
      "reward": -969.0,
      "steps": 38,
      "mean_loss": 1402.469290683144,
      "epsilon": 0.378342000003255
    },
    {
      "episode": 2492,
      "score": 220,
      "reward": -881.0,
      "steps": 56,
      "mean_loss": 3410.032844747816,
      "epsilon": 0.3782860000032565
    },
    {
      "episode": 2493,
      "score": 251,
      "reward": -872.0,
      "steps": 62,
      "mean_loss": 3519.6708942536384,
      "epsilon": 0.3782240000032582
    },
    {
      "episode": 2494,
      "score": 171,
      "reward": -911.0,
      "steps": 53,
      "mean_loss": 3875.838834294733,
      "epsilon": 0.3781710000032596
    },
    {
      "episode": 2495,
      "score": 263,
      "reward": -828.0,
      "steps": 63,
      "mean_loss": 2885.64670229715,
      "epsilon": 0.3781080000032613
    },
    {
      "episode": 2496,
      "score": 92,
      "reward": -950.0,
      "steps": 34,
      "mean_loss": 1604.7311371074004,
      "epsilon": 0.3780740000032622
    },
    {
      "episode": 2497,
      "score": 240,
      "reward": -855.0,
      "steps": 60,
      "mean_loss": 4701.459785588582,
      "epsilon": 0.3780140000032638
    },
    {
      "episode": 2498,
      "score": 178,
      "reward": -904.0,
      "steps": 50,
      "mean_loss": 5090.2690982055665,
      "epsilon": 0.37796400000326513
    },
    {
      "episode": 2499,
      "score": 188,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 3190.7782578101524,
      "epsilon": 0.3779120000032665
    },
    {
      "episode": 2500,
      "score": 214,
      "reward": -886.0,
      "steps": 58,
      "mean_loss": 3796.244010037389,
      "epsilon": 0.3778540000032681
    },
    {
      "episode": 2501,
      "score": 147,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 2313.3827921030474,
      "epsilon": 0.3778050000032694
    },
    {
      "episode": 2502,
      "score": 112,
      "reward": -960.0,
      "steps": 42,
      "mean_loss": 4123.629004160563,
      "epsilon": 0.3777630000032705
    },
    {
      "episode": 2503,
      "score": 134,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 2880.9582327062435,
      "epsilon": 0.3777190000032717
    },
    {
      "episode": 2504,
      "score": 140,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 1788.841762661934,
      "epsilon": 0.37767100000327297
    },
    {
      "episode": 2505,
      "score": 107,
      "reward": -956.0,
      "steps": 40,
      "mean_loss": 4379.313518047333,
      "epsilon": 0.37763100000327404
    },
    {
      "episode": 2506,
      "score": 131,
      "reward": -956.0,
      "steps": 46,
      "mean_loss": 3058.197327489438,
      "epsilon": 0.3775850000032753
    },
    {
      "episode": 2507,
      "score": 167,
      "reward": -895.0,
      "steps": 48,
      "mean_loss": 2874.143800417582,
      "epsilon": 0.37753700000327656
    },
    {
      "episode": 2508,
      "score": 165,
      "reward": -921.0,
      "steps": 51,
      "mean_loss": 4467.133555842381,
      "epsilon": 0.3774860000032779
    },
    {
      "episode": 2509,
      "score": 167,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 4041.899220123291,
      "epsilon": 0.37743600000327926
    },
    {
      "episode": 2510,
      "score": 120,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 5670.243169784546,
      "epsilon": 0.37739200000328044
    },
    {
      "episode": 2511,
      "score": 205,
      "reward": -871.0,
      "steps": 53,
      "mean_loss": 2888.046225349858,
      "epsilon": 0.37733900000328185
    },
    {
      "episode": 2512,
      "score": 127,
      "reward": -941.0,
      "steps": 42,
      "mean_loss": 2392.2507000877745,
      "epsilon": 0.377297000003283
    },
    {
      "episode": 2513,
      "score": 197,
      "reward": -893.0,
      "steps": 53,
      "mean_loss": 1985.1079909126713,
      "epsilon": 0.3772440000032844
    },
    {
      "episode": 2514,
      "score": 131,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 3701.2644217411676,
      "epsilon": 0.3771960000032857
    },
    {
      "episode": 2515,
      "score": 121,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 5822.520516308871,
      "epsilon": 0.37715200000328686
    },
    {
      "episode": 2516,
      "score": 146,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 2343.4645899897037,
      "epsilon": 0.3771060000032881
    },
    {
      "episode": 2517,
      "score": 133,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 4974.683586769916,
      "epsilon": 0.37705900000328935
    },
    {
      "episode": 2518,
      "score": 192,
      "reward": -913.0,
      "steps": 52,
      "mean_loss": 3553.1608905792236,
      "epsilon": 0.37700700000329074
    },
    {
      "episode": 2519,
      "score": 205,
      "reward": -872.0,
      "steps": 55,
      "mean_loss": 4314.327821974321,
      "epsilon": 0.3769520000032922
    },
    {
      "episode": 2520,
      "score": 169,
      "reward": -916.0,
      "steps": 49,
      "mean_loss": 5248.7406298579,
      "epsilon": 0.3769030000032935
    },
    {
      "episode": 2521,
      "score": 111,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 3908.1331432515926,
      "epsilon": 0.3768590000032947
    },
    {
      "episode": 2522,
      "score": 165,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 4710.974047291035,
      "epsilon": 0.376810000003296
    },
    {
      "episode": 2523,
      "score": 98,
      "reward": -977.0,
      "steps": 40,
      "mean_loss": 2669.5801485061647,
      "epsilon": 0.3767700000032971
    },
    {
      "episode": 2524,
      "score": 107,
      "reward": -958.0,
      "steps": 37,
      "mean_loss": 3501.3521278999947,
      "epsilon": 0.37673300000329807
    },
    {
      "episode": 2525,
      "score": 164,
      "reward": -906.0,
      "steps": 47,
      "mean_loss": 2827.831207437718,
      "epsilon": 0.3766860000032993
    },
    {
      "episode": 2526,
      "score": 60,
      "reward": -979.0,
      "steps": 29,
      "mean_loss": 4147.420271248653,
      "epsilon": 0.3766570000033001
    },
    {
      "episode": 2527,
      "score": 83,
      "reward": -969.0,
      "steps": 37,
      "mean_loss": 1973.9689762012379,
      "epsilon": 0.3766200000033011
    },
    {
      "episode": 2528,
      "score": 204,
      "reward": -878.0,
      "steps": 53,
      "mean_loss": 2367.631246350846,
      "epsilon": 0.3765670000033025
    },
    {
      "episode": 2529,
      "score": 160,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 2691.268270889918,
      "epsilon": 0.3765190000033038
    },
    {
      "episode": 2530,
      "score": 160,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 1235.2699375541843,
      "epsilon": 0.3764700000033051
    },
    {
      "episode": 2531,
      "score": 107,
      "reward": -967.0,
      "steps": 42,
      "mean_loss": 4355.3504158655805,
      "epsilon": 0.37642800000330623
    },
    {
      "episode": 2532,
      "score": 149,
      "reward": -938.0,
      "steps": 51,
      "mean_loss": 3713.0029849632115,
      "epsilon": 0.3763770000033076
    },
    {
      "episode": 2533,
      "score": 94,
      "reward": -960.0,
      "steps": 37,
      "mean_loss": 4037.6161776362237,
      "epsilon": 0.3763400000033086
    },
    {
      "episode": 2534,
      "score": 130,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 2146.1666419658254,
      "epsilon": 0.37629300000330984
    },
    {
      "episode": 2535,
      "score": 170,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 4386.316640143301,
      "epsilon": 0.3762420000033112
    },
    {
      "episode": 2536,
      "score": 137,
      "reward": -934.0,
      "steps": 42,
      "mean_loss": 2654.7857304527647,
      "epsilon": 0.37620000000331233
    },
    {
      "episode": 2537,
      "score": 95,
      "reward": -976.0,
      "steps": 41,
      "mean_loss": 3299.2718824991366,
      "epsilon": 0.3761590000033134
    },
    {
      "episode": 2538,
      "score": 251,
      "reward": -854.0,
      "steps": 65,
      "mean_loss": 3622.2849876990686,
      "epsilon": 0.37609400000331517
    },
    {
      "episode": 2539,
      "score": 135,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 2804.208243890242,
      "epsilon": 0.37605000000331634
    },
    {
      "episode": 2540,
      "score": 160,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 2352.9942805480955,
      "epsilon": 0.3760000000033177
    },
    {
      "episode": 2541,
      "score": 174,
      "reward": -910.0,
      "steps": 53,
      "mean_loss": 4472.337299382912,
      "epsilon": 0.3759470000033191
    },
    {
      "episode": 2542,
      "score": 129,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 1643.727859377861,
      "epsilon": 0.3758990000033204
    },
    {
      "episode": 2543,
      "score": 233,
      "reward": -869.0,
      "steps": 61,
      "mean_loss": 3734.2284991154906,
      "epsilon": 0.375838000003322
    },
    {
      "episode": 2544,
      "score": 129,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 5070.011232503255,
      "epsilon": 0.3757930000033232
    },
    {
      "episode": 2545,
      "score": 182,
      "reward": -902.0,
      "steps": 51,
      "mean_loss": 2402.0089460634717,
      "epsilon": 0.3757420000033246
    },
    {
      "episode": 2546,
      "score": 119,
      "reward": -944.0,
      "steps": 40,
      "mean_loss": 3559.8341751098633,
      "epsilon": 0.37570200000332565
    },
    {
      "episode": 2547,
      "score": 136,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 2319.218299779025,
      "epsilon": 0.37565800000332683
    },
    {
      "episode": 2548,
      "score": 197,
      "reward": -893.0,
      "steps": 54,
      "mean_loss": 3454.80725147106,
      "epsilon": 0.3756040000033283
    },
    {
      "episode": 2549,
      "score": 144,
      "reward": -926.0,
      "steps": 43,
      "mean_loss": 5222.65449461826,
      "epsilon": 0.3755610000033294
    },
    {
      "episode": 2550,
      "score": 113,
      "reward": -957.0,
      "steps": 43,
      "mean_loss": 2084.406856980435,
      "epsilon": 0.3755180000033306
    },
    {
      "episode": 2551,
      "score": 55,
      "reward": -992.0,
      "steps": 29,
      "mean_loss": 3967.4694308576913,
      "epsilon": 0.37548900000333135
    },
    {
      "episode": 2552,
      "score": 227,
      "reward": -859.0,
      "steps": 58,
      "mean_loss": 7047.863143328963,
      "epsilon": 0.3754310000033329
    },
    {
      "episode": 2553,
      "score": 204,
      "reward": -879.0,
      "steps": 56,
      "mean_loss": 3695.0622094699315,
      "epsilon": 0.3753750000033344
    },
    {
      "episode": 2554,
      "score": 130,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 2556.2728697594175,
      "epsilon": 0.37532800000333566
    },
    {
      "episode": 2555,
      "score": 165,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 5430.779974937439,
      "epsilon": 0.37528000000333694
    },
    {
      "episode": 2556,
      "score": 143,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 2553.5408627257057,
      "epsilon": 0.37523100000333826
    },
    {
      "episode": 2557,
      "score": 178,
      "reward": -916.0,
      "steps": 54,
      "mean_loss": 4275.179034480342,
      "epsilon": 0.3751770000033397
    },
    {
      "episode": 2558,
      "score": 189,
      "reward": -899.0,
      "steps": 55,
      "mean_loss": 4952.071589521928,
      "epsilon": 0.37512200000334117
    },
    {
      "episode": 2559,
      "score": 74,
      "reward": -980.0,
      "steps": 34,
      "mean_loss": 5147.391756955315,
      "epsilon": 0.3750880000033421
    },
    {
      "episode": 2560,
      "score": 144,
      "reward": -935.0,
      "steps": 47,
      "mean_loss": 2010.0362304525172,
      "epsilon": 0.37504100000334334
    },
    {
      "episode": 2561,
      "score": 151,
      "reward": -939.0,
      "steps": 49,
      "mean_loss": 1711.458908431384,
      "epsilon": 0.37499200000334465
    },
    {
      "episode": 2562,
      "score": 135,
      "reward": -929.0,
      "steps": 43,
      "mean_loss": 1925.712955208712,
      "epsilon": 0.3749490000033458
    },
    {
      "episode": 2563,
      "score": 146,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 2667.238792622343,
      "epsilon": 0.37490200000334706
    },
    {
      "episode": 2564,
      "score": 195,
      "reward": -882.0,
      "steps": 55,
      "mean_loss": 2470.249107985063,
      "epsilon": 0.37484700000334853
    },
    {
      "episode": 2565,
      "score": 173,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 4737.149115929236,
      "epsilon": 0.3747950000033499
    },
    {
      "episode": 2566,
      "score": 142,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 2798.9869581858316,
      "epsilon": 0.3747470000033512
    },
    {
      "episode": 2567,
      "score": 225,
      "reward": -883.0,
      "steps": 58,
      "mean_loss": 4146.315830033401,
      "epsilon": 0.37468900000335276
    },
    {
      "episode": 2568,
      "score": 178,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 3005.426249063932,
      "epsilon": 0.37463700000335415
    },
    {
      "episode": 2569,
      "score": 156,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 2680.692443198346,
      "epsilon": 0.3745900000033554
    },
    {
      "episode": 2570,
      "score": 184,
      "reward": -903.0,
      "steps": 53,
      "mean_loss": 5007.596243444479,
      "epsilon": 0.3745370000033568
    },
    {
      "episode": 2571,
      "score": 190,
      "reward": -897.0,
      "steps": 54,
      "mean_loss": 2720.719269010756,
      "epsilon": 0.37448300000335827
    },
    {
      "episode": 2572,
      "score": 140,
      "reward": -924.0,
      "steps": 43,
      "mean_loss": 3271.19203957846,
      "epsilon": 0.3744400000033594
    },
    {
      "episode": 2573,
      "score": 111,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 1865.5720992769513,
      "epsilon": 0.37439800000336054
    },
    {
      "episode": 2574,
      "score": 181,
      "reward": -903.0,
      "steps": 53,
      "mean_loss": 3264.978939992077,
      "epsilon": 0.37434500000336196
    },
    {
      "episode": 2575,
      "score": 169,
      "reward": -906.0,
      "steps": 51,
      "mean_loss": 1810.7119779399798,
      "epsilon": 0.3742940000033633
    },
    {
      "episode": 2576,
      "score": 187,
      "reward": -900.0,
      "steps": 55,
      "mean_loss": 4228.541391268644,
      "epsilon": 0.3742390000033648
    },
    {
      "episode": 2577,
      "score": 125,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 2214.531221058058,
      "epsilon": 0.374193000003366
    },
    {
      "episode": 2578,
      "score": 148,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 4910.498347759247,
      "epsilon": 0.3741450000033673
    },
    {
      "episode": 2579,
      "score": 148,
      "reward": -934.0,
      "steps": 50,
      "mean_loss": 3666.7929266357423,
      "epsilon": 0.37409500000336865
    },
    {
      "episode": 2580,
      "score": 111,
      "reward": -965.0,
      "steps": 43,
      "mean_loss": 3414.4350761591004,
      "epsilon": 0.3740520000033698
    },
    {
      "episode": 2581,
      "score": 180,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 2870.663930306068,
      "epsilon": 0.3740000000033712
    },
    {
      "episode": 2582,
      "score": 163,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 2279.7270571650292,
      "epsilon": 0.3739510000033725
    },
    {
      "episode": 2583,
      "score": 134,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 3752.9294737110968,
      "epsilon": 0.37390500000337373
    },
    {
      "episode": 2584,
      "score": 95,
      "reward": -960.0,
      "steps": 41,
      "mean_loss": 6730.560640381604,
      "epsilon": 0.37386400000337483
    },
    {
      "episode": 2585,
      "score": 206,
      "reward": -882.0,
      "steps": 55,
      "mean_loss": 2992.3676932594994,
      "epsilon": 0.3738090000033763
    },
    {
      "episode": 2586,
      "score": 144,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 2492.7358809937823,
      "epsilon": 0.37376200000337756
    },
    {
      "episode": 2587,
      "score": 143,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 3509.9085341108607,
      "epsilon": 0.3737150000033788
    },
    {
      "episode": 2588,
      "score": 86,
      "reward": -962.0,
      "steps": 32,
      "mean_loss": 3759.168705403805,
      "epsilon": 0.3736830000033797
    },
    {
      "episode": 2589,
      "score": 171,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 2408.680303039551,
      "epsilon": 0.373633000003381
    },
    {
      "episode": 2590,
      "score": 221,
      "reward": -877.0,
      "steps": 60,
      "mean_loss": 3967.1497102101644,
      "epsilon": 0.3735730000033826
    },
    {
      "episode": 2591,
      "score": 165,
      "reward": -902.0,
      "steps": 49,
      "mean_loss": 2486.1234797263633,
      "epsilon": 0.3735240000033839
    },
    {
      "episode": 2592,
      "score": 113,
      "reward": -949.0,
      "steps": 39,
      "mean_loss": 4230.660361754589,
      "epsilon": 0.37348500000338497
    },
    {
      "episode": 2593,
      "score": 132,
      "reward": -942.0,
      "steps": 42,
      "mean_loss": 7472.492046537854,
      "epsilon": 0.3734430000033861
    },
    {
      "episode": 2594,
      "score": 81,
      "reward": -993.0,
      "steps": 39,
      "mean_loss": 6168.679339090983,
      "epsilon": 0.37340400000338714
    },
    {
      "episode": 2595,
      "score": 162,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 4384.1573378753665,
      "epsilon": 0.3733540000033885
    },
    {
      "episode": 2596,
      "score": 126,
      "reward": -949.0,
      "steps": 46,
      "mean_loss": 5695.114047340725,
      "epsilon": 0.3733080000033897
    },
    {
      "episode": 2597,
      "score": 164,
      "reward": -920.0,
      "steps": 53,
      "mean_loss": 2751.271567866487,
      "epsilon": 0.3732550000033911
    },
    {
      "episode": 2598,
      "score": 106,
      "reward": -974.0,
      "steps": 44,
      "mean_loss": 3381.620948444713,
      "epsilon": 0.3732110000033923
    },
    {
      "episode": 2599,
      "score": 109,
      "reward": -949.0,
      "steps": 38,
      "mean_loss": 3419.2092865391783,
      "epsilon": 0.3731730000033933
    },
    {
      "episode": 2600,
      "score": 193,
      "reward": -894.0,
      "steps": 55,
      "mean_loss": 2608.671548947421,
      "epsilon": 0.3731180000033948
    },
    {
      "episode": 2601,
      "score": 88,
      "reward": -968.0,
      "steps": 35,
      "mean_loss": 3626.0714184352328,
      "epsilon": 0.3730830000033957
    },
    {
      "episode": 2602,
      "score": 103,
      "reward": -971.0,
      "steps": 43,
      "mean_loss": 3034.3564988956896,
      "epsilon": 0.3730400000033969
    },
    {
      "episode": 2603,
      "score": 179,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 3926.8075492293747,
      "epsilon": 0.3729860000033983
    },
    {
      "episode": 2604,
      "score": 148,
      "reward": -939.0,
      "steps": 50,
      "mean_loss": 4481.85435836792,
      "epsilon": 0.37293600000339966
    },
    {
      "episode": 2605,
      "score": 240,
      "reward": -863.0,
      "steps": 61,
      "mean_loss": 2693.953178718442,
      "epsilon": 0.3728750000034013
    },
    {
      "episode": 2606,
      "score": 226,
      "reward": -885.0,
      "steps": 61,
      "mean_loss": 5638.160728642198,
      "epsilon": 0.3728140000034029
    },
    {
      "episode": 2607,
      "score": 154,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 4231.266678314209,
      "epsilon": 0.37276400000340426
    },
    {
      "episode": 2608,
      "score": 131,
      "reward": -957.0,
      "steps": 47,
      "mean_loss": 3179.9052563119444,
      "epsilon": 0.3727170000034055
    },
    {
      "episode": 2609,
      "score": 164,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 2286.8067437841537,
      "epsilon": 0.3726700000034068
    },
    {
      "episode": 2610,
      "score": 99,
      "reward": -961.0,
      "steps": 39,
      "mean_loss": 3466.8463911398862,
      "epsilon": 0.3726310000034078
    },
    {
      "episode": 2611,
      "score": 219,
      "reward": -860.0,
      "steps": 56,
      "mean_loss": 3495.9943578924454,
      "epsilon": 0.3725750000034093
    },
    {
      "episode": 2612,
      "score": 163,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 2272.621049807622,
      "epsilon": 0.3725230000034107
    },
    {
      "episode": 2613,
      "score": 201,
      "reward": -890.0,
      "steps": 55,
      "mean_loss": 1839.8239332719284,
      "epsilon": 0.3724680000034122
    },
    {
      "episode": 2614,
      "score": 195,
      "reward": -895.0,
      "steps": 53,
      "mean_loss": 4753.812702394881,
      "epsilon": 0.3724150000034136
    },
    {
      "episode": 2615,
      "score": 219,
      "reward": -861.0,
      "steps": 55,
      "mean_loss": 5024.475013559515,
      "epsilon": 0.37236000000341507
    },
    {
      "episode": 2616,
      "score": 214,
      "reward": -865.0,
      "steps": 55,
      "mean_loss": 3180.820147670399,
      "epsilon": 0.37230500000341654
    },
    {
      "episode": 2617,
      "score": 165,
      "reward": -913.0,
      "steps": 47,
      "mean_loss": 3426.4870318960634,
      "epsilon": 0.3722580000034178
    },
    {
      "episode": 2618,
      "score": 213,
      "reward": -868.0,
      "steps": 57,
      "mean_loss": 3568.907928600646,
      "epsilon": 0.3722010000034193
    },
    {
      "episode": 2619,
      "score": 167,
      "reward": -901.0,
      "steps": 49,
      "mean_loss": 2797.938828682413,
      "epsilon": 0.37215200000342064
    },
    {
      "episode": 2620,
      "score": 80,
      "reward": -988.0,
      "steps": 37,
      "mean_loss": 3780.48698430448,
      "epsilon": 0.3721150000034216
    },
    {
      "episode": 2621,
      "score": 182,
      "reward": -906.0,
      "steps": 53,
      "mean_loss": 4142.4370487860915,
      "epsilon": 0.37206200000342304
    },
    {
      "episode": 2622,
      "score": 147,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 5498.999503343001,
      "epsilon": 0.3720160000034243
    },
    {
      "episode": 2623,
      "score": 143,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 1361.6505169969923,
      "epsilon": 0.37196900000342553
    },
    {
      "episode": 2624,
      "score": 134,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 6467.932746140853,
      "epsilon": 0.37192300000342676
    },
    {
      "episode": 2625,
      "score": 205,
      "reward": -896.0,
      "steps": 56,
      "mean_loss": 3184.6070713996887,
      "epsilon": 0.37186700000342826
    },
    {
      "episode": 2626,
      "score": 169,
      "reward": -922.0,
      "steps": 51,
      "mean_loss": 2829.353314156626,
      "epsilon": 0.3718160000034296
    },
    {
      "episode": 2627,
      "score": 105,
      "reward": -968.0,
      "steps": 36,
      "mean_loss": 5385.742467986212,
      "epsilon": 0.3717800000034306
    },
    {
      "episode": 2628,
      "score": 95,
      "reward": -968.0,
      "steps": 40,
      "mean_loss": 1420.2087025642395,
      "epsilon": 0.37174000000343166
    },
    {
      "episode": 2629,
      "score": 258,
      "reward": -838.0,
      "steps": 67,
      "mean_loss": 2376.6297630765544,
      "epsilon": 0.37167300000343345
    },
    {
      "episode": 2630,
      "score": 97,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 4360.4354660397485,
      "epsilon": 0.3716310000034346
    },
    {
      "episode": 2631,
      "score": 266,
      "reward": -816.0,
      "steps": 63,
      "mean_loss": 2839.5578477042063,
      "epsilon": 0.37156800000343626
    },
    {
      "episode": 2632,
      "score": 114,
      "reward": -963.0,
      "steps": 45,
      "mean_loss": 4711.207278272841,
      "epsilon": 0.37152300000343746
    },
    {
      "episode": 2633,
      "score": 241,
      "reward": -860.0,
      "steps": 62,
      "mean_loss": 3606.9211407323037,
      "epsilon": 0.3714610000034391
    },
    {
      "episode": 2634,
      "score": 144,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 2532.03767712911,
      "epsilon": 0.3714130000034404
    },
    {
      "episode": 2635,
      "score": 162,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 2848.154514389038,
      "epsilon": 0.37136300000344175
    },
    {
      "episode": 2636,
      "score": 98,
      "reward": -961.0,
      "steps": 35,
      "mean_loss": 3600.2709612165177,
      "epsilon": 0.3713280000034427
    },
    {
      "episode": 2637,
      "score": 147,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 3562.2786321640015,
      "epsilon": 0.37128000000344397
    },
    {
      "episode": 2638,
      "score": 120,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 6164.794476799343,
      "epsilon": 0.3712340000034452
    },
    {
      "episode": 2639,
      "score": 92,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 3864.966075377031,
      "epsilon": 0.3711900000034464
    },
    {
      "episode": 2640,
      "score": 122,
      "reward": -938.0,
      "steps": 41,
      "mean_loss": 2290.5338190590464,
      "epsilon": 0.37114900000344747
    },
    {
      "episode": 2641,
      "score": 214,
      "reward": -883.0,
      "steps": 57,
      "mean_loss": 4049.970976980109,
      "epsilon": 0.371092000003449
    },
    {
      "episode": 2642,
      "score": 153,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 5733.314393768311,
      "epsilon": 0.37104200000345033
    },
    {
      "episode": 2643,
      "score": 94,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 2869.4765156926337,
      "epsilon": 0.3710050000034513
    },
    {
      "episode": 2644,
      "score": 202,
      "reward": -892.0,
      "steps": 57,
      "mean_loss": 6158.021651418586,
      "epsilon": 0.37094800000345285
    },
    {
      "episode": 2645,
      "score": 195,
      "reward": -882.0,
      "steps": 54,
      "mean_loss": 4835.405918121338,
      "epsilon": 0.3708940000034543
    },
    {
      "episode": 2646,
      "score": 139,
      "reward": -950.0,
      "steps": 48,
      "mean_loss": 3295.7171438535056,
      "epsilon": 0.3708460000034556
    },
    {
      "episode": 2647,
      "score": 82,
      "reward": -967.0,
      "steps": 34,
      "mean_loss": 6153.171571170583,
      "epsilon": 0.3708120000034565
    },
    {
      "episode": 2648,
      "score": 180,
      "reward": -895.0,
      "steps": 50,
      "mean_loss": 2416.2448768615723,
      "epsilon": 0.3707620000034578
    },
    {
      "episode": 2649,
      "score": 130,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 3628.793712919409,
      "epsilon": 0.370718000003459
    },
    {
      "episode": 2650,
      "score": 134,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 3030.6036362214522,
      "epsilon": 0.3706740000034602
    },
    {
      "episode": 2651,
      "score": 218,
      "reward": -879.0,
      "steps": 55,
      "mean_loss": 3839.398916764693,
      "epsilon": 0.37061900000346165
    },
    {
      "episode": 2652,
      "score": 194,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 5317.073650433467,
      "epsilon": 0.37056700000346304
    },
    {
      "episode": 2653,
      "score": 130,
      "reward": -934.0,
      "steps": 42,
      "mean_loss": 3884.25369762239,
      "epsilon": 0.37052500000346417
    },
    {
      "episode": 2654,
      "score": 135,
      "reward": -949.0,
      "steps": 47,
      "mean_loss": 3582.4657547727543,
      "epsilon": 0.3704780000034654
    },
    {
      "episode": 2655,
      "score": 127,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 5053.099078698592,
      "epsilon": 0.3704340000034666
    },
    {
      "episode": 2656,
      "score": 165,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 4414.459790910993,
      "epsilon": 0.3703850000034679
    },
    {
      "episode": 2657,
      "score": 110,
      "reward": -956.0,
      "steps": 39,
      "mean_loss": 5151.807945642716,
      "epsilon": 0.37034600000346896
    },
    {
      "episode": 2658,
      "score": 152,
      "reward": -919.0,
      "steps": 45,
      "mean_loss": 6326.515248277452,
      "epsilon": 0.37030100000347016
    },
    {
      "episode": 2659,
      "score": 175,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 2933.1307301423985,
      "epsilon": 0.37025200000347147
    },
    {
      "episode": 2660,
      "score": 168,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 4062.722144640409,
      "epsilon": 0.37020000000347286
    },
    {
      "episode": 2661,
      "score": 107,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 3551.1389033577657,
      "epsilon": 0.37015600000347404
    },
    {
      "episode": 2662,
      "score": 124,
      "reward": -957.0,
      "steps": 45,
      "mean_loss": 3810.8246029324,
      "epsilon": 0.37011100000347524
    },
    {
      "episode": 2663,
      "score": 160,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 3652.4523898922666,
      "epsilon": 0.37006200000347655
    },
    {
      "episode": 2664,
      "score": 85,
      "reward": -972.0,
      "steps": 37,
      "mean_loss": 1918.383193351127,
      "epsilon": 0.37002500000347754
    },
    {
      "episode": 2665,
      "score": 301,
      "reward": -820.0,
      "steps": 69,
      "mean_loss": 3325.6756411566253,
      "epsilon": 0.3699560000034794
    },
    {
      "episode": 2666,
      "score": 87,
      "reward": -985.0,
      "steps": 38,
      "mean_loss": 3913.8867831983066,
      "epsilon": 0.3699180000034804
    },
    {
      "episode": 2667,
      "score": 155,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 4627.088521118164,
      "epsilon": 0.36986800000348174
    },
    {
      "episode": 2668,
      "score": 150,
      "reward": -910.0,
      "steps": 48,
      "mean_loss": 4462.401823361714,
      "epsilon": 0.36982000000348303
    },
    {
      "episode": 2669,
      "score": 230,
      "reward": -866.0,
      "steps": 59,
      "mean_loss": 5125.661803940595,
      "epsilon": 0.3697610000034846
    },
    {
      "episode": 2670,
      "score": 194,
      "reward": -895.0,
      "steps": 55,
      "mean_loss": 4913.112390622226,
      "epsilon": 0.3697060000034861
    },
    {
      "episode": 2671,
      "score": 191,
      "reward": -887.0,
      "steps": 53,
      "mean_loss": 3646.539507452047,
      "epsilon": 0.3696530000034875
    },
    {
      "episode": 2672,
      "score": 177,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 3816.326350542215,
      "epsilon": 0.3696010000034889
    },
    {
      "episode": 2673,
      "score": 144,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 4402.114347107557,
      "epsilon": 0.3695520000034902
    },
    {
      "episode": 2674,
      "score": 67,
      "reward": -980.0,
      "steps": 32,
      "mean_loss": 2402.545833826065,
      "epsilon": 0.36952000000349106
    },
    {
      "episode": 2675,
      "score": 84,
      "reward": -971.0,
      "steps": 33,
      "mean_loss": 3366.3649598323937,
      "epsilon": 0.36948700000349194
    },
    {
      "episode": 2676,
      "score": 169,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 4002.70109664917,
      "epsilon": 0.3694370000034933
    },
    {
      "episode": 2677,
      "score": 132,
      "reward": -959.0,
      "steps": 49,
      "mean_loss": 2746.8740596381986,
      "epsilon": 0.3693880000034946
    },
    {
      "episode": 2678,
      "score": 162,
      "reward": -911.0,
      "steps": 48,
      "mean_loss": 6024.502595504125,
      "epsilon": 0.36934000000349587
    },
    {
      "episode": 2679,
      "score": 194,
      "reward": -891.0,
      "steps": 53,
      "mean_loss": 1871.2039540128887,
      "epsilon": 0.3692870000034973
    },
    {
      "episode": 2680,
      "score": 150,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 2772.542842825254,
      "epsilon": 0.3692390000034986
    },
    {
      "episode": 2681,
      "score": 157,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 2812.7496099853515,
      "epsilon": 0.3691890000034999
    },
    {
      "episode": 2682,
      "score": 160,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 4990.081879218419,
      "epsilon": 0.3691410000035012
    },
    {
      "episode": 2683,
      "score": 162,
      "reward": -918.0,
      "steps": 46,
      "mean_loss": 5344.617144087087,
      "epsilon": 0.3690950000035024
    },
    {
      "episode": 2684,
      "score": 86,
      "reward": -996.0,
      "steps": 40,
      "mean_loss": 4649.39335565567,
      "epsilon": 0.3690550000035035
    },
    {
      "episode": 2685,
      "score": 172,
      "reward": -902.0,
      "steps": 51,
      "mean_loss": 2645.3931829041126,
      "epsilon": 0.36900400000350486
    },
    {
      "episode": 2686,
      "score": 144,
      "reward": -924.0,
      "steps": 45,
      "mean_loss": 3667.279936981201,
      "epsilon": 0.36895900000350607
    },
    {
      "episode": 2687,
      "score": 111,
      "reward": -957.0,
      "steps": 36,
      "mean_loss": 2246.05016819636,
      "epsilon": 0.36892300000350703
    },
    {
      "episode": 2688,
      "score": 100,
      "reward": -975.0,
      "steps": 42,
      "mean_loss": 3595.2920043582008,
      "epsilon": 0.36888100000350815
    },
    {
      "episode": 2689,
      "score": 253,
      "reward": -839.0,
      "steps": 64,
      "mean_loss": 4275.451021909714,
      "epsilon": 0.36881700000350987
    },
    {
      "episode": 2690,
      "score": 140,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 4612.235787550609,
      "epsilon": 0.36876900000351115
    },
    {
      "episode": 2691,
      "score": 175,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 2115.492040361677,
      "epsilon": 0.36872000000351246
    },
    {
      "episode": 2692,
      "score": 106,
      "reward": -951.0,
      "steps": 36,
      "mean_loss": 4623.023085912068,
      "epsilon": 0.3686840000035134
    },
    {
      "episode": 2693,
      "score": 185,
      "reward": -896.0,
      "steps": 53,
      "mean_loss": 4616.834331728377,
      "epsilon": 0.36863100000351484
    },
    {
      "episode": 2694,
      "score": 86,
      "reward": -982.0,
      "steps": 38,
      "mean_loss": 2990.8108655026085,
      "epsilon": 0.36859300000351586
    },
    {
      "episode": 2695,
      "score": 186,
      "reward": -894.0,
      "steps": 53,
      "mean_loss": 6241.630223112286,
      "epsilon": 0.3685400000035173
    },
    {
      "episode": 2696,
      "score": 40,
      "reward": -1011.0,
      "steps": 27,
      "mean_loss": 5208.231635764793,
      "epsilon": 0.368513000003518
    },
    {
      "episode": 2697,
      "score": 224,
      "reward": -897.0,
      "steps": 59,
      "mean_loss": 5138.272784540209,
      "epsilon": 0.3684540000035196
    },
    {
      "episode": 2698,
      "score": 134,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 3042.5540021531124,
      "epsilon": 0.36840700000352083
    },
    {
      "episode": 2699,
      "score": 146,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 2032.7484372727415,
      "epsilon": 0.3683600000035221
    },
    {
      "episode": 2700,
      "score": 116,
      "reward": -960.0,
      "steps": 45,
      "mean_loss": 4734.669021606445,
      "epsilon": 0.3683150000035233
    },
    {
      "episode": 2701,
      "score": 226,
      "reward": -864.0,
      "steps": 59,
      "mean_loss": 4478.511908062434,
      "epsilon": 0.3682560000035249
    },
    {
      "episode": 2702,
      "score": 106,
      "reward": -975.0,
      "steps": 44,
      "mean_loss": 3921.4550870548596,
      "epsilon": 0.36821200000352605
    },
    {
      "episode": 2703,
      "score": 233,
      "reward": -885.0,
      "steps": 61,
      "mean_loss": 5470.217360324547,
      "epsilon": 0.3681510000035277
    },
    {
      "episode": 2704,
      "score": 126,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 8204.583054802635,
      "epsilon": 0.36810700000352886
    },
    {
      "episode": 2705,
      "score": 123,
      "reward": -921.0,
      "steps": 35,
      "mean_loss": 2980.0325449262346,
      "epsilon": 0.3680720000035298
    },
    {
      "episode": 2706,
      "score": 103,
      "reward": -952.0,
      "steps": 38,
      "mean_loss": 3619.8425983629727,
      "epsilon": 0.3680340000035308
    },
    {
      "episode": 2707,
      "score": 179,
      "reward": -893.0,
      "steps": 54,
      "mean_loss": 2439.747671551175,
      "epsilon": 0.36798000000353226
    },
    {
      "episode": 2708,
      "score": 155,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 2940.7538816880206,
      "epsilon": 0.36793100000353357
    },
    {
      "episode": 2709,
      "score": 175,
      "reward": -910.0,
      "steps": 53,
      "mean_loss": 2550.0618761170585,
      "epsilon": 0.367878000003535
    },
    {
      "episode": 2710,
      "score": 162,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 3011.5912010955813,
      "epsilon": 0.3678280000035363
    },
    {
      "episode": 2711,
      "score": 167,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 2626.8994282942554,
      "epsilon": 0.3677760000035377
    },
    {
      "episode": 2712,
      "score": 142,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 4608.856260050898,
      "epsilon": 0.36773000000353895
    },
    {
      "episode": 2713,
      "score": 126,
      "reward": -955.0,
      "steps": 48,
      "mean_loss": 3538.536174337069,
      "epsilon": 0.36768200000354023
    },
    {
      "episode": 2714,
      "score": 104,
      "reward": -961.0,
      "steps": 41,
      "mean_loss": 5776.205172468976,
      "epsilon": 0.36764100000354133
    },
    {
      "episode": 2715,
      "score": 151,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 3733.0302349791236,
      "epsilon": 0.36759200000354264
    },
    {
      "episode": 2716,
      "score": 180,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 2508.4395723882712,
      "epsilon": 0.36753900000354406
    },
    {
      "episode": 2717,
      "score": 251,
      "reward": -847.0,
      "steps": 62,
      "mean_loss": 4783.636602247915,
      "epsilon": 0.3674770000035457
    },
    {
      "episode": 2718,
      "score": 227,
      "reward": -854.0,
      "steps": 58,
      "mean_loss": 3364.9893754761792,
      "epsilon": 0.36741900000354727
    },
    {
      "episode": 2719,
      "score": 174,
      "reward": -920.0,
      "steps": 54,
      "mean_loss": 3618.691091042978,
      "epsilon": 0.3673650000035487
    },
    {
      "episode": 2720,
      "score": 175,
      "reward": -895.0,
      "steps": 54,
      "mean_loss": 3392.287189059787,
      "epsilon": 0.36731100000355016
    },
    {
      "episode": 2721,
      "score": 116,
      "reward": -967.0,
      "steps": 45,
      "mean_loss": 5976.903945922852,
      "epsilon": 0.36726600000355136
    },
    {
      "episode": 2722,
      "score": 93,
      "reward": -987.0,
      "steps": 44,
      "mean_loss": 3959.843548081138,
      "epsilon": 0.36722200000355254
    },
    {
      "episode": 2723,
      "score": 159,
      "reward": -927.0,
      "steps": 51,
      "mean_loss": 3283.0252165326883,
      "epsilon": 0.3671710000035539
    },
    {
      "episode": 2724,
      "score": 171,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 2342.9692739339976,
      "epsilon": 0.3671190000035553
    },
    {
      "episode": 2725,
      "score": 235,
      "reward": -856.0,
      "steps": 60,
      "mean_loss": 3075.302381960551,
      "epsilon": 0.3670590000035569
    },
    {
      "episode": 2726,
      "score": 125,
      "reward": -946.0,
      "steps": 47,
      "mean_loss": 2294.643044735523,
      "epsilon": 0.36701200000355816
    },
    {
      "episode": 2727,
      "score": 137,
      "reward": -928.0,
      "steps": 45,
      "mean_loss": 3428.6063875834147,
      "epsilon": 0.36696700000355936
    },
    {
      "episode": 2728,
      "score": 103,
      "reward": -958.0,
      "steps": 36,
      "mean_loss": 5165.061786757575,
      "epsilon": 0.3669310000035603
    },
    {
      "episode": 2729,
      "score": 275,
      "reward": -825.0,
      "steps": 68,
      "mean_loss": 2039.5608147452858,
      "epsilon": 0.36686300000356215
    },
    {
      "episode": 2730,
      "score": 125,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 3133.416570497596,
      "epsilon": 0.3668170000035634
    },
    {
      "episode": 2731,
      "score": 144,
      "reward": -918.0,
      "steps": 46,
      "mean_loss": 1719.4168779124384,
      "epsilon": 0.3667710000035646
    },
    {
      "episode": 2732,
      "score": 218,
      "reward": -877.0,
      "steps": 57,
      "mean_loss": 2328.569881439209,
      "epsilon": 0.36671400000356613
    },
    {
      "episode": 2733,
      "score": 162,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 3828.10603250776,
      "epsilon": 0.36666500000356744
    },
    {
      "episode": 2734,
      "score": 123,
      "reward": -937.0,
      "steps": 38,
      "mean_loss": 1738.1439500106007,
      "epsilon": 0.36662700000356846
    },
    {
      "episode": 2735,
      "score": 110,
      "reward": -946.0,
      "steps": 38,
      "mean_loss": 3738.532268122623,
      "epsilon": 0.3665890000035695
    },
    {
      "episode": 2736,
      "score": 164,
      "reward": -914.0,
      "steps": 51,
      "mean_loss": 2283.7081610361734,
      "epsilon": 0.36653800000357084
    },
    {
      "episode": 2737,
      "score": 144,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 5137.8735944058035,
      "epsilon": 0.3664910000035721
    },
    {
      "episode": 2738,
      "score": 171,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 3319.238451860389,
      "epsilon": 0.3664420000035734
    },
    {
      "episode": 2739,
      "score": 205,
      "reward": -878.0,
      "steps": 56,
      "mean_loss": 4355.339126791273,
      "epsilon": 0.3663860000035749
    },
    {
      "episode": 2740,
      "score": 102,
      "reward": -946.0,
      "steps": 35,
      "mean_loss": 2621.564270237514,
      "epsilon": 0.36635100000357584
    },
    {
      "episode": 2741,
      "score": 132,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 3145.4417457783475,
      "epsilon": 0.3663040000035771
    },
    {
      "episode": 2742,
      "score": 157,
      "reward": -907.0,
      "steps": 47,
      "mean_loss": 2468.7224979806456,
      "epsilon": 0.36625700000357836
    },
    {
      "episode": 2743,
      "score": 270,
      "reward": -814.0,
      "steps": 64,
      "mean_loss": 4150.3338831067085,
      "epsilon": 0.36619300000358007
    },
    {
      "episode": 2744,
      "score": 175,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 3023.447654577402,
      "epsilon": 0.36614100000358146
    },
    {
      "episode": 2745,
      "score": 107,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 4070.0996006011965,
      "epsilon": 0.36610100000358253
    },
    {
      "episode": 2746,
      "score": 71,
      "reward": -998.0,
      "steps": 37,
      "mean_loss": 3512.00124142621,
      "epsilon": 0.3660640000035835
    },
    {
      "episode": 2747,
      "score": 174,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 2376.4956854277966,
      "epsilon": 0.3660130000035849
    },
    {
      "episode": 2748,
      "score": 181,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 2986.6756972899802,
      "epsilon": 0.3659610000035863
    },
    {
      "episode": 2749,
      "score": 169,
      "reward": -905.0,
      "steps": 53,
      "mean_loss": 2318.4351721349753,
      "epsilon": 0.3659080000035877
    },
    {
      "episode": 2750,
      "score": 164,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 2628.2176353014434,
      "epsilon": 0.3658560000035891
    },
    {
      "episode": 2751,
      "score": 161,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 3943.9143604278565,
      "epsilon": 0.3658060000035904
    },
    {
      "episode": 2752,
      "score": 197,
      "reward": -894.0,
      "steps": 49,
      "mean_loss": 4096.244024432435,
      "epsilon": 0.36575700000359174
    },
    {
      "episode": 2753,
      "score": 149,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 4462.743093490601,
      "epsilon": 0.365709000003593
    },
    {
      "episode": 2754,
      "score": 115,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 3138.6775389671325,
      "epsilon": 0.3656690000035941
    },
    {
      "episode": 2755,
      "score": 137,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 5120.823176201354,
      "epsilon": 0.36562200000359535
    },
    {
      "episode": 2756,
      "score": 127,
      "reward": -956.0,
      "steps": 46,
      "mean_loss": 1874.444376655247,
      "epsilon": 0.3655760000035966
    },
    {
      "episode": 2757,
      "score": 256,
      "reward": -840.0,
      "steps": 60,
      "mean_loss": 3042.3241638183595,
      "epsilon": 0.3655160000035982
    },
    {
      "episode": 2758,
      "score": 118,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 5320.964953483419,
      "epsilon": 0.36546900000359944
    },
    {
      "episode": 2759,
      "score": 167,
      "reward": -919.0,
      "steps": 52,
      "mean_loss": 5287.38440829057,
      "epsilon": 0.36541700000360083
    },
    {
      "episode": 2760,
      "score": 230,
      "reward": -865.0,
      "steps": 58,
      "mean_loss": 2110.99671508526,
      "epsilon": 0.3653590000036024
    },
    {
      "episode": 2761,
      "score": 123,
      "reward": -942.0,
      "steps": 45,
      "mean_loss": 3215.785137261285,
      "epsilon": 0.3653140000036036
    },
    {
      "episode": 2762,
      "score": 91,
      "reward": -971.0,
      "steps": 39,
      "mean_loss": 3199.2318965227178,
      "epsilon": 0.36527500000360463
    },
    {
      "episode": 2763,
      "score": 180,
      "reward": -895.0,
      "steps": 52,
      "mean_loss": 2159.670387561505,
      "epsilon": 0.365223000003606
    },
    {
      "episode": 2764,
      "score": 215,
      "reward": -878.0,
      "steps": 57,
      "mean_loss": 3247.699367723967,
      "epsilon": 0.36516600000360755
    },
    {
      "episode": 2765,
      "score": 280,
      "reward": -825.0,
      "steps": 69,
      "mean_loss": 5010.321305661962,
      "epsilon": 0.3650970000036094
    },
    {
      "episode": 2766,
      "score": 165,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 2350.8113737487793,
      "epsilon": 0.36504700000361073
    },
    {
      "episode": 2767,
      "score": 80,
      "reward": -971.0,
      "steps": 34,
      "mean_loss": 4867.157541611616,
      "epsilon": 0.36501300000361164
    },
    {
      "episode": 2768,
      "score": 170,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 2865.197318150447,
      "epsilon": 0.36496100000361303
    },
    {
      "episode": 2769,
      "score": 179,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 4515.566186269124,
      "epsilon": 0.3649070000036145
    },
    {
      "episode": 2770,
      "score": 180,
      "reward": -906.0,
      "steps": 51,
      "mean_loss": 5528.6446591545555,
      "epsilon": 0.36485600000361584
    },
    {
      "episode": 2771,
      "score": 122,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 3839.641445853493,
      "epsilon": 0.364812000003617
    },
    {
      "episode": 2772,
      "score": 127,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3522.3789714466443,
      "epsilon": 0.3647680000036182
    },
    {
      "episode": 2773,
      "score": 146,
      "reward": -940.0,
      "steps": 50,
      "mean_loss": 3010.822104301453,
      "epsilon": 0.36471800000361954
    },
    {
      "episode": 2774,
      "score": 244,
      "reward": -861.0,
      "steps": 63,
      "mean_loss": 4302.654665871272,
      "epsilon": 0.3646550000036212
    },
    {
      "episode": 2775,
      "score": 206,
      "reward": -882.0,
      "steps": 57,
      "mean_loss": 4334.300048694276,
      "epsilon": 0.36459800000362275
    },
    {
      "episode": 2776,
      "score": 173,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 3125.897967375242,
      "epsilon": 0.36454600000362414
    },
    {
      "episode": 2777,
      "score": 198,
      "reward": -876.0,
      "steps": 55,
      "mean_loss": 3709.7705805691808,
      "epsilon": 0.3644910000036256
    },
    {
      "episode": 2778,
      "score": 185,
      "reward": -894.0,
      "steps": 52,
      "mean_loss": 5021.617870477529,
      "epsilon": 0.364439000003627
    },
    {
      "episode": 2779,
      "score": 113,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 3291.4750218824906,
      "epsilon": 0.3643950000036282
    },
    {
      "episode": 2780,
      "score": 201,
      "reward": -878.0,
      "steps": 54,
      "mean_loss": 3489.652106108489,
      "epsilon": 0.3643410000036296
    },
    {
      "episode": 2781,
      "score": 130,
      "reward": -941.0,
      "steps": 38,
      "mean_loss": 3326.300159153185,
      "epsilon": 0.36430300000363064
    },
    {
      "episode": 2782,
      "score": 189,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 4585.76034473923,
      "epsilon": 0.36425000000363206
    },
    {
      "episode": 2783,
      "score": 169,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 2670.0694881750615,
      "epsilon": 0.36420100000363337
    },
    {
      "episode": 2784,
      "score": 165,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 2823.67668503406,
      "epsilon": 0.36415000000363473
    },
    {
      "episode": 2785,
      "score": 149,
      "reward": -921.0,
      "steps": 47,
      "mean_loss": 2521.8923405586406,
      "epsilon": 0.364103000003636
    },
    {
      "episode": 2786,
      "score": 215,
      "reward": -866.0,
      "steps": 54,
      "mean_loss": 3729.520700172142,
      "epsilon": 0.36404900000363744
    },
    {
      "episode": 2787,
      "score": 108,
      "reward": -958.0,
      "steps": 42,
      "mean_loss": 2941.950345448085,
      "epsilon": 0.36400700000363856
    },
    {
      "episode": 2788,
      "score": 125,
      "reward": -937.0,
      "steps": 41,
      "mean_loss": 5795.336479466136,
      "epsilon": 0.36396600000363966
    },
    {
      "episode": 2789,
      "score": 165,
      "reward": -928.0,
      "steps": 53,
      "mean_loss": 2607.897797494564,
      "epsilon": 0.3639130000036411
    },
    {
      "episode": 2790,
      "score": 156,
      "reward": -914.0,
      "steps": 51,
      "mean_loss": 2737.1596507652134,
      "epsilon": 0.36386200000364244
    },
    {
      "episode": 2791,
      "score": 151,
      "reward": -911.0,
      "steps": 47,
      "mean_loss": 4146.418772474249,
      "epsilon": 0.3638150000036437
    },
    {
      "episode": 2792,
      "score": 97,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 5383.62186122585,
      "epsilon": 0.3637780000036447
    },
    {
      "episode": 2793,
      "score": 109,
      "reward": -957.0,
      "steps": 37,
      "mean_loss": 4296.9499708639605,
      "epsilon": 0.3637410000036457
    },
    {
      "episode": 2794,
      "score": 196,
      "reward": -889.0,
      "steps": 55,
      "mean_loss": 3427.15961005471,
      "epsilon": 0.36368600000364715
    },
    {
      "episode": 2795,
      "score": 65,
      "reward": -980.0,
      "steps": 31,
      "mean_loss": 2511.1567030875913,
      "epsilon": 0.363655000003648
    },
    {
      "episode": 2796,
      "score": 110,
      "reward": -946.0,
      "steps": 39,
      "mean_loss": 5440.0593674488555,
      "epsilon": 0.363616000003649
    },
    {
      "episode": 2797,
      "score": 100,
      "reward": -955.0,
      "steps": 35,
      "mean_loss": 3860.806745801653,
      "epsilon": 0.36358100000364996
    },
    {
      "episode": 2798,
      "score": 270,
      "reward": -824.0,
      "steps": 63,
      "mean_loss": 2448.065316760351,
      "epsilon": 0.36351800000365164
    },
    {
      "episode": 2799,
      "score": 139,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 964.3992287179698,
      "epsilon": 0.3634720000036529
    },
    {
      "episode": 2800,
      "score": 149,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 6199.972561369551,
      "epsilon": 0.36342500000365413
    },
    {
      "episode": 2801,
      "score": 195,
      "reward": -887.0,
      "steps": 53,
      "mean_loss": 3687.4435556519707,
      "epsilon": 0.36337200000365555
    },
    {
      "episode": 2802,
      "score": 70,
      "reward": -984.0,
      "steps": 34,
      "mean_loss": 1963.5642727683571,
      "epsilon": 0.36333800000365646
    },
    {
      "episode": 2803,
      "score": 152,
      "reward": -922.0,
      "steps": 49,
      "mean_loss": 4219.103867277807,
      "epsilon": 0.36328900000365777
    },
    {
      "episode": 2804,
      "score": 176,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 2636.949062983195,
      "epsilon": 0.36323800000365913
    },
    {
      "episode": 2805,
      "score": 189,
      "reward": -890.0,
      "steps": 54,
      "mean_loss": 1654.8168755284062,
      "epsilon": 0.3631840000036606
    },
    {
      "episode": 2806,
      "score": 180,
      "reward": -896.0,
      "steps": 50,
      "mean_loss": 2399.061273727417,
      "epsilon": 0.3631340000036619
    },
    {
      "episode": 2807,
      "score": 194,
      "reward": -892.0,
      "steps": 56,
      "mean_loss": 3910.036262239729,
      "epsilon": 0.3630780000036634
    },
    {
      "episode": 2808,
      "score": 144,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 4466.674650275189,
      "epsilon": 0.36303200000366465
    },
    {
      "episode": 2809,
      "score": 270,
      "reward": -849.0,
      "steps": 68,
      "mean_loss": 5935.033497305478,
      "epsilon": 0.36296400000366646
    },
    {
      "episode": 2810,
      "score": 232,
      "reward": -860.0,
      "steps": 59,
      "mean_loss": 3815.3126702712752,
      "epsilon": 0.36290500000366804
    },
    {
      "episode": 2811,
      "score": 153,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 4310.132937908173,
      "epsilon": 0.3628570000036693
    },
    {
      "episode": 2812,
      "score": 304,
      "reward": -814.0,
      "steps": 70,
      "mean_loss": 3530.5750707353864,
      "epsilon": 0.3627870000036712
    },
    {
      "episode": 2813,
      "score": 124,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 5716.168871010675,
      "epsilon": 0.3627420000036724
    },
    {
      "episode": 2814,
      "score": 159,
      "reward": -899.0,
      "steps": 46,
      "mean_loss": 3075.85714613873,
      "epsilon": 0.36269600000367364
    },
    {
      "episode": 2815,
      "score": 107,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 2199.355305975134,
      "epsilon": 0.3626520000036748
    },
    {
      "episode": 2816,
      "score": 147,
      "reward": -935.0,
      "steps": 49,
      "mean_loss": 3398.2941882853606,
      "epsilon": 0.3626030000036761
    },
    {
      "episode": 2817,
      "score": 120,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 4438.679161889212,
      "epsilon": 0.36256100000367725
    },
    {
      "episode": 2818,
      "score": 178,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 3644.3388687647307,
      "epsilon": 0.36250900000367864
    },
    {
      "episode": 2819,
      "score": 177,
      "reward": -916.0,
      "steps": 55,
      "mean_loss": 4584.040524812178,
      "epsilon": 0.3624540000036801
    },
    {
      "episode": 2820,
      "score": 152,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 2331.012473678589,
      "epsilon": 0.36240400000368145
    },
    {
      "episode": 2821,
      "score": 158,
      "reward": -930.0,
      "steps": 51,
      "mean_loss": 4814.708428326775,
      "epsilon": 0.3623530000036828
    },
    {
      "episode": 2822,
      "score": 90,
      "reward": -966.0,
      "steps": 34,
      "mean_loss": 5011.448450088501,
      "epsilon": 0.3623190000036837
    },
    {
      "episode": 2823,
      "score": 156,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 3176.980071826857,
      "epsilon": 0.36227000000368503
    },
    {
      "episode": 2824,
      "score": 200,
      "reward": -894.0,
      "steps": 54,
      "mean_loss": 4799.1056520673965,
      "epsilon": 0.3622160000036865
    },
    {
      "episode": 2825,
      "score": 151,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 4153.771138872419,
      "epsilon": 0.3621670000036878
    },
    {
      "episode": 2826,
      "score": 148,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 3867.485054178441,
      "epsilon": 0.36212000000368905
    },
    {
      "episode": 2827,
      "score": 124,
      "reward": -936.0,
      "steps": 38,
      "mean_loss": 2944.798889561703,
      "epsilon": 0.36208200000369006
    },
    {
      "episode": 2828,
      "score": 166,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 2456.217915904765,
      "epsilon": 0.3620330000036914
    },
    {
      "episode": 2829,
      "score": 96,
      "reward": -982.0,
      "steps": 41,
      "mean_loss": 3653.3051090705685,
      "epsilon": 0.36199200000369247
    },
    {
      "episode": 2830,
      "score": 105,
      "reward": -967.0,
      "steps": 39,
      "mean_loss": 1600.7795235071426,
      "epsilon": 0.3619530000036935
    },
    {
      "episode": 2831,
      "score": 182,
      "reward": -895.0,
      "steps": 51,
      "mean_loss": 2543.063528098312,
      "epsilon": 0.3619020000036949
    },
    {
      "episode": 2832,
      "score": 125,
      "reward": -947.0,
      "steps": 42,
      "mean_loss": 3342.152288709368,
      "epsilon": 0.361860000003696
    },
    {
      "episode": 2833,
      "score": 91,
      "reward": -974.0,
      "steps": 39,
      "mean_loss": 1924.6011881706042,
      "epsilon": 0.36182100000369705
    },
    {
      "episode": 2834,
      "score": 77,
      "reward": -999.0,
      "steps": 40,
      "mean_loss": 3214.588163471222,
      "epsilon": 0.3617810000036981
    },
    {
      "episode": 2835,
      "score": 97,
      "reward": -968.0,
      "steps": 35,
      "mean_loss": 3245.1721814836774,
      "epsilon": 0.36174600000369905
    },
    {
      "episode": 2836,
      "score": 208,
      "reward": -874.0,
      "steps": 57,
      "mean_loss": 3805.4369231776186,
      "epsilon": 0.3616890000037006
    },
    {
      "episode": 2837,
      "score": 145,
      "reward": -923.0,
      "steps": 44,
      "mean_loss": 3250.6326983191752,
      "epsilon": 0.36164500000370176
    },
    {
      "episode": 2838,
      "score": 176,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 4337.246192614238,
      "epsilon": 0.3615910000037032
    },
    {
      "episode": 2839,
      "score": 127,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 3746.1041462638163,
      "epsilon": 0.3615470000037044
    },
    {
      "episode": 2840,
      "score": 119,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 2734.5196737809615,
      "epsilon": 0.36150300000370555
    },
    {
      "episode": 2841,
      "score": 227,
      "reward": -867.0,
      "steps": 57,
      "mean_loss": 4264.125496077956,
      "epsilon": 0.3614460000037071
    },
    {
      "episode": 2842,
      "score": 163,
      "reward": -930.0,
      "steps": 51,
      "mean_loss": 3271.548355476529,
      "epsilon": 0.36139500000370844
    },
    {
      "episode": 2843,
      "score": 212,
      "reward": -882.0,
      "steps": 56,
      "mean_loss": 4308.278346538544,
      "epsilon": 0.36133900000370994
    },
    {
      "episode": 2844,
      "score": 231,
      "reward": -858.0,
      "steps": 59,
      "mean_loss": 4799.986220214327,
      "epsilon": 0.3612800000037115
    },
    {
      "episode": 2845,
      "score": 121,
      "reward": -938.0,
      "steps": 39,
      "mean_loss": 3100.441471295479,
      "epsilon": 0.36124100000371256
    },
    {
      "episode": 2846,
      "score": 154,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4043.973974033278,
      "epsilon": 0.3611920000037139
    },
    {
      "episode": 2847,
      "score": 160,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 1558.324440876643,
      "epsilon": 0.36114400000371516
    },
    {
      "episode": 2848,
      "score": 166,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 5404.736179618835,
      "epsilon": 0.3610940000037165
    },
    {
      "episode": 2849,
      "score": 210,
      "reward": -878.0,
      "steps": 58,
      "mean_loss": 4003.715955602712,
      "epsilon": 0.36103600000371805
    },
    {
      "episode": 2850,
      "score": 71,
      "reward": -989.0,
      "steps": 32,
      "mean_loss": 2337.5092630386353,
      "epsilon": 0.3610040000037189
    },
    {
      "episode": 2851,
      "score": 228,
      "reward": -887.0,
      "steps": 57,
      "mean_loss": 4066.6045362238297,
      "epsilon": 0.36094700000372043
    },
    {
      "episode": 2852,
      "score": 111,
      "reward": -969.0,
      "steps": 43,
      "mean_loss": 3528.623048383136,
      "epsilon": 0.3609040000037216
    },
    {
      "episode": 2853,
      "score": 132,
      "reward": -945.0,
      "steps": 45,
      "mean_loss": 3116.985725063748,
      "epsilon": 0.3608590000037228
    },
    {
      "episode": 2854,
      "score": 92,
      "reward": -965.0,
      "steps": 38,
      "mean_loss": 3116.2345111244604,
      "epsilon": 0.3608210000037238
    },
    {
      "episode": 2855,
      "score": 235,
      "reward": -870.0,
      "steps": 62,
      "mean_loss": 4041.575584657731,
      "epsilon": 0.36075900000372546
    },
    {
      "episode": 2856,
      "score": 166,
      "reward": -902.0,
      "steps": 48,
      "mean_loss": 2168.0781308809915,
      "epsilon": 0.36071100000372674
    },
    {
      "episode": 2857,
      "score": 145,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3882.564449634958,
      "epsilon": 0.360664000003728
    },
    {
      "episode": 2858,
      "score": 162,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 3337.9296628914626,
      "epsilon": 0.36061300000372937
    },
    {
      "episode": 2859,
      "score": 109,
      "reward": -960.0,
      "steps": 43,
      "mean_loss": 3407.372820477153,
      "epsilon": 0.3605700000037305
    },
    {
      "episode": 2860,
      "score": 160,
      "reward": -919.0,
      "steps": 49,
      "mean_loss": 3390.019877219687,
      "epsilon": 0.36052100000373183
    },
    {
      "episode": 2861,
      "score": 106,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 3218.207565654408,
      "epsilon": 0.360477000003733
    },
    {
      "episode": 2862,
      "score": 109,
      "reward": -959.0,
      "steps": 42,
      "mean_loss": 2728.6490495772587,
      "epsilon": 0.36043500000373413
    },
    {
      "episode": 2863,
      "score": 102,
      "reward": -956.0,
      "steps": 35,
      "mean_loss": 1576.9139820643834,
      "epsilon": 0.36040000000373507
    },
    {
      "episode": 2864,
      "score": 105,
      "reward": -955.0,
      "steps": 35,
      "mean_loss": 2554.8507731846403,
      "epsilon": 0.360365000003736
    },
    {
      "episode": 2865,
      "score": 150,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 4149.947613449097,
      "epsilon": 0.36031500000373734
    },
    {
      "episode": 2866,
      "score": 237,
      "reward": -865.0,
      "steps": 62,
      "mean_loss": 2754.624087179861,
      "epsilon": 0.360253000003739
    },
    {
      "episode": 2867,
      "score": 85,
      "reward": -984.0,
      "steps": 38,
      "mean_loss": 3069.5569638704,
      "epsilon": 0.36021500000374
    },
    {
      "episode": 2868,
      "score": 81,
      "reward": -981.0,
      "steps": 37,
      "mean_loss": 4917.084518948117,
      "epsilon": 0.360178000003741
    },
    {
      "episode": 2869,
      "score": 113,
      "reward": -958.0,
      "steps": 43,
      "mean_loss": 3117.0776030961856,
      "epsilon": 0.36013500000374216
    },
    {
      "episode": 2870,
      "score": 181,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 3172.242786931057,
      "epsilon": 0.3600840000037435
    },
    {
      "episode": 2871,
      "score": 195,
      "reward": -889.0,
      "steps": 54,
      "mean_loss": 3917.819477010656,
      "epsilon": 0.36003000000374497
    },
    {
      "episode": 2872,
      "score": 201,
      "reward": -893.0,
      "steps": 56,
      "mean_loss": 3799.818431990487,
      "epsilon": 0.35997400000374646
    },
    {
      "episode": 2873,
      "score": 121,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3367.175181648948,
      "epsilon": 0.35993000000374764
    },
    {
      "episode": 2874,
      "score": 192,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 3065.515670635082,
      "epsilon": 0.3598760000037491
    },
    {
      "episode": 2875,
      "score": 162,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 3137.691300372688,
      "epsilon": 0.3598270000037504
    },
    {
      "episode": 2876,
      "score": 134,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 2442.5750127633414,
      "epsilon": 0.3597790000037517
    },
    {
      "episode": 2877,
      "score": 167,
      "reward": -902.0,
      "steps": 48,
      "mean_loss": 2560.534685174624,
      "epsilon": 0.35973100000375297
    },
    {
      "episode": 2878,
      "score": 122,
      "reward": -952.0,
      "steps": 42,
      "mean_loss": 4358.083424068633,
      "epsilon": 0.3596890000037541
    },
    {
      "episode": 2879,
      "score": 72,
      "reward": -999.0,
      "steps": 37,
      "mean_loss": 2985.0680562612174,
      "epsilon": 0.3596520000037551
    },
    {
      "episode": 2880,
      "score": 220,
      "reward": -871.0,
      "steps": 58,
      "mean_loss": 1853.8707964338105,
      "epsilon": 0.35959400000375663
    },
    {
      "episode": 2881,
      "score": 216,
      "reward": -867.0,
      "steps": 55,
      "mean_loss": 3039.669460851496,
      "epsilon": 0.3595390000037581
    },
    {
      "episode": 2882,
      "score": 82,
      "reward": -978.0,
      "steps": 32,
      "mean_loss": 4899.7027369737625,
      "epsilon": 0.35950700000375896
    },
    {
      "episode": 2883,
      "score": 196,
      "reward": -900.0,
      "steps": 55,
      "mean_loss": 4696.625452076305,
      "epsilon": 0.35945200000376043
    },
    {
      "episode": 2884,
      "score": 102,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 3682.3502227609806,
      "epsilon": 0.3594080000037616
    },
    {
      "episode": 2885,
      "score": 148,
      "reward": -930.0,
      "steps": 45,
      "mean_loss": 3741.275345102946,
      "epsilon": 0.3593630000037628
    },
    {
      "episode": 2886,
      "score": 279,
      "reward": -816.0,
      "steps": 67,
      "mean_loss": 3314.004123431533,
      "epsilon": 0.3592960000037646
    },
    {
      "episode": 2887,
      "score": 117,
      "reward": -954.0,
      "steps": 40,
      "mean_loss": 3866.1210996627806,
      "epsilon": 0.3592560000037657
    },
    {
      "episode": 2888,
      "score": 123,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 2219.889666297219,
      "epsilon": 0.35921200000376685
    },
    {
      "episode": 2889,
      "score": 144,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 3521.295946161798,
      "epsilon": 0.3591650000037681
    },
    {
      "episode": 2890,
      "score": 161,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 4733.665816802979,
      "epsilon": 0.35911500000376945
    },
    {
      "episode": 2891,
      "score": 144,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 3111.5057383598164,
      "epsilon": 0.3590680000037707
    },
    {
      "episode": 2892,
      "score": 162,
      "reward": -905.0,
      "steps": 46,
      "mean_loss": 6628.343332456506,
      "epsilon": 0.35902200000377194
    },
    {
      "episode": 2893,
      "score": 179,
      "reward": -908.0,
      "steps": 54,
      "mean_loss": 3800.040078551681,
      "epsilon": 0.3589680000037734
    },
    {
      "episode": 2894,
      "score": 147,
      "reward": -934.0,
      "steps": 50,
      "mean_loss": 2288.713033905029,
      "epsilon": 0.3589180000037747
    },
    {
      "episode": 2895,
      "score": 185,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 5037.462954788208,
      "epsilon": 0.35886800000377606
    },
    {
      "episode": 2896,
      "score": 157,
      "reward": -918.0,
      "steps": 52,
      "mean_loss": 4530.4925666955805,
      "epsilon": 0.35881600000377745
    },
    {
      "episode": 2897,
      "score": 191,
      "reward": -893.0,
      "steps": 52,
      "mean_loss": 2227.4273925194375,
      "epsilon": 0.35876400000377884
    },
    {
      "episode": 2898,
      "score": 166,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 1596.786401601938,
      "epsilon": 0.35871200000378023
    },
    {
      "episode": 2899,
      "score": 166,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 2419.7571971369725,
      "epsilon": 0.3586610000037816
    },
    {
      "episode": 2900,
      "score": 84,
      "reward": -981.0,
      "steps": 37,
      "mean_loss": 4799.755643277555,
      "epsilon": 0.3586240000037826
    },
    {
      "episode": 2901,
      "score": 235,
      "reward": -868.0,
      "steps": 62,
      "mean_loss": 2752.4305752169703,
      "epsilon": 0.35856200000378424
    },
    {
      "episode": 2902,
      "score": 115,
      "reward": -967.0,
      "steps": 37,
      "mean_loss": 1882.9225704090015,
      "epsilon": 0.35852500000378523
    },
    {
      "episode": 2903,
      "score": 163,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 3796.416428645452,
      "epsilon": 0.3584770000037865
    },
    {
      "episode": 2904,
      "score": 201,
      "reward": -904.0,
      "steps": 57,
      "mean_loss": 3882.4324772483424,
      "epsilon": 0.35842000000378804
    },
    {
      "episode": 2905,
      "score": 191,
      "reward": -895.0,
      "steps": 50,
      "mean_loss": 1539.0018452453614,
      "epsilon": 0.3583700000037894
    },
    {
      "episode": 2906,
      "score": 138,
      "reward": -954.0,
      "steps": 48,
      "mean_loss": 3823.1194603045783,
      "epsilon": 0.35832200000379066
    },
    {
      "episode": 2907,
      "score": 123,
      "reward": -940.0,
      "steps": 37,
      "mean_loss": 2907.5761016639503,
      "epsilon": 0.35828500000379165
    },
    {
      "episode": 2908,
      "score": 120,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 3942.3981104532877,
      "epsilon": 0.35824000000379286
    },
    {
      "episode": 2909,
      "score": 162,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 3408.240320789571,
      "epsilon": 0.35819100000379417
    },
    {
      "episode": 2910,
      "score": 196,
      "reward": -900.0,
      "steps": 55,
      "mean_loss": 4573.907989640669,
      "epsilon": 0.35813600000379564
    },
    {
      "episode": 2911,
      "score": 169,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 4197.17009399414,
      "epsilon": 0.358086000003797
    },
    {
      "episode": 2912,
      "score": 181,
      "reward": -897.0,
      "steps": 52,
      "mean_loss": 2775.472162246704,
      "epsilon": 0.35803400000379837
    },
    {
      "episode": 2913,
      "score": 189,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 4987.747241196809,
      "epsilon": 0.3579800000037998
    },
    {
      "episode": 2914,
      "score": 126,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 1310.7597330729166,
      "epsilon": 0.357935000003801
    },
    {
      "episode": 2915,
      "score": 156,
      "reward": -927.0,
      "steps": 48,
      "mean_loss": 2540.2783432006836,
      "epsilon": 0.3578870000038023
    },
    {
      "episode": 2916,
      "score": 158,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 2575.7708279356666,
      "epsilon": 0.3578380000038036
    },
    {
      "episode": 2917,
      "score": 159,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 3458.6350336277737,
      "epsilon": 0.35779100000380487
    },
    {
      "episode": 2918,
      "score": 157,
      "reward": -918.0,
      "steps": 48,
      "mean_loss": 2622.7833755016327,
      "epsilon": 0.35774300000380616
    },
    {
      "episode": 2919,
      "score": 136,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 3251.9628008578684,
      "epsilon": 0.3576960000038074
    },
    {
      "episode": 2920,
      "score": 140,
      "reward": -932.0,
      "steps": 50,
      "mean_loss": 5075.247885284424,
      "epsilon": 0.35764600000380875
    },
    {
      "episode": 2921,
      "score": 165,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 1972.9198391972757,
      "epsilon": 0.35759700000381006
    },
    {
      "episode": 2922,
      "score": 140,
      "reward": -936.0,
      "steps": 45,
      "mean_loss": 2481.287707010905,
      "epsilon": 0.35755200000381127
    },
    {
      "episode": 2923,
      "score": 134,
      "reward": -942.0,
      "steps": 46,
      "mean_loss": 5740.770179831464,
      "epsilon": 0.3575060000038125
    },
    {
      "episode": 2924,
      "score": 130,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 3648.809108170596,
      "epsilon": 0.3574620000038137
    },
    {
      "episode": 2925,
      "score": 187,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 2758.0696188853335,
      "epsilon": 0.35741000000381506
    },
    {
      "episode": 2926,
      "score": 114,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 2525.4896895235233,
      "epsilon": 0.35736600000381624
    },
    {
      "episode": 2927,
      "score": 155,
      "reward": -906.0,
      "steps": 44,
      "mean_loss": 3864.4562492370605,
      "epsilon": 0.3573220000038174
    },
    {
      "episode": 2928,
      "score": 124,
      "reward": -933.0,
      "steps": 39,
      "mean_loss": 2024.171842917418,
      "epsilon": 0.35728300000381846
    },
    {
      "episode": 2929,
      "score": 126,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 2315.3522550794814,
      "epsilon": 0.35723800000381967
    },
    {
      "episode": 2930,
      "score": 111,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 1975.1723121296275,
      "epsilon": 0.35719400000382084
    },
    {
      "episode": 2931,
      "score": 216,
      "reward": -880.0,
      "steps": 56,
      "mean_loss": 3939.1676604066574,
      "epsilon": 0.35713800000382234
    },
    {
      "episode": 2932,
      "score": 171,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3865.4428132629396,
      "epsilon": 0.3570880000038237
    },
    {
      "episode": 2933,
      "score": 88,
      "reward": -973.0,
      "steps": 36,
      "mean_loss": 1716.7244874106514,
      "epsilon": 0.35705200000382464
    },
    {
      "episode": 2934,
      "score": 139,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 2152.592878381411,
      "epsilon": 0.3570040000038259
    },
    {
      "episode": 2935,
      "score": 187,
      "reward": -904.0,
      "steps": 56,
      "mean_loss": 1464.0957253319878,
      "epsilon": 0.3569480000038274
    },
    {
      "episode": 2936,
      "score": 137,
      "reward": -925.0,
      "steps": 41,
      "mean_loss": 2910.764901882265,
      "epsilon": 0.3569070000038285
    },
    {
      "episode": 2937,
      "score": 216,
      "reward": -889.0,
      "steps": 57,
      "mean_loss": 4021.285208518045,
      "epsilon": 0.35685000000383005
    },
    {
      "episode": 2938,
      "score": 175,
      "reward": -923.0,
      "steps": 52,
      "mean_loss": 1362.8760581383337,
      "epsilon": 0.35679800000383144
    },
    {
      "episode": 2939,
      "score": 145,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3610.772876090192,
      "epsilon": 0.3567510000038327
    },
    {
      "episode": 2940,
      "score": 109,
      "reward": -966.0,
      "steps": 44,
      "mean_loss": 2206.1050388162785,
      "epsilon": 0.3567070000038339
    },
    {
      "episode": 2941,
      "score": 117,
      "reward": -935.0,
      "steps": 39,
      "mean_loss": 2114.1497288239307,
      "epsilon": 0.3566680000038349
    },
    {
      "episode": 2942,
      "score": 156,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 7059.548881920016,
      "epsilon": 0.35661900000383623
    },
    {
      "episode": 2943,
      "score": 123,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 3831.630635348233,
      "epsilon": 0.3565750000038374
    },
    {
      "episode": 2944,
      "score": 138,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 2967.4601615558972,
      "epsilon": 0.3565310000038386
    },
    {
      "episode": 2945,
      "score": 198,
      "reward": -927.0,
      "steps": 53,
      "mean_loss": 1684.868904185745,
      "epsilon": 0.35647800000384
    },
    {
      "episode": 2946,
      "score": 86,
      "reward": -964.0,
      "steps": 33,
      "mean_loss": 2979.961169387355,
      "epsilon": 0.3564450000038409
    },
    {
      "episode": 2947,
      "score": 98,
      "reward": -958.0,
      "steps": 41,
      "mean_loss": 2364.8980612405917,
      "epsilon": 0.356404000003842
    },
    {
      "episode": 2948,
      "score": 149,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 5567.150791898687,
      "epsilon": 0.35635700000384324
    },
    {
      "episode": 2949,
      "score": 108,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 2732.8245714278446,
      "epsilon": 0.35631500000384436
    },
    {
      "episode": 2950,
      "score": 167,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 3261.406089782715,
      "epsilon": 0.3562660000038457
    },
    {
      "episode": 2951,
      "score": 111,
      "reward": -953.0,
      "steps": 43,
      "mean_loss": 2561.3125796207164,
      "epsilon": 0.3562230000038468
    },
    {
      "episode": 2952,
      "score": 170,
      "reward": -924.0,
      "steps": 51,
      "mean_loss": 3685.568073796291,
      "epsilon": 0.3561720000038482
    },
    {
      "episode": 2953,
      "score": 79,
      "reward": -973.0,
      "steps": 34,
      "mean_loss": 3527.3909603567686,
      "epsilon": 0.3561380000038491
    },
    {
      "episode": 2954,
      "score": 179,
      "reward": -887.0,
      "steps": 48,
      "mean_loss": 3046.5320991675057,
      "epsilon": 0.3560900000038504
    },
    {
      "episode": 2955,
      "score": 182,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 1999.5591183082731,
      "epsilon": 0.35603900000385175
    },
    {
      "episode": 2956,
      "score": 155,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 3183.403608093262,
      "epsilon": 0.3559890000038531
    },
    {
      "episode": 2957,
      "score": 138,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 2630.358282725016,
      "epsilon": 0.35594100000385437
    },
    {
      "episode": 2958,
      "score": 187,
      "reward": -888.0,
      "steps": 52,
      "mean_loss": 5341.462948762453,
      "epsilon": 0.35588900000385576
    },
    {
      "episode": 2959,
      "score": 133,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 2835.591468302409,
      "epsilon": 0.35584400000385696
    },
    {
      "episode": 2960,
      "score": 176,
      "reward": -932.0,
      "steps": 53,
      "mean_loss": 3431.3548707782097,
      "epsilon": 0.3557910000038584
    },
    {
      "episode": 2961,
      "score": 128,
      "reward": -935.0,
      "steps": 40,
      "mean_loss": 3975.0041946411134,
      "epsilon": 0.35575100000385945
    },
    {
      "episode": 2962,
      "score": 108,
      "reward": -952.0,
      "steps": 37,
      "mean_loss": 5129.719418603021,
      "epsilon": 0.35571400000386044
    },
    {
      "episode": 2963,
      "score": 131,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 4647.693520255711,
      "epsilon": 0.3556680000038617
    },
    {
      "episode": 2964,
      "score": 149,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 3371.2375067852913,
      "epsilon": 0.35562100000386293
    },
    {
      "episode": 2965,
      "score": 103,
      "reward": -961.0,
      "steps": 38,
      "mean_loss": 3773.5490437557823,
      "epsilon": 0.35558300000386395
    },
    {
      "episode": 2966,
      "score": 125,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 2165.7786360220475,
      "epsilon": 0.3555390000038651
    },
    {
      "episode": 2967,
      "score": 110,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 3836.5122951594267,
      "epsilon": 0.3554950000038663
    },
    {
      "episode": 2968,
      "score": 189,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 3053.7053633089417,
      "epsilon": 0.35544100000386775
    },
    {
      "episode": 2969,
      "score": 151,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 2160.4134304777103,
      "epsilon": 0.355394000003869
    },
    {
      "episode": 2970,
      "score": 193,
      "reward": -878.0,
      "steps": 54,
      "mean_loss": 3284.805967896073,
      "epsilon": 0.35534000000387045
    },
    {
      "episode": 2971,
      "score": 105,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 2894.3504173811093,
      "epsilon": 0.3552970000038716
    },
    {
      "episode": 2972,
      "score": 200,
      "reward": -880.0,
      "steps": 53,
      "mean_loss": 3174.1345773732887,
      "epsilon": 0.355244000003873
    },
    {
      "episode": 2973,
      "score": 122,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 3277.9229522705077,
      "epsilon": 0.3551990000038742
    },
    {
      "episode": 2974,
      "score": 164,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 4872.491512695949,
      "epsilon": 0.3551510000038755
    },
    {
      "episode": 2975,
      "score": 139,
      "reward": -947.0,
      "steps": 48,
      "mean_loss": 1751.6682126522064,
      "epsilon": 0.3551030000038768
    },
    {
      "episode": 2976,
      "score": 217,
      "reward": -866.0,
      "steps": 60,
      "mean_loss": 5573.0118434270225,
      "epsilon": 0.3550430000038784
    },
    {
      "episode": 2977,
      "score": 116,
      "reward": -966.0,
      "steps": 45,
      "mean_loss": 3670.3487935384114,
      "epsilon": 0.3549980000038796
    },
    {
      "episode": 2978,
      "score": 151,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 1862.0312341192493,
      "epsilon": 0.35495200000388083
    },
    {
      "episode": 2979,
      "score": 203,
      "reward": -889.0,
      "steps": 56,
      "mean_loss": 2887.149232183184,
      "epsilon": 0.35489600000388233
    },
    {
      "episode": 2980,
      "score": 123,
      "reward": -928.0,
      "steps": 44,
      "mean_loss": 2226.1169603521175,
      "epsilon": 0.3548520000038835
    },
    {
      "episode": 2981,
      "score": 268,
      "reward": -838.0,
      "steps": 63,
      "mean_loss": 3090.793137928796,
      "epsilon": 0.3547890000038852
    },
    {
      "episode": 2982,
      "score": 189,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 3805.301649489493,
      "epsilon": 0.3547360000038866
    },
    {
      "episode": 2983,
      "score": 254,
      "reward": -848.0,
      "steps": 63,
      "mean_loss": 4475.395591917492,
      "epsilon": 0.3546730000038883
    },
    {
      "episode": 2984,
      "score": 144,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 6219.6204183862565,
      "epsilon": 0.35462600000388955
    },
    {
      "episode": 2985,
      "score": 105,
      "reward": -966.0,
      "steps": 41,
      "mean_loss": 4777.444893813715,
      "epsilon": 0.35458500000389065
    },
    {
      "episode": 2986,
      "score": 95,
      "reward": -963.0,
      "steps": 37,
      "mean_loss": 4942.4065325453475,
      "epsilon": 0.35454800000389164
    },
    {
      "episode": 2987,
      "score": 96,
      "reward": -967.0,
      "steps": 39,
      "mean_loss": 6381.522020584498,
      "epsilon": 0.3545090000038927
    },
    {
      "episode": 2988,
      "score": 240,
      "reward": -863.0,
      "steps": 63,
      "mean_loss": 2695.5305150349936,
      "epsilon": 0.35444600000389437
    },
    {
      "episode": 2989,
      "score": 187,
      "reward": -896.0,
      "steps": 53,
      "mean_loss": 2156.5711642571214,
      "epsilon": 0.3543930000038958
    },
    {
      "episode": 2990,
      "score": 85,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 3405.677545908335,
      "epsilon": 0.3543560000038968
    },
    {
      "episode": 2991,
      "score": 70,
      "reward": -987.0,
      "steps": 34,
      "mean_loss": 1389.511786965763,
      "epsilon": 0.3543220000038977
    },
    {
      "episode": 2992,
      "score": 147,
      "reward": -935.0,
      "steps": 51,
      "mean_loss": 1253.0410960328345,
      "epsilon": 0.35427100000389905
    },
    {
      "episode": 2993,
      "score": 229,
      "reward": -877.0,
      "steps": 57,
      "mean_loss": 2517.2741298340916,
      "epsilon": 0.3542140000039006
    },
    {
      "episode": 2994,
      "score": 229,
      "reward": -866.0,
      "steps": 56,
      "mean_loss": 2535.7324939455307,
      "epsilon": 0.3541580000039021
    },
    {
      "episode": 2995,
      "score": 114,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 3039.3597787510266,
      "epsilon": 0.35411400000390325
    },
    {
      "episode": 2996,
      "score": 184,
      "reward": -889.0,
      "steps": 52,
      "mean_loss": 4203.481917601365,
      "epsilon": 0.35406200000390464
    },
    {
      "episode": 2997,
      "score": 185,
      "reward": -894.0,
      "steps": 50,
      "mean_loss": 2235.563867111206,
      "epsilon": 0.354012000003906
    },
    {
      "episode": 2998,
      "score": 159,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 1582.2412149078991,
      "epsilon": 0.3539630000039073
    },
    {
      "episode": 2999,
      "score": 126,
      "reward": -947.0,
      "steps": 46,
      "mean_loss": 2988.460943304974,
      "epsilon": 0.3539170000039085
    },
    {
      "episode": 3000,
      "score": 77,
      "reward": -982.0,
      "steps": 34,
      "mean_loss": 3540.786587827346,
      "epsilon": 0.35388300000390943
    },
    {
      "episode": 3001,
      "score": 176,
      "reward": -885.0,
      "steps": 46,
      "mean_loss": 4130.6590557927675,
      "epsilon": 0.35383700000391066
    },
    {
      "episode": 3002,
      "score": 148,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 3691.9419610500336,
      "epsilon": 0.35378900000391195
    },
    {
      "episode": 3003,
      "score": 119,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 4123.668682878668,
      "epsilon": 0.3537450000039131
    },
    {
      "episode": 3004,
      "score": 178,
      "reward": -920.0,
      "steps": 54,
      "mean_loss": 1931.986174689399,
      "epsilon": 0.35369100000391457
    },
    {
      "episode": 3005,
      "score": 198,
      "reward": -887.0,
      "steps": 55,
      "mean_loss": 3825.154743645408,
      "epsilon": 0.35363600000391604
    },
    {
      "episode": 3006,
      "score": 281,
      "reward": -834.0,
      "steps": 68,
      "mean_loss": 2733.0883505765128,
      "epsilon": 0.35356800000391786
    },
    {
      "episode": 3007,
      "score": 255,
      "reward": -846.0,
      "steps": 63,
      "mean_loss": 1378.8640804593526,
      "epsilon": 0.35350500000391955
    },
    {
      "episode": 3008,
      "score": 179,
      "reward": -891.0,
      "steps": 52,
      "mean_loss": 3612.71218424577,
      "epsilon": 0.35345300000392094
    },
    {
      "episode": 3009,
      "score": 151,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 5352.55149311922,
      "epsilon": 0.35340400000392225
    },
    {
      "episode": 3010,
      "score": 92,
      "reward": -971.0,
      "steps": 38,
      "mean_loss": 4844.8263356560155,
      "epsilon": 0.35336600000392326
    },
    {
      "episode": 3011,
      "score": 188,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 3621.6360540569954,
      "epsilon": 0.3533130000039247
    },
    {
      "episode": 3012,
      "score": 136,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 3887.0972306271815,
      "epsilon": 0.35326600000392594
    },
    {
      "episode": 3013,
      "score": 180,
      "reward": -899.0,
      "steps": 51,
      "mean_loss": 1951.2321217106837,
      "epsilon": 0.3532150000039273
    },
    {
      "episode": 3014,
      "score": 200,
      "reward": -891.0,
      "steps": 55,
      "mean_loss": 3458.880382121693,
      "epsilon": 0.3531600000039288
    },
    {
      "episode": 3015,
      "score": 176,
      "reward": -896.0,
      "steps": 53,
      "mean_loss": 4314.544150946275,
      "epsilon": 0.3531070000039302
    },
    {
      "episode": 3016,
      "score": 131,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 2852.9500500939107,
      "epsilon": 0.35306300000393137
    },
    {
      "episode": 3017,
      "score": 258,
      "reward": -852.0,
      "steps": 63,
      "mean_loss": 4452.945202237084,
      "epsilon": 0.35300000000393306
    },
    {
      "episode": 3018,
      "score": 128,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 3080.797769018944,
      "epsilon": 0.3529530000039343
    },
    {
      "episode": 3019,
      "score": 117,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3467.283360481262,
      "epsilon": 0.3529090000039355
    },
    {
      "episode": 3020,
      "score": 74,
      "reward": -988.0,
      "steps": 37,
      "mean_loss": 2901.5341793782004,
      "epsilon": 0.3528720000039365
    },
    {
      "episode": 3021,
      "score": 214,
      "reward": -881.0,
      "steps": 57,
      "mean_loss": 3362.3120504011185,
      "epsilon": 0.352815000003938
    },
    {
      "episode": 3022,
      "score": 165,
      "reward": -910.0,
      "steps": 48,
      "mean_loss": 3026.193969408671,
      "epsilon": 0.3527670000039393
    },
    {
      "episode": 3023,
      "score": 101,
      "reward": -965.0,
      "steps": 37,
      "mean_loss": 2281.8841497060416,
      "epsilon": 0.3527300000039403
    },
    {
      "episode": 3024,
      "score": 223,
      "reward": -883.0,
      "steps": 61,
      "mean_loss": 4028.415285360618,
      "epsilon": 0.3526690000039419
    },
    {
      "episode": 3025,
      "score": 245,
      "reward": -845.0,
      "steps": 59,
      "mean_loss": 4552.43017720368,
      "epsilon": 0.3526100000039435
    },
    {
      "episode": 3026,
      "score": 157,
      "reward": -912.0,
      "steps": 47,
      "mean_loss": 2176.76015082826,
      "epsilon": 0.35256300000394475
    },
    {
      "episode": 3027,
      "score": 154,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 3100.47701312126,
      "epsilon": 0.352516000003946
    },
    {
      "episode": 3028,
      "score": 153,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 4197.409509036006,
      "epsilon": 0.3524670000039473
    },
    {
      "episode": 3029,
      "score": 211,
      "reward": -880.0,
      "steps": 57,
      "mean_loss": 2859.2361697983324,
      "epsilon": 0.35241000000394884
    },
    {
      "episode": 3030,
      "score": 61,
      "reward": -995.0,
      "steps": 31,
      "mean_loss": 1643.462865521831,
      "epsilon": 0.35237900000394967
    },
    {
      "episode": 3031,
      "score": 187,
      "reward": -881.0,
      "steps": 51,
      "mean_loss": 3830.6698585959043,
      "epsilon": 0.35232800000395104
    },
    {
      "episode": 3032,
      "score": 166,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 4139.131470115817,
      "epsilon": 0.35227900000395235
    },
    {
      "episode": 3033,
      "score": 126,
      "reward": -932.0,
      "steps": 41,
      "mean_loss": 4533.021898688339,
      "epsilon": 0.35223800000395344
    },
    {
      "episode": 3034,
      "score": 85,
      "reward": -984.0,
      "steps": 36,
      "mean_loss": 3190.929920196533,
      "epsilon": 0.3522020000039544
    },
    {
      "episode": 3035,
      "score": 182,
      "reward": -898.0,
      "steps": 52,
      "mean_loss": 3190.1132169136636,
      "epsilon": 0.3521500000039558
    },
    {
      "episode": 3036,
      "score": 122,
      "reward": -976.0,
      "steps": 46,
      "mean_loss": 5007.879668526028,
      "epsilon": 0.35210400000395703
    },
    {
      "episode": 3037,
      "score": 116,
      "reward": -957.0,
      "steps": 42,
      "mean_loss": 4726.583440689814,
      "epsilon": 0.35206200000395815
    },
    {
      "episode": 3038,
      "score": 155,
      "reward": -916.0,
      "steps": 48,
      "mean_loss": 2892.80096411705,
      "epsilon": 0.35201400000395944
    },
    {
      "episode": 3039,
      "score": 122,
      "reward": -958.0,
      "steps": 45,
      "mean_loss": 3194.6343646579317,
      "epsilon": 0.35196900000396064
    },
    {
      "episode": 3040,
      "score": 177,
      "reward": -914.0,
      "steps": 56,
      "mean_loss": 3068.9350684370315,
      "epsilon": 0.35191300000396214
    },
    {
      "episode": 3041,
      "score": 122,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 2272.5709900551656,
      "epsilon": 0.3518660000039634
    },
    {
      "episode": 3042,
      "score": 177,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 5032.912823028564,
      "epsilon": 0.35181600000396474
    },
    {
      "episode": 3043,
      "score": 152,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 3123.806980701203,
      "epsilon": 0.351769000003966
    },
    {
      "episode": 3044,
      "score": 125,
      "reward": -939.0,
      "steps": 36,
      "mean_loss": 3458.6112268235947,
      "epsilon": 0.35173300000396696
    },
    {
      "episode": 3045,
      "score": 104,
      "reward": -972.0,
      "steps": 43,
      "mean_loss": 2379.391840823861,
      "epsilon": 0.3516900000039681
    },
    {
      "episode": 3046,
      "score": 162,
      "reward": -913.0,
      "steps": 49,
      "mean_loss": 3887.9757629705937,
      "epsilon": 0.3516410000039694
    },
    {
      "episode": 3047,
      "score": 274,
      "reward": -828.0,
      "steps": 68,
      "mean_loss": 2029.3428037587335,
      "epsilon": 0.35157300000397124
    },
    {
      "episode": 3048,
      "score": 133,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 2131.6779620393795,
      "epsilon": 0.3515260000039725
    },
    {
      "episode": 3049,
      "score": 268,
      "reward": -842.0,
      "steps": 66,
      "mean_loss": 3469.029289534598,
      "epsilon": 0.35146000000397426
    },
    {
      "episode": 3050,
      "score": 238,
      "reward": -882.0,
      "steps": 56,
      "mean_loss": 4896.370445387704,
      "epsilon": 0.35140400000397576
    },
    {
      "episode": 3051,
      "score": 144,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 4878.0686233693905,
      "epsilon": 0.35136000000397694
    },
    {
      "episode": 3052,
      "score": 237,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 3632.1039586652787,
      "epsilon": 0.35130300000397846
    },
    {
      "episode": 3053,
      "score": 132,
      "reward": -930.0,
      "steps": 44,
      "mean_loss": 4029.6589090173893,
      "epsilon": 0.35125900000397964
    },
    {
      "episode": 3054,
      "score": 268,
      "reward": -828.0,
      "steps": 67,
      "mean_loss": 4119.704298788042,
      "epsilon": 0.35119200000398143
    },
    {
      "episode": 3055,
      "score": 198,
      "reward": -881.0,
      "steps": 54,
      "mean_loss": 3530.5442044999863,
      "epsilon": 0.3511380000039829
    },
    {
      "episode": 3056,
      "score": 111,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 4823.709664798918,
      "epsilon": 0.351096000003984
    },
    {
      "episode": 3057,
      "score": 75,
      "reward": -961.0,
      "steps": 30,
      "mean_loss": 2773.6573475519817,
      "epsilon": 0.3510660000039848
    },
    {
      "episode": 3058,
      "score": 156,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 2816.5845074653625,
      "epsilon": 0.3510180000039861
    },
    {
      "episode": 3059,
      "score": 234,
      "reward": -868.0,
      "steps": 60,
      "mean_loss": 4054.078861109416,
      "epsilon": 0.3509580000039877
    },
    {
      "episode": 3060,
      "score": 224,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 3388.511590723406,
      "epsilon": 0.3509010000039892
    },
    {
      "episode": 3061,
      "score": 219,
      "reward": -865.0,
      "steps": 56,
      "mean_loss": 5930.936392034803,
      "epsilon": 0.3508450000039907
    },
    {
      "episode": 3062,
      "score": 184,
      "reward": -901.0,
      "steps": 54,
      "mean_loss": 3300.588760305334,
      "epsilon": 0.35079100000399216
    },
    {
      "episode": 3063,
      "score": 125,
      "reward": -957.0,
      "steps": 46,
      "mean_loss": 3714.021771389505,
      "epsilon": 0.3507450000039934
    },
    {
      "episode": 3064,
      "score": 109,
      "reward": -951.0,
      "steps": 39,
      "mean_loss": 3779.075838431334,
      "epsilon": 0.35070600000399443
    },
    {
      "episode": 3065,
      "score": 128,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 3005.6116358150134,
      "epsilon": 0.3506620000039956
    },
    {
      "episode": 3066,
      "score": 219,
      "reward": -859.0,
      "steps": 51,
      "mean_loss": 5051.228692447438,
      "epsilon": 0.350611000003997
    },
    {
      "episode": 3067,
      "score": 237,
      "reward": -850.0,
      "steps": 62,
      "mean_loss": 3978.632168646782,
      "epsilon": 0.35054900000399863
    },
    {
      "episode": 3068,
      "score": 155,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 3256.141717125388,
      "epsilon": 0.350498000004
    },
    {
      "episode": 3069,
      "score": 156,
      "reward": -926.0,
      "steps": 46,
      "mean_loss": 3873.7707677509475,
      "epsilon": 0.35045200000400123
    },
    {
      "episode": 3070,
      "score": 173,
      "reward": -902.0,
      "steps": 53,
      "mean_loss": 2961.0439774855126,
      "epsilon": 0.35039900000400265
    },
    {
      "episode": 3071,
      "score": 145,
      "reward": -936.0,
      "steps": 50,
      "mean_loss": 3444.013295516968,
      "epsilon": 0.350349000004004
    },
    {
      "episode": 3072,
      "score": 101,
      "reward": -974.0,
      "steps": 43,
      "mean_loss": 3695.6501244833303,
      "epsilon": 0.35030600000400514
    },
    {
      "episode": 3073,
      "score": 157,
      "reward": -921.0,
      "steps": 46,
      "mean_loss": 3528.9971204011335,
      "epsilon": 0.35026000000400637
    },
    {
      "episode": 3074,
      "score": 139,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 6497.648341539171,
      "epsilon": 0.35021500000400757
    },
    {
      "episode": 3075,
      "score": 124,
      "reward": -929.0,
      "steps": 37,
      "mean_loss": 3798.012219815641,
      "epsilon": 0.35017800000400856
    },
    {
      "episode": 3076,
      "score": 177,
      "reward": -898.0,
      "steps": 51,
      "mean_loss": 3578.863208022772,
      "epsilon": 0.3501270000040099
    },
    {
      "episode": 3077,
      "score": 134,
      "reward": -920.0,
      "steps": 44,
      "mean_loss": 4331.779450069775,
      "epsilon": 0.3500830000040111
    },
    {
      "episode": 3078,
      "score": 228,
      "reward": -864.0,
      "steps": 56,
      "mean_loss": 2444.5212880883896,
      "epsilon": 0.3500270000040126
    },
    {
      "episode": 3079,
      "score": 127,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 3448.4638026844373,
      "epsilon": 0.3499830000040138
    },
    {
      "episode": 3080,
      "score": 134,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 3371.205272425776,
      "epsilon": 0.349937000004015
    },
    {
      "episode": 3081,
      "score": 129,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 5138.258845329285,
      "epsilon": 0.3498930000040162
    },
    {
      "episode": 3082,
      "score": 143,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 5949.088391677193,
      "epsilon": 0.3498470000040174
    },
    {
      "episode": 3083,
      "score": 234,
      "reward": -866.0,
      "steps": 59,
      "mean_loss": 3806.342388217732,
      "epsilon": 0.349788000004019
    },
    {
      "episode": 3084,
      "score": 104,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 3063.004558910023,
      "epsilon": 0.3497440000040202
    },
    {
      "episode": 3085,
      "score": 119,
      "reward": -955.0,
      "steps": 41,
      "mean_loss": 4227.785351450851,
      "epsilon": 0.34970300000402127
    },
    {
      "episode": 3086,
      "score": 169,
      "reward": -894.0,
      "steps": 52,
      "mean_loss": 2245.399759072524,
      "epsilon": 0.34965100000402266
    },
    {
      "episode": 3087,
      "score": 170,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 4366.299270336444,
      "epsilon": 0.34959900000402405
    },
    {
      "episode": 3088,
      "score": 164,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 3217.189819024534,
      "epsilon": 0.34955000000402536
    },
    {
      "episode": 3089,
      "score": 155,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 3838.235316297743,
      "epsilon": 0.34950500000402657
    },
    {
      "episode": 3090,
      "score": 122,
      "reward": -948.0,
      "steps": 41,
      "mean_loss": 2203.227079158876,
      "epsilon": 0.34946400000402766
    },
    {
      "episode": 3091,
      "score": 161,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 5032.886919937134,
      "epsilon": 0.349414000004029
    },
    {
      "episode": 3092,
      "score": 184,
      "reward": -916.0,
      "steps": 54,
      "mean_loss": 1793.898627669723,
      "epsilon": 0.34936000000403045
    },
    {
      "episode": 3093,
      "score": 121,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 2217.335638999939,
      "epsilon": 0.3493160000040316
    },
    {
      "episode": 3094,
      "score": 232,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 2320.0306070822257,
      "epsilon": 0.34926200000403307
    },
    {
      "episode": 3095,
      "score": 120,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 2629.2297359964123,
      "epsilon": 0.3492160000040343
    },
    {
      "episode": 3096,
      "score": 173,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 2967.4701974575337,
      "epsilon": 0.3491640000040357
    },
    {
      "episode": 3097,
      "score": 130,
      "reward": -963.0,
      "steps": 49,
      "mean_loss": 3115.5069337961627,
      "epsilon": 0.349115000004037
    },
    {
      "episode": 3098,
      "score": 122,
      "reward": -951.0,
      "steps": 45,
      "mean_loss": 2895.2938150193954,
      "epsilon": 0.3490700000040382
    },
    {
      "episode": 3099,
      "score": 156,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 4396.960695495605,
      "epsilon": 0.34902000000403954
    },
    {
      "episode": 3100,
      "score": 155,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 2175.9890892505646,
      "epsilon": 0.3489720000040408
    },
    {
      "episode": 3101,
      "score": 151,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 3832.5434165487486,
      "epsilon": 0.34892300000404214
    },
    {
      "episode": 3102,
      "score": 168,
      "reward": -916.0,
      "steps": 51,
      "mean_loss": 4788.885114445406,
      "epsilon": 0.3488720000040435
    },
    {
      "episode": 3103,
      "score": 126,
      "reward": -938.0,
      "steps": 42,
      "mean_loss": 4376.326844805762,
      "epsilon": 0.3488300000040446
    },
    {
      "episode": 3104,
      "score": 151,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 2989.0186923412566,
      "epsilon": 0.3487830000040459
    },
    {
      "episode": 3105,
      "score": 217,
      "reward": -879.0,
      "steps": 58,
      "mean_loss": 4443.229840114199,
      "epsilon": 0.34872500000404744
    },
    {
      "episode": 3106,
      "score": 160,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 3371.890849833586,
      "epsilon": 0.34867600000404875
    },
    {
      "episode": 3107,
      "score": 110,
      "reward": -968.0,
      "steps": 41,
      "mean_loss": 2460.978732969703,
      "epsilon": 0.34863500000404984
    },
    {
      "episode": 3108,
      "score": 168,
      "reward": -914.0,
      "steps": 51,
      "mean_loss": 5676.752133088953,
      "epsilon": 0.3485840000040512
    },
    {
      "episode": 3109,
      "score": 103,
      "reward": -979.0,
      "steps": 44,
      "mean_loss": 2451.83111112768,
      "epsilon": 0.3485400000040524
    },
    {
      "episode": 3110,
      "score": 260,
      "reward": -840.0,
      "steps": 64,
      "mean_loss": 3176.8705519884825,
      "epsilon": 0.3484760000040541
    },
    {
      "episode": 3111,
      "score": 124,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 3266.310015851801,
      "epsilon": 0.3484320000040553
    },
    {
      "episode": 3112,
      "score": 184,
      "reward": -902.0,
      "steps": 51,
      "mean_loss": 2612.919634800331,
      "epsilon": 0.34838100000405664
    },
    {
      "episode": 3113,
      "score": 138,
      "reward": -938.0,
      "steps": 46,
      "mean_loss": 4512.240813960199,
      "epsilon": 0.34833500000405787
    },
    {
      "episode": 3114,
      "score": 198,
      "reward": -888.0,
      "steps": 53,
      "mean_loss": 3517.631581144513,
      "epsilon": 0.3482820000040593
    },
    {
      "episode": 3115,
      "score": 154,
      "reward": -953.0,
      "steps": 50,
      "mean_loss": 3415.669436340332,
      "epsilon": 0.3482320000040606
    },
    {
      "episode": 3116,
      "score": 147,
      "reward": -936.0,
      "steps": 49,
      "mean_loss": 1768.4687329506387,
      "epsilon": 0.34818300000406194
    },
    {
      "episode": 3117,
      "score": 224,
      "reward": -870.0,
      "steps": 59,
      "mean_loss": 3097.35435608686,
      "epsilon": 0.3481240000040635
    },
    {
      "episode": 3118,
      "score": 109,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 977.3507877349854,
      "epsilon": 0.3480840000040646
    },
    {
      "episode": 3119,
      "score": 267,
      "reward": -838.0,
      "steps": 67,
      "mean_loss": 2358.8289421707836,
      "epsilon": 0.3480170000040664
    },
    {
      "episode": 3120,
      "score": 184,
      "reward": -915.0,
      "steps": 55,
      "mean_loss": 4550.180662814054,
      "epsilon": 0.34796200000406785
    },
    {
      "episode": 3121,
      "score": 291,
      "reward": -861.0,
      "steps": 66,
      "mean_loss": 3409.852572556698,
      "epsilon": 0.3478960000040696
    },
    {
      "episode": 3122,
      "score": 173,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 2046.6247748595017,
      "epsilon": 0.347844000004071
    },
    {
      "episode": 3123,
      "score": 136,
      "reward": -926.0,
      "steps": 46,
      "mean_loss": 4724.325637236885,
      "epsilon": 0.34779800000407224
    },
    {
      "episode": 3124,
      "score": 183,
      "reward": -909.0,
      "steps": 54,
      "mean_loss": 2881.6333112363463,
      "epsilon": 0.3477440000040737
    },
    {
      "episode": 3125,
      "score": 137,
      "reward": -954.0,
      "steps": 50,
      "mean_loss": 4940.826246490478,
      "epsilon": 0.347694000004075
    },
    {
      "episode": 3126,
      "score": 106,
      "reward": -963.0,
      "steps": 40,
      "mean_loss": 2088.34672832489,
      "epsilon": 0.3476540000040761
    },
    {
      "episode": 3127,
      "score": 176,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 5701.629620869954,
      "epsilon": 0.34760300000407746
    },
    {
      "episode": 3128,
      "score": 290,
      "reward": -833.0,
      "steps": 71,
      "mean_loss": 3485.5048191312335,
      "epsilon": 0.34753200000407936
    },
    {
      "episode": 3129,
      "score": 90,
      "reward": -960.0,
      "steps": 34,
      "mean_loss": 4762.051452524522,
      "epsilon": 0.34749800000408027
    },
    {
      "episode": 3130,
      "score": 165,
      "reward": -901.0,
      "steps": 45,
      "mean_loss": 2576.5125161065,
      "epsilon": 0.34745300000408147
    },
    {
      "episode": 3131,
      "score": 98,
      "reward": -968.0,
      "steps": 44,
      "mean_loss": 4852.929803067987,
      "epsilon": 0.34740900000408265
    },
    {
      "episode": 3132,
      "score": 205,
      "reward": -874.0,
      "steps": 55,
      "mean_loss": 3429.735363630815,
      "epsilon": 0.3473540000040841
    },
    {
      "episode": 3133,
      "score": 160,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 4595.737382431031,
      "epsilon": 0.34730400000408546
    },
    {
      "episode": 3134,
      "score": 75,
      "reward": -996.0,
      "steps": 38,
      "mean_loss": 5447.908159306175,
      "epsilon": 0.3472660000040865
    },
    {
      "episode": 3135,
      "score": 115,
      "reward": -938.0,
      "steps": 38,
      "mean_loss": 2104.928999248304,
      "epsilon": 0.3472280000040875
    },
    {
      "episode": 3136,
      "score": 129,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 5644.9546195983885,
      "epsilon": 0.3471830000040887
    },
    {
      "episode": 3137,
      "score": 179,
      "reward": -891.0,
      "steps": 52,
      "mean_loss": 2905.814315209022,
      "epsilon": 0.3471310000040901
    },
    {
      "episode": 3138,
      "score": 80,
      "reward": -985.0,
      "steps": 37,
      "mean_loss": 4541.630582964098,
      "epsilon": 0.3470940000040911
    },
    {
      "episode": 3139,
      "score": 152,
      "reward": -933.0,
      "steps": 48,
      "mean_loss": 2649.2000710169473,
      "epsilon": 0.34704600000409236
    },
    {
      "episode": 3140,
      "score": 128,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 3244.520413796107,
      "epsilon": 0.34699800000409364
    },
    {
      "episode": 3141,
      "score": 143,
      "reward": -928.0,
      "steps": 46,
      "mean_loss": 3528.0424825834193,
      "epsilon": 0.3469520000040949
    },
    {
      "episode": 3142,
      "score": 143,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 5670.259888019968,
      "epsilon": 0.34690500000409613
    },
    {
      "episode": 3143,
      "score": 88,
      "reward": -974.0,
      "steps": 39,
      "mean_loss": 1485.5838031279734,
      "epsilon": 0.3468660000040972
    },
    {
      "episode": 3144,
      "score": 185,
      "reward": -888.0,
      "steps": 48,
      "mean_loss": 3541.716007312139,
      "epsilon": 0.34681800000409846
    },
    {
      "episode": 3145,
      "score": 176,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 2471.3497455215456,
      "epsilon": 0.3467680000040998
    },
    {
      "episode": 3146,
      "score": 160,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 2179.0865603855677,
      "epsilon": 0.3467190000041011
    },
    {
      "episode": 3147,
      "score": 148,
      "reward": -937.0,
      "steps": 50,
      "mean_loss": 4887.509903106689,
      "epsilon": 0.34666900000410245
    },
    {
      "episode": 3148,
      "score": 203,
      "reward": -881.0,
      "steps": 53,
      "mean_loss": 5646.549795906499,
      "epsilon": 0.34661600000410386
    },
    {
      "episode": 3149,
      "score": 131,
      "reward": -942.0,
      "steps": 46,
      "mean_loss": 3948.3708246479864,
      "epsilon": 0.3465700000041051
    },
    {
      "episode": 3150,
      "score": 159,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 2106.639371288066,
      "epsilon": 0.3465210000041064
    },
    {
      "episode": 3151,
      "score": 172,
      "reward": -922.0,
      "steps": 52,
      "mean_loss": 4572.784738540649,
      "epsilon": 0.3464690000041078
    },
    {
      "episode": 3152,
      "score": 173,
      "reward": -903.0,
      "steps": 53,
      "mean_loss": 1784.6732858261971,
      "epsilon": 0.3464160000041092
    },
    {
      "episode": 3153,
      "score": 279,
      "reward": -816.0,
      "steps": 67,
      "mean_loss": 3658.31088809113,
      "epsilon": 0.346349000004111
    },
    {
      "episode": 3154,
      "score": 117,
      "reward": -938.0,
      "steps": 40,
      "mean_loss": 2420.2051001548766,
      "epsilon": 0.3463090000041121
    },
    {
      "episode": 3155,
      "score": 165,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 5154.311250724045,
      "epsilon": 0.34625800000411344
    },
    {
      "episode": 3156,
      "score": 103,
      "reward": -962.0,
      "steps": 37,
      "mean_loss": 6974.717881795523,
      "epsilon": 0.34622100000411443
    },
    {
      "episode": 3157,
      "score": 116,
      "reward": -963.0,
      "steps": 44,
      "mean_loss": 3252.034841797569,
      "epsilon": 0.3461770000041156
    },
    {
      "episode": 3158,
      "score": 97,
      "reward": -982.0,
      "steps": 37,
      "mean_loss": 4839.234140138368,
      "epsilon": 0.3461400000041166
    },
    {
      "episode": 3159,
      "score": 110,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 2429.1983973329716,
      "epsilon": 0.3460960000041178
    },
    {
      "episode": 3160,
      "score": 153,
      "reward": -934.0,
      "steps": 49,
      "mean_loss": 7272.98121043614,
      "epsilon": 0.3460470000041191
    },
    {
      "episode": 3161,
      "score": 145,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 3446.5164624477957,
      "epsilon": 0.34600000000412034
    },
    {
      "episode": 3162,
      "score": 206,
      "reward": -874.0,
      "steps": 56,
      "mean_loss": 2809.51452262061,
      "epsilon": 0.34594400000412184
    },
    {
      "episode": 3163,
      "score": 186,
      "reward": -891.0,
      "steps": 53,
      "mean_loss": 4669.878100701098,
      "epsilon": 0.34589100000412326
    },
    {
      "episode": 3164,
      "score": 110,
      "reward": -950.0,
      "steps": 40,
      "mean_loss": 4469.69520072937,
      "epsilon": 0.34585100000412433
    },
    {
      "episode": 3165,
      "score": 238,
      "reward": -860.0,
      "steps": 59,
      "mean_loss": 1783.2552157579842,
      "epsilon": 0.3457920000041259
    },
    {
      "episode": 3166,
      "score": 175,
      "reward": -924.0,
      "steps": 53,
      "mean_loss": 3241.063267581868,
      "epsilon": 0.34573900000412733
    },
    {
      "episode": 3167,
      "score": 127,
      "reward": -933.0,
      "steps": 41,
      "mean_loss": 3547.295881317883,
      "epsilon": 0.3456980000041284
    },
    {
      "episode": 3168,
      "score": 178,
      "reward": -905.0,
      "steps": 51,
      "mean_loss": 5442.028526605344,
      "epsilon": 0.3456470000041298
    },
    {
      "episode": 3169,
      "score": 111,
      "reward": -962.0,
      "steps": 43,
      "mean_loss": 3401.306942518367,
      "epsilon": 0.34560400000413094
    },
    {
      "episode": 3170,
      "score": 146,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 2608.059525428934,
      "epsilon": 0.3455570000041322
    },
    {
      "episode": 3171,
      "score": 124,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 3526.6235355463896,
      "epsilon": 0.3455130000041334
    },
    {
      "episode": 3172,
      "score": 161,
      "reward": -892.0,
      "steps": 45,
      "mean_loss": 2053.8829412672253,
      "epsilon": 0.3454680000041346
    },
    {
      "episode": 3173,
      "score": 288,
      "reward": -810.0,
      "steps": 64,
      "mean_loss": 3305.480368077755,
      "epsilon": 0.3454040000041363
    },
    {
      "episode": 3174,
      "score": 121,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 3425.0788306322966,
      "epsilon": 0.34536000000413747
    },
    {
      "episode": 3175,
      "score": 194,
      "reward": -885.0,
      "steps": 55,
      "mean_loss": 3073.7570101651277,
      "epsilon": 0.34530500000413894
    },
    {
      "episode": 3176,
      "score": 260,
      "reward": -834.0,
      "steps": 63,
      "mean_loss": 3055.681354219951,
      "epsilon": 0.3452420000041406
    },
    {
      "episode": 3177,
      "score": 165,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 2050.0029582977295,
      "epsilon": 0.34519200000414196
    },
    {
      "episode": 3178,
      "score": 211,
      "reward": -887.0,
      "steps": 56,
      "mean_loss": 4091.265465191432,
      "epsilon": 0.34513600000414346
    },
    {
      "episode": 3179,
      "score": 158,
      "reward": -924.0,
      "steps": 49,
      "mean_loss": 4027.1756111456425,
      "epsilon": 0.3450870000041448
    },
    {
      "episode": 3180,
      "score": 100,
      "reward": -962.0,
      "steps": 36,
      "mean_loss": 2102.51053375668,
      "epsilon": 0.34505100000414574
    },
    {
      "episode": 3181,
      "score": 116,
      "reward": -954.0,
      "steps": 45,
      "mean_loss": 4113.791684977214,
      "epsilon": 0.34500600000414694
    },
    {
      "episode": 3182,
      "score": 223,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 2201.9992223668983,
      "epsilon": 0.3449520000041484
    },
    {
      "episode": 3183,
      "score": 148,
      "reward": -910.0,
      "steps": 46,
      "mean_loss": 2722.248745047528,
      "epsilon": 0.3449060000041496
    },
    {
      "episode": 3184,
      "score": 144,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 2723.2760533650717,
      "epsilon": 0.3448610000041508
    },
    {
      "episode": 3185,
      "score": 123,
      "reward": -941.0,
      "steps": 43,
      "mean_loss": 3103.047753888507,
      "epsilon": 0.34481800000415197
    },
    {
      "episode": 3186,
      "score": 124,
      "reward": -955.0,
      "steps": 43,
      "mean_loss": 3324.1808102629907,
      "epsilon": 0.3447750000041531
    },
    {
      "episode": 3187,
      "score": 139,
      "reward": -943.0,
      "steps": 49,
      "mean_loss": 4048.2303173298737,
      "epsilon": 0.34472600000415443
    },
    {
      "episode": 3188,
      "score": 109,
      "reward": -963.0,
      "steps": 43,
      "mean_loss": 3504.4161059800967,
      "epsilon": 0.3446830000041556
    },
    {
      "episode": 3189,
      "score": 118,
      "reward": -953.0,
      "steps": 47,
      "mean_loss": 2150.3821351883257,
      "epsilon": 0.34463600000415684
    },
    {
      "episode": 3190,
      "score": 134,
      "reward": -943.0,
      "steps": 48,
      "mean_loss": 4635.2964878877,
      "epsilon": 0.3445880000041581
    },
    {
      "episode": 3191,
      "score": 136,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 2002.2340315528538,
      "epsilon": 0.34454200000415935
    },
    {
      "episode": 3192,
      "score": 153,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 2273.375894018944,
      "epsilon": 0.3444950000041606
    },
    {
      "episode": 3193,
      "score": 112,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 3751.990361907265,
      "epsilon": 0.3444510000041618
    },
    {
      "episode": 3194,
      "score": 235,
      "reward": -868.0,
      "steps": 58,
      "mean_loss": 1972.4247633835364,
      "epsilon": 0.34439300000416334
    },
    {
      "episode": 3195,
      "score": 140,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 2643.148476580356,
      "epsilon": 0.3443460000041646
    },
    {
      "episode": 3196,
      "score": 248,
      "reward": -859.0,
      "steps": 64,
      "mean_loss": 3195.046246945858,
      "epsilon": 0.3442820000041663
    },
    {
      "episode": 3197,
      "score": 113,
      "reward": -955.0,
      "steps": 43,
      "mean_loss": 4306.089440811512,
      "epsilon": 0.34423900000416746
    },
    {
      "episode": 3198,
      "score": 125,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 4150.931494366039,
      "epsilon": 0.34419500000416864
    },
    {
      "episode": 3199,
      "score": 154,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 3478.3922727833624,
      "epsilon": 0.34414900000416987
    },
    {
      "episode": 3200,
      "score": 160,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 4322.261729278564,
      "epsilon": 0.3440990000041712
    },
    {
      "episode": 3201,
      "score": 108,
      "reward": -963.0,
      "steps": 41,
      "mean_loss": 3392.8908817012134,
      "epsilon": 0.3440580000041723
    },
    {
      "episode": 3202,
      "score": 106,
      "reward": -955.0,
      "steps": 36,
      "mean_loss": 3660.207130432129,
      "epsilon": 0.34402200000417327
    },
    {
      "episode": 3203,
      "score": 147,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 3706.4454317295804,
      "epsilon": 0.3439750000041745
    },
    {
      "episode": 3204,
      "score": 152,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 1411.2845946502684,
      "epsilon": 0.34392500000417586
    },
    {
      "episode": 3205,
      "score": 175,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 4001.6789599990843,
      "epsilon": 0.3438750000041772
    },
    {
      "episode": 3206,
      "score": 157,
      "reward": -909.0,
      "steps": 45,
      "mean_loss": 5918.976161617703,
      "epsilon": 0.3438300000041784
    },
    {
      "episode": 3207,
      "score": 122,
      "reward": -955.0,
      "steps": 45,
      "mean_loss": 4116.151133728027,
      "epsilon": 0.3437850000041796
    },
    {
      "episode": 3208,
      "score": 173,
      "reward": -906.0,
      "steps": 50,
      "mean_loss": 5275.309091529846,
      "epsilon": 0.34373500000418095
    },
    {
      "episode": 3209,
      "score": 105,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 2523.2708705720447,
      "epsilon": 0.34369300000418207
    },
    {
      "episode": 3210,
      "score": 269,
      "reward": -844.0,
      "steps": 67,
      "mean_loss": 4179.67776136256,
      "epsilon": 0.34362600000418386
    },
    {
      "episode": 3211,
      "score": 134,
      "reward": -925.0,
      "steps": 44,
      "mean_loss": 2818.8516961877995,
      "epsilon": 0.34358200000418504
    },
    {
      "episode": 3212,
      "score": 95,
      "reward": -991.0,
      "steps": 44,
      "mean_loss": 5647.7901377244425,
      "epsilon": 0.3435380000041862
    },
    {
      "episode": 3213,
      "score": 132,
      "reward": -957.0,
      "steps": 48,
      "mean_loss": 4963.845919370651,
      "epsilon": 0.3434900000041875
    },
    {
      "episode": 3214,
      "score": 69,
      "reward": -988.0,
      "steps": 34,
      "mean_loss": 3186.0126635607553,
      "epsilon": 0.3434560000041884
    },
    {
      "episode": 3215,
      "score": 105,
      "reward": -971.0,
      "steps": 44,
      "mean_loss": 3907.259551308372,
      "epsilon": 0.3434120000041896
    },
    {
      "episode": 3216,
      "score": 132,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 3798.0852230389914,
      "epsilon": 0.3433640000041909
    },
    {
      "episode": 3217,
      "score": 118,
      "reward": -939.0,
      "steps": 38,
      "mean_loss": 4075.5022692931325,
      "epsilon": 0.3433260000041919
    },
    {
      "episode": 3218,
      "score": 164,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 3377.726022760919,
      "epsilon": 0.34327900000419315
    },
    {
      "episode": 3219,
      "score": 104,
      "reward": -976.0,
      "steps": 44,
      "mean_loss": 5544.042028513822,
      "epsilon": 0.3432350000041943
    },
    {
      "episode": 3220,
      "score": 147,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 6226.1872152774895,
      "epsilon": 0.3431880000041956
    },
    {
      "episode": 3221,
      "score": 164,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 2961.478411132214,
      "epsilon": 0.34313700000419695
    },
    {
      "episode": 3222,
      "score": 136,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 3085.102272890052,
      "epsilon": 0.34308800000419826
    },
    {
      "episode": 3223,
      "score": 150,
      "reward": -911.0,
      "steps": 47,
      "mean_loss": 2528.2901354647697,
      "epsilon": 0.3430410000041995
    },
    {
      "episode": 3224,
      "score": 175,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 4159.367450567393,
      "epsilon": 0.3429890000042009
    },
    {
      "episode": 3225,
      "score": 181,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 5752.356266163014,
      "epsilon": 0.34293500000420235
    },
    {
      "episode": 3226,
      "score": 119,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 3006.3832149505615,
      "epsilon": 0.34289100000420353
    },
    {
      "episode": 3227,
      "score": 108,
      "reward": -951.0,
      "steps": 39,
      "mean_loss": 6019.661262707833,
      "epsilon": 0.34285200000420457
    },
    {
      "episode": 3228,
      "score": 225,
      "reward": -860.0,
      "steps": 55,
      "mean_loss": 3501.3660063310103,
      "epsilon": 0.34279700000420604
    },
    {
      "episode": 3229,
      "score": 198,
      "reward": -892.0,
      "steps": 54,
      "mean_loss": 4063.765278674938,
      "epsilon": 0.3427430000042075
    },
    {
      "episode": 3230,
      "score": 129,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 6861.915855147622,
      "epsilon": 0.34269900000420866
    },
    {
      "episode": 3231,
      "score": 179,
      "reward": -903.0,
      "steps": 53,
      "mean_loss": 2595.539212784677,
      "epsilon": 0.3426460000042101
    },
    {
      "episode": 3232,
      "score": 187,
      "reward": -894.0,
      "steps": 50,
      "mean_loss": 3640.645499267578,
      "epsilon": 0.3425960000042114
    },
    {
      "episode": 3233,
      "score": 190,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 3971.3050553003945,
      "epsilon": 0.34254200000421287
    },
    {
      "episode": 3234,
      "score": 174,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 4508.466812973023,
      "epsilon": 0.3424920000042142
    },
    {
      "episode": 3235,
      "score": 85,
      "reward": -967.0,
      "steps": 35,
      "mean_loss": 3359.9223003932407,
      "epsilon": 0.34245700000421514
    },
    {
      "episode": 3236,
      "score": 206,
      "reward": -886.0,
      "steps": 57,
      "mean_loss": 3885.669785282068,
      "epsilon": 0.34240000000421666
    },
    {
      "episode": 3237,
      "score": 133,
      "reward": -953.0,
      "steps": 48,
      "mean_loss": 7144.04192050298,
      "epsilon": 0.34235200000421795
    },
    {
      "episode": 3238,
      "score": 165,
      "reward": -922.0,
      "steps": 51,
      "mean_loss": 2066.3829616471835,
      "epsilon": 0.3423010000042193
    },
    {
      "episode": 3239,
      "score": 178,
      "reward": -891.0,
      "steps": 52,
      "mean_loss": 3407.818896807157,
      "epsilon": 0.3422490000042207
    },
    {
      "episode": 3240,
      "score": 212,
      "reward": -889.0,
      "steps": 58,
      "mean_loss": 4317.976071061759,
      "epsilon": 0.34219100000422226
    },
    {
      "episode": 3241,
      "score": 218,
      "reward": -854.0,
      "steps": 55,
      "mean_loss": 4250.231301533092,
      "epsilon": 0.34213600000422373
    },
    {
      "episode": 3242,
      "score": 165,
      "reward": -911.0,
      "steps": 49,
      "mean_loss": 3406.474312140017,
      "epsilon": 0.34208700000422504
    },
    {
      "episode": 3243,
      "score": 184,
      "reward": -907.0,
      "steps": 54,
      "mean_loss": 5794.735482498451,
      "epsilon": 0.3420330000042265
    },
    {
      "episode": 3244,
      "score": 163,
      "reward": -903.0,
      "steps": 47,
      "mean_loss": 5700.149976121618,
      "epsilon": 0.34198600000422774
    },
    {
      "episode": 3245,
      "score": 226,
      "reward": -867.0,
      "steps": 59,
      "mean_loss": 4844.716253603919,
      "epsilon": 0.3419270000042293
    },
    {
      "episode": 3246,
      "score": 138,
      "reward": -923.0,
      "steps": 44,
      "mean_loss": 2935.4884333177047,
      "epsilon": 0.3418830000042305
    },
    {
      "episode": 3247,
      "score": 218,
      "reward": -866.0,
      "steps": 59,
      "mean_loss": 2844.39010277441,
      "epsilon": 0.3418240000042321
    },
    {
      "episode": 3248,
      "score": 127,
      "reward": -962.0,
      "steps": 47,
      "mean_loss": 2143.5623622650796,
      "epsilon": 0.34177700000423333
    },
    {
      "episode": 3249,
      "score": 140,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 4630.157815162172,
      "epsilon": 0.3417300000042346
    },
    {
      "episode": 3250,
      "score": 156,
      "reward": -915.0,
      "steps": 45,
      "mean_loss": 3864.161900414361,
      "epsilon": 0.3416850000042358
    },
    {
      "episode": 3251,
      "score": 27,
      "reward": -997.0,
      "steps": 18,
      "mean_loss": 2890.6543477376304,
      "epsilon": 0.3416670000042363
    },
    {
      "episode": 3252,
      "score": 114,
      "reward": -945.0,
      "steps": 39,
      "mean_loss": 3606.5740935496797,
      "epsilon": 0.3416280000042373
    },
    {
      "episode": 3253,
      "score": 172,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 5628.519216610835,
      "epsilon": 0.3415760000042387
    },
    {
      "episode": 3254,
      "score": 157,
      "reward": -920.0,
      "steps": 47,
      "mean_loss": 3382.220418118416,
      "epsilon": 0.34152900000423997
    },
    {
      "episode": 3255,
      "score": 276,
      "reward": -819.0,
      "steps": 66,
      "mean_loss": 2393.5559392986875,
      "epsilon": 0.34146300000424173
    },
    {
      "episode": 3256,
      "score": 188,
      "reward": -898.0,
      "steps": 53,
      "mean_loss": 2001.587832037008,
      "epsilon": 0.34141000000424315
    },
    {
      "episode": 3257,
      "score": 198,
      "reward": -875.0,
      "steps": 52,
      "mean_loss": 5569.996495613685,
      "epsilon": 0.34135800000424454
    },
    {
      "episode": 3258,
      "score": 276,
      "reward": -833.0,
      "steps": 68,
      "mean_loss": 4143.593638812795,
      "epsilon": 0.34129000000424636
    },
    {
      "episode": 3259,
      "score": 101,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 6226.074469961771,
      "epsilon": 0.34124900000424746
    },
    {
      "episode": 3260,
      "score": 12,
      "reward": -1014.0,
      "steps": 16,
      "mean_loss": 4134.881877183914,
      "epsilon": 0.3412330000042479
    },
    {
      "episode": 3261,
      "score": 227,
      "reward": -871.0,
      "steps": 59,
      "mean_loss": 5378.01935302605,
      "epsilon": 0.34117400000424947
    },
    {
      "episode": 3262,
      "score": 110,
      "reward": -973.0,
      "steps": 46,
      "mean_loss": 2204.9247395059338,
      "epsilon": 0.3411280000042507
    },
    {
      "episode": 3263,
      "score": 131,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 1307.5412266102244,
      "epsilon": 0.34108100000425196
    },
    {
      "episode": 3264,
      "score": 135,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 3212.536895751953,
      "epsilon": 0.3410340000042532
    },
    {
      "episode": 3265,
      "score": 162,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 2939.0314622217297,
      "epsilon": 0.3409850000042545
    },
    {
      "episode": 3266,
      "score": 118,
      "reward": -948.0,
      "steps": 41,
      "mean_loss": 3751.005636075648,
      "epsilon": 0.3409440000042556
    },
    {
      "episode": 3267,
      "score": 89,
      "reward": -970.0,
      "steps": 36,
      "mean_loss": 3010.54380162557,
      "epsilon": 0.3409080000042566
    },
    {
      "episode": 3268,
      "score": 158,
      "reward": -937.0,
      "steps": 46,
      "mean_loss": 3822.119219282399,
      "epsilon": 0.3408620000042578
    },
    {
      "episode": 3269,
      "score": 124,
      "reward": -969.0,
      "steps": 46,
      "mean_loss": 1935.221244480299,
      "epsilon": 0.34081600000425905
    },
    {
      "episode": 3270,
      "score": 116,
      "reward": -940.0,
      "steps": 36,
      "mean_loss": 2927.815501636929,
      "epsilon": 0.34078000000426
    },
    {
      "episode": 3271,
      "score": 302,
      "reward": -813.0,
      "steps": 71,
      "mean_loss": 3825.3277525297353,
      "epsilon": 0.3407090000042619
    },
    {
      "episode": 3272,
      "score": 180,
      "reward": -890.0,
      "steps": 51,
      "mean_loss": 3532.4517606847426,
      "epsilon": 0.3406580000042633
    },
    {
      "episode": 3273,
      "score": 171,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 6822.049562562187,
      "epsilon": 0.3406050000042647
    },
    {
      "episode": 3274,
      "score": 159,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 3764.582665939331,
      "epsilon": 0.34055500000426603
    },
    {
      "episode": 3275,
      "score": 158,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 3863.412435849508,
      "epsilon": 0.3405070000042673
    },
    {
      "episode": 3276,
      "score": 126,
      "reward": -941.0,
      "steps": 41,
      "mean_loss": 3343.795376382223,
      "epsilon": 0.3404660000042684
    },
    {
      "episode": 3277,
      "score": 191,
      "reward": -888.0,
      "steps": 54,
      "mean_loss": 4373.278069390191,
      "epsilon": 0.34041200000426985
    },
    {
      "episode": 3278,
      "score": 131,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 3882.460133639249,
      "epsilon": 0.34036800000427103
    },
    {
      "episode": 3279,
      "score": 179,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 1615.4566659560571,
      "epsilon": 0.3403160000042724
    },
    {
      "episode": 3280,
      "score": 124,
      "reward": -952.0,
      "steps": 42,
      "mean_loss": 4260.775100617182,
      "epsilon": 0.34027400000427355
    },
    {
      "episode": 3281,
      "score": 120,
      "reward": -949.0,
      "steps": 42,
      "mean_loss": 2360.6755752563477,
      "epsilon": 0.34023200000427467
    },
    {
      "episode": 3282,
      "score": 159,
      "reward": -912.0,
      "steps": 47,
      "mean_loss": 3368.6037307495767,
      "epsilon": 0.34018500000427593
    },
    {
      "episode": 3283,
      "score": 207,
      "reward": -887.0,
      "steps": 55,
      "mean_loss": 1636.6316042119806,
      "epsilon": 0.3401300000042774
    },
    {
      "episode": 3284,
      "score": 286,
      "reward": -833.0,
      "steps": 69,
      "mean_loss": 2127.482534657354,
      "epsilon": 0.34006100000427925
    },
    {
      "episode": 3285,
      "score": 97,
      "reward": -980.0,
      "steps": 40,
      "mean_loss": 3301.5040049552917,
      "epsilon": 0.3400210000042803
    },
    {
      "episode": 3286,
      "score": 110,
      "reward": -948.0,
      "steps": 42,
      "mean_loss": 3682.4747355779014,
      "epsilon": 0.33997900000428144
    },
    {
      "episode": 3287,
      "score": 120,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 5255.827269554138,
      "epsilon": 0.3399350000042826
    },
    {
      "episode": 3288,
      "score": 229,
      "reward": -861.0,
      "steps": 58,
      "mean_loss": 2799.911941791403,
      "epsilon": 0.33987700000428417
    },
    {
      "episode": 3289,
      "score": 111,
      "reward": -939.0,
      "steps": 35,
      "mean_loss": 2559.258523123605,
      "epsilon": 0.3398420000042851
    },
    {
      "episode": 3290,
      "score": 145,
      "reward": -946.0,
      "steps": 47,
      "mean_loss": 4468.059169444632,
      "epsilon": 0.33979500000428636
    },
    {
      "episode": 3291,
      "score": 107,
      "reward": -973.0,
      "steps": 45,
      "mean_loss": 2051.5392754448785,
      "epsilon": 0.33975000000428757
    },
    {
      "episode": 3292,
      "score": 159,
      "reward": -899.0,
      "steps": 44,
      "mean_loss": 6101.867912552573,
      "epsilon": 0.33970600000428874
    },
    {
      "episode": 3293,
      "score": 157,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 2945.61119718137,
      "epsilon": 0.33966000000429
    },
    {
      "episode": 3294,
      "score": 149,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 3575.621545363446,
      "epsilon": 0.3396110000042913
    },
    {
      "episode": 3295,
      "score": 154,
      "reward": -942.0,
      "steps": 49,
      "mean_loss": 3644.921606881278,
      "epsilon": 0.3395620000042926
    },
    {
      "episode": 3296,
      "score": 105,
      "reward": -962.0,
      "steps": 41,
      "mean_loss": 4735.341581856333,
      "epsilon": 0.3395210000042937
    },
    {
      "episode": 3297,
      "score": 73,
      "reward": -987.0,
      "steps": 35,
      "mean_loss": 2246.8340769086567,
      "epsilon": 0.33948600000429463
    },
    {
      "episode": 3298,
      "score": 160,
      "reward": -909.0,
      "steps": 48,
      "mean_loss": 2144.803384621938,
      "epsilon": 0.3394380000042959
    },
    {
      "episode": 3299,
      "score": 157,
      "reward": -936.0,
      "steps": 51,
      "mean_loss": 6192.367639616424,
      "epsilon": 0.3393870000042973
    },
    {
      "episode": 3300,
      "score": 159,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 4688.531863937378,
      "epsilon": 0.3393370000042986
    },
    {
      "episode": 3301,
      "score": 151,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 3287.2712634472136,
      "epsilon": 0.3392900000042999
    },
    {
      "episode": 3302,
      "score": 141,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 3924.331875253231,
      "epsilon": 0.33924300000430113
    },
    {
      "episode": 3303,
      "score": 158,
      "reward": -921.0,
      "steps": 48,
      "mean_loss": 2502.2030299901962,
      "epsilon": 0.3391950000043024
    },
    {
      "episode": 3304,
      "score": 127,
      "reward": -931.0,
      "steps": 42,
      "mean_loss": 3458.392153467451,
      "epsilon": 0.33915300000430354
    },
    {
      "episode": 3305,
      "score": 93,
      "reward": -978.0,
      "steps": 36,
      "mean_loss": 765.2851433224148,
      "epsilon": 0.3391170000043045
    },
    {
      "episode": 3306,
      "score": 172,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 5001.1215710359465,
      "epsilon": 0.33906600000430587
    },
    {
      "episode": 3307,
      "score": 142,
      "reward": -949.0,
      "steps": 49,
      "mean_loss": 4573.634291746179,
      "epsilon": 0.3390170000043072
    },
    {
      "episode": 3308,
      "score": 177,
      "reward": -907.0,
      "steps": 51,
      "mean_loss": 3349.1035011141907,
      "epsilon": 0.33896600000430854
    },
    {
      "episode": 3309,
      "score": 55,
      "reward": -1000.0,
      "steps": 32,
      "mean_loss": 4712.436779022217,
      "epsilon": 0.3389340000043094
    },
    {
      "episode": 3310,
      "score": 159,
      "reward": -920.0,
      "steps": 51,
      "mean_loss": 2349.846739320194,
      "epsilon": 0.33888300000431076
    },
    {
      "episode": 3311,
      "score": 207,
      "reward": -901.0,
      "steps": 56,
      "mean_loss": 4716.599784340177,
      "epsilon": 0.33882700000431226
    },
    {
      "episode": 3312,
      "score": 93,
      "reward": -976.0,
      "steps": 42,
      "mean_loss": 6394.143546603975,
      "epsilon": 0.3387850000043134
    },
    {
      "episode": 3313,
      "score": 130,
      "reward": -945.0,
      "steps": 45,
      "mean_loss": 6863.301635318332,
      "epsilon": 0.3387400000043146
    },
    {
      "episode": 3314,
      "score": 235,
      "reward": -869.0,
      "steps": 62,
      "mean_loss": 6103.00269785235,
      "epsilon": 0.33867800000431625
    },
    {
      "episode": 3315,
      "score": 122,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 4425.549770545959,
      "epsilon": 0.3386380000043173
    },
    {
      "episode": 3316,
      "score": 147,
      "reward": -921.0,
      "steps": 46,
      "mean_loss": 3208.7126915973167,
      "epsilon": 0.33859200000431855
    },
    {
      "episode": 3317,
      "score": 176,
      "reward": -899.0,
      "steps": 51,
      "mean_loss": 2381.9421863929897,
      "epsilon": 0.3385410000043199
    },
    {
      "episode": 3318,
      "score": 126,
      "reward": -957.0,
      "steps": 47,
      "mean_loss": 3192.180115720059,
      "epsilon": 0.33849400000432117
    },
    {
      "episode": 3319,
      "score": 112,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 3243.7200812385195,
      "epsilon": 0.3384520000043223
    },
    {
      "episode": 3320,
      "score": 130,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 8055.965943336487,
      "epsilon": 0.3384080000043235
    },
    {
      "episode": 3321,
      "score": 162,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 6653.955032854664,
      "epsilon": 0.3383590000043248
    },
    {
      "episode": 3322,
      "score": 104,
      "reward": -972.0,
      "steps": 42,
      "mean_loss": 4551.269753955659,
      "epsilon": 0.3383170000043259
    },
    {
      "episode": 3323,
      "score": 147,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 3964.5335346221923,
      "epsilon": 0.3382720000043271
    },
    {
      "episode": 3324,
      "score": 118,
      "reward": -937.0,
      "steps": 40,
      "mean_loss": 4459.505035686493,
      "epsilon": 0.3382320000043282
    },
    {
      "episode": 3325,
      "score": 116,
      "reward": -946.0,
      "steps": 41,
      "mean_loss": 4135.136700234762,
      "epsilon": 0.3381910000043293
    },
    {
      "episode": 3326,
      "score": 124,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 2078.288139682346,
      "epsilon": 0.3381460000043305
    },
    {
      "episode": 3327,
      "score": 125,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 1287.1199904547798,
      "epsilon": 0.3381010000043317
    },
    {
      "episode": 3328,
      "score": 209,
      "reward": -879.0,
      "steps": 54,
      "mean_loss": 4183.576006854022,
      "epsilon": 0.33804700000433313
    },
    {
      "episode": 3329,
      "score": 117,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 5741.080155112527,
      "epsilon": 0.3380030000043343
    },
    {
      "episode": 3330,
      "score": 144,
      "reward": -938.0,
      "steps": 51,
      "mean_loss": 2745.5699833888634,
      "epsilon": 0.3379520000043357
    },
    {
      "episode": 3331,
      "score": 107,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 2046.4273720818596,
      "epsilon": 0.33791500000433666
    },
    {
      "episode": 3332,
      "score": 79,
      "reward": -990.0,
      "steps": 39,
      "mean_loss": 3491.918519582504,
      "epsilon": 0.3378760000043377
    },
    {
      "episode": 3333,
      "score": 183,
      "reward": -896.0,
      "steps": 48,
      "mean_loss": 4313.292125066121,
      "epsilon": 0.337828000004339
    },
    {
      "episode": 3334,
      "score": 129,
      "reward": -952.0,
      "steps": 47,
      "mean_loss": 4276.036444806038,
      "epsilon": 0.33778100000434025
    },
    {
      "episode": 3335,
      "score": 129,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 3068.2042629972416,
      "epsilon": 0.3377340000043415
    },
    {
      "episode": 3336,
      "score": 81,
      "reward": -987.0,
      "steps": 37,
      "mean_loss": 4563.258157369253,
      "epsilon": 0.3376970000043425
    },
    {
      "episode": 3337,
      "score": 117,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 3801.5937762693925,
      "epsilon": 0.3376530000043437
    },
    {
      "episode": 3338,
      "score": 200,
      "reward": -888.0,
      "steps": 55,
      "mean_loss": 2947.2285022388805,
      "epsilon": 0.33759800000434514
    },
    {
      "episode": 3339,
      "score": 162,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 7237.856446210076,
      "epsilon": 0.3375470000043465
    },
    {
      "episode": 3340,
      "score": 119,
      "reward": -964.0,
      "steps": 45,
      "mean_loss": 3669.5955491807727,
      "epsilon": 0.3375020000043477
    },
    {
      "episode": 3341,
      "score": 86,
      "reward": -969.0,
      "steps": 35,
      "mean_loss": 2805.3598629542757,
      "epsilon": 0.33746700000434865
    },
    {
      "episode": 3342,
      "score": 176,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 5455.54066335238,
      "epsilon": 0.33741500000435004
    },
    {
      "episode": 3343,
      "score": 156,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 3602.853538831075,
      "epsilon": 0.3373670000043513
    },
    {
      "episode": 3344,
      "score": 102,
      "reward": -953.0,
      "steps": 33,
      "mean_loss": 6141.796862226544,
      "epsilon": 0.3373340000043522
    },
    {
      "episode": 3345,
      "score": 169,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 5460.751915969849,
      "epsilon": 0.33728400000435355
    },
    {
      "episode": 3346,
      "score": 254,
      "reward": -857.0,
      "steps": 65,
      "mean_loss": 3193.336571443998,
      "epsilon": 0.3372190000043553
    },
    {
      "episode": 3347,
      "score": 153,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 3241.052397634469,
      "epsilon": 0.33716800000435665
    },
    {
      "episode": 3348,
      "score": 128,
      "reward": -934.0,
      "steps": 39,
      "mean_loss": 5896.115545566266,
      "epsilon": 0.3371290000043577
    },
    {
      "episode": 3349,
      "score": 115,
      "reward": -951.0,
      "steps": 43,
      "mean_loss": 1200.339565765026,
      "epsilon": 0.33708600000435884
    },
    {
      "episode": 3350,
      "score": 181,
      "reward": -917.0,
      "steps": 54,
      "mean_loss": 5862.012863406429,
      "epsilon": 0.3370320000043603
    },
    {
      "episode": 3351,
      "score": 229,
      "reward": -867.0,
      "steps": 58,
      "mean_loss": 3938.667924946752,
      "epsilon": 0.33697400000436184
    },
    {
      "episode": 3352,
      "score": 110,
      "reward": -942.0,
      "steps": 36,
      "mean_loss": 6230.478303803338,
      "epsilon": 0.3369380000043628
    },
    {
      "episode": 3353,
      "score": 208,
      "reward": -876.0,
      "steps": 55,
      "mean_loss": 4155.716065354781,
      "epsilon": 0.3368830000043643
    },
    {
      "episode": 3354,
      "score": 183,
      "reward": -906.0,
      "steps": 54,
      "mean_loss": 3682.8651358992965,
      "epsilon": 0.3368290000043657
    },
    {
      "episode": 3355,
      "score": 116,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 3748.2619835747614,
      "epsilon": 0.3367840000043669
    },
    {
      "episode": 3356,
      "score": 152,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 3311.292430674776,
      "epsilon": 0.3367370000043682
    },
    {
      "episode": 3357,
      "score": 127,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 4096.44680039779,
      "epsilon": 0.3366910000043694
    },
    {
      "episode": 3358,
      "score": 160,
      "reward": -900.0,
      "steps": 42,
      "mean_loss": 4889.62585408347,
      "epsilon": 0.33664900000437054
    },
    {
      "episode": 3359,
      "score": 106,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 2951.373503251509,
      "epsilon": 0.3366050000043717
    },
    {
      "episode": 3360,
      "score": 137,
      "reward": -931.0,
      "steps": 44,
      "mean_loss": 5095.975944865833,
      "epsilon": 0.3365610000043729
    },
    {
      "episode": 3361,
      "score": 149,
      "reward": -912.0,
      "steps": 46,
      "mean_loss": 4275.002634546031,
      "epsilon": 0.3365150000043741
    },
    {
      "episode": 3362,
      "score": 162,
      "reward": -913.0,
      "steps": 49,
      "mean_loss": 3788.2981424137038,
      "epsilon": 0.33646600000437543
    },
    {
      "episode": 3363,
      "score": 86,
      "reward": -979.0,
      "steps": 37,
      "mean_loss": 2859.4523081392854,
      "epsilon": 0.3364290000043764
    },
    {
      "episode": 3364,
      "score": 97,
      "reward": -967.0,
      "steps": 42,
      "mean_loss": 1773.4603848230272,
      "epsilon": 0.33638700000437755
    },
    {
      "episode": 3365,
      "score": 140,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 3279.7795984795753,
      "epsilon": 0.3363400000043788
    },
    {
      "episode": 3366,
      "score": 161,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 4589.362390556335,
      "epsilon": 0.33629000000438014
    },
    {
      "episode": 3367,
      "score": 214,
      "reward": -857.0,
      "steps": 53,
      "mean_loss": 3382.3276760173294,
      "epsilon": 0.33623700000438156
    },
    {
      "episode": 3368,
      "score": 101,
      "reward": -974.0,
      "steps": 42,
      "mean_loss": 3368.5950362795875,
      "epsilon": 0.3361950000043827
    },
    {
      "episode": 3369,
      "score": 77,
      "reward": -978.0,
      "steps": 34,
      "mean_loss": 2294.3196181129006,
      "epsilon": 0.3361610000043836
    },
    {
      "episode": 3370,
      "score": 167,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 2693.458721235687,
      "epsilon": 0.33611000000438496
    },
    {
      "episode": 3371,
      "score": 119,
      "reward": -958.0,
      "steps": 45,
      "mean_loss": 3203.5612275017634,
      "epsilon": 0.33606500000438616
    },
    {
      "episode": 3372,
      "score": 162,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 3211.989146308899,
      "epsilon": 0.3360150000043875
    },
    {
      "episode": 3373,
      "score": 79,
      "reward": -981.0,
      "steps": 34,
      "mean_loss": 4036.745087230907,
      "epsilon": 0.3359810000043884
    },
    {
      "episode": 3374,
      "score": 265,
      "reward": -836.0,
      "steps": 64,
      "mean_loss": 3023.6675667762756,
      "epsilon": 0.3359170000043901
    },
    {
      "episode": 3375,
      "score": 233,
      "reward": -882.0,
      "steps": 60,
      "mean_loss": 4872.176032320658,
      "epsilon": 0.3358570000043917
    },
    {
      "episode": 3376,
      "score": 134,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 2762.6517380653545,
      "epsilon": 0.335810000004393
    },
    {
      "episode": 3377,
      "score": 182,
      "reward": -893.0,
      "steps": 53,
      "mean_loss": 2191.6515028251793,
      "epsilon": 0.3357570000043944
    },
    {
      "episode": 3378,
      "score": 134,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 2557.3222405043516,
      "epsilon": 0.3357130000043956
    },
    {
      "episode": 3379,
      "score": 139,
      "reward": -929.0,
      "steps": 44,
      "mean_loss": 2257.3744442679667,
      "epsilon": 0.33566900000439676
    },
    {
      "episode": 3380,
      "score": 161,
      "reward": -914.0,
      "steps": 45,
      "mean_loss": 2573.775120968289,
      "epsilon": 0.33562400000439796
    },
    {
      "episode": 3381,
      "score": 142,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 4623.854853651259,
      "epsilon": 0.33557900000439916
    },
    {
      "episode": 3382,
      "score": 175,
      "reward": -908.0,
      "steps": 51,
      "mean_loss": 1555.6719071631337,
      "epsilon": 0.33552800000440053
    },
    {
      "episode": 3383,
      "score": 155,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 3701.1515166473387,
      "epsilon": 0.33547800000440187
    },
    {
      "episode": 3384,
      "score": 140,
      "reward": -926.0,
      "steps": 44,
      "mean_loss": 2643.7603456757283,
      "epsilon": 0.33543400000440304
    },
    {
      "episode": 3385,
      "score": 161,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 3759.9293025334678,
      "epsilon": 0.3353860000044043
    },
    {
      "episode": 3386,
      "score": 164,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 5582.121118288774,
      "epsilon": 0.3353340000044057
    },
    {
      "episode": 3387,
      "score": 22,
      "reward": -998.0,
      "steps": 17,
      "mean_loss": 1249.1882485782398,
      "epsilon": 0.3353170000044062
    },
    {
      "episode": 3388,
      "score": 177,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 3993.930229700529,
      "epsilon": 0.33526500000440757
    },
    {
      "episode": 3389,
      "score": 141,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 3157.5548965778758,
      "epsilon": 0.3352180000044088
    },
    {
      "episode": 3390,
      "score": 213,
      "reward": -882.0,
      "steps": 56,
      "mean_loss": 3318.570632117135,
      "epsilon": 0.3351620000044103
    },
    {
      "episode": 3391,
      "score": 190,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 5118.482629847977,
      "epsilon": 0.33510900000441174
    },
    {
      "episode": 3392,
      "score": 102,
      "reward": -964.0,
      "steps": 42,
      "mean_loss": 4584.443666730608,
      "epsilon": 0.33506700000441286
    },
    {
      "episode": 3393,
      "score": 75,
      "reward": -984.0,
      "steps": 35,
      "mean_loss": 5416.364280809675,
      "epsilon": 0.3350320000044138
    },
    {
      "episode": 3394,
      "score": 58,
      "reward": -1007.0,
      "steps": 34,
      "mean_loss": 3973.8562907050637,
      "epsilon": 0.3349980000044147
    },
    {
      "episode": 3395,
      "score": 61,
      "reward": -1000.0,
      "steps": 34,
      "mean_loss": 1681.0614650950713,
      "epsilon": 0.3349640000044156
    },
    {
      "episode": 3396,
      "score": 128,
      "reward": -932.0,
      "steps": 42,
      "mean_loss": 4120.5484864371165,
      "epsilon": 0.33492200000441674
    },
    {
      "episode": 3397,
      "score": 167,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 3219.8946129294004,
      "epsilon": 0.3348710000044181
    },
    {
      "episode": 3398,
      "score": 100,
      "reward": -975.0,
      "steps": 44,
      "mean_loss": 2742.0860119299455,
      "epsilon": 0.3348270000044193
    },
    {
      "episode": 3399,
      "score": 166,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 3583.7620677214404,
      "epsilon": 0.3347750000044207
    },
    {
      "episode": 3400,
      "score": 79,
      "reward": -994.0,
      "steps": 37,
      "mean_loss": 5144.069790711274,
      "epsilon": 0.33473800000442167
    },
    {
      "episode": 3401,
      "score": 146,
      "reward": -944.0,
      "steps": 47,
      "mean_loss": 2079.133060130667,
      "epsilon": 0.3346910000044229
    },
    {
      "episode": 3402,
      "score": 181,
      "reward": -905.0,
      "steps": 54,
      "mean_loss": 4002.72354917173,
      "epsilon": 0.33463700000442437
    },
    {
      "episode": 3403,
      "score": 141,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 5614.558451875727,
      "epsilon": 0.3345900000044256
    },
    {
      "episode": 3404,
      "score": 151,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 2990.7877412637076,
      "epsilon": 0.3345420000044269
    },
    {
      "episode": 3405,
      "score": 175,
      "reward": -915.0,
      "steps": 53,
      "mean_loss": 2490.964683892592,
      "epsilon": 0.3344890000044283
    },
    {
      "episode": 3406,
      "score": 175,
      "reward": -914.0,
      "steps": 54,
      "mean_loss": 2566.157441598398,
      "epsilon": 0.33443500000442977
    },
    {
      "episode": 3407,
      "score": 81,
      "reward": -984.0,
      "steps": 38,
      "mean_loss": 5885.356805249265,
      "epsilon": 0.3343970000044308
    },
    {
      "episode": 3408,
      "score": 130,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 2809.012952717868,
      "epsilon": 0.33435300000443197
    },
    {
      "episode": 3409,
      "score": 144,
      "reward": -925.0,
      "steps": 42,
      "mean_loss": 6671.814672560919,
      "epsilon": 0.3343110000044331
    },
    {
      "episode": 3410,
      "score": 103,
      "reward": -955.0,
      "steps": 36,
      "mean_loss": 3295.5802680651345,
      "epsilon": 0.33427500000443405
    },
    {
      "episode": 3411,
      "score": 146,
      "reward": -938.0,
      "steps": 49,
      "mean_loss": 4181.113324651913,
      "epsilon": 0.33422600000443536
    },
    {
      "episode": 3412,
      "score": 248,
      "reward": -857.0,
      "steps": 63,
      "mean_loss": 5083.903949979752,
      "epsilon": 0.33416300000443705
    },
    {
      "episode": 3413,
      "score": 193,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 3586.4724613703215,
      "epsilon": 0.33411100000443844
    },
    {
      "episode": 3414,
      "score": 151,
      "reward": -918.0,
      "steps": 47,
      "mean_loss": 5056.486042022705,
      "epsilon": 0.3340640000044397
    },
    {
      "episode": 3415,
      "score": 94,
      "reward": -974.0,
      "steps": 41,
      "mean_loss": 3683.3648718857185,
      "epsilon": 0.3340230000044408
    },
    {
      "episode": 3416,
      "score": 183,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 3846.498352784377,
      "epsilon": 0.3339710000044422
    },
    {
      "episode": 3417,
      "score": 152,
      "reward": -922.0,
      "steps": 45,
      "mean_loss": 5049.786192660861,
      "epsilon": 0.3339260000044434
    },
    {
      "episode": 3418,
      "score": 139,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 3484.527439514796,
      "epsilon": 0.3338780000044447
    },
    {
      "episode": 3419,
      "score": 95,
      "reward": -974.0,
      "steps": 38,
      "mean_loss": 4012.0500442103335,
      "epsilon": 0.3338400000044457
    },
    {
      "episode": 3420,
      "score": 172,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 4408.794470572958,
      "epsilon": 0.333791000004447
    },
    {
      "episode": 3421,
      "score": 158,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 4518.728594551087,
      "epsilon": 0.33374100000444834
    },
    {
      "episode": 3422,
      "score": 175,
      "reward": -894.0,
      "steps": 48,
      "mean_loss": 1371.1604613463085,
      "epsilon": 0.3336930000044496
    },
    {
      "episode": 3423,
      "score": 111,
      "reward": -954.0,
      "steps": 37,
      "mean_loss": 2848.202625274658,
      "epsilon": 0.3336560000044506
    },
    {
      "episode": 3424,
      "score": 110,
      "reward": -960.0,
      "steps": 40,
      "mean_loss": 4621.330139923096,
      "epsilon": 0.3336160000044517
    },
    {
      "episode": 3425,
      "score": 190,
      "reward": -911.0,
      "steps": 53,
      "mean_loss": 2732.536317285502,
      "epsilon": 0.3335630000044531
    },
    {
      "episode": 3426,
      "score": 137,
      "reward": -929.0,
      "steps": 44,
      "mean_loss": 3520.4010566364636,
      "epsilon": 0.3335190000044543
    },
    {
      "episode": 3427,
      "score": 174,
      "reward": -925.0,
      "steps": 54,
      "mean_loss": 2316.8050578435264,
      "epsilon": 0.3334650000044557
    },
    {
      "episode": 3428,
      "score": 179,
      "reward": -892.0,
      "steps": 51,
      "mean_loss": 6279.174183939018,
      "epsilon": 0.3334140000044571
    },
    {
      "episode": 3429,
      "score": 184,
      "reward": -898.0,
      "steps": 52,
      "mean_loss": 1960.6681302877573,
      "epsilon": 0.3333620000044585
    },
    {
      "episode": 3430,
      "score": 218,
      "reward": -884.0,
      "steps": 59,
      "mean_loss": 4056.4757573402535,
      "epsilon": 0.33330300000446006
    },
    {
      "episode": 3431,
      "score": 166,
      "reward": -902.0,
      "steps": 50,
      "mean_loss": 5096.980633392334,
      "epsilon": 0.3332530000044614
    },
    {
      "episode": 3432,
      "score": 161,
      "reward": -920.0,
      "steps": 51,
      "mean_loss": 4208.383244233973,
      "epsilon": 0.33320200000446276
    },
    {
      "episode": 3433,
      "score": 142,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 2267.6684695534086,
      "epsilon": 0.333156000004464
    },
    {
      "episode": 3434,
      "score": 126,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 4275.556273196606,
      "epsilon": 0.33310900000446525
    },
    {
      "episode": 3435,
      "score": 138,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 2120.8528854694773,
      "epsilon": 0.3330620000044665
    },
    {
      "episode": 3436,
      "score": 112,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 7002.094519918615,
      "epsilon": 0.3330180000044677
    },
    {
      "episode": 3437,
      "score": 112,
      "reward": -947.0,
      "steps": 40,
      "mean_loss": 3067.6255168914795,
      "epsilon": 0.33297800000446875
    },
    {
      "episode": 3438,
      "score": 120,
      "reward": -939.0,
      "steps": 40,
      "mean_loss": 5126.957044410706,
      "epsilon": 0.3329380000044698
    },
    {
      "episode": 3439,
      "score": 125,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 6343.451466062795,
      "epsilon": 0.33289200000447106
    },
    {
      "episode": 3440,
      "score": 97,
      "reward": -975.0,
      "steps": 39,
      "mean_loss": 4895.953796875782,
      "epsilon": 0.3328530000044721
    },
    {
      "episode": 3441,
      "score": 121,
      "reward": -940.0,
      "steps": 38,
      "mean_loss": 5183.174386827569,
      "epsilon": 0.3328150000044731
    },
    {
      "episode": 3442,
      "score": 167,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 2745.6493574142455,
      "epsilon": 0.33276500000447445
    },
    {
      "episode": 3443,
      "score": 141,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 5375.4889684518175,
      "epsilon": 0.33271700000447574
    },
    {
      "episode": 3444,
      "score": 89,
      "reward": -996.0,
      "steps": 40,
      "mean_loss": 5600.8868680000305,
      "epsilon": 0.3326770000044768
    },
    {
      "episode": 3445,
      "score": 149,
      "reward": -928.0,
      "steps": 51,
      "mean_loss": 6207.03575927136,
      "epsilon": 0.3326260000044782
    },
    {
      "episode": 3446,
      "score": 235,
      "reward": -861.0,
      "steps": 63,
      "mean_loss": 3384.2158136821927,
      "epsilon": 0.33256300000447986
    },
    {
      "episode": 3447,
      "score": 105,
      "reward": -951.0,
      "steps": 37,
      "mean_loss": 4559.793521159404,
      "epsilon": 0.33252600000448085
    },
    {
      "episode": 3448,
      "score": 232,
      "reward": -871.0,
      "steps": 59,
      "mean_loss": 3100.2741649757,
      "epsilon": 0.3324670000044824
    },
    {
      "episode": 3449,
      "score": 177,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 4605.550046187181,
      "epsilon": 0.3324150000044838
    },
    {
      "episode": 3450,
      "score": 195,
      "reward": -888.0,
      "steps": 55,
      "mean_loss": 3461.2525165211073,
      "epsilon": 0.3323600000044853
    },
    {
      "episode": 3451,
      "score": 162,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 3398.8162443199935,
      "epsilon": 0.3323110000044866
    },
    {
      "episode": 3452,
      "score": 203,
      "reward": -881.0,
      "steps": 53,
      "mean_loss": 5030.647567605072,
      "epsilon": 0.332258000004488
    },
    {
      "episode": 3453,
      "score": 147,
      "reward": -930.0,
      "steps": 46,
      "mean_loss": 3805.6976154161534,
      "epsilon": 0.33221200000448925
    },
    {
      "episode": 3454,
      "score": 166,
      "reward": -936.0,
      "steps": 50,
      "mean_loss": 2442.902067642212,
      "epsilon": 0.3321620000044906
    },
    {
      "episode": 3455,
      "score": 131,
      "reward": -939.0,
      "steps": 43,
      "mean_loss": 1683.7594364077545,
      "epsilon": 0.33211900000449174
    },
    {
      "episode": 3456,
      "score": 134,
      "reward": -937.0,
      "steps": 42,
      "mean_loss": 6738.579403105236,
      "epsilon": 0.33207700000449286
    },
    {
      "episode": 3457,
      "score": 116,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 4252.7532842809505,
      "epsilon": 0.33203300000449404
    },
    {
      "episode": 3458,
      "score": 255,
      "reward": -838.0,
      "steps": 63,
      "mean_loss": 5270.968680063884,
      "epsilon": 0.3319700000044957
    },
    {
      "episode": 3459,
      "score": 121,
      "reward": -977.0,
      "steps": 46,
      "mean_loss": 5421.823229416557,
      "epsilon": 0.33192400000449696
    },
    {
      "episode": 3460,
      "score": 175,
      "reward": -920.0,
      "steps": 53,
      "mean_loss": 5468.502387928513,
      "epsilon": 0.3318710000044984
    },
    {
      "episode": 3461,
      "score": 183,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 3544.5352915250337,
      "epsilon": 0.33181900000449976
    },
    {
      "episode": 3462,
      "score": 198,
      "reward": -925.0,
      "steps": 52,
      "mean_loss": 3876.447842377883,
      "epsilon": 0.33176700000450116
    },
    {
      "episode": 3463,
      "score": 122,
      "reward": -956.0,
      "steps": 41,
      "mean_loss": 3864.3595303791326,
      "epsilon": 0.33172600000450225
    },
    {
      "episode": 3464,
      "score": 241,
      "reward": -864.0,
      "steps": 63,
      "mean_loss": 4695.142160385374,
      "epsilon": 0.33166300000450394
    },
    {
      "episode": 3465,
      "score": 249,
      "reward": -877.0,
      "steps": 62,
      "mean_loss": 1230.3683073289933,
      "epsilon": 0.3316010000045056
    },
    {
      "episode": 3466,
      "score": 163,
      "reward": -918.0,
      "steps": 47,
      "mean_loss": 4033.358549239788,
      "epsilon": 0.33155400000450685
    },
    {
      "episode": 3467,
      "score": 137,
      "reward": -929.0,
      "steps": 42,
      "mean_loss": 3760.7997144063315,
      "epsilon": 0.331512000004508
    },
    {
      "episode": 3468,
      "score": 105,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 2760.483578335155,
      "epsilon": 0.33146800000450916
    },
    {
      "episode": 3469,
      "score": 260,
      "reward": -857.0,
      "steps": 63,
      "mean_loss": 3068.3290175180587,
      "epsilon": 0.33140500000451084
    },
    {
      "episode": 3470,
      "score": 147,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 4197.601650481529,
      "epsilon": 0.3313580000045121
    },
    {
      "episode": 3471,
      "score": 189,
      "reward": -906.0,
      "steps": 55,
      "mean_loss": 4223.178140120072,
      "epsilon": 0.33130300000451357
    },
    {
      "episode": 3472,
      "score": 122,
      "reward": -934.0,
      "steps": 44,
      "mean_loss": 3518.37301939184,
      "epsilon": 0.33125900000451475
    },
    {
      "episode": 3473,
      "score": 134,
      "reward": -944.0,
      "steps": 46,
      "mean_loss": 4374.736545645673,
      "epsilon": 0.331213000004516
    },
    {
      "episode": 3474,
      "score": 151,
      "reward": -923.0,
      "steps": 47,
      "mean_loss": 4467.58090404754,
      "epsilon": 0.33116600000451724
    },
    {
      "episode": 3475,
      "score": 158,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 4856.231806618826,
      "epsilon": 0.33111700000451855
    },
    {
      "episode": 3476,
      "score": 142,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 2270.8801237612356,
      "epsilon": 0.33106800000451986
    },
    {
      "episode": 3477,
      "score": 126,
      "reward": -951.0,
      "steps": 45,
      "mean_loss": 6402.905633629693,
      "epsilon": 0.33102300000452106
    },
    {
      "episode": 3478,
      "score": 108,
      "reward": -952.0,
      "steps": 39,
      "mean_loss": 4738.454547246297,
      "epsilon": 0.3309840000045221
    },
    {
      "episode": 3479,
      "score": 151,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 7235.23157184682,
      "epsilon": 0.33093700000452336
    },
    {
      "episode": 3480,
      "score": 263,
      "reward": -849.0,
      "steps": 65,
      "mean_loss": 4546.097583506657,
      "epsilon": 0.3308720000045251
    },
    {
      "episode": 3481,
      "score": 75,
      "reward": -976.0,
      "steps": 34,
      "mean_loss": 3889.7611220864687,
      "epsilon": 0.330838000004526
    },
    {
      "episode": 3482,
      "score": 153,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 2074.1308165740966,
      "epsilon": 0.33078800000452735
    },
    {
      "episode": 3483,
      "score": 167,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 4832.016104484091,
      "epsilon": 0.33073900000452866
    },
    {
      "episode": 3484,
      "score": 109,
      "reward": -964.0,
      "steps": 41,
      "mean_loss": 6609.510785079584,
      "epsilon": 0.33069800000452976
    },
    {
      "episode": 3485,
      "score": 108,
      "reward": -950.0,
      "steps": 35,
      "mean_loss": 3886.489570617676,
      "epsilon": 0.3306630000045307
    },
    {
      "episode": 3486,
      "score": 105,
      "reward": -978.0,
      "steps": 44,
      "mean_loss": 2680.99884371324,
      "epsilon": 0.33061900000453187
    },
    {
      "episode": 3487,
      "score": 165,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 5576.8506507873535,
      "epsilon": 0.3305690000045332
    },
    {
      "episode": 3488,
      "score": 96,
      "reward": -978.0,
      "steps": 42,
      "mean_loss": 4114.985702877953,
      "epsilon": 0.33052700000453433
    },
    {
      "episode": 3489,
      "score": 168,
      "reward": -901.0,
      "steps": 49,
      "mean_loss": 6342.668628225521,
      "epsilon": 0.33047800000453564
    },
    {
      "episode": 3490,
      "score": 131,
      "reward": -940.0,
      "steps": 43,
      "mean_loss": 6665.73091666643,
      "epsilon": 0.3304350000045368
    },
    {
      "episode": 3491,
      "score": 114,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 4196.248400461106,
      "epsilon": 0.3303930000045379
    },
    {
      "episode": 3492,
      "score": 204,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 5768.342062656696,
      "epsilon": 0.3303410000045393
    },
    {
      "episode": 3493,
      "score": 89,
      "reward": -972.0,
      "steps": 39,
      "mean_loss": 1960.3689226003794,
      "epsilon": 0.33030200000454035
    },
    {
      "episode": 3494,
      "score": 231,
      "reward": -863.0,
      "steps": 58,
      "mean_loss": 4351.604287246178,
      "epsilon": 0.3302440000045419
    },
    {
      "episode": 3495,
      "score": 88,
      "reward": -970.0,
      "steps": 35,
      "mean_loss": 3635.7362088884624,
      "epsilon": 0.33020900000454284
    },
    {
      "episode": 3496,
      "score": 132,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 4238.891833853214,
      "epsilon": 0.3301620000045441
    },
    {
      "episode": 3497,
      "score": 84,
      "reward": -972.0,
      "steps": 34,
      "mean_loss": 4468.100187806522,
      "epsilon": 0.330128000004545
    },
    {
      "episode": 3498,
      "score": 162,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 3623.2238213348387,
      "epsilon": 0.33007800000454635
    },
    {
      "episode": 3499,
      "score": 242,
      "reward": -844.0,
      "steps": 62,
      "mean_loss": 5126.256277145878,
      "epsilon": 0.330016000004548
    },
    {
      "episode": 3500,
      "score": 114,
      "reward": -952.0,
      "steps": 43,
      "mean_loss": 2166.6454431400743,
      "epsilon": 0.32997300000454916
    },
    {
      "episode": 3501,
      "score": 163,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 5270.529461860657,
      "epsilon": 0.3299230000045505
    },
    {
      "episode": 3502,
      "score": 218,
      "reward": -870.0,
      "steps": 57,
      "mean_loss": 4997.577543727139,
      "epsilon": 0.329866000004552
    },
    {
      "episode": 3503,
      "score": 169,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 2643.625249825272,
      "epsilon": 0.3298150000045534
    },
    {
      "episode": 3504,
      "score": 168,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 4472.076015625,
      "epsilon": 0.3297650000045547
    },
    {
      "episode": 3505,
      "score": 183,
      "reward": -898.0,
      "steps": 53,
      "mean_loss": 3807.387967487551,
      "epsilon": 0.32971200000455614
    },
    {
      "episode": 3506,
      "score": 164,
      "reward": -924.0,
      "steps": 51,
      "mean_loss": 4643.1021525813085,
      "epsilon": 0.3296610000045575
    },
    {
      "episode": 3507,
      "score": 125,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 5306.221856573354,
      "epsilon": 0.32961500000455873
    },
    {
      "episode": 3508,
      "score": 176,
      "reward": -898.0,
      "steps": 52,
      "mean_loss": 4698.848088337825,
      "epsilon": 0.3295630000045601
    },
    {
      "episode": 3509,
      "score": 96,
      "reward": -975.0,
      "steps": 39,
      "mean_loss": 3370.388258127066,
      "epsilon": 0.32952400000456117
    },
    {
      "episode": 3510,
      "score": 168,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 2002.8997665405273,
      "epsilon": 0.3294740000045625
    },
    {
      "episode": 3511,
      "score": 134,
      "reward": -949.0,
      "steps": 45,
      "mean_loss": 3009.59270807902,
      "epsilon": 0.3294290000045637
    },
    {
      "episode": 3512,
      "score": 157,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 5294.423746566772,
      "epsilon": 0.32937900000456505
    },
    {
      "episode": 3513,
      "score": 99,
      "reward": -966.0,
      "steps": 38,
      "mean_loss": 5467.776472693996,
      "epsilon": 0.32934100000456606
    },
    {
      "episode": 3514,
      "score": 192,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 2108.192693673647,
      "epsilon": 0.32928900000456746
    },
    {
      "episode": 3515,
      "score": 123,
      "reward": -944.0,
      "steps": 40,
      "mean_loss": 5218.943053722382,
      "epsilon": 0.3292490000045685
    },
    {
      "episode": 3516,
      "score": 117,
      "reward": -950.0,
      "steps": 42,
      "mean_loss": 5256.153534208025,
      "epsilon": 0.32920700000456965
    },
    {
      "episode": 3517,
      "score": 149,
      "reward": -935.0,
      "steps": 49,
      "mean_loss": 6086.265015738351,
      "epsilon": 0.32915800000457096
    },
    {
      "episode": 3518,
      "score": 120,
      "reward": -942.0,
      "steps": 40,
      "mean_loss": 6026.117113876343,
      "epsilon": 0.32911800000457203
    },
    {
      "episode": 3519,
      "score": 117,
      "reward": -940.0,
      "steps": 36,
      "mean_loss": 3686.759047402276,
      "epsilon": 0.329082000004573
    },
    {
      "episode": 3520,
      "score": 136,
      "reward": -918.0,
      "steps": 44,
      "mean_loss": 3856.465721477162,
      "epsilon": 0.32903800000457417
    },
    {
      "episode": 3521,
      "score": 129,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 2431.4797909476542,
      "epsilon": 0.32899400000457535
    },
    {
      "episode": 3522,
      "score": 174,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 2637.375948791504,
      "epsilon": 0.3289440000045767
    },
    {
      "episode": 3523,
      "score": 139,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 4993.384494213347,
      "epsilon": 0.32889700000457794
    },
    {
      "episode": 3524,
      "score": 216,
      "reward": -894.0,
      "steps": 58,
      "mean_loss": 1493.4280393534693,
      "epsilon": 0.3288390000045795
    },
    {
      "episode": 3525,
      "score": 151,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 5135.547355572383,
      "epsilon": 0.3287910000045808
    },
    {
      "episode": 3526,
      "score": 152,
      "reward": -943.0,
      "steps": 50,
      "mean_loss": 4900.348686828614,
      "epsilon": 0.3287410000045821
    },
    {
      "episode": 3527,
      "score": 127,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 6512.5158508964205,
      "epsilon": 0.32869500000458335
    },
    {
      "episode": 3528,
      "score": 138,
      "reward": -924.0,
      "steps": 45,
      "mean_loss": 6416.81409517924,
      "epsilon": 0.32865000000458455
    },
    {
      "episode": 3529,
      "score": 272,
      "reward": -841.0,
      "steps": 68,
      "mean_loss": 3438.7531952016493,
      "epsilon": 0.32858200000458637
    },
    {
      "episode": 3530,
      "score": 161,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 2491.5072718048095,
      "epsilon": 0.3285320000045877
    },
    {
      "episode": 3531,
      "score": 249,
      "reward": -836.0,
      "steps": 59,
      "mean_loss": 2991.833867218535,
      "epsilon": 0.3284730000045893
    },
    {
      "episode": 3532,
      "score": 208,
      "reward": -870.0,
      "steps": 56,
      "mean_loss": 3820.805889878954,
      "epsilon": 0.3284170000045908
    },
    {
      "episode": 3533,
      "score": 275,
      "reward": -823.0,
      "steps": 64,
      "mean_loss": 5464.248502135277,
      "epsilon": 0.3283530000045925
    },
    {
      "episode": 3534,
      "score": 172,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 3190.0823863983155,
      "epsilon": 0.32830300000459384
    },
    {
      "episode": 3535,
      "score": 133,
      "reward": -952.0,
      "steps": 48,
      "mean_loss": 5122.65360190471,
      "epsilon": 0.3282550000045951
    },
    {
      "episode": 3536,
      "score": 109,
      "reward": -958.0,
      "steps": 39,
      "mean_loss": 4138.210037720509,
      "epsilon": 0.32821600000459616
    },
    {
      "episode": 3537,
      "score": 22,
      "reward": -1004.0,
      "steps": 18,
      "mean_loss": 2724.689051310221,
      "epsilon": 0.32819800000459665
    },
    {
      "episode": 3538,
      "score": 97,
      "reward": -956.0,
      "steps": 34,
      "mean_loss": 3752.5720604167263,
      "epsilon": 0.32816400000459756
    },
    {
      "episode": 3539,
      "score": 158,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 3432.3323192596436,
      "epsilon": 0.3281140000045989
    },
    {
      "episode": 3540,
      "score": 97,
      "reward": -969.0,
      "steps": 39,
      "mean_loss": 2078.331328563201,
      "epsilon": 0.32807500000459994
    },
    {
      "episode": 3541,
      "score": 126,
      "reward": -948.0,
      "steps": 46,
      "mean_loss": 2947.7390006106834,
      "epsilon": 0.32802900000460117
    },
    {
      "episode": 3542,
      "score": 104,
      "reward": -949.0,
      "steps": 34,
      "mean_loss": 2113.783437392291,
      "epsilon": 0.3279950000046021
    },
    {
      "episode": 3543,
      "score": 166,
      "reward": -909.0,
      "steps": 50,
      "mean_loss": 3595.3504361724854,
      "epsilon": 0.3279450000046034
    },
    {
      "episode": 3544,
      "score": 114,
      "reward": -960.0,
      "steps": 39,
      "mean_loss": 3650.460331256573,
      "epsilon": 0.32790600000460446
    },
    {
      "episode": 3545,
      "score": 174,
      "reward": -922.0,
      "steps": 51,
      "mean_loss": 5405.388768214805,
      "epsilon": 0.3278550000046058
    },
    {
      "episode": 3546,
      "score": 196,
      "reward": -897.0,
      "steps": 55,
      "mean_loss": 3584.0642279885033,
      "epsilon": 0.3278000000046073
    },
    {
      "episode": 3547,
      "score": 141,
      "reward": -928.0,
      "steps": 43,
      "mean_loss": 4212.979102910951,
      "epsilon": 0.32775700000460845
    },
    {
      "episode": 3548,
      "score": 77,
      "reward": -982.0,
      "steps": 34,
      "mean_loss": 3392.0750450246474,
      "epsilon": 0.32772300000460935
    },
    {
      "episode": 3549,
      "score": 161,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 2875.3155583751445,
      "epsilon": 0.32767400000461067
    },
    {
      "episode": 3550,
      "score": 190,
      "reward": -883.0,
      "steps": 52,
      "mean_loss": 5746.417231119596,
      "epsilon": 0.32762200000461206
    },
    {
      "episode": 3551,
      "score": 144,
      "reward": -922.0,
      "steps": 41,
      "mean_loss": 3177.7372780776604,
      "epsilon": 0.32758100000461315
    },
    {
      "episode": 3552,
      "score": 112,
      "reward": -966.0,
      "steps": 44,
      "mean_loss": 2629.555518063632,
      "epsilon": 0.32753700000461433
    },
    {
      "episode": 3553,
      "score": 143,
      "reward": -911.0,
      "steps": 43,
      "mean_loss": 3316.512024901634,
      "epsilon": 0.3274940000046155
    },
    {
      "episode": 3554,
      "score": 199,
      "reward": -890.0,
      "steps": 56,
      "mean_loss": 6258.78199498994,
      "epsilon": 0.327438000004617
    },
    {
      "episode": 3555,
      "score": 165,
      "reward": -905.0,
      "steps": 49,
      "mean_loss": 4774.919246440031,
      "epsilon": 0.3273890000046183
    },
    {
      "episode": 3556,
      "score": 163,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 3792.502033817525,
      "epsilon": 0.3273400000046196
    },
    {
      "episode": 3557,
      "score": 263,
      "reward": -847.0,
      "steps": 66,
      "mean_loss": 4224.439200950392,
      "epsilon": 0.32727400000462137
    },
    {
      "episode": 3558,
      "score": 99,
      "reward": -966.0,
      "steps": 39,
      "mean_loss": 1038.181832093459,
      "epsilon": 0.3272350000046224
    },
    {
      "episode": 3559,
      "score": 190,
      "reward": -898.0,
      "steps": 54,
      "mean_loss": 6929.1626098774095,
      "epsilon": 0.32718100000462386
    },
    {
      "episode": 3560,
      "score": 127,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 4117.175784891302,
      "epsilon": 0.32713700000462503
    },
    {
      "episode": 3561,
      "score": 101,
      "reward": -961.0,
      "steps": 41,
      "mean_loss": 4518.932900219429,
      "epsilon": 0.32709600000462613
    },
    {
      "episode": 3562,
      "score": 123,
      "reward": -941.0,
      "steps": 42,
      "mean_loss": 3789.142867769514,
      "epsilon": 0.32705400000462725
    },
    {
      "episode": 3563,
      "score": 216,
      "reward": -884.0,
      "steps": 56,
      "mean_loss": 7713.720979826791,
      "epsilon": 0.32699800000462875
    },
    {
      "episode": 3564,
      "score": 158,
      "reward": -903.0,
      "steps": 46,
      "mean_loss": 3438.455099022907,
      "epsilon": 0.32695200000463
    },
    {
      "episode": 3565,
      "score": 171,
      "reward": -904.0,
      "steps": 48,
      "mean_loss": 5332.420994440715,
      "epsilon": 0.32690400000463127
    },
    {
      "episode": 3566,
      "score": 131,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 3966.164956699718,
      "epsilon": 0.32686000000463244
    },
    {
      "episode": 3567,
      "score": 247,
      "reward": -858.0,
      "steps": 61,
      "mean_loss": 4593.556784176436,
      "epsilon": 0.3267990000046341
    },
    {
      "episode": 3568,
      "score": 124,
      "reward": -936.0,
      "steps": 39,
      "mean_loss": 1156.6297396146333,
      "epsilon": 0.3267600000046351
    },
    {
      "episode": 3569,
      "score": 124,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 3690.138152995008,
      "epsilon": 0.3267130000046364
    },
    {
      "episode": 3570,
      "score": 142,
      "reward": -931.0,
      "steps": 50,
      "mean_loss": 2996.100654602051,
      "epsilon": 0.3266630000046377
    },
    {
      "episode": 3571,
      "score": 235,
      "reward": -875.0,
      "steps": 62,
      "mean_loss": 4527.810176234091,
      "epsilon": 0.3266010000046394
    },
    {
      "episode": 3572,
      "score": 178,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 3984.9326786994934,
      "epsilon": 0.32654900000464077
    },
    {
      "episode": 3573,
      "score": 194,
      "reward": -877.0,
      "steps": 51,
      "mean_loss": 3431.904452604406,
      "epsilon": 0.32649800000464213
    },
    {
      "episode": 3574,
      "score": 187,
      "reward": -892.0,
      "steps": 50,
      "mean_loss": 4503.084963226318,
      "epsilon": 0.32644800000464347
    },
    {
      "episode": 3575,
      "score": 164,
      "reward": -903.0,
      "steps": 50,
      "mean_loss": 6181.695981369018,
      "epsilon": 0.3263980000046448
    },
    {
      "episode": 3576,
      "score": 145,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 4806.655072834181,
      "epsilon": 0.32635200000464604
    },
    {
      "episode": 3577,
      "score": 53,
      "reward": -1017.0,
      "steps": 33,
      "mean_loss": 6160.4050897540465,
      "epsilon": 0.3263190000046469
    },
    {
      "episode": 3578,
      "score": 188,
      "reward": -902.0,
      "steps": 50,
      "mean_loss": 4203.2787510681155,
      "epsilon": 0.32626900000464826
    },
    {
      "episode": 3579,
      "score": 140,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 6621.555838875149,
      "epsilon": 0.3262230000046495
    },
    {
      "episode": 3580,
      "score": 75,
      "reward": -975.0,
      "steps": 34,
      "mean_loss": 2110.511910831227,
      "epsilon": 0.3261890000046504
    },
    {
      "episode": 3581,
      "score": 133,
      "reward": -940.0,
      "steps": 45,
      "mean_loss": 3177.9032386779786,
      "epsilon": 0.3261440000046516
    },
    {
      "episode": 3582,
      "score": 144,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 5777.206276796302,
      "epsilon": 0.3260950000046529
    },
    {
      "episode": 3583,
      "score": 242,
      "reward": -857.0,
      "steps": 62,
      "mean_loss": 4607.403480222149,
      "epsilon": 0.32603300000465457
    },
    {
      "episode": 3584,
      "score": 193,
      "reward": -895.0,
      "steps": 53,
      "mean_loss": 5474.808594649693,
      "epsilon": 0.325980000004656
    },
    {
      "episode": 3585,
      "score": 163,
      "reward": -918.0,
      "steps": 50,
      "mean_loss": 3610.4788150787354,
      "epsilon": 0.3259300000046573
    },
    {
      "episode": 3586,
      "score": 88,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 2156.4218308732316,
      "epsilon": 0.3258930000046583
    },
    {
      "episode": 3587,
      "score": 92,
      "reward": -974.0,
      "steps": 38,
      "mean_loss": 4503.824450643439,
      "epsilon": 0.32585500000465933
    },
    {
      "episode": 3588,
      "score": 106,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 3408.870214809071,
      "epsilon": 0.3258110000046605
    },
    {
      "episode": 3589,
      "score": 123,
      "reward": -946.0,
      "steps": 43,
      "mean_loss": 4788.835083806238,
      "epsilon": 0.32576800000466166
    },
    {
      "episode": 3590,
      "score": 132,
      "reward": -944.0,
      "steps": 47,
      "mean_loss": 2753.659288446954,
      "epsilon": 0.3257210000046629
    },
    {
      "episode": 3591,
      "score": 194,
      "reward": -902.0,
      "steps": 56,
      "mean_loss": 6831.7284026145935,
      "epsilon": 0.3256650000046644
    },
    {
      "episode": 3592,
      "score": 128,
      "reward": -951.0,
      "steps": 47,
      "mean_loss": 3794.466834291499,
      "epsilon": 0.3256180000046657
    },
    {
      "episode": 3593,
      "score": 167,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 4805.126973208259,
      "epsilon": 0.32556700000466704
    },
    {
      "episode": 3594,
      "score": 187,
      "reward": -891.0,
      "steps": 52,
      "mean_loss": 3978.019557292645,
      "epsilon": 0.32551500000466843
    },
    {
      "episode": 3595,
      "score": 189,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 5447.206742286682,
      "epsilon": 0.3254630000046698
    },
    {
      "episode": 3596,
      "score": 251,
      "reward": -836.0,
      "steps": 61,
      "mean_loss": 5439.270948284962,
      "epsilon": 0.32540200000467145
    },
    {
      "episode": 3597,
      "score": 184,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 7200.115480276255,
      "epsilon": 0.32535000000467285
    },
    {
      "episode": 3598,
      "score": 121,
      "reward": -959.0,
      "steps": 47,
      "mean_loss": 6279.148293271978,
      "epsilon": 0.3253030000046741
    },
    {
      "episode": 3599,
      "score": 149,
      "reward": -923.0,
      "steps": 48,
      "mean_loss": 6758.418677171071,
      "epsilon": 0.3252550000046754
    },
    {
      "episode": 3600,
      "score": 166,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 7341.957565382415,
      "epsilon": 0.32520400000467675
    },
    {
      "episode": 3601,
      "score": 175,
      "reward": -912.0,
      "steps": 53,
      "mean_loss": 3779.8087375209016,
      "epsilon": 0.32515100000467817
    },
    {
      "episode": 3602,
      "score": 265,
      "reward": -853.0,
      "steps": 68,
      "mean_loss": 3429.9267385146195,
      "epsilon": 0.32508300000468
    },
    {
      "episode": 3603,
      "score": 218,
      "reward": -865.0,
      "steps": 57,
      "mean_loss": 2081.1998903709546,
      "epsilon": 0.3250260000046815
    },
    {
      "episode": 3604,
      "score": 101,
      "reward": -963.0,
      "steps": 40,
      "mean_loss": 3353.5989151000977,
      "epsilon": 0.3249860000046826
    },
    {
      "episode": 3605,
      "score": 86,
      "reward": -970.0,
      "steps": 36,
      "mean_loss": 7533.918407334222,
      "epsilon": 0.32495000000468355
    },
    {
      "episode": 3606,
      "score": 118,
      "reward": -964.0,
      "steps": 46,
      "mean_loss": 6283.399351949277,
      "epsilon": 0.3249040000046848
    },
    {
      "episode": 3607,
      "score": 77,
      "reward": -977.0,
      "steps": 31,
      "mean_loss": 1839.476389361966,
      "epsilon": 0.3248730000046856
    },
    {
      "episode": 3608,
      "score": 217,
      "reward": -865.0,
      "steps": 57,
      "mean_loss": 4839.457592646281,
      "epsilon": 0.32481600000468713
    },
    {
      "episode": 3609,
      "score": 118,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 5275.269578240134,
      "epsilon": 0.3247720000046883
    },
    {
      "episode": 3610,
      "score": 215,
      "reward": -881.0,
      "steps": 60,
      "mean_loss": 4434.755605951945,
      "epsilon": 0.3247120000046899
    },
    {
      "episode": 3611,
      "score": 131,
      "reward": -935.0,
      "steps": 46,
      "mean_loss": 4556.229117020317,
      "epsilon": 0.32466600000469115
    },
    {
      "episode": 3612,
      "score": 233,
      "reward": -871.0,
      "steps": 62,
      "mean_loss": 3318.813282628213,
      "epsilon": 0.3246040000046928
    },
    {
      "episode": 3613,
      "score": 163,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 3039.672467818627,
      "epsilon": 0.3245520000046942
    },
    {
      "episode": 3614,
      "score": 151,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 2404.1025482813516,
      "epsilon": 0.3245040000046955
    },
    {
      "episode": 3615,
      "score": 160,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 3889.6894280569895,
      "epsilon": 0.3244550000046968
    },
    {
      "episode": 3616,
      "score": 134,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 3049.8282500108085,
      "epsilon": 0.3244070000046981
    },
    {
      "episode": 3617,
      "score": 110,
      "reward": -969.0,
      "steps": 42,
      "mean_loss": 4059.2958235059464,
      "epsilon": 0.3243650000046992
    },
    {
      "episode": 3618,
      "score": 85,
      "reward": -985.0,
      "steps": 37,
      "mean_loss": 3860.111204301989,
      "epsilon": 0.3243280000047002
    },
    {
      "episode": 3619,
      "score": 145,
      "reward": -921.0,
      "steps": 43,
      "mean_loss": 5432.409873252691,
      "epsilon": 0.32428500000470134
    },
    {
      "episode": 3620,
      "score": 123,
      "reward": -953.0,
      "steps": 45,
      "mean_loss": 4973.752138985528,
      "epsilon": 0.32424000000470254
    },
    {
      "episode": 3621,
      "score": 156,
      "reward": -914.0,
      "steps": 45,
      "mean_loss": 5242.8299080318875,
      "epsilon": 0.32419500000470375
    },
    {
      "episode": 3622,
      "score": 113,
      "reward": -941.0,
      "steps": 40,
      "mean_loss": 4776.074742126465,
      "epsilon": 0.3241550000047048
    },
    {
      "episode": 3623,
      "score": 115,
      "reward": -933.0,
      "steps": 36,
      "mean_loss": 3147.536816067166,
      "epsilon": 0.3241190000047058
    },
    {
      "episode": 3624,
      "score": 107,
      "reward": -962.0,
      "steps": 41,
      "mean_loss": 4467.885934876233,
      "epsilon": 0.3240780000047069
    },
    {
      "episode": 3625,
      "score": 174,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 3698.085951690674,
      "epsilon": 0.3240280000047082
    },
    {
      "episode": 3626,
      "score": 130,
      "reward": -955.0,
      "steps": 48,
      "mean_loss": 3676.8115383783975,
      "epsilon": 0.3239800000047095
    },
    {
      "episode": 3627,
      "score": 129,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 5205.03870084069,
      "epsilon": 0.3239360000047107
    },
    {
      "episode": 3628,
      "score": 133,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 6193.513850800535,
      "epsilon": 0.32388900000471194
    },
    {
      "episode": 3629,
      "score": 115,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 5908.210985010321,
      "epsilon": 0.3238450000047131
    },
    {
      "episode": 3630,
      "score": 109,
      "reward": -970.0,
      "steps": 44,
      "mean_loss": 1730.3963952498002,
      "epsilon": 0.3238010000047143
    },
    {
      "episode": 3631,
      "score": 166,
      "reward": -925.0,
      "steps": 51,
      "mean_loss": 4583.635278327793,
      "epsilon": 0.32375000000471565
    },
    {
      "episode": 3632,
      "score": 142,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 4384.988817638821,
      "epsilon": 0.32370500000471686
    },
    {
      "episode": 3633,
      "score": 161,
      "reward": -934.0,
      "steps": 51,
      "mean_loss": 4597.033948412129,
      "epsilon": 0.3236540000047182
    },
    {
      "episode": 3634,
      "score": 209,
      "reward": -884.0,
      "steps": 53,
      "mean_loss": 4724.900986941356,
      "epsilon": 0.32360100000471964
    },
    {
      "episode": 3635,
      "score": 174,
      "reward": -908.0,
      "steps": 49,
      "mean_loss": 3985.8262037938953,
      "epsilon": 0.32355200000472095
    },
    {
      "episode": 3636,
      "score": 201,
      "reward": -879.0,
      "steps": 51,
      "mean_loss": 6203.59792619593,
      "epsilon": 0.3235010000047223
    },
    {
      "episode": 3637,
      "score": 171,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 3607.0240501092403,
      "epsilon": 0.3234520000047236
    },
    {
      "episode": 3638,
      "score": 59,
      "reward": -997.0,
      "steps": 33,
      "mean_loss": 4745.2195043852835,
      "epsilon": 0.3234190000047245
    },
    {
      "episode": 3639,
      "score": 129,
      "reward": -952.0,
      "steps": 46,
      "mean_loss": 7965.062946817149,
      "epsilon": 0.32337300000472574
    },
    {
      "episode": 3640,
      "score": 143,
      "reward": -920.0,
      "steps": 45,
      "mean_loss": 6467.907828521728,
      "epsilon": 0.32332800000472695
    },
    {
      "episode": 3641,
      "score": 138,
      "reward": -934.0,
      "steps": 51,
      "mean_loss": 4085.735336415908,
      "epsilon": 0.3232770000047283
    },
    {
      "episode": 3642,
      "score": 189,
      "reward": -896.0,
      "steps": 53,
      "mean_loss": 6255.149848794037,
      "epsilon": 0.32322400000472973
    },
    {
      "episode": 3643,
      "score": 99,
      "reward": -953.0,
      "steps": 36,
      "mean_loss": 8530.641149308947,
      "epsilon": 0.3231880000047307
    },
    {
      "episode": 3644,
      "score": 88,
      "reward": -974.0,
      "steps": 37,
      "mean_loss": 2654.777449633624,
      "epsilon": 0.3231510000047317
    },
    {
      "episode": 3645,
      "score": 108,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 3041.8057992571876,
      "epsilon": 0.3231090000047328
    },
    {
      "episode": 3646,
      "score": 179,
      "reward": -907.0,
      "steps": 52,
      "mean_loss": 6347.11336693397,
      "epsilon": 0.3230570000047342
    },
    {
      "episode": 3647,
      "score": 179,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 4694.209616147555,
      "epsilon": 0.3230050000047356
    },
    {
      "episode": 3648,
      "score": 92,
      "reward": -986.0,
      "steps": 40,
      "mean_loss": 3301.0599621772767,
      "epsilon": 0.32296500000473666
    },
    {
      "episode": 3649,
      "score": 166,
      "reward": -905.0,
      "steps": 52,
      "mean_loss": 4455.033052261059,
      "epsilon": 0.32291300000473805
    },
    {
      "episode": 3650,
      "score": 76,
      "reward": -980.0,
      "steps": 34,
      "mean_loss": 3288.4190624461453,
      "epsilon": 0.32287900000473896
    },
    {
      "episode": 3651,
      "score": 169,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 3666.806310044958,
      "epsilon": 0.3228320000047402
    },
    {
      "episode": 3652,
      "score": 303,
      "reward": -803.0,
      "steps": 72,
      "mean_loss": 3838.3932995266387,
      "epsilon": 0.32276000000474214
    },
    {
      "episode": 3653,
      "score": 73,
      "reward": -988.0,
      "steps": 34,
      "mean_loss": 3692.749261856079,
      "epsilon": 0.32272600000474305
    },
    {
      "episode": 3654,
      "score": 189,
      "reward": -898.0,
      "steps": 53,
      "mean_loss": 3560.1742992761,
      "epsilon": 0.32267300000474447
    },
    {
      "episode": 3655,
      "score": 162,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 5317.1681593322755,
      "epsilon": 0.3226230000047458
    },
    {
      "episode": 3656,
      "score": 170,
      "reward": -910.0,
      "steps": 51,
      "mean_loss": 3539.8442306144566,
      "epsilon": 0.3225720000047472
    },
    {
      "episode": 3657,
      "score": 268,
      "reward": -838.0,
      "steps": 64,
      "mean_loss": 7062.488713681698,
      "epsilon": 0.3225080000047489
    },
    {
      "episode": 3658,
      "score": 141,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 6127.533971537714,
      "epsilon": 0.3224620000047501
    },
    {
      "episode": 3659,
      "score": 182,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 6195.909613079495,
      "epsilon": 0.32240800000475156
    },
    {
      "episode": 3660,
      "score": 210,
      "reward": -891.0,
      "steps": 56,
      "mean_loss": 2622.9390509469167,
      "epsilon": 0.32235200000475306
    },
    {
      "episode": 3661,
      "score": 127,
      "reward": -941.0,
      "steps": 44,
      "mean_loss": 3128.511355486783,
      "epsilon": 0.32230800000475424
    },
    {
      "episode": 3662,
      "score": 159,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 2862.3294124214017,
      "epsilon": 0.32225900000475555
    },
    {
      "episode": 3663,
      "score": 123,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 3870.6847099122547,
      "epsilon": 0.32221700000475667
    },
    {
      "episode": 3664,
      "score": 176,
      "reward": -909.0,
      "steps": 50,
      "mean_loss": 1894.6155088424682,
      "epsilon": 0.322167000004758
    },
    {
      "episode": 3665,
      "score": 111,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 5796.70638630002,
      "epsilon": 0.32212400000475916
    },
    {
      "episode": 3666,
      "score": 165,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 4638.50588117327,
      "epsilon": 0.32207500000476047
    },
    {
      "episode": 3667,
      "score": 122,
      "reward": -940.0,
      "steps": 40,
      "mean_loss": 5786.506519889832,
      "epsilon": 0.32203500000476154
    },
    {
      "episode": 3668,
      "score": 122,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 3477.2091301137752,
      "epsilon": 0.3219910000047627
    },
    {
      "episode": 3669,
      "score": 106,
      "reward": -948.0,
      "steps": 39,
      "mean_loss": 5763.855059941609,
      "epsilon": 0.32195200000476376
    },
    {
      "episode": 3670,
      "score": 169,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 6994.915588607788,
      "epsilon": 0.3219020000047651
    },
    {
      "episode": 3671,
      "score": 180,
      "reward": -919.0,
      "steps": 53,
      "mean_loss": 6199.7872807484755,
      "epsilon": 0.3218490000047665
    },
    {
      "episode": 3672,
      "score": 158,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 5291.100787963867,
      "epsilon": 0.32179900000476785
    },
    {
      "episode": 3673,
      "score": 147,
      "reward": -926.0,
      "steps": 45,
      "mean_loss": 3222.427883063422,
      "epsilon": 0.32175400000476906
    },
    {
      "episode": 3674,
      "score": 159,
      "reward": -927.0,
      "steps": 50,
      "mean_loss": 2437.07472114563,
      "epsilon": 0.3217040000047704
    },
    {
      "episode": 3675,
      "score": 269,
      "reward": -852.0,
      "steps": 64,
      "mean_loss": 4291.215945214033,
      "epsilon": 0.3216400000047721
    },
    {
      "episode": 3676,
      "score": 100,
      "reward": -955.0,
      "steps": 38,
      "mean_loss": 4767.464146363108,
      "epsilon": 0.3216020000047731
    },
    {
      "episode": 3677,
      "score": 233,
      "reward": -858.0,
      "steps": 61,
      "mean_loss": 3731.701097206991,
      "epsilon": 0.32154100000477476
    },
    {
      "episode": 3678,
      "score": 195,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 4022.1456392782707,
      "epsilon": 0.3214870000047762
    },
    {
      "episode": 3679,
      "score": 125,
      "reward": -963.0,
      "steps": 46,
      "mean_loss": 1952.128842395285,
      "epsilon": 0.32144100000477743
    },
    {
      "episode": 3680,
      "score": 123,
      "reward": -960.0,
      "steps": 45,
      "mean_loss": 4619.17974887424,
      "epsilon": 0.32139600000477864
    },
    {
      "episode": 3681,
      "score": 165,
      "reward": -925.0,
      "steps": 52,
      "mean_loss": 4799.541438396161,
      "epsilon": 0.32134400000478003
    },
    {
      "episode": 3682,
      "score": 180,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 6435.375303160469,
      "epsilon": 0.32129100000478145
    },
    {
      "episode": 3683,
      "score": 176,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 6241.527210595473,
      "epsilon": 0.32123800000478286
    },
    {
      "episode": 3684,
      "score": 151,
      "reward": -931.0,
      "steps": 47,
      "mean_loss": 4430.805505224999,
      "epsilon": 0.3211910000047841
    },
    {
      "episode": 3685,
      "score": 136,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 4993.47286070154,
      "epsilon": 0.3211440000047854
    },
    {
      "episode": 3686,
      "score": 162,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 5483.331796459123,
      "epsilon": 0.32109300000478674
    },
    {
      "episode": 3687,
      "score": 155,
      "reward": -937.0,
      "steps": 50,
      "mean_loss": 3329.496040878296,
      "epsilon": 0.3210430000047881
    },
    {
      "episode": 3688,
      "score": 180,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 5400.5917813227725,
      "epsilon": 0.3209910000047895
    },
    {
      "episode": 3689,
      "score": 140,
      "reward": -918.0,
      "steps": 41,
      "mean_loss": 2799.753553623106,
      "epsilon": 0.32095000000479057
    },
    {
      "episode": 3690,
      "score": 161,
      "reward": -916.0,
      "steps": 48,
      "mean_loss": 2535.6091841856637,
      "epsilon": 0.32090200000479185
    },
    {
      "episode": 3691,
      "score": 280,
      "reward": -821.0,
      "steps": 69,
      "mean_loss": 4599.362690580064,
      "epsilon": 0.3208330000047937
    },
    {
      "episode": 3692,
      "score": 89,
      "reward": -959.0,
      "steps": 32,
      "mean_loss": 3169.989365696907,
      "epsilon": 0.32080100000479456
    },
    {
      "episode": 3693,
      "score": 205,
      "reward": -901.0,
      "steps": 57,
      "mean_loss": 4647.982684955262,
      "epsilon": 0.3207440000047961
    },
    {
      "episode": 3694,
      "score": 97,
      "reward": -964.0,
      "steps": 36,
      "mean_loss": 5038.120111041599,
      "epsilon": 0.32070800000479704
    },
    {
      "episode": 3695,
      "score": 150,
      "reward": -922.0,
      "steps": 47,
      "mean_loss": 6773.194431954242,
      "epsilon": 0.3206610000047983
    },
    {
      "episode": 3696,
      "score": 162,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 4693.619824371338,
      "epsilon": 0.32061100000479964
    },
    {
      "episode": 3697,
      "score": 189,
      "reward": -876.0,
      "steps": 50,
      "mean_loss": 4855.793151779175,
      "epsilon": 0.320561000004801
    },
    {
      "episode": 3698,
      "score": 196,
      "reward": -877.0,
      "steps": 56,
      "mean_loss": 1784.3652213982173,
      "epsilon": 0.3205050000048025
    },
    {
      "episode": 3699,
      "score": 96,
      "reward": -975.0,
      "steps": 40,
      "mean_loss": 5246.509016227722,
      "epsilon": 0.32046500000480355
    },
    {
      "episode": 3700,
      "score": 128,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 9113.280019972059,
      "epsilon": 0.32042000000480475
    },
    {
      "episode": 3701,
      "score": 122,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 4515.810106147419,
      "epsilon": 0.3203760000048059
    },
    {
      "episode": 3702,
      "score": 132,
      "reward": -947.0,
      "steps": 48,
      "mean_loss": 7535.718000014623,
      "epsilon": 0.3203280000048072
    },
    {
      "episode": 3703,
      "score": 226,
      "reward": -874.0,
      "steps": 58,
      "mean_loss": 8434.84100960041,
      "epsilon": 0.32027000000480876
    },
    {
      "episode": 3704,
      "score": 110,
      "reward": -967.0,
      "steps": 45,
      "mean_loss": 4305.326474846734,
      "epsilon": 0.32022500000480997
    },
    {
      "episode": 3705,
      "score": 231,
      "reward": -887.0,
      "steps": 58,
      "mean_loss": 5819.394357681274,
      "epsilon": 0.3201670000048115
    },
    {
      "episode": 3706,
      "score": 92,
      "reward": -969.0,
      "steps": 35,
      "mean_loss": 5349.482829502651,
      "epsilon": 0.32013200000481246
    },
    {
      "episode": 3707,
      "score": 222,
      "reward": -884.0,
      "steps": 62,
      "mean_loss": 2811.9314471214047,
      "epsilon": 0.3200700000048141
    },
    {
      "episode": 3708,
      "score": 163,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 5195.407483704236,
      "epsilon": 0.3200210000048154
    },
    {
      "episode": 3709,
      "score": 91,
      "reward": -978.0,
      "steps": 39,
      "mean_loss": 3065.6532723842524,
      "epsilon": 0.31998200000481647
    },
    {
      "episode": 3710,
      "score": 114,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 3657.586765003204,
      "epsilon": 0.31994200000481754
    },
    {
      "episode": 3711,
      "score": 167,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 4634.490650863648,
      "epsilon": 0.3198920000048189
    },
    {
      "episode": 3712,
      "score": 191,
      "reward": -878.0,
      "steps": 52,
      "mean_loss": 2732.9108885985156,
      "epsilon": 0.31984000000482027
    },
    {
      "episode": 3713,
      "score": 84,
      "reward": -973.0,
      "steps": 35,
      "mean_loss": 3218.0351625714984,
      "epsilon": 0.3198050000048212
    },
    {
      "episode": 3714,
      "score": 186,
      "reward": -911.0,
      "steps": 54,
      "mean_loss": 4856.316526130394,
      "epsilon": 0.31975100000482265
    },
    {
      "episode": 3715,
      "score": 133,
      "reward": -967.0,
      "steps": 46,
      "mean_loss": 8555.197373763374,
      "epsilon": 0.3197050000048239
    },
    {
      "episode": 3716,
      "score": 130,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 6954.036209626632,
      "epsilon": 0.31966100000482506
    },
    {
      "episode": 3717,
      "score": 179,
      "reward": -894.0,
      "steps": 50,
      "mean_loss": 2870.228601226807,
      "epsilon": 0.3196110000048264
    },
    {
      "episode": 3718,
      "score": 116,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 5276.520871032368,
      "epsilon": 0.3195670000048276
    },
    {
      "episode": 3719,
      "score": 12,
      "reward": -1012.0,
      "steps": 15,
      "mean_loss": 1615.9804387410481,
      "epsilon": 0.319552000004828
    },
    {
      "episode": 3720,
      "score": 160,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 4914.66720046997,
      "epsilon": 0.3195020000048293
    },
    {
      "episode": 3721,
      "score": 129,
      "reward": -931.0,
      "steps": 46,
      "mean_loss": 4598.37834648464,
      "epsilon": 0.31945600000483054
    },
    {
      "episode": 3722,
      "score": 171,
      "reward": -898.0,
      "steps": 50,
      "mean_loss": 5786.131040420532,
      "epsilon": 0.3194060000048319
    },
    {
      "episode": 3723,
      "score": 121,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 4946.877668931749,
      "epsilon": 0.3193610000048331
    },
    {
      "episode": 3724,
      "score": 242,
      "reward": -857.0,
      "steps": 62,
      "mean_loss": 3734.7433472910234,
      "epsilon": 0.31929900000483474
    },
    {
      "episode": 3725,
      "score": 24,
      "reward": -993.0,
      "steps": 17,
      "mean_loss": 3102.4619636535645,
      "epsilon": 0.3192820000048352
    },
    {
      "episode": 3726,
      "score": 166,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 6336.303251149703,
      "epsilon": 0.3192330000048365
    },
    {
      "episode": 3727,
      "score": 118,
      "reward": -962.0,
      "steps": 45,
      "mean_loss": 3983.104746585422,
      "epsilon": 0.3191880000048377
    },
    {
      "episode": 3728,
      "score": 134,
      "reward": -940.0,
      "steps": 46,
      "mean_loss": 4359.0518501115885,
      "epsilon": 0.31914200000483894
    },
    {
      "episode": 3729,
      "score": 293,
      "reward": -821.0,
      "steps": 69,
      "mean_loss": 3432.309328936148,
      "epsilon": 0.3190730000048408
    },
    {
      "episode": 3730,
      "score": 168,
      "reward": -908.0,
      "steps": 49,
      "mean_loss": 4590.193402815838,
      "epsilon": 0.3190240000048421
    },
    {
      "episode": 3731,
      "score": 234,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 5462.70045451114,
      "epsilon": 0.3189670000048436
    },
    {
      "episode": 3732,
      "score": 110,
      "reward": -949.0,
      "steps": 40,
      "mean_loss": 4852.518800640106,
      "epsilon": 0.3189270000048447
    },
    {
      "episode": 3733,
      "score": 191,
      "reward": -872.0,
      "steps": 53,
      "mean_loss": 4991.72934744493,
      "epsilon": 0.3188740000048461
    },
    {
      "episode": 3734,
      "score": 27,
      "reward": -994.0,
      "steps": 17,
      "mean_loss": 5309.17692341524,
      "epsilon": 0.31885700000484657
    },
    {
      "episode": 3735,
      "score": 165,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 5520.890519409179,
      "epsilon": 0.3188070000048479
    },
    {
      "episode": 3736,
      "score": 91,
      "reward": -988.0,
      "steps": 43,
      "mean_loss": 5067.676813347395,
      "epsilon": 0.31876400000484906
    },
    {
      "episode": 3737,
      "score": 124,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 4084.6287427382035,
      "epsilon": 0.31872000000485023
    },
    {
      "episode": 3738,
      "score": 145,
      "reward": -921.0,
      "steps": 44,
      "mean_loss": 4675.553933273663,
      "epsilon": 0.3186760000048514
    },
    {
      "episode": 3739,
      "score": 200,
      "reward": -886.0,
      "steps": 56,
      "mean_loss": 3791.6664569718496,
      "epsilon": 0.3186200000048529
    },
    {
      "episode": 3740,
      "score": 175,
      "reward": -909.0,
      "steps": 50,
      "mean_loss": 4561.590744819641,
      "epsilon": 0.31857000000485425
    },
    {
      "episode": 3741,
      "score": 247,
      "reward": -859.0,
      "steps": 61,
      "mean_loss": 3886.9182021344295,
      "epsilon": 0.3185090000048559
    },
    {
      "episode": 3742,
      "score": 140,
      "reward": -933.0,
      "steps": 45,
      "mean_loss": 5333.30675438775,
      "epsilon": 0.3184640000048571
    },
    {
      "episode": 3743,
      "score": 159,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 2751.4502745609657,
      "epsilon": 0.31841300000485845
    },
    {
      "episode": 3744,
      "score": 125,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 4597.303104968782,
      "epsilon": 0.3183660000048597
    },
    {
      "episode": 3745,
      "score": 94,
      "reward": -967.0,
      "steps": 37,
      "mean_loss": 1984.1158852448334,
      "epsilon": 0.3183290000048607
    },
    {
      "episode": 3746,
      "score": 102,
      "reward": -985.0,
      "steps": 43,
      "mean_loss": 5512.777970070063,
      "epsilon": 0.31828600000486185
    },
    {
      "episode": 3747,
      "score": 301,
      "reward": -801.0,
      "steps": 71,
      "mean_loss": 7726.711243427975,
      "epsilon": 0.31821500000486375
    },
    {
      "episode": 3748,
      "score": 125,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 6310.5402373419865,
      "epsilon": 0.31817000000486495
    },
    {
      "episode": 3749,
      "score": 149,
      "reward": -946.0,
      "steps": 50,
      "mean_loss": 5295.406308097839,
      "epsilon": 0.3181200000048663
    },
    {
      "episode": 3750,
      "score": 119,
      "reward": -947.0,
      "steps": 37,
      "mean_loss": 5674.014291917955,
      "epsilon": 0.3180830000048673
    },
    {
      "episode": 3751,
      "score": 167,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 6210.525523300171,
      "epsilon": 0.3180330000048686
    },
    {
      "episode": 3752,
      "score": 220,
      "reward": -878.0,
      "steps": 60,
      "mean_loss": 3228.6881015141803,
      "epsilon": 0.3179730000048702
    },
    {
      "episode": 3753,
      "score": 153,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 4574.590727217654,
      "epsilon": 0.3179260000048715
    },
    {
      "episode": 3754,
      "score": 149,
      "reward": -922.0,
      "steps": 47,
      "mean_loss": 8864.385321353344,
      "epsilon": 0.31787900000487274
    },
    {
      "episode": 3755,
      "score": 162,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 2689.978522936503,
      "epsilon": 0.317831000004874
    },
    {
      "episode": 3756,
      "score": 92,
      "reward": -982.0,
      "steps": 38,
      "mean_loss": 4440.2602934586375,
      "epsilon": 0.31779300000487504
    },
    {
      "episode": 3757,
      "score": 138,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 5365.074678296628,
      "epsilon": 0.31774700000487627
    },
    {
      "episode": 3758,
      "score": 100,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 5355.320772868831,
      "epsilon": 0.31770600000487736
    },
    {
      "episode": 3759,
      "score": 164,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 6513.201634483337,
      "epsilon": 0.3176560000048787
    },
    {
      "episode": 3760,
      "score": 111,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 8236.001785189606,
      "epsilon": 0.31761300000487985
    },
    {
      "episode": 3761,
      "score": 131,
      "reward": -940.0,
      "steps": 42,
      "mean_loss": 5266.229356856573,
      "epsilon": 0.317571000004881
    },
    {
      "episode": 3762,
      "score": 114,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 4432.189492180234,
      "epsilon": 0.3175290000048821
    },
    {
      "episode": 3763,
      "score": 132,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 3372.6167708457783,
      "epsilon": 0.31748200000488336
    },
    {
      "episode": 3764,
      "score": 266,
      "reward": -844.0,
      "steps": 65,
      "mean_loss": 2517.4952067155104,
      "epsilon": 0.3174170000048851
    },
    {
      "episode": 3765,
      "score": 150,
      "reward": -937.0,
      "steps": 52,
      "mean_loss": 3629.800795701834,
      "epsilon": 0.3173650000048865
    },
    {
      "episode": 3766,
      "score": 116,
      "reward": -954.0,
      "steps": 42,
      "mean_loss": 4017.3471400851295,
      "epsilon": 0.3173230000048876
    },
    {
      "episode": 3767,
      "score": 149,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 1695.4186940987904,
      "epsilon": 0.3172750000048889
    },
    {
      "episode": 3768,
      "score": 177,
      "reward": -904.0,
      "steps": 49,
      "mean_loss": 1404.184638509945,
      "epsilon": 0.3172260000048902
    },
    {
      "episode": 3769,
      "score": 63,
      "reward": -978.0,
      "steps": 27,
      "mean_loss": 5756.169094792119,
      "epsilon": 0.31719900000489093
    },
    {
      "episode": 3770,
      "score": 163,
      "reward": -932.0,
      "steps": 53,
      "mean_loss": 2488.1195399446306,
      "epsilon": 0.31714600000489235
    },
    {
      "episode": 3771,
      "score": 98,
      "reward": -971.0,
      "steps": 41,
      "mean_loss": 3905.149303808445,
      "epsilon": 0.31710500000489344
    },
    {
      "episode": 3772,
      "score": 96,
      "reward": -962.0,
      "steps": 36,
      "mean_loss": 3147.402385817634,
      "epsilon": 0.3170690000048944
    },
    {
      "episode": 3773,
      "score": 126,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 2800.6971204931087,
      "epsilon": 0.3170250000048956
    },
    {
      "episode": 3774,
      "score": 108,
      "reward": -976.0,
      "steps": 44,
      "mean_loss": 7225.013130014593,
      "epsilon": 0.31698100000489676
    },
    {
      "episode": 3775,
      "score": 190,
      "reward": -917.0,
      "steps": 53,
      "mean_loss": 4178.1897122725,
      "epsilon": 0.3169280000048982
    },
    {
      "episode": 3776,
      "score": 162,
      "reward": -912.0,
      "steps": 47,
      "mean_loss": 2474.2973766732725,
      "epsilon": 0.31688100000489944
    },
    {
      "episode": 3777,
      "score": 256,
      "reward": -860.0,
      "steps": 66,
      "mean_loss": 1700.506464062315,
      "epsilon": 0.3168150000049012
    },
    {
      "episode": 3778,
      "score": 112,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 9692.022778164257,
      "epsilon": 0.3167710000049024
    },
    {
      "episode": 3779,
      "score": 146,
      "reward": -929.0,
      "steps": 47,
      "mean_loss": 2538.3131090529423,
      "epsilon": 0.31672400000490364
    },
    {
      "episode": 3780,
      "score": 240,
      "reward": -862.0,
      "steps": 62,
      "mean_loss": 3804.237536891814,
      "epsilon": 0.3166620000049053
    },
    {
      "episode": 3781,
      "score": 146,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 7517.195120970408,
      "epsilon": 0.3166140000049066
    },
    {
      "episode": 3782,
      "score": 81,
      "reward": -978.0,
      "steps": 37,
      "mean_loss": 2828.966456645244,
      "epsilon": 0.31657700000490757
    },
    {
      "episode": 3783,
      "score": 190,
      "reward": -882.0,
      "steps": 52,
      "mean_loss": 3737.0624832740195,
      "epsilon": 0.31652500000490896
    },
    {
      "episode": 3784,
      "score": 226,
      "reward": -858.0,
      "steps": 53,
      "mean_loss": 5102.5944223224,
      "epsilon": 0.3164720000049104
    },
    {
      "episode": 3785,
      "score": 126,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 5614.4880737954,
      "epsilon": 0.31642500000491164
    },
    {
      "episode": 3786,
      "score": 117,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 3963.6421442667643,
      "epsilon": 0.31638000000491284
    },
    {
      "episode": 3787,
      "score": 282,
      "reward": -821.0,
      "steps": 68,
      "mean_loss": 5671.877514783074,
      "epsilon": 0.31631200000491466
    },
    {
      "episode": 3788,
      "score": 128,
      "reward": -939.0,
      "steps": 43,
      "mean_loss": 2965.1452553327695,
      "epsilon": 0.3162690000049158
    },
    {
      "episode": 3789,
      "score": 146,
      "reward": -927.0,
      "steps": 45,
      "mean_loss": 4724.60303416782,
      "epsilon": 0.316224000004917
    },
    {
      "episode": 3790,
      "score": 99,
      "reward": -974.0,
      "steps": 38,
      "mean_loss": 6176.414286964818,
      "epsilon": 0.31618600000491803
    },
    {
      "episode": 3791,
      "score": 166,
      "reward": -894.0,
      "steps": 47,
      "mean_loss": 5074.493439451177,
      "epsilon": 0.3161390000049193
    },
    {
      "episode": 3792,
      "score": 146,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 6266.315029059516,
      "epsilon": 0.3160940000049205
    },
    {
      "episode": 3793,
      "score": 172,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 2749.556992034912,
      "epsilon": 0.31604400000492183
    },
    {
      "episode": 3794,
      "score": 140,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 5976.130219936371,
      "epsilon": 0.3159960000049231
    },
    {
      "episode": 3795,
      "score": 163,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 3803.5768828582763,
      "epsilon": 0.31594600000492445
    },
    {
      "episode": 3796,
      "score": 127,
      "reward": -955.0,
      "steps": 46,
      "mean_loss": 2256.908789095671,
      "epsilon": 0.3159000000049257
    },
    {
      "episode": 3797,
      "score": 265,
      "reward": -842.0,
      "steps": 62,
      "mean_loss": 4305.235815478909,
      "epsilon": 0.31583800000492734
    },
    {
      "episode": 3798,
      "score": 144,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 5548.004166350072,
      "epsilon": 0.31578900000492865
    },
    {
      "episode": 3799,
      "score": 121,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 1128.6913338574495,
      "epsilon": 0.31574500000492983
    },
    {
      "episode": 3800,
      "score": 180,
      "reward": -890.0,
      "steps": 52,
      "mean_loss": 3247.628675387456,
      "epsilon": 0.3156930000049312
    },
    {
      "episode": 3801,
      "score": 153,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 3372.8634128570557,
      "epsilon": 0.31564300000493256
    },
    {
      "episode": 3802,
      "score": 150,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 3849.257424724345,
      "epsilon": 0.3155940000049339
    },
    {
      "episode": 3803,
      "score": 141,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 6445.46908864108,
      "epsilon": 0.31555000000493505
    },
    {
      "episode": 3804,
      "score": 148,
      "reward": -943.0,
      "steps": 49,
      "mean_loss": 7864.859039851597,
      "epsilon": 0.31550100000493636
    },
    {
      "episode": 3805,
      "score": 160,
      "reward": -925.0,
      "steps": 51,
      "mean_loss": 4647.026722328335,
      "epsilon": 0.3154500000049377
    },
    {
      "episode": 3806,
      "score": 162,
      "reward": -917.0,
      "steps": 50,
      "mean_loss": 6559.544793243408,
      "epsilon": 0.31540000000493906
    },
    {
      "episode": 3807,
      "score": 136,
      "reward": -936.0,
      "steps": 46,
      "mean_loss": 4678.089211754177,
      "epsilon": 0.3153540000049403
    },
    {
      "episode": 3808,
      "score": 122,
      "reward": -949.0,
      "steps": 45,
      "mean_loss": 6238.833036380344,
      "epsilon": 0.3153090000049415
    },
    {
      "episode": 3809,
      "score": 167,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 4830.418932266235,
      "epsilon": 0.31525900000494284
    },
    {
      "episode": 3810,
      "score": 119,
      "reward": -940.0,
      "steps": 41,
      "mean_loss": 3862.9735846170565,
      "epsilon": 0.31521800000494393
    },
    {
      "episode": 3811,
      "score": 127,
      "reward": -931.0,
      "steps": 42,
      "mean_loss": 4120.295525505429,
      "epsilon": 0.31517600000494506
    },
    {
      "episode": 3812,
      "score": 228,
      "reward": -879.0,
      "steps": 61,
      "mean_loss": 2660.022113237225,
      "epsilon": 0.3151150000049467
    },
    {
      "episode": 3813,
      "score": 131,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 2250.2149460419364,
      "epsilon": 0.3150690000049479
    },
    {
      "episode": 3814,
      "score": 158,
      "reward": -925.0,
      "steps": 51,
      "mean_loss": 6010.414921330471,
      "epsilon": 0.3150180000049493
    },
    {
      "episode": 3815,
      "score": 94,
      "reward": -971.0,
      "steps": 36,
      "mean_loss": 2901.694919056363,
      "epsilon": 0.31498200000495025
    },
    {
      "episode": 3816,
      "score": 144,
      "reward": -937.0,
      "steps": 46,
      "mean_loss": 5282.265628980554,
      "epsilon": 0.3149360000049515
    },
    {
      "episode": 3817,
      "score": 132,
      "reward": -936.0,
      "steps": 43,
      "mean_loss": 3133.5509379187297,
      "epsilon": 0.31489300000495263
    },
    {
      "episode": 3818,
      "score": 162,
      "reward": -922.0,
      "steps": 49,
      "mean_loss": 5593.886248919429,
      "epsilon": 0.31484400000495394
    },
    {
      "episode": 3819,
      "score": 215,
      "reward": -875.0,
      "steps": 60,
      "mean_loss": 5404.583016967774,
      "epsilon": 0.31478400000495554
    },
    {
      "episode": 3820,
      "score": 158,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 5180.734813534484,
      "epsilon": 0.31473500000495686
    },
    {
      "episode": 3821,
      "score": 143,
      "reward": -941.0,
      "steps": 49,
      "mean_loss": 6934.937301791444,
      "epsilon": 0.31468600000495817
    },
    {
      "episode": 3822,
      "score": 119,
      "reward": -938.0,
      "steps": 41,
      "mean_loss": 3680.7913133574693,
      "epsilon": 0.31464500000495926
    },
    {
      "episode": 3823,
      "score": 151,
      "reward": -922.0,
      "steps": 45,
      "mean_loss": 6200.646583048502,
      "epsilon": 0.31460000000496047
    },
    {
      "episode": 3824,
      "score": 229,
      "reward": -868.0,
      "steps": 58,
      "mean_loss": 4082.566739772928,
      "epsilon": 0.314542000004962
    },
    {
      "episode": 3825,
      "score": 185,
      "reward": -916.0,
      "steps": 53,
      "mean_loss": 5727.809775658374,
      "epsilon": 0.31448900000496344
    },
    {
      "episode": 3826,
      "score": 158,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 2732.684844017029,
      "epsilon": 0.3144410000049647
    },
    {
      "episode": 3827,
      "score": 107,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 5091.53757704758,
      "epsilon": 0.3144000000049658
    },
    {
      "episode": 3828,
      "score": 81,
      "reward": -977.0,
      "steps": 37,
      "mean_loss": 4282.682228603879,
      "epsilon": 0.3143630000049668
    },
    {
      "episode": 3829,
      "score": 132,
      "reward": -945.0,
      "steps": 45,
      "mean_loss": 3514.373974609375,
      "epsilon": 0.314318000004968
    },
    {
      "episode": 3830,
      "score": 284,
      "reward": -863.0,
      "steps": 68,
      "mean_loss": 3241.7851033491247,
      "epsilon": 0.31425000000496983
    },
    {
      "episode": 3831,
      "score": 236,
      "reward": -878.0,
      "steps": 62,
      "mean_loss": 4913.4141301185855,
      "epsilon": 0.3141880000049715
    },
    {
      "episode": 3832,
      "score": 101,
      "reward": -971.0,
      "steps": 44,
      "mean_loss": 4304.040492274545,
      "epsilon": 0.31414400000497267
    },
    {
      "episode": 3833,
      "score": 197,
      "reward": -896.0,
      "steps": 56,
      "mean_loss": 3906.2099749701365,
      "epsilon": 0.31408800000497417
    },
    {
      "episode": 3834,
      "score": 192,
      "reward": -896.0,
      "steps": 53,
      "mean_loss": 6242.724854091428,
      "epsilon": 0.3140350000049756
    },
    {
      "episode": 3835,
      "score": 78,
      "reward": -1002.0,
      "steps": 39,
      "mean_loss": 1358.9396137335361,
      "epsilon": 0.3139960000049766
    },
    {
      "episode": 3836,
      "score": 254,
      "reward": -858.0,
      "steps": 62,
      "mean_loss": 4042.1886886473626,
      "epsilon": 0.3139340000049783
    },
    {
      "episode": 3837,
      "score": 203,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 3587.321724149916,
      "epsilon": 0.31388000000497973
    },
    {
      "episode": 3838,
      "score": 146,
      "reward": -920.0,
      "steps": 44,
      "mean_loss": 2348.7124163454228,
      "epsilon": 0.3138360000049809
    },
    {
      "episode": 3839,
      "score": 263,
      "reward": -841.0,
      "steps": 63,
      "mean_loss": 6410.414087991866,
      "epsilon": 0.3137730000049826
    },
    {
      "episode": 3840,
      "score": 179,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 3746.955279643719,
      "epsilon": 0.313721000004984
    },
    {
      "episode": 3841,
      "score": 199,
      "reward": -865.0,
      "steps": 50,
      "mean_loss": 6410.853917312622,
      "epsilon": 0.3136710000049853
    },
    {
      "episode": 3842,
      "score": 130,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 3310.8194567362466,
      "epsilon": 0.3136230000049866
    },
    {
      "episode": 3843,
      "score": 19,
      "reward": -1001.0,
      "steps": 16,
      "mean_loss": 3336.4534640312195,
      "epsilon": 0.31360700000498704
    },
    {
      "episode": 3844,
      "score": 112,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 3007.3106150627136,
      "epsilon": 0.3135630000049882
    },
    {
      "episode": 3845,
      "score": 86,
      "reward": -963.0,
      "steps": 35,
      "mean_loss": 6683.294466509138,
      "epsilon": 0.31352800000498915
    },
    {
      "episode": 3846,
      "score": 135,
      "reward": -934.0,
      "steps": 46,
      "mean_loss": 3735.287901007611,
      "epsilon": 0.3134820000049904
    },
    {
      "episode": 3847,
      "score": 156,
      "reward": -936.0,
      "steps": 46,
      "mean_loss": 5037.162389423536,
      "epsilon": 0.3134360000049916
    },
    {
      "episode": 3848,
      "score": 156,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 4716.0674710083,
      "epsilon": 0.31338600000499295
    },
    {
      "episode": 3849,
      "score": 153,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 4757.824973185857,
      "epsilon": 0.31333800000499423
    },
    {
      "episode": 3850,
      "score": 135,
      "reward": -938.0,
      "steps": 40,
      "mean_loss": 4809.99998588562,
      "epsilon": 0.3132980000049953
    },
    {
      "episode": 3851,
      "score": 131,
      "reward": -932.0,
      "steps": 45,
      "mean_loss": 3996.9665668911402,
      "epsilon": 0.3132530000049965
    },
    {
      "episode": 3852,
      "score": 122,
      "reward": -959.0,
      "steps": 45,
      "mean_loss": 3063.2004954867894,
      "epsilon": 0.3132080000049977
    },
    {
      "episode": 3853,
      "score": 157,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 2977.1648157368536,
      "epsilon": 0.31316200000499894
    },
    {
      "episode": 3854,
      "score": 139,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 3039.1104094982147,
      "epsilon": 0.3131140000050002
    },
    {
      "episode": 3855,
      "score": 118,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 8439.355520161715,
      "epsilon": 0.3130700000050014
    },
    {
      "episode": 3856,
      "score": 165,
      "reward": -907.0,
      "steps": 47,
      "mean_loss": 2492.1887194856686,
      "epsilon": 0.31302300000500266
    },
    {
      "episode": 3857,
      "score": 190,
      "reward": -902.0,
      "steps": 55,
      "mean_loss": 5260.432154430043,
      "epsilon": 0.31296800000500413
    },
    {
      "episode": 3858,
      "score": 243,
      "reward": -856.0,
      "steps": 61,
      "mean_loss": 4029.190487095567,
      "epsilon": 0.31290700000500576
    },
    {
      "episode": 3859,
      "score": 192,
      "reward": -898.0,
      "steps": 54,
      "mean_loss": 4053.871965690895,
      "epsilon": 0.3128530000050072
    },
    {
      "episode": 3860,
      "score": 109,
      "reward": -958.0,
      "steps": 39,
      "mean_loss": 3618.26353033995,
      "epsilon": 0.31281400000500825
    },
    {
      "episode": 3861,
      "score": 122,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 4088.808099300303,
      "epsilon": 0.3127670000050095
    },
    {
      "episode": 3862,
      "score": 58,
      "reward": -1003.0,
      "steps": 31,
      "mean_loss": 4396.154587161156,
      "epsilon": 0.31273600000501034
    },
    {
      "episode": 3863,
      "score": 254,
      "reward": -854.0,
      "steps": 62,
      "mean_loss": 4945.993120131954,
      "epsilon": 0.312674000005012
    },
    {
      "episode": 3864,
      "score": 179,
      "reward": -910.0,
      "steps": 53,
      "mean_loss": 1297.461544684644,
      "epsilon": 0.3126210000050134
    },
    {
      "episode": 3865,
      "score": 150,
      "reward": -921.0,
      "steps": 44,
      "mean_loss": 3537.7476797970858,
      "epsilon": 0.3125770000050146
    },
    {
      "episode": 3866,
      "score": 52,
      "reward": -1021.0,
      "steps": 32,
      "mean_loss": 5134.444198966026,
      "epsilon": 0.31254500000501545
    },
    {
      "episode": 3867,
      "score": 151,
      "reward": -962.0,
      "steps": 45,
      "mean_loss": 6043.484855567084,
      "epsilon": 0.31250000000501665
    },
    {
      "episode": 3868,
      "score": 176,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 3732.4141917052093,
      "epsilon": 0.3124460000050181
    },
    {
      "episode": 3869,
      "score": 155,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 5699.642708019334,
      "epsilon": 0.3123970000050194
    },
    {
      "episode": 3870,
      "score": 148,
      "reward": -935.0,
      "steps": 47,
      "mean_loss": 2416.2932579365183,
      "epsilon": 0.31235000000502067
    },
    {
      "episode": 3871,
      "score": 226,
      "reward": -864.0,
      "steps": 58,
      "mean_loss": 5750.763506659146,
      "epsilon": 0.3122920000050222
    },
    {
      "episode": 3872,
      "score": 121,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 3645.155325456099,
      "epsilon": 0.3122480000050234
    },
    {
      "episode": 3873,
      "score": 253,
      "reward": -844.0,
      "steps": 61,
      "mean_loss": 5394.188367937432,
      "epsilon": 0.31218700000502503
    },
    {
      "episode": 3874,
      "score": 230,
      "reward": -855.0,
      "steps": 60,
      "mean_loss": 4540.721093241374,
      "epsilon": 0.31212700000502663
    },
    {
      "episode": 3875,
      "score": 185,
      "reward": -889.0,
      "steps": 52,
      "mean_loss": 4055.534781235915,
      "epsilon": 0.312075000005028
    },
    {
      "episode": 3876,
      "score": 170,
      "reward": -909.0,
      "steps": 48,
      "mean_loss": 4071.4462081193924,
      "epsilon": 0.3120270000050293
    },
    {
      "episode": 3877,
      "score": 12,
      "reward": -1013.0,
      "steps": 16,
      "mean_loss": 3216.583172559738,
      "epsilon": 0.31201100000502974
    },
    {
      "episode": 3878,
      "score": 89,
      "reward": -976.0,
      "steps": 39,
      "mean_loss": 6361.299142201741,
      "epsilon": 0.3119720000050308
    },
    {
      "episode": 3879,
      "score": 217,
      "reward": -872.0,
      "steps": 54,
      "mean_loss": 5442.28817014341,
      "epsilon": 0.3119180000050322
    },
    {
      "episode": 3880,
      "score": 199,
      "reward": -880.0,
      "steps": 51,
      "mean_loss": 3464.9972680035758,
      "epsilon": 0.3118670000050336
    },
    {
      "episode": 3881,
      "score": 157,
      "reward": -940.0,
      "steps": 52,
      "mean_loss": 3738.6298971176147,
      "epsilon": 0.311815000005035
    },
    {
      "episode": 3882,
      "score": 244,
      "reward": -870.0,
      "steps": 63,
      "mean_loss": 5209.831105822608,
      "epsilon": 0.31175200000503667
    },
    {
      "episode": 3883,
      "score": 147,
      "reward": -947.0,
      "steps": 49,
      "mean_loss": 6112.004144551803,
      "epsilon": 0.311703000005038
    },
    {
      "episode": 3884,
      "score": 184,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 4424.519756529066,
      "epsilon": 0.3116490000050394
    },
    {
      "episode": 3885,
      "score": 240,
      "reward": -852.0,
      "steps": 60,
      "mean_loss": 3179.9033782958986,
      "epsilon": 0.31158900000504103
    },
    {
      "episode": 3886,
      "score": 173,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 4883.419898529053,
      "epsilon": 0.31153900000504237
    },
    {
      "episode": 3887,
      "score": 134,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 6834.004339131442,
      "epsilon": 0.31149500000504354
    },
    {
      "episode": 3888,
      "score": 153,
      "reward": -940.0,
      "steps": 50,
      "mean_loss": 2702.949703063965,
      "epsilon": 0.3114450000050449
    },
    {
      "episode": 3889,
      "score": 165,
      "reward": -908.0,
      "steps": 48,
      "mean_loss": 4098.484952529271,
      "epsilon": 0.31139700000504617
    },
    {
      "episode": 3890,
      "score": 159,
      "reward": -910.0,
      "steps": 47,
      "mean_loss": 5436.865082192929,
      "epsilon": 0.3113500000050474
    },
    {
      "episode": 3891,
      "score": 150,
      "reward": -966.0,
      "steps": 50,
      "mean_loss": 1943.2650463104249,
      "epsilon": 0.31130000000504876
    },
    {
      "episode": 3892,
      "score": 68,
      "reward": -995.0,
      "steps": 34,
      "mean_loss": 3769.6151342952953,
      "epsilon": 0.31126600000504967
    },
    {
      "episode": 3893,
      "score": 173,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 3651.284309350527,
      "epsilon": 0.31121400000505106
    },
    {
      "episode": 3894,
      "score": 184,
      "reward": -901.0,
      "steps": 54,
      "mean_loss": 3607.6313097918473,
      "epsilon": 0.3111600000050525
    },
    {
      "episode": 3895,
      "score": 123,
      "reward": -981.0,
      "steps": 45,
      "mean_loss": 3752.741169908312,
      "epsilon": 0.3111150000050537
    },
    {
      "episode": 3896,
      "score": 97,
      "reward": -967.0,
      "steps": 35,
      "mean_loss": 8682.932061440604,
      "epsilon": 0.31108000000505465
    },
    {
      "episode": 3897,
      "score": 85,
      "reward": -983.0,
      "steps": 39,
      "mean_loss": 3973.9680727934224,
      "epsilon": 0.3110410000050557
    },
    {
      "episode": 3898,
      "score": 171,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 3939.9056937408445,
      "epsilon": 0.31099100000505703
    },
    {
      "episode": 3899,
      "score": 211,
      "reward": -868.0,
      "steps": 56,
      "mean_loss": 3834.4134351866587,
      "epsilon": 0.3109350000050585
    },
    {
      "episode": 3900,
      "score": 102,
      "reward": -975.0,
      "steps": 40,
      "mean_loss": 5685.934478616715,
      "epsilon": 0.3108950000050596
    },
    {
      "episode": 3901,
      "score": 153,
      "reward": -932.0,
      "steps": 50,
      "mean_loss": 4150.810296173096,
      "epsilon": 0.31084500000506093
    },
    {
      "episode": 3902,
      "score": 176,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 2685.843284023051,
      "epsilon": 0.31079600000506225
    },
    {
      "episode": 3903,
      "score": 124,
      "reward": -950.0,
      "steps": 42,
      "mean_loss": 3775.690373738607,
      "epsilon": 0.31075400000506337
    },
    {
      "episode": 3904,
      "score": 122,
      "reward": -954.0,
      "steps": 47,
      "mean_loss": 3311.907818611632,
      "epsilon": 0.3107070000050646
    },
    {
      "episode": 3905,
      "score": 128,
      "reward": -947.0,
      "steps": 48,
      "mean_loss": 4481.175861040751,
      "epsilon": 0.3106590000050659
    },
    {
      "episode": 3906,
      "score": 105,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 5193.234783263433,
      "epsilon": 0.31061700000506703
    },
    {
      "episode": 3907,
      "score": 253,
      "reward": -855.0,
      "steps": 66,
      "mean_loss": 3484.587219353878,
      "epsilon": 0.3105510000050688
    },
    {
      "episode": 3908,
      "score": 69,
      "reward": -988.0,
      "steps": 31,
      "mean_loss": 5361.275232376591,
      "epsilon": 0.31052000000506963
    },
    {
      "episode": 3909,
      "score": 141,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 4427.590008187802,
      "epsilon": 0.3104730000050709
    },
    {
      "episode": 3910,
      "score": 267,
      "reward": -853.0,
      "steps": 68,
      "mean_loss": 6175.764305675731,
      "epsilon": 0.3104050000050727
    },
    {
      "episode": 3911,
      "score": 115,
      "reward": -951.0,
      "steps": 42,
      "mean_loss": 4115.612729390462,
      "epsilon": 0.31036300000507383
    },
    {
      "episode": 3912,
      "score": 182,
      "reward": -901.0,
      "steps": 51,
      "mean_loss": 5018.509765924192,
      "epsilon": 0.3103120000050752
    },
    {
      "episode": 3913,
      "score": 156,
      "reward": -927.0,
      "steps": 49,
      "mean_loss": 5858.397914652922,
      "epsilon": 0.3102630000050765
    },
    {
      "episode": 3914,
      "score": 210,
      "reward": -894.0,
      "steps": 55,
      "mean_loss": 3464.2874292547053,
      "epsilon": 0.310208000005078
    },
    {
      "episode": 3915,
      "score": 101,
      "reward": -975.0,
      "steps": 40,
      "mean_loss": 2354.437060022354,
      "epsilon": 0.31016800000507905
    },
    {
      "episode": 3916,
      "score": 85,
      "reward": -981.0,
      "steps": 36,
      "mean_loss": 5284.6868272357515,
      "epsilon": 0.31013200000508
    },
    {
      "episode": 3917,
      "score": 208,
      "reward": -897.0,
      "steps": 57,
      "mean_loss": 4768.026380037007,
      "epsilon": 0.31007500000508154
    },
    {
      "episode": 3918,
      "score": 180,
      "reward": -892.0,
      "steps": 51,
      "mean_loss": 4963.913361343683,
      "epsilon": 0.3100240000050829
    },
    {
      "episode": 3919,
      "score": 178,
      "reward": -912.0,
      "steps": 51,
      "mean_loss": 4341.481182098389,
      "epsilon": 0.30997300000508426
    },
    {
      "episode": 3920,
      "score": 140,
      "reward": -952.0,
      "steps": 48,
      "mean_loss": 2825.7326215108237,
      "epsilon": 0.30992500000508555
    },
    {
      "episode": 3921,
      "score": 64,
      "reward": -985.0,
      "steps": 32,
      "mean_loss": 2420.268187582493,
      "epsilon": 0.3098930000050864
    },
    {
      "episode": 3922,
      "score": 103,
      "reward": -984.0,
      "steps": 42,
      "mean_loss": 4140.945335569836,
      "epsilon": 0.30985100000508753
    },
    {
      "episode": 3923,
      "score": 104,
      "reward": -953.0,
      "steps": 39,
      "mean_loss": 7676.781237382155,
      "epsilon": 0.3098120000050886
    },
    {
      "episode": 3924,
      "score": 297,
      "reward": -820.0,
      "steps": 69,
      "mean_loss": 2835.716253944065,
      "epsilon": 0.3097430000050904
    },
    {
      "episode": 3925,
      "score": 207,
      "reward": -893.0,
      "steps": 56,
      "mean_loss": 1546.1946412495204,
      "epsilon": 0.3096870000050919
    },
    {
      "episode": 3926,
      "score": 102,
      "reward": -966.0,
      "steps": 37,
      "mean_loss": 5757.46840757937,
      "epsilon": 0.3096500000050929
    },
    {
      "episode": 3927,
      "score": 105,
      "reward": -972.0,
      "steps": 44,
      "mean_loss": 3149.25823653828,
      "epsilon": 0.3096060000050941
    },
    {
      "episode": 3928,
      "score": 116,
      "reward": -963.0,
      "steps": 45,
      "mean_loss": 4446.609254964193,
      "epsilon": 0.3095610000050953
    },
    {
      "episode": 3929,
      "score": 93,
      "reward": -973.0,
      "steps": 36,
      "mean_loss": 6481.176094320085,
      "epsilon": 0.30952500000509625
    },
    {
      "episode": 3930,
      "score": 169,
      "reward": -919.0,
      "steps": 52,
      "mean_loss": 5718.903475761414,
      "epsilon": 0.30947300000509764
    },
    {
      "episode": 3931,
      "score": 185,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 5699.573668641864,
      "epsilon": 0.30942000000509906
    },
    {
      "episode": 3932,
      "score": 72,
      "reward": -972.0,
      "steps": 30,
      "mean_loss": 5649.043847783407,
      "epsilon": 0.30939000000509986
    },
    {
      "episode": 3933,
      "score": 133,
      "reward": -948.0,
      "steps": 46,
      "mean_loss": 5944.961410024892,
      "epsilon": 0.3093440000051011
    },
    {
      "episode": 3934,
      "score": 228,
      "reward": -859.0,
      "steps": 57,
      "mean_loss": 4970.568733549954,
      "epsilon": 0.3092870000051026
    },
    {
      "episode": 3935,
      "score": 15,
      "reward": -1006.0,
      "steps": 15,
      "mean_loss": 2921.9133224487305,
      "epsilon": 0.309272000005103
    },
    {
      "episode": 3936,
      "score": 130,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 3214.9471423936925,
      "epsilon": 0.30922600000510425
    },
    {
      "episode": 3937,
      "score": 104,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 5365.461052287708,
      "epsilon": 0.30918200000510543
    },
    {
      "episode": 3938,
      "score": 125,
      "reward": -940.0,
      "steps": 38,
      "mean_loss": 3228.434719688014,
      "epsilon": 0.30914400000510645
    },
    {
      "episode": 3939,
      "score": 180,
      "reward": -911.0,
      "steps": 54,
      "mean_loss": 2713.9428393752487,
      "epsilon": 0.3090900000051079
    },
    {
      "episode": 3940,
      "score": 159,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 6095.352083790059,
      "epsilon": 0.3090410000051092
    },
    {
      "episode": 3941,
      "score": 161,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 5355.945982055664,
      "epsilon": 0.30899100000511054
    },
    {
      "episode": 3942,
      "score": 236,
      "reward": -867.0,
      "steps": 62,
      "mean_loss": 4828.792114811559,
      "epsilon": 0.3089290000051122
    },
    {
      "episode": 3943,
      "score": 234,
      "reward": -875.0,
      "steps": 62,
      "mean_loss": 5854.399904804845,
      "epsilon": 0.30886700000511386
    },
    {
      "episode": 3944,
      "score": 148,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 2488.9360695291075,
      "epsilon": 0.3088200000051151
    },
    {
      "episode": 3945,
      "score": 103,
      "reward": -977.0,
      "steps": 44,
      "mean_loss": 1213.2746039303865,
      "epsilon": 0.3087760000051163
    },
    {
      "episode": 3946,
      "score": 135,
      "reward": -944.0,
      "steps": 49,
      "mean_loss": 5429.339805641953,
      "epsilon": 0.3087270000051176
    },
    {
      "episode": 3947,
      "score": 81,
      "reward": -983.0,
      "steps": 35,
      "mean_loss": 3490.9194640023366,
      "epsilon": 0.30869200000511854
    },
    {
      "episode": 3948,
      "score": 136,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 5492.636097279001,
      "epsilon": 0.3086450000051198
    },
    {
      "episode": 3949,
      "score": 137,
      "reward": -938.0,
      "steps": 48,
      "mean_loss": 5802.9391305446625,
      "epsilon": 0.3085970000051211
    },
    {
      "episode": 3950,
      "score": 146,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 6762.780670124552,
      "epsilon": 0.3085510000051223
    },
    {
      "episode": 3951,
      "score": 153,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 4459.319170270647,
      "epsilon": 0.3085020000051236
    },
    {
      "episode": 3952,
      "score": 129,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 5265.153921127319,
      "epsilon": 0.3084580000051248
    },
    {
      "episode": 3953,
      "score": 156,
      "reward": -907.0,
      "steps": 45,
      "mean_loss": 7625.600118086073,
      "epsilon": 0.308413000005126
    },
    {
      "episode": 3954,
      "score": 93,
      "reward": -961.0,
      "steps": 37,
      "mean_loss": 3348.724640304978,
      "epsilon": 0.308376000005127
    },
    {
      "episode": 3955,
      "score": 111,
      "reward": -948.0,
      "steps": 36,
      "mean_loss": 2890.3082513809204,
      "epsilon": 0.30834000000512796
    },
    {
      "episode": 3956,
      "score": 165,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 4255.519567061444,
      "epsilon": 0.30829100000512927
    },
    {
      "episode": 3957,
      "score": 114,
      "reward": -945.0,
      "steps": 36,
      "mean_loss": 6001.040977689955,
      "epsilon": 0.30825500000513023
    },
    {
      "episode": 3958,
      "score": 184,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 3756.4854766038748,
      "epsilon": 0.3082030000051316
    },
    {
      "episode": 3959,
      "score": 113,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 2972.6617327603426,
      "epsilon": 0.3081590000051328
    },
    {
      "episode": 3960,
      "score": 111,
      "reward": -976.0,
      "steps": 45,
      "mean_loss": 3814.3508037990996,
      "epsilon": 0.308114000005134
    },
    {
      "episode": 3961,
      "score": 141,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 2609.7461484411488,
      "epsilon": 0.30806800000513523
    },
    {
      "episode": 3962,
      "score": 168,
      "reward": -902.0,
      "steps": 51,
      "mean_loss": 6551.481086282169,
      "epsilon": 0.3080170000051366
    },
    {
      "episode": 3963,
      "score": 131,
      "reward": -940.0,
      "steps": 45,
      "mean_loss": 6061.88301349216,
      "epsilon": 0.3079720000051378
    },
    {
      "episode": 3964,
      "score": 136,
      "reward": -945.0,
      "steps": 47,
      "mean_loss": 4396.812453574323,
      "epsilon": 0.30792500000513906
    },
    {
      "episode": 3965,
      "score": 140,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 4305.631339263916,
      "epsilon": 0.30788000000514026
    },
    {
      "episode": 3966,
      "score": 99,
      "reward": -959.0,
      "steps": 37,
      "mean_loss": 3818.974397401552,
      "epsilon": 0.30784300000514125
    },
    {
      "episode": 3967,
      "score": 116,
      "reward": -954.0,
      "steps": 45,
      "mean_loss": 5279.787367248535,
      "epsilon": 0.30779800000514246
    },
    {
      "episode": 3968,
      "score": 190,
      "reward": -879.0,
      "steps": 55,
      "mean_loss": 4015.2619037281383,
      "epsilon": 0.30774300000514393
    },
    {
      "episode": 3969,
      "score": 129,
      "reward": -943.0,
      "steps": 42,
      "mean_loss": 4495.078293754941,
      "epsilon": 0.30770100000514505
    },
    {
      "episode": 3970,
      "score": 64,
      "reward": -1006.0,
      "steps": 35,
      "mean_loss": 2081.6923164367677,
      "epsilon": 0.307666000005146
    },
    {
      "episode": 3971,
      "score": 118,
      "reward": -945.0,
      "steps": 37,
      "mean_loss": 3301.4081225008576,
      "epsilon": 0.307629000005147
    },
    {
      "episode": 3972,
      "score": 204,
      "reward": -864.0,
      "steps": 53,
      "mean_loss": 3382.1961737218894,
      "epsilon": 0.3075760000051484
    },
    {
      "episode": 3973,
      "score": 185,
      "reward": -907.0,
      "steps": 54,
      "mean_loss": 2737.922065028438,
      "epsilon": 0.30752200000514984
    },
    {
      "episode": 3974,
      "score": 162,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 4575.234379437505,
      "epsilon": 0.30747300000515115
    },
    {
      "episode": 3975,
      "score": 143,
      "reward": -949.0,
      "steps": 50,
      "mean_loss": 4215.708483810425,
      "epsilon": 0.3074230000051525
    },
    {
      "episode": 3976,
      "score": 135,
      "reward": -944.0,
      "steps": 46,
      "mean_loss": 5328.534457828688,
      "epsilon": 0.3073770000051537
    },
    {
      "episode": 3977,
      "score": 170,
      "reward": -905.0,
      "steps": 52,
      "mean_loss": 3602.50936464163,
      "epsilon": 0.3073250000051551
    },
    {
      "episode": 3978,
      "score": 270,
      "reward": -844.0,
      "steps": 68,
      "mean_loss": 5577.063389609842,
      "epsilon": 0.30725700000515693
    },
    {
      "episode": 3979,
      "score": 187,
      "reward": -908.0,
      "steps": 55,
      "mean_loss": 5903.682021609219,
      "epsilon": 0.3072020000051584
    },
    {
      "episode": 3980,
      "score": 183,
      "reward": -911.0,
      "steps": 54,
      "mean_loss": 2454.8620734038177,
      "epsilon": 0.30714800000515985
    },
    {
      "episode": 3981,
      "score": 112,
      "reward": -965.0,
      "steps": 41,
      "mean_loss": 4723.538782910603,
      "epsilon": 0.30710700000516095
    },
    {
      "episode": 3982,
      "score": 160,
      "reward": -907.0,
      "steps": 46,
      "mean_loss": 5522.496772185616,
      "epsilon": 0.3070610000051622
    },
    {
      "episode": 3983,
      "score": 176,
      "reward": -903.0,
      "steps": 49,
      "mean_loss": 6046.826468020069,
      "epsilon": 0.3070120000051635
    },
    {
      "episode": 3984,
      "score": 230,
      "reward": -876.0,
      "steps": 62,
      "mean_loss": 3889.2202249342395,
      "epsilon": 0.30695000000516515
    },
    {
      "episode": 3985,
      "score": 112,
      "reward": -951.0,
      "steps": 37,
      "mean_loss": 4531.182385058017,
      "epsilon": 0.30691300000516614
    },
    {
      "episode": 3986,
      "score": 127,
      "reward": -950.0,
      "steps": 49,
      "mean_loss": 4283.4684297211315,
      "epsilon": 0.30686400000516745
    },
    {
      "episode": 3987,
      "score": 207,
      "reward": -866.0,
      "steps": 56,
      "mean_loss": 7854.8929933820455,
      "epsilon": 0.30680800000516895
    },
    {
      "episode": 3988,
      "score": 180,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 4693.315627024724,
      "epsilon": 0.30675600000517034
    },
    {
      "episode": 3989,
      "score": 111,
      "reward": -965.0,
      "steps": 42,
      "mean_loss": 3618.7858866737,
      "epsilon": 0.30671400000517146
    },
    {
      "episode": 3990,
      "score": 194,
      "reward": -888.0,
      "steps": 55,
      "mean_loss": 4883.970134943182,
      "epsilon": 0.30665900000517293
    },
    {
      "episode": 3991,
      "score": 112,
      "reward": -961.0,
      "steps": 43,
      "mean_loss": 3326.1653261406477,
      "epsilon": 0.3066160000051741
    },
    {
      "episode": 3992,
      "score": 153,
      "reward": -911.0,
      "steps": 44,
      "mean_loss": 7452.026237834583,
      "epsilon": 0.30657200000517526
    },
    {
      "episode": 3993,
      "score": 94,
      "reward": -989.0,
      "steps": 40,
      "mean_loss": 4018.576359605789,
      "epsilon": 0.30653200000517633
    },
    {
      "episode": 3994,
      "score": 87,
      "reward": -952.0,
      "steps": 33,
      "mean_loss": 2980.838735291452,
      "epsilon": 0.3064990000051772
    },
    {
      "episode": 3995,
      "score": 160,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 6630.976078033447,
      "epsilon": 0.30644900000517855
    },
    {
      "episode": 3996,
      "score": 155,
      "reward": -911.0,
      "steps": 45,
      "mean_loss": 3408.716568544176,
      "epsilon": 0.30640400000517976
    },
    {
      "episode": 3997,
      "score": 146,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 4687.347225824992,
      "epsilon": 0.30635600000518104
    },
    {
      "episode": 3998,
      "score": 84,
      "reward": -988.0,
      "steps": 38,
      "mean_loss": 5849.463199816252,
      "epsilon": 0.30631800000518206
    },
    {
      "episode": 3999,
      "score": 194,
      "reward": -899.0,
      "steps": 55,
      "mean_loss": 4922.911078921231,
      "epsilon": 0.3062630000051835
    },
    {
      "episode": 4000,
      "score": 74,
      "reward": -984.0,
      "steps": 33,
      "mean_loss": 2423.4210316051135,
      "epsilon": 0.3062300000051844
    },
    {
      "episode": 4001,
      "score": 118,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 4625.250405571677,
      "epsilon": 0.3061860000051856
    },
    {
      "episode": 4002,
      "score": 176,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 4422.478339305291,
      "epsilon": 0.306134000005187
    },
    {
      "episode": 4003,
      "score": 194,
      "reward": -883.0,
      "steps": 53,
      "mean_loss": 5431.408135899957,
      "epsilon": 0.3060810000051884
    },
    {
      "episode": 4004,
      "score": 252,
      "reward": -865.0,
      "steps": 66,
      "mean_loss": 5640.720181609645,
      "epsilon": 0.30601500000519016
    },
    {
      "episode": 4005,
      "score": 97,
      "reward": -965.0,
      "steps": 39,
      "mean_loss": 3809.42383096157,
      "epsilon": 0.3059760000051912
    },
    {
      "episode": 4006,
      "score": 131,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 5163.088956252388,
      "epsilon": 0.30593000000519244
    },
    {
      "episode": 4007,
      "score": 125,
      "reward": -935.0,
      "steps": 41,
      "mean_loss": 3915.800904343768,
      "epsilon": 0.30588900000519353
    },
    {
      "episode": 4008,
      "score": 156,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 3721.4877172197616,
      "epsilon": 0.30584000000519485
    },
    {
      "episode": 4009,
      "score": 160,
      "reward": -923.0,
      "steps": 46,
      "mean_loss": 4328.4337730407715,
      "epsilon": 0.3057940000051961
    },
    {
      "episode": 4010,
      "score": 135,
      "reward": -957.0,
      "steps": 49,
      "mean_loss": 4467.267411290383,
      "epsilon": 0.3057450000051974
    },
    {
      "episode": 4011,
      "score": 104,
      "reward": -962.0,
      "steps": 38,
      "mean_loss": 2739.1498000496313,
      "epsilon": 0.3057070000051984
    },
    {
      "episode": 4012,
      "score": 114,
      "reward": -963.0,
      "steps": 41,
      "mean_loss": 4163.714344489865,
      "epsilon": 0.3056660000051995
    },
    {
      "episode": 4013,
      "score": 179,
      "reward": -905.0,
      "steps": 52,
      "mean_loss": 4331.879838503324,
      "epsilon": 0.3056140000052009
    },
    {
      "episode": 4014,
      "score": 153,
      "reward": -936.0,
      "steps": 50,
      "mean_loss": 7438.683862609863,
      "epsilon": 0.30556400000520223
    },
    {
      "episode": 4015,
      "score": 195,
      "reward": -916.0,
      "steps": 54,
      "mean_loss": 3726.4130101027313,
      "epsilon": 0.3055100000052037
    },
    {
      "episode": 4016,
      "score": 234,
      "reward": -884.0,
      "steps": 61,
      "mean_loss": 4622.904035474433,
      "epsilon": 0.3054490000052053
    },
    {
      "episode": 4017,
      "score": 127,
      "reward": -946.0,
      "steps": 47,
      "mean_loss": 3407.5754607180334,
      "epsilon": 0.30540200000520656
    },
    {
      "episode": 4018,
      "score": 78,
      "reward": -981.0,
      "steps": 37,
      "mean_loss": 6716.590030979466,
      "epsilon": 0.30536500000520755
    },
    {
      "episode": 4019,
      "score": 297,
      "reward": -808.0,
      "steps": 70,
      "mean_loss": 5135.43477734157,
      "epsilon": 0.3052950000052094
    },
    {
      "episode": 4020,
      "score": 170,
      "reward": -918.0,
      "steps": 49,
      "mean_loss": 3064.1377863202774,
      "epsilon": 0.30524600000521074
    },
    {
      "episode": 4021,
      "score": 201,
      "reward": -898.0,
      "steps": 55,
      "mean_loss": 4457.433439774947,
      "epsilon": 0.3051910000052122
    },
    {
      "episode": 4022,
      "score": 184,
      "reward": -923.0,
      "steps": 54,
      "mean_loss": 4383.176029770462,
      "epsilon": 0.30513700000521365
    },
    {
      "episode": 4023,
      "score": 74,
      "reward": -978.0,
      "steps": 33,
      "mean_loss": 7207.473472595215,
      "epsilon": 0.30510400000521454
    },
    {
      "episode": 4024,
      "score": 122,
      "reward": -954.0,
      "steps": 42,
      "mean_loss": 5500.514205296834,
      "epsilon": 0.30506200000521566
    },
    {
      "episode": 4025,
      "score": 110,
      "reward": -948.0,
      "steps": 40,
      "mean_loss": 6724.135133838654,
      "epsilon": 0.30502200000521673
    },
    {
      "episode": 4026,
      "score": 152,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 2628.7320329348245,
      "epsilon": 0.304974000005218
    },
    {
      "episode": 4027,
      "score": 86,
      "reward": -965.0,
      "steps": 34,
      "mean_loss": 5161.017030940337,
      "epsilon": 0.3049400000052189
    },
    {
      "episode": 4028,
      "score": 225,
      "reward": -875.0,
      "steps": 58,
      "mean_loss": 3314.655628138575,
      "epsilon": 0.3048820000052205
    },
    {
      "episode": 4029,
      "score": 167,
      "reward": -904.0,
      "steps": 50,
      "mean_loss": 4901.445251922607,
      "epsilon": 0.3048320000052218
    },
    {
      "episode": 4030,
      "score": 169,
      "reward": -914.0,
      "steps": 52,
      "mean_loss": 4404.472863417405,
      "epsilon": 0.3047800000052232
    },
    {
      "episode": 4031,
      "score": 87,
      "reward": -972.0,
      "steps": 37,
      "mean_loss": 2437.864046766951,
      "epsilon": 0.3047430000052242
    },
    {
      "episode": 4032,
      "score": 154,
      "reward": -921.0,
      "steps": 48,
      "mean_loss": 5233.804641405742,
      "epsilon": 0.3046950000052255
    },
    {
      "episode": 4033,
      "score": 170,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 3143.6737551786464,
      "epsilon": 0.3046460000052268
    },
    {
      "episode": 4034,
      "score": 100,
      "reward": -986.0,
      "steps": 40,
      "mean_loss": 3430.5774461746214,
      "epsilon": 0.30460600000522786
    },
    {
      "episode": 4035,
      "score": 109,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 2567.7675676345825,
      "epsilon": 0.30456200000522904
    },
    {
      "episode": 4036,
      "score": 109,
      "reward": -981.0,
      "steps": 46,
      "mean_loss": 4968.358989383863,
      "epsilon": 0.30451600000523027
    },
    {
      "episode": 4037,
      "score": 83,
      "reward": -1001.0,
      "steps": 41,
      "mean_loss": 3509.8528614509396,
      "epsilon": 0.30447500000523137
    },
    {
      "episode": 4038,
      "score": 161,
      "reward": -906.0,
      "steps": 47,
      "mean_loss": 4299.676664311835,
      "epsilon": 0.3044280000052326
    },
    {
      "episode": 4039,
      "score": 154,
      "reward": -924.0,
      "steps": 46,
      "mean_loss": 2155.317357685255,
      "epsilon": 0.30438200000523385
    },
    {
      "episode": 4040,
      "score": 160,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 3103.3637782078163,
      "epsilon": 0.3043310000052352
    },
    {
      "episode": 4041,
      "score": 104,
      "reward": -979.0,
      "steps": 42,
      "mean_loss": 4527.658283415295,
      "epsilon": 0.30428900000523634
    },
    {
      "episode": 4042,
      "score": 162,
      "reward": -910.0,
      "steps": 47,
      "mean_loss": 5421.348624046813,
      "epsilon": 0.3042420000052376
    },
    {
      "episode": 4043,
      "score": 85,
      "reward": -983.0,
      "steps": 39,
      "mean_loss": 4263.183638841678,
      "epsilon": 0.30420300000523864
    },
    {
      "episode": 4044,
      "score": 158,
      "reward": -921.0,
      "steps": 46,
      "mean_loss": 2999.559668706811,
      "epsilon": 0.3041570000052399
    },
    {
      "episode": 4045,
      "score": 135,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 5122.186138698033,
      "epsilon": 0.3041080000052412
    },
    {
      "episode": 4046,
      "score": 27,
      "reward": -993.0,
      "steps": 18,
      "mean_loss": 1223.488639831543,
      "epsilon": 0.30409000000524167
    },
    {
      "episode": 4047,
      "score": 130,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 6246.531832088123,
      "epsilon": 0.30404600000524284
    },
    {
      "episode": 4048,
      "score": 190,
      "reward": -894.0,
      "steps": 51,
      "mean_loss": 7343.746951159309,
      "epsilon": 0.3039950000052442
    },
    {
      "episode": 4049,
      "score": 139,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 3555.4231622574175,
      "epsilon": 0.30394800000524547
    },
    {
      "episode": 4050,
      "score": 180,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 5505.758805630254,
      "epsilon": 0.30389700000524683
    },
    {
      "episode": 4051,
      "score": 216,
      "reward": -872.0,
      "steps": 56,
      "mean_loss": 5838.658823592322,
      "epsilon": 0.30384100000524833
    },
    {
      "episode": 4052,
      "score": 184,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 5321.184882090642,
      "epsilon": 0.3037890000052497
    },
    {
      "episode": 4053,
      "score": 156,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 3090.157031853994,
      "epsilon": 0.303741000005251
    },
    {
      "episode": 4054,
      "score": 75,
      "reward": -978.0,
      "steps": 33,
      "mean_loss": 6753.069407202981,
      "epsilon": 0.3037080000052519
    },
    {
      "episode": 4055,
      "score": 98,
      "reward": -966.0,
      "steps": 37,
      "mean_loss": 6386.420529855264,
      "epsilon": 0.3036710000052529
    },
    {
      "episode": 4056,
      "score": 184,
      "reward": -891.0,
      "steps": 50,
      "mean_loss": 3737.35656791687,
      "epsilon": 0.3036210000052542
    },
    {
      "episode": 4057,
      "score": 156,
      "reward": -906.0,
      "steps": 45,
      "mean_loss": 3479.2566066318086,
      "epsilon": 0.3035760000052554
    },
    {
      "episode": 4058,
      "score": 151,
      "reward": -929.0,
      "steps": 49,
      "mean_loss": 4946.250112105389,
      "epsilon": 0.30352700000525673
    },
    {
      "episode": 4059,
      "score": 119,
      "reward": -942.0,
      "steps": 42,
      "mean_loss": 4917.227283114478,
      "epsilon": 0.30348500000525785
    },
    {
      "episode": 4060,
      "score": 165,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 5428.581747483234,
      "epsilon": 0.30343600000525917
    },
    {
      "episode": 4061,
      "score": 144,
      "reward": -948.0,
      "steps": 49,
      "mean_loss": 5441.102455761968,
      "epsilon": 0.3033870000052605
    },
    {
      "episode": 4062,
      "score": 108,
      "reward": -976.0,
      "steps": 42,
      "mean_loss": 3812.001217456091,
      "epsilon": 0.3033450000052616
    },
    {
      "episode": 4063,
      "score": 138,
      "reward": -943.0,
      "steps": 46,
      "mean_loss": 4488.554888352104,
      "epsilon": 0.30329900000526283
    },
    {
      "episode": 4064,
      "score": 86,
      "reward": -973.0,
      "steps": 35,
      "mean_loss": 3750.000988333566,
      "epsilon": 0.30326400000526377
    },
    {
      "episode": 4065,
      "score": 215,
      "reward": -886.0,
      "steps": 58,
      "mean_loss": 5629.398205921568,
      "epsilon": 0.3032060000052653
    },
    {
      "episode": 4066,
      "score": 138,
      "reward": -939.0,
      "steps": 50,
      "mean_loss": 4361.669507141113,
      "epsilon": 0.30315600000526666
    },
    {
      "episode": 4067,
      "score": 104,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 5467.590006750983,
      "epsilon": 0.30311900000526765
    },
    {
      "episode": 4068,
      "score": 73,
      "reward": -994.0,
      "steps": 37,
      "mean_loss": 2813.8460101565797,
      "epsilon": 0.30308200000526864
    },
    {
      "episode": 4069,
      "score": 151,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 2679.1490440368652,
      "epsilon": 0.30303100000527
    },
    {
      "episode": 4070,
      "score": 142,
      "reward": -948.0,
      "steps": 48,
      "mean_loss": 3291.7588835954666,
      "epsilon": 0.3029830000052713
    },
    {
      "episode": 4071,
      "score": 128,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 5565.987574937609,
      "epsilon": 0.3029380000052725
    },
    {
      "episode": 4072,
      "score": 152,
      "reward": -922.0,
      "steps": 49,
      "mean_loss": 3484.7429497387943,
      "epsilon": 0.3028890000052738
    },
    {
      "episode": 4073,
      "score": 111,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 6030.626825462688,
      "epsilon": 0.302845000005275
    },
    {
      "episode": 4074,
      "score": 178,
      "reward": -886.0,
      "steps": 49,
      "mean_loss": 6737.216913340043,
      "epsilon": 0.3027960000052763
    },
    {
      "episode": 4075,
      "score": 133,
      "reward": -945.0,
      "steps": 44,
      "mean_loss": 4600.528950171037,
      "epsilon": 0.30275200000527747
    },
    {
      "episode": 4076,
      "score": 108,
      "reward": -969.0,
      "steps": 45,
      "mean_loss": 4278.28064587911,
      "epsilon": 0.30270700000527867
    },
    {
      "episode": 4077,
      "score": 194,
      "reward": -897.0,
      "steps": 55,
      "mean_loss": 4372.260995344682,
      "epsilon": 0.30265200000528014
    },
    {
      "episode": 4078,
      "score": 230,
      "reward": -875.0,
      "steps": 62,
      "mean_loss": 2756.237256942257,
      "epsilon": 0.3025900000052818
    },
    {
      "episode": 4079,
      "score": 134,
      "reward": -943.0,
      "steps": 45,
      "mean_loss": 5209.220802052816,
      "epsilon": 0.302545000005283
    },
    {
      "episode": 4080,
      "score": 112,
      "reward": -971.0,
      "steps": 45,
      "mean_loss": 5077.926868184408,
      "epsilon": 0.3025000000052842
    },
    {
      "episode": 4081,
      "score": 135,
      "reward": -935.0,
      "steps": 46,
      "mean_loss": 2402.165730020274,
      "epsilon": 0.30245400000528544
    },
    {
      "episode": 4082,
      "score": 156,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 4049.3137062228457,
      "epsilon": 0.30240500000528675
    },
    {
      "episode": 4083,
      "score": 62,
      "reward": -983.0,
      "steps": 31,
      "mean_loss": 8459.077233345279,
      "epsilon": 0.3023740000052876
    },
    {
      "episode": 4084,
      "score": 173,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 1426.1196720646876,
      "epsilon": 0.30232300000528894
    },
    {
      "episode": 4085,
      "score": 75,
      "reward": -977.0,
      "steps": 34,
      "mean_loss": 6311.64533996582,
      "epsilon": 0.30228900000528985
    },
    {
      "episode": 4086,
      "score": 152,
      "reward": -915.0,
      "steps": 44,
      "mean_loss": 5117.031798189337,
      "epsilon": 0.30224500000529103
    },
    {
      "episode": 4087,
      "score": 79,
      "reward": -992.0,
      "steps": 36,
      "mean_loss": 1760.976305961609,
      "epsilon": 0.302209000005292
    },
    {
      "episode": 4088,
      "score": 107,
      "reward": -957.0,
      "steps": 39,
      "mean_loss": 4933.75061010703,
      "epsilon": 0.30217000000529304
    },
    {
      "episode": 4089,
      "score": 139,
      "reward": -948.0,
      "steps": 47,
      "mean_loss": 2466.0553888361505,
      "epsilon": 0.3021230000052943
    },
    {
      "episode": 4090,
      "score": 144,
      "reward": -928.0,
      "steps": 47,
      "mean_loss": 3753.413754848724,
      "epsilon": 0.30207600000529555
    },
    {
      "episode": 4091,
      "score": 135,
      "reward": -945.0,
      "steps": 46,
      "mean_loss": 3726.7809554804926,
      "epsilon": 0.3020300000052968
    },
    {
      "episode": 4092,
      "score": 187,
      "reward": -896.0,
      "steps": 55,
      "mean_loss": 2721.136074621027,
      "epsilon": 0.30197500000529826
    },
    {
      "episode": 4093,
      "score": 178,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 5011.292283376058,
      "epsilon": 0.3019240000052996
    },
    {
      "episode": 4094,
      "score": 109,
      "reward": -970.0,
      "steps": 40,
      "mean_loss": 2781.56126241684,
      "epsilon": 0.3018840000053007
    },
    {
      "episode": 4095,
      "score": 150,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 3925.762635946274,
      "epsilon": 0.301836000005302
    },
    {
      "episode": 4096,
      "score": 109,
      "reward": -965.0,
      "steps": 43,
      "mean_loss": 2262.8450088944546,
      "epsilon": 0.3017930000053031
    },
    {
      "episode": 4097,
      "score": 134,
      "reward": -936.0,
      "steps": 43,
      "mean_loss": 4405.467244081719,
      "epsilon": 0.3017500000053043
    },
    {
      "episode": 4098,
      "score": 111,
      "reward": -962.0,
      "steps": 43,
      "mean_loss": 5261.2395277688665,
      "epsilon": 0.3017070000053054
    },
    {
      "episode": 4099,
      "score": 93,
      "reward": -976.0,
      "steps": 37,
      "mean_loss": 4863.51124407794,
      "epsilon": 0.3016700000053064
    },
    {
      "episode": 4100,
      "score": 108,
      "reward": -955.0,
      "steps": 40,
      "mean_loss": 2792.4259316444395,
      "epsilon": 0.3016300000053075
    },
    {
      "episode": 4101,
      "score": 186,
      "reward": -916.0,
      "steps": 54,
      "mean_loss": 4491.985136985779,
      "epsilon": 0.30157600000530893
    },
    {
      "episode": 4102,
      "score": 150,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 4687.380849877182,
      "epsilon": 0.30152700000531024
    },
    {
      "episode": 4103,
      "score": 189,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 5124.127035680807,
      "epsilon": 0.30147400000531166
    },
    {
      "episode": 4104,
      "score": 157,
      "reward": -923.0,
      "steps": 49,
      "mean_loss": 4735.152548731589,
      "epsilon": 0.30142500000531297
    },
    {
      "episode": 4105,
      "score": 204,
      "reward": -875.0,
      "steps": 54,
      "mean_loss": 4549.755863684195,
      "epsilon": 0.3013710000053144
    },
    {
      "episode": 4106,
      "score": 233,
      "reward": -874.0,
      "steps": 61,
      "mean_loss": 3865.6821089885275,
      "epsilon": 0.30131000000531605
    },
    {
      "episode": 4107,
      "score": 245,
      "reward": -858.0,
      "steps": 60,
      "mean_loss": 6706.4725367863975,
      "epsilon": 0.30125000000531765
    },
    {
      "episode": 4108,
      "score": 217,
      "reward": -871.0,
      "steps": 61,
      "mean_loss": 4270.591306655133,
      "epsilon": 0.3011890000053193
    },
    {
      "episode": 4109,
      "score": 286,
      "reward": -810.0,
      "steps": 70,
      "mean_loss": 5215.368348802839,
      "epsilon": 0.30111900000532116
    },
    {
      "episode": 4110,
      "score": 197,
      "reward": -886.0,
      "steps": 55,
      "mean_loss": 5698.459587582675,
      "epsilon": 0.30106400000532263
    },
    {
      "episode": 4111,
      "score": 151,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 2105.985407808994,
      "epsilon": 0.3010170000053239
    },
    {
      "episode": 4112,
      "score": 186,
      "reward": -885.0,
      "steps": 52,
      "mean_loss": 4143.91225037208,
      "epsilon": 0.3009650000053253
    },
    {
      "episode": 4113,
      "score": 122,
      "reward": -946.0,
      "steps": 41,
      "mean_loss": 5832.000071548834,
      "epsilon": 0.3009240000053264
    },
    {
      "episode": 4114,
      "score": 123,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 5797.650894247968,
      "epsilon": 0.3008780000053276
    },
    {
      "episode": 4115,
      "score": 84,
      "reward": -991.0,
      "steps": 40,
      "mean_loss": 5127.728101921081,
      "epsilon": 0.3008380000053287
    },
    {
      "episode": 4116,
      "score": 118,
      "reward": -955.0,
      "steps": 40,
      "mean_loss": 3600.890855884552,
      "epsilon": 0.30079800000532975
    },
    {
      "episode": 4117,
      "score": 126,
      "reward": -961.0,
      "steps": 49,
      "mean_loss": 4652.069388097646,
      "epsilon": 0.30074900000533106
    },
    {
      "episode": 4118,
      "score": 119,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 5423.341653130271,
      "epsilon": 0.30070500000533223
    },
    {
      "episode": 4119,
      "score": 148,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 3614.546511467467,
      "epsilon": 0.3006580000053335
    },
    {
      "episode": 4120,
      "score": 109,
      "reward": -955.0,
      "steps": 39,
      "mean_loss": 3001.7498380220854,
      "epsilon": 0.30061900000533454
    },
    {
      "episode": 4121,
      "score": 134,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 5629.167782523416,
      "epsilon": 0.3005750000053357
    },
    {
      "episode": 4122,
      "score": 232,
      "reward": -864.0,
      "steps": 58,
      "mean_loss": 7109.738313740698,
      "epsilon": 0.30051700000533726
    },
    {
      "episode": 4123,
      "score": 67,
      "reward": -962.0,
      "steps": 25,
      "mean_loss": 6056.868921051026,
      "epsilon": 0.30049200000533793
    },
    {
      "episode": 4124,
      "score": 224,
      "reward": -878.0,
      "steps": 62,
      "mean_loss": 4617.618412756151,
      "epsilon": 0.3004300000053396
    },
    {
      "episode": 4125,
      "score": 96,
      "reward": -972.0,
      "steps": 39,
      "mean_loss": 2933.50006098625,
      "epsilon": 0.30039100000534064
    },
    {
      "episode": 4126,
      "score": 104,
      "reward": -961.0,
      "steps": 41,
      "mean_loss": 3812.9832325912103,
      "epsilon": 0.30035000000534173
    },
    {
      "episode": 4127,
      "score": 121,
      "reward": -947.0,
      "steps": 42,
      "mean_loss": 5403.584715616135,
      "epsilon": 0.30030800000534286
    },
    {
      "episode": 4128,
      "score": 140,
      "reward": -933.0,
      "steps": 45,
      "mean_loss": 4563.206079398261,
      "epsilon": 0.30026300000534406
    },
    {
      "episode": 4129,
      "score": 157,
      "reward": -912.0,
      "steps": 49,
      "mean_loss": 3545.8136564760794,
      "epsilon": 0.30021400000534537
    },
    {
      "episode": 4130,
      "score": 102,
      "reward": -962.0,
      "steps": 37,
      "mean_loss": 1997.0981383452545,
      "epsilon": 0.30017700000534636
    },
    {
      "episode": 4131,
      "score": 240,
      "reward": -850.0,
      "steps": 58,
      "mean_loss": 5196.558362566191,
      "epsilon": 0.3001190000053479
    },
    {
      "episode": 4132,
      "score": 137,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 5145.112191739289,
      "epsilon": 0.30007300000534914
    },
    {
      "episode": 4133,
      "score": 149,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 3629.303067703247,
      "epsilon": 0.3000230000053505
    },
    {
      "episode": 4134,
      "score": 188,
      "reward": -902.0,
      "steps": 56,
      "mean_loss": 2452.6575803756714,
      "epsilon": 0.299967000005352
    },
    {
      "episode": 4135,
      "score": 145,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 4663.742314338684,
      "epsilon": 0.29991900000535326
    },
    {
      "episode": 4136,
      "score": 153,
      "reward": -943.0,
      "steps": 50,
      "mean_loss": 6811.765113830566,
      "epsilon": 0.2998690000053546
    },
    {
      "episode": 4137,
      "score": 192,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 4970.631858825684,
      "epsilon": 0.299817000005356
    },
    {
      "episode": 4138,
      "score": 164,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 6484.0801435089115,
      "epsilon": 0.29976700000535733
    },
    {
      "episode": 4139,
      "score": 127,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 3374.6495545994153,
      "epsilon": 0.2997230000053585
    },
    {
      "episode": 4140,
      "score": 148,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 3598.060513476936,
      "epsilon": 0.2996740000053598
    },
    {
      "episode": 4141,
      "score": 200,
      "reward": -882.0,
      "steps": 54,
      "mean_loss": 2350.447511213797,
      "epsilon": 0.29962000000536126
    },
    {
      "episode": 4142,
      "score": 195,
      "reward": -897.0,
      "steps": 54,
      "mean_loss": 5465.917914072673,
      "epsilon": 0.2995660000053627
    },
    {
      "episode": 4143,
      "score": 226,
      "reward": -874.0,
      "steps": 55,
      "mean_loss": 5812.27833702781,
      "epsilon": 0.2995110000053642
    },
    {
      "episode": 4144,
      "score": 116,
      "reward": -943.0,
      "steps": 40,
      "mean_loss": 5948.8945983886715,
      "epsilon": 0.29947100000536525
    },
    {
      "episode": 4145,
      "score": 158,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 3573.348489602407,
      "epsilon": 0.29942300000536654
    },
    {
      "episode": 4146,
      "score": 126,
      "reward": -946.0,
      "steps": 46,
      "mean_loss": 4886.623896474423,
      "epsilon": 0.29937700000536777
    },
    {
      "episode": 4147,
      "score": 84,
      "reward": -965.0,
      "steps": 33,
      "mean_loss": 3782.1040566184306,
      "epsilon": 0.29934400000536865
    },
    {
      "episode": 4148,
      "score": 171,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 5934.332426452636,
      "epsilon": 0.29929400000537
    },
    {
      "episode": 4149,
      "score": 103,
      "reward": -972.0,
      "steps": 43,
      "mean_loss": 2402.224764624307,
      "epsilon": 0.29925100000537114
    },
    {
      "episode": 4150,
      "score": 71,
      "reward": -987.0,
      "steps": 34,
      "mean_loss": 6533.823986951043,
      "epsilon": 0.29921700000537205
    },
    {
      "episode": 4151,
      "score": 154,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 3526.1832896471024,
      "epsilon": 0.29916900000537333
    },
    {
      "episode": 4152,
      "score": 147,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 3441.590488109183,
      "epsilon": 0.2991220000053746
    },
    {
      "episode": 4153,
      "score": 153,
      "reward": -922.0,
      "steps": 46,
      "mean_loss": 2056.025860496189,
      "epsilon": 0.2990760000053758
    },
    {
      "episode": 4154,
      "score": 141,
      "reward": -925.0,
      "steps": 48,
      "mean_loss": 3517.7487921714783,
      "epsilon": 0.2990280000053771
    },
    {
      "episode": 4155,
      "score": 152,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 3024.831035375595,
      "epsilon": 0.2989800000053784
    },
    {
      "episode": 4156,
      "score": 217,
      "reward": -886.0,
      "steps": 57,
      "mean_loss": 6713.158325797634,
      "epsilon": 0.2989230000053799
    },
    {
      "episode": 4157,
      "score": 220,
      "reward": -881.0,
      "steps": 58,
      "mean_loss": 4371.437788239841,
      "epsilon": 0.29886500000538146
    },
    {
      "episode": 4158,
      "score": 143,
      "reward": -902.0,
      "steps": 39,
      "mean_loss": 1754.9191536536584,
      "epsilon": 0.2988260000053825
    },
    {
      "episode": 4159,
      "score": 251,
      "reward": -858.0,
      "steps": 64,
      "mean_loss": 4298.356372356415,
      "epsilon": 0.2987620000053842
    },
    {
      "episode": 4160,
      "score": 199,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 3772.393318600125,
      "epsilon": 0.29870800000538567
    },
    {
      "episode": 4161,
      "score": 126,
      "reward": -933.0,
      "steps": 39,
      "mean_loss": 4019.587329082,
      "epsilon": 0.2986690000053867
    },
    {
      "episode": 4162,
      "score": 159,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 4968.471491910974,
      "epsilon": 0.298620000005388
    },
    {
      "episode": 4163,
      "score": 150,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 2730.5385417938232,
      "epsilon": 0.2985720000053893
    },
    {
      "episode": 4164,
      "score": 144,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 5530.90057302981,
      "epsilon": 0.2985230000053906
    },
    {
      "episode": 4165,
      "score": 148,
      "reward": -932.0,
      "steps": 45,
      "mean_loss": 4250.356775622898,
      "epsilon": 0.2984780000053918
    },
    {
      "episode": 4166,
      "score": 216,
      "reward": -859.0,
      "steps": 57,
      "mean_loss": 3743.209924697876,
      "epsilon": 0.29842100000539334
    },
    {
      "episode": 4167,
      "score": 229,
      "reward": -871.0,
      "steps": 54,
      "mean_loss": 3944.91368177202,
      "epsilon": 0.2983670000053948
    },
    {
      "episode": 4168,
      "score": 98,
      "reward": -970.0,
      "steps": 42,
      "mean_loss": 5515.657346271333,
      "epsilon": 0.2983250000053959
    },
    {
      "episode": 4169,
      "score": 117,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 7094.32446306402,
      "epsilon": 0.2982810000053971
    },
    {
      "episode": 4170,
      "score": 218,
      "reward": -886.0,
      "steps": 58,
      "mean_loss": 7337.762906896657,
      "epsilon": 0.29822300000539864
    },
    {
      "episode": 4171,
      "score": 180,
      "reward": -901.0,
      "steps": 52,
      "mean_loss": 4769.426439798795,
      "epsilon": 0.29817100000540003
    },
    {
      "episode": 4172,
      "score": 211,
      "reward": -895.0,
      "steps": 58,
      "mean_loss": 4446.451560119102,
      "epsilon": 0.2981130000054016
    },
    {
      "episode": 4173,
      "score": 173,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 6572.754473172701,
      "epsilon": 0.298061000005403
    },
    {
      "episode": 4174,
      "score": 170,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 6207.364972774799,
      "epsilon": 0.29800900000540437
    },
    {
      "episode": 4175,
      "score": 117,
      "reward": -958.0,
      "steps": 43,
      "mean_loss": 3733.8377841239753,
      "epsilon": 0.2979660000054055
    },
    {
      "episode": 4176,
      "score": 279,
      "reward": -812.0,
      "steps": 67,
      "mean_loss": 2994.16362603031,
      "epsilon": 0.2978990000054073
    },
    {
      "episode": 4177,
      "score": 152,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4328.484614313865,
      "epsilon": 0.2978500000054086
    },
    {
      "episode": 4178,
      "score": 134,
      "reward": -923.0,
      "steps": 44,
      "mean_loss": 4096.421337040988,
      "epsilon": 0.2978060000054098
    },
    {
      "episode": 4179,
      "score": 126,
      "reward": -946.0,
      "steps": 44,
      "mean_loss": 4502.092989661477,
      "epsilon": 0.297762000005411
    },
    {
      "episode": 4180,
      "score": 139,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 3775.1770570966933,
      "epsilon": 0.2977170000054122
    },
    {
      "episode": 4181,
      "score": 155,
      "reward": -929.0,
      "steps": 50,
      "mean_loss": 3817.4427174377442,
      "epsilon": 0.2976670000054135
    },
    {
      "episode": 4182,
      "score": 196,
      "reward": -896.0,
      "steps": 56,
      "mean_loss": 6090.823748588562,
      "epsilon": 0.297611000005415
    },
    {
      "episode": 4183,
      "score": 118,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 2924.8926481767135,
      "epsilon": 0.2975670000054162
    },
    {
      "episode": 4184,
      "score": 167,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 6575.255360285441,
      "epsilon": 0.2975190000054175
    },
    {
      "episode": 4185,
      "score": 291,
      "reward": -816.0,
      "steps": 68,
      "mean_loss": 4284.544645365547,
      "epsilon": 0.2974510000054193
    },
    {
      "episode": 4186,
      "score": 83,
      "reward": -988.0,
      "steps": 39,
      "mean_loss": 4193.705472897261,
      "epsilon": 0.29741200000542034
    },
    {
      "episode": 4187,
      "score": 118,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 5209.905028618707,
      "epsilon": 0.29736700000542154
    },
    {
      "episode": 4188,
      "score": 186,
      "reward": -892.0,
      "steps": 52,
      "mean_loss": 3078.85143500108,
      "epsilon": 0.29731500000542294
    },
    {
      "episode": 4189,
      "score": 221,
      "reward": -881.0,
      "steps": 60,
      "mean_loss": 3347.8696639378863,
      "epsilon": 0.29725500000542454
    },
    {
      "episode": 4190,
      "score": 161,
      "reward": -928.0,
      "steps": 52,
      "mean_loss": 7365.217087819026,
      "epsilon": 0.29720300000542593
    },
    {
      "episode": 4191,
      "score": 177,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 3682.937636228708,
      "epsilon": 0.2971510000054273
    },
    {
      "episode": 4192,
      "score": 69,
      "reward": -985.0,
      "steps": 33,
      "mean_loss": 2814.2177208409166,
      "epsilon": 0.2971180000054282
    },
    {
      "episode": 4193,
      "score": 167,
      "reward": -909.0,
      "steps": 48,
      "mean_loss": 5278.26384862264,
      "epsilon": 0.2970700000054295
    },
    {
      "episode": 4194,
      "score": 177,
      "reward": -913.0,
      "steps": 53,
      "mean_loss": 4084.7279499701735,
      "epsilon": 0.2970170000054309
    },
    {
      "episode": 4195,
      "score": 110,
      "reward": -962.0,
      "steps": 43,
      "mean_loss": 5146.877582195193,
      "epsilon": 0.29697400000543206
    },
    {
      "episode": 4196,
      "score": 120,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 4022.55478997664,
      "epsilon": 0.29693000000543324
    },
    {
      "episode": 4197,
      "score": 134,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 6822.7559989582405,
      "epsilon": 0.2968860000054344
    },
    {
      "episode": 4198,
      "score": 85,
      "reward": -989.0,
      "steps": 38,
      "mean_loss": 4848.6088248805,
      "epsilon": 0.29684800000543543
    },
    {
      "episode": 4199,
      "score": 158,
      "reward": -923.0,
      "steps": 47,
      "mean_loss": 5060.279010366886,
      "epsilon": 0.2968010000054367
    },
    {
      "episode": 4200,
      "score": 147,
      "reward": -933.0,
      "steps": 47,
      "mean_loss": 3188.2284508563102,
      "epsilon": 0.29675400000543795
    },
    {
      "episode": 4201,
      "score": 134,
      "reward": -938.0,
      "steps": 45,
      "mean_loss": 5777.418403201633,
      "epsilon": 0.29670900000543915
    },
    {
      "episode": 4202,
      "score": 134,
      "reward": -946.0,
      "steps": 45,
      "mean_loss": 3459.621387905545,
      "epsilon": 0.29666400000544035
    },
    {
      "episode": 4203,
      "score": 155,
      "reward": -929.0,
      "steps": 49,
      "mean_loss": 5118.3171524514955,
      "epsilon": 0.29661500000544166
    },
    {
      "episode": 4204,
      "score": 152,
      "reward": -931.0,
      "steps": 51,
      "mean_loss": 4675.982420229444,
      "epsilon": 0.29656400000544303
    },
    {
      "episode": 4205,
      "score": 189,
      "reward": -882.0,
      "steps": 53,
      "mean_loss": 4451.28200199919,
      "epsilon": 0.29651100000544445
    },
    {
      "episode": 4206,
      "score": 103,
      "reward": -971.0,
      "steps": 39,
      "mean_loss": 5649.560451752101,
      "epsilon": 0.2964720000054455
    },
    {
      "episode": 4207,
      "score": 157,
      "reward": -909.0,
      "steps": 49,
      "mean_loss": 4159.099677786535,
      "epsilon": 0.2964230000054468
    },
    {
      "episode": 4208,
      "score": 88,
      "reward": -987.0,
      "steps": 35,
      "mean_loss": 2260.599807739258,
      "epsilon": 0.29638800000544774
    },
    {
      "episode": 4209,
      "score": 132,
      "reward": -946.0,
      "steps": 48,
      "mean_loss": 4837.983219623566,
      "epsilon": 0.296340000005449
    },
    {
      "episode": 4210,
      "score": 210,
      "reward": -891.0,
      "steps": 56,
      "mean_loss": 5182.802994217192,
      "epsilon": 0.2962840000054505
    },
    {
      "episode": 4211,
      "score": 151,
      "reward": -942.0,
      "steps": 50,
      "mean_loss": 3355.3542108917236,
      "epsilon": 0.29623400000545186
    },
    {
      "episode": 4212,
      "score": 123,
      "reward": -956.0,
      "steps": 45,
      "mean_loss": 5445.278899214003,
      "epsilon": 0.29618900000545306
    },
    {
      "episode": 4213,
      "score": 253,
      "reward": -845.0,
      "steps": 64,
      "mean_loss": 5379.473213493824,
      "epsilon": 0.2961250000054548
    },
    {
      "episode": 4214,
      "score": 158,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 4880.174376507195,
      "epsilon": 0.2960760000054561
    },
    {
      "episode": 4215,
      "score": 149,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 2295.241059859594,
      "epsilon": 0.29602800000545737
    },
    {
      "episode": 4216,
      "score": 175,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 3607.06204597905,
      "epsilon": 0.2959750000054588
    },
    {
      "episode": 4217,
      "score": 227,
      "reward": -865.0,
      "steps": 58,
      "mean_loss": 3949.741407065556,
      "epsilon": 0.29591700000546034
    },
    {
      "episode": 4218,
      "score": 114,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 7190.382423574274,
      "epsilon": 0.2958730000054615
    },
    {
      "episode": 4219,
      "score": 250,
      "reward": -848.0,
      "steps": 61,
      "mean_loss": 5440.52294246486,
      "epsilon": 0.29581200000546315
    },
    {
      "episode": 4220,
      "score": 243,
      "reward": -863.0,
      "steps": 60,
      "mean_loss": 5104.20552186966,
      "epsilon": 0.29575200000546475
    },
    {
      "episode": 4221,
      "score": 95,
      "reward": -970.0,
      "steps": 37,
      "mean_loss": 2136.804804724616,
      "epsilon": 0.29571500000546574
    },
    {
      "episode": 4222,
      "score": 188,
      "reward": -885.0,
      "steps": 52,
      "mean_loss": 3257.3842670000518,
      "epsilon": 0.29566300000546714
    },
    {
      "episode": 4223,
      "score": 249,
      "reward": -856.0,
      "steps": 63,
      "mean_loss": 5764.541236211383,
      "epsilon": 0.2956000000054688
    },
    {
      "episode": 4224,
      "score": 149,
      "reward": -927.0,
      "steps": 45,
      "mean_loss": 3300.8962157355413,
      "epsilon": 0.29555500000547
    },
    {
      "episode": 4225,
      "score": 138,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 3976.943604895409,
      "epsilon": 0.2955080000054713
    },
    {
      "episode": 4226,
      "score": 136,
      "reward": -919.0,
      "steps": 44,
      "mean_loss": 4745.929830637845,
      "epsilon": 0.29546400000547246
    },
    {
      "episode": 4227,
      "score": 142,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 5274.808809239814,
      "epsilon": 0.2954170000054737
    },
    {
      "episode": 4228,
      "score": 170,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 5733.934521026611,
      "epsilon": 0.29536700000547506
    },
    {
      "episode": 4229,
      "score": 22,
      "reward": -1002.0,
      "steps": 18,
      "mean_loss": 7218.85868941413,
      "epsilon": 0.29534900000547554
    },
    {
      "episode": 4230,
      "score": 99,
      "reward": -984.0,
      "steps": 43,
      "mean_loss": 3059.6615102901014,
      "epsilon": 0.2953060000054767
    },
    {
      "episode": 4231,
      "score": 133,
      "reward": -937.0,
      "steps": 45,
      "mean_loss": 6011.123051198324,
      "epsilon": 0.2952610000054779
    },
    {
      "episode": 4232,
      "score": 114,
      "reward": -967.0,
      "steps": 45,
      "mean_loss": 2265.8465443081327,
      "epsilon": 0.2952160000054791
    },
    {
      "episode": 4233,
      "score": 215,
      "reward": -872.0,
      "steps": 56,
      "mean_loss": 1613.746711390359,
      "epsilon": 0.2951600000054806
    },
    {
      "episode": 4234,
      "score": 170,
      "reward": -900.0,
      "steps": 49,
      "mean_loss": 4064.0039935987825,
      "epsilon": 0.2951110000054819
    },
    {
      "episode": 4235,
      "score": 141,
      "reward": -924.0,
      "steps": 45,
      "mean_loss": 3763.787239456177,
      "epsilon": 0.2950660000054831
    },
    {
      "episode": 4236,
      "score": 144,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 4053.5573554343364,
      "epsilon": 0.29501900000548437
    },
    {
      "episode": 4237,
      "score": 164,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 4349.6321529006955,
      "epsilon": 0.2949690000054857
    },
    {
      "episode": 4238,
      "score": 164,
      "reward": -914.0,
      "steps": 51,
      "mean_loss": 6188.65553485646,
      "epsilon": 0.29491800000548707
    },
    {
      "episode": 4239,
      "score": 156,
      "reward": -918.0,
      "steps": 47,
      "mean_loss": 3279.421513212488,
      "epsilon": 0.2948710000054883
    },
    {
      "episode": 4240,
      "score": 156,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 2189.605660496926,
      "epsilon": 0.29482200000548964
    },
    {
      "episode": 4241,
      "score": 147,
      "reward": -926.0,
      "steps": 43,
      "mean_loss": 1681.3772113711334,
      "epsilon": 0.2947790000054908
    },
    {
      "episode": 4242,
      "score": 143,
      "reward": -948.0,
      "steps": 46,
      "mean_loss": 4771.403132065483,
      "epsilon": 0.294733000005492
    },
    {
      "episode": 4243,
      "score": 140,
      "reward": -932.0,
      "steps": 46,
      "mean_loss": 2000.201396237249,
      "epsilon": 0.29468700000549325
    },
    {
      "episode": 4244,
      "score": 166,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 4575.775310554504,
      "epsilon": 0.2946370000054946
    },
    {
      "episode": 4245,
      "score": 100,
      "reward": -971.0,
      "steps": 38,
      "mean_loss": 4250.497259039628,
      "epsilon": 0.2945990000054956
    },
    {
      "episode": 4246,
      "score": 109,
      "reward": -961.0,
      "steps": 45,
      "mean_loss": 4161.089611731635,
      "epsilon": 0.2945540000054968
    },
    {
      "episode": 4247,
      "score": 181,
      "reward": -898.0,
      "steps": 54,
      "mean_loss": 5114.856773023253,
      "epsilon": 0.29450000000549825
    },
    {
      "episode": 4248,
      "score": 129,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 4993.672561158525,
      "epsilon": 0.2944530000054995
    },
    {
      "episode": 4249,
      "score": 167,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 5139.91420917511,
      "epsilon": 0.29440300000550085
    },
    {
      "episode": 4250,
      "score": 84,
      "reward": -990.0,
      "steps": 39,
      "mean_loss": 3928.1295527922803,
      "epsilon": 0.2943640000055019
    },
    {
      "episode": 4251,
      "score": 145,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 5156.57044828699,
      "epsilon": 0.29431700000550315
    },
    {
      "episode": 4252,
      "score": 137,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 3394.4466256486608,
      "epsilon": 0.2942700000055044
    },
    {
      "episode": 4253,
      "score": 91,
      "reward": -979.0,
      "steps": 41,
      "mean_loss": 3543.790793395624,
      "epsilon": 0.2942290000055055
    },
    {
      "episode": 4254,
      "score": 162,
      "reward": -905.0,
      "steps": 47,
      "mean_loss": 3519.5254643217045,
      "epsilon": 0.29418200000550676
    },
    {
      "episode": 4255,
      "score": 111,
      "reward": -978.0,
      "steps": 45,
      "mean_loss": 5511.5904293484155,
      "epsilon": 0.29413700000550796
    },
    {
      "episode": 4256,
      "score": 75,
      "reward": -983.0,
      "steps": 33,
      "mean_loss": 2339.5142578356194,
      "epsilon": 0.29410400000550885
    },
    {
      "episode": 4257,
      "score": 97,
      "reward": -978.0,
      "steps": 42,
      "mean_loss": 4247.0729044051395,
      "epsilon": 0.29406200000550997
    },
    {
      "episode": 4258,
      "score": 243,
      "reward": -858.0,
      "steps": 61,
      "mean_loss": 3694.775258048636,
      "epsilon": 0.2940010000055116
    },
    {
      "episode": 4259,
      "score": 164,
      "reward": -908.0,
      "steps": 47,
      "mean_loss": 3804.3619048341793,
      "epsilon": 0.29395400000551286
    },
    {
      "episode": 4260,
      "score": 130,
      "reward": -944.0,
      "steps": 45,
      "mean_loss": 4720.864205296834,
      "epsilon": 0.29390900000551407
    },
    {
      "episode": 4261,
      "score": 156,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 2394.8177142333984,
      "epsilon": 0.2938590000055154
    },
    {
      "episode": 4262,
      "score": 112,
      "reward": -942.0,
      "steps": 39,
      "mean_loss": 3966.673371632894,
      "epsilon": 0.29382000000551645
    },
    {
      "episode": 4263,
      "score": 131,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 4191.95630793138,
      "epsilon": 0.2937760000055176
    },
    {
      "episode": 4264,
      "score": 93,
      "reward": -973.0,
      "steps": 37,
      "mean_loss": 2906.5369969960807,
      "epsilon": 0.2937390000055186
    },
    {
      "episode": 4265,
      "score": 158,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 2310.2301985931394,
      "epsilon": 0.29368900000551995
    },
    {
      "episode": 4266,
      "score": 83,
      "reward": -980.0,
      "steps": 36,
      "mean_loss": 3800.9129298528037,
      "epsilon": 0.2936530000055209
    },
    {
      "episode": 4267,
      "score": 110,
      "reward": -963.0,
      "steps": 39,
      "mean_loss": 6214.16905378684,
      "epsilon": 0.29361400000552196
    },
    {
      "episode": 4268,
      "score": 154,
      "reward": -932.0,
      "steps": 51,
      "mean_loss": 5042.080222111123,
      "epsilon": 0.2935630000055233
    },
    {
      "episode": 4269,
      "score": 134,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 4478.9050896421395,
      "epsilon": 0.2935160000055246
    },
    {
      "episode": 4270,
      "score": 107,
      "reward": -956.0,
      "steps": 36,
      "mean_loss": 4074.251856909858,
      "epsilon": 0.29348000000552554
    },
    {
      "episode": 4271,
      "score": 164,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 5810.2955802606075,
      "epsilon": 0.29343100000552685
    },
    {
      "episode": 4272,
      "score": 195,
      "reward": -892.0,
      "steps": 53,
      "mean_loss": 3510.496809761479,
      "epsilon": 0.29337800000552827
    },
    {
      "episode": 4273,
      "score": 153,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 5062.580668185619,
      "epsilon": 0.29333100000552953
    },
    {
      "episode": 4274,
      "score": 67,
      "reward": -963.0,
      "steps": 25,
      "mean_loss": 1824.4468911743163,
      "epsilon": 0.2933060000055302
    },
    {
      "episode": 4275,
      "score": 129,
      "reward": -937.0,
      "steps": 44,
      "mean_loss": 5577.811565919356,
      "epsilon": 0.2932620000055314
    },
    {
      "episode": 4276,
      "score": 240,
      "reward": -849.0,
      "steps": 62,
      "mean_loss": 5477.5532676942885,
      "epsilon": 0.29320000000553303
    },
    {
      "episode": 4277,
      "score": 262,
      "reward": -829.0,
      "steps": 60,
      "mean_loss": 3613.353744951884,
      "epsilon": 0.29314000000553464
    },
    {
      "episode": 4278,
      "score": 104,
      "reward": -969.0,
      "steps": 42,
      "mean_loss": 4473.750043641953,
      "epsilon": 0.29309800000553576
    },
    {
      "episode": 4279,
      "score": 158,
      "reward": -916.0,
      "steps": 46,
      "mean_loss": 2243.2609301028047,
      "epsilon": 0.293052000005537
    },
    {
      "episode": 4280,
      "score": 167,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 3215.7996883766323,
      "epsilon": 0.29300100000553836
    },
    {
      "episode": 4281,
      "score": 183,
      "reward": -898.0,
      "steps": 48,
      "mean_loss": 7604.774736563365,
      "epsilon": 0.29295300000553964
    },
    {
      "episode": 4282,
      "score": 114,
      "reward": -952.0,
      "steps": 39,
      "mean_loss": 2620.6479403177896,
      "epsilon": 0.2929140000055407
    },
    {
      "episode": 4283,
      "score": 155,
      "reward": -929.0,
      "steps": 46,
      "mean_loss": 4440.6821702044945,
      "epsilon": 0.2928680000055419
    },
    {
      "episode": 4284,
      "score": 113,
      "reward": -979.0,
      "steps": 46,
      "mean_loss": 3645.3026443149733,
      "epsilon": 0.29282200000554315
    },
    {
      "episode": 4285,
      "score": 243,
      "reward": -875.0,
      "steps": 62,
      "mean_loss": 4728.105737101647,
      "epsilon": 0.2927600000055448
    },
    {
      "episode": 4286,
      "score": 147,
      "reward": -927.0,
      "steps": 45,
      "mean_loss": 3920.171113671197,
      "epsilon": 0.292715000005546
    },
    {
      "episode": 4287,
      "score": 146,
      "reward": -924.0,
      "steps": 45,
      "mean_loss": 3561.81952395969,
      "epsilon": 0.2926700000055472
    },
    {
      "episode": 4288,
      "score": 158,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 5929.248662520428,
      "epsilon": 0.2926210000055485
    },
    {
      "episode": 4289,
      "score": 110,
      "reward": -951.0,
      "steps": 39,
      "mean_loss": 2772.9566806891025,
      "epsilon": 0.29258200000554957
    },
    {
      "episode": 4290,
      "score": 79,
      "reward": -957.0,
      "steps": 28,
      "mean_loss": 3062.667242050171,
      "epsilon": 0.2925540000055503
    },
    {
      "episode": 4291,
      "score": 114,
      "reward": -959.0,
      "steps": 41,
      "mean_loss": 4293.44814691311,
      "epsilon": 0.2925130000055514
    },
    {
      "episode": 4292,
      "score": 120,
      "reward": -943.0,
      "steps": 39,
      "mean_loss": 3853.066623296493,
      "epsilon": 0.29247400000555246
    },
    {
      "episode": 4293,
      "score": 122,
      "reward": -952.0,
      "steps": 40,
      "mean_loss": 6277.727737903595,
      "epsilon": 0.29243400000555353
    },
    {
      "episode": 4294,
      "score": 141,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 5661.673747677273,
      "epsilon": 0.29238900000555473
    },
    {
      "episode": 4295,
      "score": 196,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 3483.318021491722,
      "epsilon": 0.2923350000055562
    },
    {
      "episode": 4296,
      "score": 97,
      "reward": -976.0,
      "steps": 38,
      "mean_loss": 7245.5990008304,
      "epsilon": 0.2922970000055572
    },
    {
      "episode": 4297,
      "score": 132,
      "reward": -955.0,
      "steps": 47,
      "mean_loss": 4927.852038525521,
      "epsilon": 0.29225000000555845
    },
    {
      "episode": 4298,
      "score": 124,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 1732.164627156359,
      "epsilon": 0.2922030000055597
    },
    {
      "episode": 4299,
      "score": 233,
      "reward": -875.0,
      "steps": 62,
      "mean_loss": 6838.489937105486,
      "epsilon": 0.29214100000556137
    },
    {
      "episode": 4300,
      "score": 156,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 3788.8333214569093,
      "epsilon": 0.2920910000055627
    },
    {
      "episode": 4301,
      "score": 139,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 5377.490264018376,
      "epsilon": 0.292043000005564
    },
    {
      "episode": 4302,
      "score": 147,
      "reward": -926.0,
      "steps": 46,
      "mean_loss": 4254.731715907221,
      "epsilon": 0.2919970000055652
    },
    {
      "episode": 4303,
      "score": 181,
      "reward": -902.0,
      "steps": 54,
      "mean_loss": 1818.5228116070782,
      "epsilon": 0.29194300000556667
    },
    {
      "episode": 4304,
      "score": 114,
      "reward": -983.0,
      "steps": 39,
      "mean_loss": 4581.838957468669,
      "epsilon": 0.2919040000055677
    },
    {
      "episode": 4305,
      "score": 163,
      "reward": -903.0,
      "steps": 47,
      "mean_loss": 2436.467301794823,
      "epsilon": 0.29185700000556897
    },
    {
      "episode": 4306,
      "score": 136,
      "reward": -950.0,
      "steps": 48,
      "mean_loss": 2208.54605948925,
      "epsilon": 0.29180900000557025
    },
    {
      "episode": 4307,
      "score": 87,
      "reward": -970.0,
      "steps": 33,
      "mean_loss": 4767.823702841094,
      "epsilon": 0.29177600000557113
    },
    {
      "episode": 4308,
      "score": 158,
      "reward": -917.0,
      "steps": 49,
      "mean_loss": 2821.8157117804703,
      "epsilon": 0.29172700000557245
    },
    {
      "episode": 4309,
      "score": 181,
      "reward": -900.0,
      "steps": 51,
      "mean_loss": 3420.2463568519142,
      "epsilon": 0.2916760000055738
    },
    {
      "episode": 4310,
      "score": 142,
      "reward": -949.0,
      "steps": 48,
      "mean_loss": 4610.207054694493,
      "epsilon": 0.2916280000055751
    },
    {
      "episode": 4311,
      "score": 146,
      "reward": -953.0,
      "steps": 47,
      "mean_loss": 5004.874953898978,
      "epsilon": 0.29158100000557635
    },
    {
      "episode": 4312,
      "score": 110,
      "reward": -958.0,
      "steps": 39,
      "mean_loss": 5106.761216090275,
      "epsilon": 0.2915420000055774
    },
    {
      "episode": 4313,
      "score": 108,
      "reward": -974.0,
      "steps": 45,
      "mean_loss": 4677.6852246602375,
      "epsilon": 0.2914970000055786
    },
    {
      "episode": 4314,
      "score": 132,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 2581.77875166354,
      "epsilon": 0.29145100000557983
    },
    {
      "episode": 4315,
      "score": 122,
      "reward": -953.0,
      "steps": 44,
      "mean_loss": 2522.4860046560116,
      "epsilon": 0.291407000005581
    },
    {
      "episode": 4316,
      "score": 214,
      "reward": -879.0,
      "steps": 56,
      "mean_loss": 4880.34196288245,
      "epsilon": 0.2913510000055825
    },
    {
      "episode": 4317,
      "score": 156,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 3437.2465728521347,
      "epsilon": 0.2913030000055838
    },
    {
      "episode": 4318,
      "score": 87,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 3757.249333252778,
      "epsilon": 0.2912660000055848
    },
    {
      "episode": 4319,
      "score": 154,
      "reward": -914.0,
      "steps": 48,
      "mean_loss": 1629.1733025709789,
      "epsilon": 0.29121800000558606
    },
    {
      "episode": 4320,
      "score": 169,
      "reward": -905.0,
      "steps": 50,
      "mean_loss": 7177.718543930054,
      "epsilon": 0.2911680000055874
    },
    {
      "episode": 4321,
      "score": 197,
      "reward": -894.0,
      "steps": 55,
      "mean_loss": 3981.380340090665,
      "epsilon": 0.2911130000055889
    },
    {
      "episode": 4322,
      "score": 179,
      "reward": -909.0,
      "steps": 53,
      "mean_loss": 2270.805149510222,
      "epsilon": 0.2910600000055903
    },
    {
      "episode": 4323,
      "score": 196,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 6275.866712216978,
      "epsilon": 0.29100600000559174
    },
    {
      "episode": 4324,
      "score": 22,
      "reward": -997.0,
      "steps": 16,
      "mean_loss": 1997.2836192846298,
      "epsilon": 0.29099000000559216
    },
    {
      "episode": 4325,
      "score": 173,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 7034.553248611151,
      "epsilon": 0.29093900000559353
    },
    {
      "episode": 4326,
      "score": 130,
      "reward": -960.0,
      "steps": 46,
      "mean_loss": 5191.184892073921,
      "epsilon": 0.29089300000559476
    },
    {
      "episode": 4327,
      "score": 193,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 3239.8860475045662,
      "epsilon": 0.2908390000055962
    },
    {
      "episode": 4328,
      "score": 163,
      "reward": -904.0,
      "steps": 47,
      "mean_loss": 4986.612042609681,
      "epsilon": 0.29079200000559746
    },
    {
      "episode": 4329,
      "score": 182,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 4491.109447552608,
      "epsilon": 0.29074000000559885
    },
    {
      "episode": 4330,
      "score": 135,
      "reward": -949.0,
      "steps": 45,
      "mean_loss": 4540.356309678819,
      "epsilon": 0.29069500000560006
    },
    {
      "episode": 4331,
      "score": 158,
      "reward": -925.0,
      "steps": 51,
      "mean_loss": 4639.411810669245,
      "epsilon": 0.2906440000056014
    },
    {
      "episode": 4332,
      "score": 180,
      "reward": -910.0,
      "steps": 51,
      "mean_loss": 5942.887381834143,
      "epsilon": 0.2905930000056028
    },
    {
      "episode": 4333,
      "score": 222,
      "reward": -879.0,
      "steps": 59,
      "mean_loss": 4864.2100257226975,
      "epsilon": 0.29053400000560436
    },
    {
      "episode": 4334,
      "score": 112,
      "reward": -957.0,
      "steps": 44,
      "mean_loss": 5814.6287269592285,
      "epsilon": 0.29049000000560554
    },
    {
      "episode": 4335,
      "score": 137,
      "reward": -939.0,
      "steps": 46,
      "mean_loss": 7151.19970935324,
      "epsilon": 0.2904440000056068
    },
    {
      "episode": 4336,
      "score": 190,
      "reward": -906.0,
      "steps": 55,
      "mean_loss": 9728.01682137576,
      "epsilon": 0.29038900000560824
    },
    {
      "episode": 4337,
      "score": 209,
      "reward": -889.0,
      "steps": 58,
      "mean_loss": 2491.1061765407694,
      "epsilon": 0.2903310000056098
    },
    {
      "episode": 4338,
      "score": 155,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 6809.993261496226,
      "epsilon": 0.2902830000056111
    },
    {
      "episode": 4339,
      "score": 89,
      "reward": -980.0,
      "steps": 41,
      "mean_loss": 3734.923470473871,
      "epsilon": 0.2902420000056122
    },
    {
      "episode": 4340,
      "score": 154,
      "reward": -938.0,
      "steps": 51,
      "mean_loss": 3685.992505129646,
      "epsilon": 0.29019100000561354
    },
    {
      "episode": 4341,
      "score": 116,
      "reward": -947.0,
      "steps": 41,
      "mean_loss": 4753.413871486013,
      "epsilon": 0.29015000000561464
    },
    {
      "episode": 4342,
      "score": 146,
      "reward": -934.0,
      "steps": 49,
      "mean_loss": 2677.3383086846798,
      "epsilon": 0.29010100000561595
    },
    {
      "episode": 4343,
      "score": 151,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 5917.479555480334,
      "epsilon": 0.29005200000561726
    },
    {
      "episode": 4344,
      "score": 105,
      "reward": -975.0,
      "steps": 45,
      "mean_loss": 5728.9565249972875,
      "epsilon": 0.29000700000561846
    },
    {
      "episode": 4345,
      "score": 118,
      "reward": -962.0,
      "steps": 45,
      "mean_loss": 2990.328499815199,
      "epsilon": 0.28996200000561967
    },
    {
      "episode": 4346,
      "score": 180,
      "reward": -901.0,
      "steps": 49,
      "mean_loss": 7508.144139348245,
      "epsilon": 0.289913000005621
    },
    {
      "episode": 4347,
      "score": 159,
      "reward": -925.0,
      "steps": 50,
      "mean_loss": 4551.403090820312,
      "epsilon": 0.2898630000056223
    },
    {
      "episode": 4348,
      "score": 139,
      "reward": -925.0,
      "steps": 44,
      "mean_loss": 4338.8698029084635,
      "epsilon": 0.2898190000056235
    },
    {
      "episode": 4349,
      "score": 192,
      "reward": -898.0,
      "steps": 53,
      "mean_loss": 6310.895707256389,
      "epsilon": 0.2897660000056249
    },
    {
      "episode": 4350,
      "score": 477,
      "reward": -654.0,
      "steps": 104,
      "mean_loss": 3657.284764436575,
      "epsilon": 0.2896620000056277
    },
    {
      "episode": 4351,
      "score": 184,
      "reward": -896.0,
      "steps": 51,
      "mean_loss": 3637.5097061606016,
      "epsilon": 0.28961100000562906
    },
    {
      "episode": 4352,
      "score": 176,
      "reward": -896.0,
      "steps": 49,
      "mean_loss": 4916.7052181399595,
      "epsilon": 0.28956200000563037
    },
    {
      "episode": 4353,
      "score": 119,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 5147.657455617731,
      "epsilon": 0.28951800000563155
    },
    {
      "episode": 4354,
      "score": 133,
      "reward": -932.0,
      "steps": 45,
      "mean_loss": 5823.588826243083,
      "epsilon": 0.28947300000563275
    },
    {
      "episode": 4355,
      "score": 130,
      "reward": -942.0,
      "steps": 47,
      "mean_loss": 5935.948037898287,
      "epsilon": 0.289426000005634
    },
    {
      "episode": 4356,
      "score": 127,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 3549.3822575887043,
      "epsilon": 0.2893810000056352
    },
    {
      "episode": 4357,
      "score": 177,
      "reward": -908.0,
      "steps": 49,
      "mean_loss": 6726.030125987773,
      "epsilon": 0.2893320000056365
    },
    {
      "episode": 4358,
      "score": 221,
      "reward": -883.0,
      "steps": 56,
      "mean_loss": 4066.3979539871216,
      "epsilon": 0.289276000005638
    },
    {
      "episode": 4359,
      "score": 108,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 3850.8527594479647,
      "epsilon": 0.2892320000056392
    },
    {
      "episode": 4360,
      "score": 155,
      "reward": -936.0,
      "steps": 50,
      "mean_loss": 2783.844503250122,
      "epsilon": 0.28918200000564054
    },
    {
      "episode": 4361,
      "score": 141,
      "reward": -939.0,
      "steps": 45,
      "mean_loss": 6154.208446290758,
      "epsilon": 0.28913700000564174
    },
    {
      "episode": 4362,
      "score": 112,
      "reward": -942.0,
      "steps": 38,
      "mean_loss": 4781.2099553158405,
      "epsilon": 0.28909900000564276
    },
    {
      "episode": 4363,
      "score": 180,
      "reward": -899.0,
      "steps": 55,
      "mean_loss": 5854.505247497558,
      "epsilon": 0.28904400000564423
    },
    {
      "episode": 4364,
      "score": 153,
      "reward": -918.0,
      "steps": 48,
      "mean_loss": 3259.6123785972595,
      "epsilon": 0.2889960000056455
    },
    {
      "episode": 4365,
      "score": 134,
      "reward": -939.0,
      "steps": 44,
      "mean_loss": 3554.8817450783467,
      "epsilon": 0.2889520000056467
    },
    {
      "episode": 4366,
      "score": 122,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 3313.1338141181254,
      "epsilon": 0.28890800000564787
    },
    {
      "episode": 4367,
      "score": 225,
      "reward": -886.0,
      "steps": 61,
      "mean_loss": 5561.87387666546,
      "epsilon": 0.2888470000056495
    },
    {
      "episode": 4368,
      "score": 121,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 4837.190388452439,
      "epsilon": 0.2888050000056506
    },
    {
      "episode": 4369,
      "score": 141,
      "reward": -928.0,
      "steps": 45,
      "mean_loss": 7707.802135382758,
      "epsilon": 0.28876000000565183
    },
    {
      "episode": 4370,
      "score": 179,
      "reward": -899.0,
      "steps": 52,
      "mean_loss": 5537.1203044011045,
      "epsilon": 0.2887080000056532
    },
    {
      "episode": 4371,
      "score": 118,
      "reward": -940.0,
      "steps": 40,
      "mean_loss": 3805.9617907524107,
      "epsilon": 0.2886680000056543
    },
    {
      "episode": 4372,
      "score": 196,
      "reward": -892.0,
      "steps": 55,
      "mean_loss": 4052.9861342690206,
      "epsilon": 0.28861300000565576
    },
    {
      "episode": 4373,
      "score": 118,
      "reward": -964.0,
      "steps": 44,
      "mean_loss": 2795.0261098688297,
      "epsilon": 0.28856900000565694
    },
    {
      "episode": 4374,
      "score": 160,
      "reward": -922.0,
      "steps": 48,
      "mean_loss": 3951.794154961904,
      "epsilon": 0.2885210000056582
    },
    {
      "episode": 4375,
      "score": 187,
      "reward": -903.0,
      "steps": 55,
      "mean_loss": 5189.382238561457,
      "epsilon": 0.2884660000056597
    },
    {
      "episode": 4376,
      "score": 158,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 5280.991754648637,
      "epsilon": 0.288417000005661
    },
    {
      "episode": 4377,
      "score": 260,
      "reward": -849.0,
      "steps": 63,
      "mean_loss": 2406.582135518392,
      "epsilon": 0.2883540000056627
    },
    {
      "episode": 4378,
      "score": 144,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 4092.1648078269145,
      "epsilon": 0.28830700000566395
    },
    {
      "episode": 4379,
      "score": 191,
      "reward": -887.0,
      "steps": 50,
      "mean_loss": 3717.6707479858396,
      "epsilon": 0.2882570000056653
    },
    {
      "episode": 4380,
      "score": 146,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 2839.713177350103,
      "epsilon": 0.2882080000056666
    },
    {
      "episode": 4381,
      "score": 120,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 2686.5528107989917,
      "epsilon": 0.2881640000056678
    },
    {
      "episode": 4382,
      "score": 193,
      "reward": -893.0,
      "steps": 51,
      "mean_loss": 2337.832005818685,
      "epsilon": 0.28811300000566914
    },
    {
      "episode": 4383,
      "score": 192,
      "reward": -889.0,
      "steps": 54,
      "mean_loss": 4539.763317108154,
      "epsilon": 0.2880590000056706
    },
    {
      "episode": 4384,
      "score": 200,
      "reward": -894.0,
      "steps": 54,
      "mean_loss": 4740.559647630762,
      "epsilon": 0.28800500000567203
    },
    {
      "episode": 4385,
      "score": 268,
      "reward": -847.0,
      "steps": 67,
      "mean_loss": 4348.062172761604,
      "epsilon": 0.2879380000056738
    },
    {
      "episode": 4386,
      "score": 154,
      "reward": -911.0,
      "steps": 46,
      "mean_loss": 3453.967518184496,
      "epsilon": 0.28789200000567505
    },
    {
      "episode": 4387,
      "score": 187,
      "reward": -886.0,
      "steps": 51,
      "mean_loss": 3958.2554506788065,
      "epsilon": 0.2878410000056764
    },
    {
      "episode": 4388,
      "score": 106,
      "reward": -966.0,
      "steps": 41,
      "mean_loss": 6452.353530883789,
      "epsilon": 0.2878000000056775
    },
    {
      "episode": 4389,
      "score": 235,
      "reward": -864.0,
      "steps": 62,
      "mean_loss": 3487.4310484855405,
      "epsilon": 0.2877380000056792
    },
    {
      "episode": 4390,
      "score": 124,
      "reward": -938.0,
      "steps": 39,
      "mean_loss": 4571.176028471727,
      "epsilon": 0.2876990000056802
    },
    {
      "episode": 4391,
      "score": 164,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 2721.549002685547,
      "epsilon": 0.28764900000568155
    },
    {
      "episode": 4392,
      "score": 132,
      "reward": -940.0,
      "steps": 45,
      "mean_loss": 5788.437470753987,
      "epsilon": 0.28760400000568276
    },
    {
      "episode": 4393,
      "score": 147,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 2808.1896670659385,
      "epsilon": 0.28755600000568404
    },
    {
      "episode": 4394,
      "score": 96,
      "reward": -987.0,
      "steps": 43,
      "mean_loss": 5257.311161928399,
      "epsilon": 0.2875130000056852
    },
    {
      "episode": 4395,
      "score": 79,
      "reward": -987.0,
      "steps": 35,
      "mean_loss": 3844.022858755929,
      "epsilon": 0.28747800000568613
    },
    {
      "episode": 4396,
      "score": 193,
      "reward": -884.0,
      "steps": 54,
      "mean_loss": 6406.865973295989,
      "epsilon": 0.2874240000056876
    },
    {
      "episode": 4397,
      "score": 163,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 4790.580927401173,
      "epsilon": 0.2873750000056889
    },
    {
      "episode": 4398,
      "score": 118,
      "reward": -956.0,
      "steps": 46,
      "mean_loss": 5940.1372993303385,
      "epsilon": 0.2873290000056901
    },
    {
      "episode": 4399,
      "score": 66,
      "reward": -990.0,
      "steps": 33,
      "mean_loss": 3983.999947230021,
      "epsilon": 0.287296000005691
    },
    {
      "episode": 4400,
      "score": 188,
      "reward": -898.0,
      "steps": 54,
      "mean_loss": 5975.612104415894,
      "epsilon": 0.28724200000569244
    },
    {
      "episode": 4401,
      "score": 166,
      "reward": -926.0,
      "steps": 51,
      "mean_loss": 8450.77600179934,
      "epsilon": 0.2871910000056938
    },
    {
      "episode": 4402,
      "score": 157,
      "reward": -924.0,
      "steps": 51,
      "mean_loss": 5752.653657202627,
      "epsilon": 0.2871400000056952
    },
    {
      "episode": 4403,
      "score": 110,
      "reward": -941.0,
      "steps": 38,
      "mean_loss": 4432.769750093159,
      "epsilon": 0.2871020000056962
    },
    {
      "episode": 4404,
      "score": 222,
      "reward": -898.0,
      "steps": 59,
      "mean_loss": 4331.647742061292,
      "epsilon": 0.28704300000569777
    },
    {
      "episode": 4405,
      "score": 117,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 4025.9753786433826,
      "epsilon": 0.28699900000569895
    },
    {
      "episode": 4406,
      "score": 166,
      "reward": -919.0,
      "steps": 49,
      "mean_loss": 3947.1964175944427,
      "epsilon": 0.28695000000570026
    },
    {
      "episode": 4407,
      "score": 161,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 6438.116473528804,
      "epsilon": 0.28690100000570157
    },
    {
      "episode": 4408,
      "score": 222,
      "reward": -879.0,
      "steps": 57,
      "mean_loss": 6230.329633679306,
      "epsilon": 0.2868440000057031
    },
    {
      "episode": 4409,
      "score": 151,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 4906.366499633789,
      "epsilon": 0.28679400000570443
    },
    {
      "episode": 4410,
      "score": 99,
      "reward": -962.0,
      "steps": 40,
      "mean_loss": 5003.047955226898,
      "epsilon": 0.2867540000057055
    },
    {
      "episode": 4411,
      "score": 113,
      "reward": -939.0,
      "steps": 34,
      "mean_loss": 2948.535539514878,
      "epsilon": 0.2867200000057064
    },
    {
      "episode": 4412,
      "score": 114,
      "reward": -951.0,
      "steps": 42,
      "mean_loss": 5232.87299810137,
      "epsilon": 0.28667800000570753
    },
    {
      "episode": 4413,
      "score": 125,
      "reward": -934.0,
      "steps": 39,
      "mean_loss": 2012.027223440317,
      "epsilon": 0.2866390000057086
    },
    {
      "episode": 4414,
      "score": 232,
      "reward": -871.0,
      "steps": 60,
      "mean_loss": 1445.6933696746826,
      "epsilon": 0.2865790000057102
    },
    {
      "episode": 4415,
      "score": 181,
      "reward": -913.0,
      "steps": 54,
      "mean_loss": 6523.101363499959,
      "epsilon": 0.2865250000057116
    },
    {
      "episode": 4416,
      "score": 103,
      "reward": -950.0,
      "steps": 34,
      "mean_loss": 2041.1702214409324,
      "epsilon": 0.28649100000571254
    },
    {
      "episode": 4417,
      "score": 197,
      "reward": -889.0,
      "steps": 55,
      "mean_loss": 5072.649224784158,
      "epsilon": 0.286436000005714
    },
    {
      "episode": 4418,
      "score": 132,
      "reward": -941.0,
      "steps": 47,
      "mean_loss": 4149.0682859623685,
      "epsilon": 0.28638900000571527
    },
    {
      "episode": 4419,
      "score": 178,
      "reward": -927.0,
      "steps": 56,
      "mean_loss": 5259.416079793657,
      "epsilon": 0.28633300000571676
    },
    {
      "episode": 4420,
      "score": 181,
      "reward": -898.0,
      "steps": 50,
      "mean_loss": 5112.9478380584715,
      "epsilon": 0.2862830000057181
    },
    {
      "episode": 4421,
      "score": 108,
      "reward": -977.0,
      "steps": 43,
      "mean_loss": 5877.371998720391,
      "epsilon": 0.28624000000571925
    },
    {
      "episode": 4422,
      "score": 244,
      "reward": -877.0,
      "steps": 63,
      "mean_loss": 6525.226996285574,
      "epsilon": 0.28617700000572094
    },
    {
      "episode": 4423,
      "score": 157,
      "reward": -928.0,
      "steps": 52,
      "mean_loss": 5491.183085074792,
      "epsilon": 0.28612500000572233
    },
    {
      "episode": 4424,
      "score": 109,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 5346.839853113348,
      "epsilon": 0.2860810000057235
    },
    {
      "episode": 4425,
      "score": 175,
      "reward": -909.0,
      "steps": 52,
      "mean_loss": 3595.356222959665,
      "epsilon": 0.2860290000057249
    },
    {
      "episode": 4426,
      "score": 105,
      "reward": -969.0,
      "steps": 44,
      "mean_loss": 3130.018599683588,
      "epsilon": 0.2859850000057261
    },
    {
      "episode": 4427,
      "score": 142,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 4426.162220080693,
      "epsilon": 0.28593700000572736
    },
    {
      "episode": 4428,
      "score": 198,
      "reward": -881.0,
      "steps": 53,
      "mean_loss": 6408.343634407475,
      "epsilon": 0.2858840000057288
    },
    {
      "episode": 4429,
      "score": 124,
      "reward": -940.0,
      "steps": 44,
      "mean_loss": 3760.912289879539,
      "epsilon": 0.28584000000572996
    },
    {
      "episode": 4430,
      "score": 121,
      "reward": -952.0,
      "steps": 44,
      "mean_loss": 4622.9188869649715,
      "epsilon": 0.28579600000573113
    },
    {
      "episode": 4431,
      "score": 193,
      "reward": -890.0,
      "steps": 54,
      "mean_loss": 3759.4497676072297,
      "epsilon": 0.2857420000057326
    },
    {
      "episode": 4432,
      "score": 157,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 3324.9602075130383,
      "epsilon": 0.28569500000573383
    },
    {
      "episode": 4433,
      "score": 146,
      "reward": -926.0,
      "steps": 45,
      "mean_loss": 4085.611371358236,
      "epsilon": 0.28565000000573504
    },
    {
      "episode": 4434,
      "score": 165,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 5678.02494594029,
      "epsilon": 0.28560100000573635
    },
    {
      "episode": 4435,
      "score": 192,
      "reward": -872.0,
      "steps": 52,
      "mean_loss": 4375.531455553495,
      "epsilon": 0.28554900000573774
    },
    {
      "episode": 4436,
      "score": 91,
      "reward": -987.0,
      "steps": 41,
      "mean_loss": 6805.374851505931,
      "epsilon": 0.28550800000573884
    },
    {
      "episode": 4437,
      "score": 176,
      "reward": -907.0,
      "steps": 51,
      "mean_loss": 5825.326573764577,
      "epsilon": 0.2854570000057402
    },
    {
      "episode": 4438,
      "score": 116,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 3686.269096808,
      "epsilon": 0.2854130000057414
    },
    {
      "episode": 4439,
      "score": 105,
      "reward": -969.0,
      "steps": 41,
      "mean_loss": 4727.7366931264,
      "epsilon": 0.2853720000057425
    },
    {
      "episode": 4440,
      "score": 248,
      "reward": -857.0,
      "steps": 63,
      "mean_loss": 4122.378976852175,
      "epsilon": 0.28530900000574416
    },
    {
      "episode": 4441,
      "score": 190,
      "reward": -888.0,
      "steps": 54,
      "mean_loss": 5308.021971243399,
      "epsilon": 0.2852550000057456
    },
    {
      "episode": 4442,
      "score": 172,
      "reward": -893.0,
      "steps": 49,
      "mean_loss": 4609.858888158993,
      "epsilon": 0.2852060000057469
    },
    {
      "episode": 4443,
      "score": 154,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 5608.008992139031,
      "epsilon": 0.2851550000057483
    },
    {
      "episode": 4444,
      "score": 184,
      "reward": -894.0,
      "steps": 48,
      "mean_loss": 2421.1536716620126,
      "epsilon": 0.28510700000574957
    },
    {
      "episode": 4445,
      "score": 142,
      "reward": -925.0,
      "steps": 45,
      "mean_loss": 6010.264230897692,
      "epsilon": 0.28506200000575077
    },
    {
      "episode": 4446,
      "score": 104,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 3403.206960496448,
      "epsilon": 0.2850200000057519
    },
    {
      "episode": 4447,
      "score": 117,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 2832.073515805331,
      "epsilon": 0.28497600000575307
    },
    {
      "episode": 4448,
      "score": 264,
      "reward": -837.0,
      "steps": 65,
      "mean_loss": 4284.592959653414,
      "epsilon": 0.2849110000057548
    },
    {
      "episode": 4449,
      "score": 164,
      "reward": -921.0,
      "steps": 49,
      "mean_loss": 5636.976349655462,
      "epsilon": 0.2848620000057561
    },
    {
      "episode": 4450,
      "score": 153,
      "reward": -922.0,
      "steps": 48,
      "mean_loss": 5445.357301751773,
      "epsilon": 0.2848140000057574
    },
    {
      "episode": 4451,
      "score": 191,
      "reward": -917.0,
      "steps": 51,
      "mean_loss": 3464.9390753203747,
      "epsilon": 0.28476300000575877
    },
    {
      "episode": 4452,
      "score": 238,
      "reward": -879.0,
      "steps": 62,
      "mean_loss": 3736.255623909735,
      "epsilon": 0.28470100000576043
    },
    {
      "episode": 4453,
      "score": 149,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 3608.217758255005,
      "epsilon": 0.28465100000576177
    },
    {
      "episode": 4454,
      "score": 160,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4968.435298452572,
      "epsilon": 0.2846020000057631
    },
    {
      "episode": 4455,
      "score": 95,
      "reward": -948.0,
      "steps": 33,
      "mean_loss": 5060.851539785212,
      "epsilon": 0.28456900000576396
    },
    {
      "episode": 4456,
      "score": 105,
      "reward": -957.0,
      "steps": 37,
      "mean_loss": 5784.273727159242,
      "epsilon": 0.28453200000576495
    },
    {
      "episode": 4457,
      "score": 190,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 5146.264606546472,
      "epsilon": 0.2844780000057664
    },
    {
      "episode": 4458,
      "score": 169,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 4377.026533813477,
      "epsilon": 0.28442800000576773
    },
    {
      "episode": 4459,
      "score": 80,
      "reward": -978.0,
      "steps": 36,
      "mean_loss": 2710.405118412442,
      "epsilon": 0.2843920000057687
    },
    {
      "episode": 4460,
      "score": 133,
      "reward": -947.0,
      "steps": 47,
      "mean_loss": 4640.011858919834,
      "epsilon": 0.28434500000576995
    },
    {
      "episode": 4461,
      "score": 155,
      "reward": -901.0,
      "steps": 46,
      "mean_loss": 4060.8822329977284,
      "epsilon": 0.2842990000057712
    },
    {
      "episode": 4462,
      "score": 31,
      "reward": -993.0,
      "steps": 18,
      "mean_loss": 3826.6427196926543,
      "epsilon": 0.28428100000577167
    },
    {
      "episode": 4463,
      "score": 144,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 3278.918070157369,
      "epsilon": 0.28423300000577295
    },
    {
      "episode": 4464,
      "score": 105,
      "reward": -981.0,
      "steps": 35,
      "mean_loss": 5859.822543443952,
      "epsilon": 0.2841980000057739
    },
    {
      "episode": 4465,
      "score": 111,
      "reward": -959.0,
      "steps": 43,
      "mean_loss": 5575.508309297784,
      "epsilon": 0.28415500000577504
    },
    {
      "episode": 4466,
      "score": 158,
      "reward": -928.0,
      "steps": 48,
      "mean_loss": 5071.4682180086775,
      "epsilon": 0.2841070000057763
    },
    {
      "episode": 4467,
      "score": 231,
      "reward": -863.0,
      "steps": 58,
      "mean_loss": 3647.2214949377653,
      "epsilon": 0.2840490000057779
    },
    {
      "episode": 4468,
      "score": 135,
      "reward": -941.0,
      "steps": 45,
      "mean_loss": 4580.2429336124,
      "epsilon": 0.2840040000057791
    },
    {
      "episode": 4469,
      "score": 162,
      "reward": -904.0,
      "steps": 47,
      "mean_loss": 5322.864157494078,
      "epsilon": 0.28395700000578034
    },
    {
      "episode": 4470,
      "score": 228,
      "reward": -859.0,
      "steps": 58,
      "mean_loss": 6240.169326847998,
      "epsilon": 0.2838990000057819
    },
    {
      "episode": 4471,
      "score": 200,
      "reward": -892.0,
      "steps": 58,
      "mean_loss": 1563.64944477739,
      "epsilon": 0.28384100000578344
    },
    {
      "episode": 4472,
      "score": 192,
      "reward": -885.0,
      "steps": 52,
      "mean_loss": 3593.7011840526875,
      "epsilon": 0.28378900000578483
    },
    {
      "episode": 4473,
      "score": 211,
      "reward": -888.0,
      "steps": 57,
      "mean_loss": 4905.570957183838,
      "epsilon": 0.28373200000578636
    },
    {
      "episode": 4474,
      "score": 130,
      "reward": -961.0,
      "steps": 49,
      "mean_loss": 4180.25221945315,
      "epsilon": 0.28368300000578767
    },
    {
      "episode": 4475,
      "score": 81,
      "reward": -993.0,
      "steps": 36,
      "mean_loss": 5225.803280618456,
      "epsilon": 0.28364700000578863
    },
    {
      "episode": 4476,
      "score": 256,
      "reward": -854.0,
      "steps": 62,
      "mean_loss": 5899.230417743806,
      "epsilon": 0.2835850000057903
    },
    {
      "episode": 4477,
      "score": 164,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 3752.423526114606,
      "epsilon": 0.28353800000579155
    },
    {
      "episode": 4478,
      "score": 119,
      "reward": -953.0,
      "steps": 39,
      "mean_loss": 2440.118991558368,
      "epsilon": 0.2834990000057926
    },
    {
      "episode": 4479,
      "score": 140,
      "reward": -921.0,
      "steps": 43,
      "mean_loss": 3419.0458924936693,
      "epsilon": 0.28345600000579374
    },
    {
      "episode": 4480,
      "score": 233,
      "reward": -848.0,
      "steps": 59,
      "mean_loss": 3959.2309290999074,
      "epsilon": 0.2833970000057953
    },
    {
      "episode": 4481,
      "score": 153,
      "reward": -930.0,
      "steps": 47,
      "mean_loss": 5644.399121304776,
      "epsilon": 0.2833500000057966
    },
    {
      "episode": 4482,
      "score": 129,
      "reward": -938.0,
      "steps": 43,
      "mean_loss": 2542.554756741191,
      "epsilon": 0.2833070000057977
    },
    {
      "episode": 4483,
      "score": 119,
      "reward": -941.0,
      "steps": 43,
      "mean_loss": 4873.325127801229,
      "epsilon": 0.2832640000057989
    },
    {
      "episode": 4484,
      "score": 215,
      "reward": -874.0,
      "steps": 54,
      "mean_loss": 3122.488600978145,
      "epsilon": 0.2832100000058003
    },
    {
      "episode": 4485,
      "score": 182,
      "reward": -909.0,
      "steps": 52,
      "mean_loss": 5454.9254728097185,
      "epsilon": 0.2831580000058017
    },
    {
      "episode": 4486,
      "score": 140,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 3535.379882082026,
      "epsilon": 0.28311100000580297
    },
    {
      "episode": 4487,
      "score": 172,
      "reward": -914.0,
      "steps": 52,
      "mean_loss": 2541.778510607206,
      "epsilon": 0.28305900000580436
    },
    {
      "episode": 4488,
      "score": 194,
      "reward": -892.0,
      "steps": 54,
      "mean_loss": 4271.121649812769,
      "epsilon": 0.2830050000058058
    },
    {
      "episode": 4489,
      "score": 121,
      "reward": -944.0,
      "steps": 41,
      "mean_loss": 3099.2398088036516,
      "epsilon": 0.2829640000058069
    },
    {
      "episode": 4490,
      "score": 231,
      "reward": -856.0,
      "steps": 58,
      "mean_loss": 4054.6815777153806,
      "epsilon": 0.28290600000580846
    },
    {
      "episode": 4491,
      "score": 169,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 6124.920936546326,
      "epsilon": 0.2828560000058098
    },
    {
      "episode": 4492,
      "score": 122,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 4536.893945087086,
      "epsilon": 0.28281200000581097
    },
    {
      "episode": 4493,
      "score": 131,
      "reward": -951.0,
      "steps": 48,
      "mean_loss": 1536.5806008577347,
      "epsilon": 0.28276400000581225
    },
    {
      "episode": 4494,
      "score": 89,
      "reward": -984.0,
      "steps": 39,
      "mean_loss": 4219.068614470653,
      "epsilon": 0.2827250000058133
    },
    {
      "episode": 4495,
      "score": 74,
      "reward": -982.0,
      "steps": 35,
      "mean_loss": 8362.257480948312,
      "epsilon": 0.28269000000581423
    },
    {
      "episode": 4496,
      "score": 118,
      "reward": -950.0,
      "steps": 40,
      "mean_loss": 3355.551896572113,
      "epsilon": 0.2826500000058153
    },
    {
      "episode": 4497,
      "score": 301,
      "reward": -800.0,
      "steps": 67,
      "mean_loss": 3269.276559260354,
      "epsilon": 0.2825830000058171
    },
    {
      "episode": 4498,
      "score": 227,
      "reward": -874.0,
      "steps": 60,
      "mean_loss": 2797.469081815084,
      "epsilon": 0.2825230000058187
    },
    {
      "episode": 4499,
      "score": 138,
      "reward": -937.0,
      "steps": 45,
      "mean_loss": 3962.1466534084743,
      "epsilon": 0.2824780000058199
    },
    {
      "episode": 4500,
      "score": 135,
      "reward": -953.0,
      "steps": 49,
      "mean_loss": 3658.048865571314,
      "epsilon": 0.2824290000058212
    },
    {
      "episode": 4501,
      "score": 232,
      "reward": -867.0,
      "steps": 57,
      "mean_loss": 5762.402221077366,
      "epsilon": 0.28237200000582274
    },
    {
      "episode": 4502,
      "score": 188,
      "reward": -880.0,
      "steps": 47,
      "mean_loss": 5585.415984133457,
      "epsilon": 0.282325000005824
    },
    {
      "episode": 4503,
      "score": 169,
      "reward": -912.0,
      "steps": 50,
      "mean_loss": 3936.7015644836424,
      "epsilon": 0.28227500000582534
    },
    {
      "episode": 4504,
      "score": 75,
      "reward": -987.0,
      "steps": 34,
      "mean_loss": 5051.338187946993,
      "epsilon": 0.28224100000582625
    },
    {
      "episode": 4505,
      "score": 151,
      "reward": -919.0,
      "steps": 46,
      "mean_loss": 4303.438575910485,
      "epsilon": 0.2821950000058275
    },
    {
      "episode": 4506,
      "score": 127,
      "reward": -944.0,
      "steps": 40,
      "mean_loss": 4173.416320419312,
      "epsilon": 0.28215500000582855
    },
    {
      "episode": 4507,
      "score": 187,
      "reward": -909.0,
      "steps": 55,
      "mean_loss": 3208.2602425661953,
      "epsilon": 0.28210000000583
    },
    {
      "episode": 4508,
      "score": 172,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 3694.4034185409546,
      "epsilon": 0.2820480000058314
    },
    {
      "episode": 4509,
      "score": 103,
      "reward": -979.0,
      "steps": 44,
      "mean_loss": 6654.028650327163,
      "epsilon": 0.2820040000058326
    },
    {
      "episode": 4510,
      "score": 242,
      "reward": -851.0,
      "steps": 60,
      "mean_loss": 2340.9458466847736,
      "epsilon": 0.2819440000058342
    },
    {
      "episode": 4511,
      "score": 148,
      "reward": -923.0,
      "steps": 45,
      "mean_loss": 5105.6474867079,
      "epsilon": 0.2818990000058354
    },
    {
      "episode": 4512,
      "score": 132,
      "reward": -944.0,
      "steps": 47,
      "mean_loss": 4707.332301931178,
      "epsilon": 0.28185200000583666
    },
    {
      "episode": 4513,
      "score": 108,
      "reward": -952.0,
      "steps": 39,
      "mean_loss": 2884.5629164866914,
      "epsilon": 0.2818130000058377
    },
    {
      "episode": 4514,
      "score": 135,
      "reward": -938.0,
      "steps": 44,
      "mean_loss": 5606.654511365024,
      "epsilon": 0.2817690000058389
    },
    {
      "episode": 4515,
      "score": 161,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 7392.749850837552,
      "epsilon": 0.2817200000058402
    },
    {
      "episode": 4516,
      "score": 205,
      "reward": -881.0,
      "steps": 53,
      "mean_loss": 4246.8926082107255,
      "epsilon": 0.2816670000058416
    },
    {
      "episode": 4517,
      "score": 197,
      "reward": -897.0,
      "steps": 54,
      "mean_loss": 3648.0866019637497,
      "epsilon": 0.28161300000584305
    },
    {
      "episode": 4518,
      "score": 155,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 3320.5247379614384,
      "epsilon": 0.28156400000584436
    },
    {
      "episode": 4519,
      "score": 116,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 3281.388502771204,
      "epsilon": 0.28152000000584554
    },
    {
      "episode": 4520,
      "score": 111,
      "reward": -962.0,
      "steps": 41,
      "mean_loss": 4456.404975565469,
      "epsilon": 0.28147900000584664
    },
    {
      "episode": 4521,
      "score": 174,
      "reward": -903.0,
      "steps": 48,
      "mean_loss": 3166.8399658997855,
      "epsilon": 0.2814310000058479
    },
    {
      "episode": 4522,
      "score": 173,
      "reward": -926.0,
      "steps": 54,
      "mean_loss": 4077.46594425484,
      "epsilon": 0.28137700000584936
    },
    {
      "episode": 4523,
      "score": 103,
      "reward": -970.0,
      "steps": 40,
      "mean_loss": 5150.206923961639,
      "epsilon": 0.28133700000585043
    },
    {
      "episode": 4524,
      "score": 165,
      "reward": -915.0,
      "steps": 52,
      "mean_loss": 5186.642991212698,
      "epsilon": 0.2812850000058518
    },
    {
      "episode": 4525,
      "score": 183,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 3294.9563484191895,
      "epsilon": 0.2812330000058532
    },
    {
      "episode": 4526,
      "score": 293,
      "reward": -804.0,
      "steps": 66,
      "mean_loss": 4493.760542493878,
      "epsilon": 0.281167000005855
    },
    {
      "episode": 4527,
      "score": 147,
      "reward": -933.0,
      "steps": 45,
      "mean_loss": 7555.232061089409,
      "epsilon": 0.2811220000058562
    },
    {
      "episode": 4528,
      "score": 209,
      "reward": -855.0,
      "steps": 53,
      "mean_loss": 5146.993490686957,
      "epsilon": 0.2810690000058576
    },
    {
      "episode": 4529,
      "score": 114,
      "reward": -968.0,
      "steps": 44,
      "mean_loss": 3182.3524651093917,
      "epsilon": 0.2810250000058588
    },
    {
      "episode": 4530,
      "score": 156,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 3691.3871110280356,
      "epsilon": 0.28097700000586007
    },
    {
      "episode": 4531,
      "score": 178,
      "reward": -900.0,
      "steps": 53,
      "mean_loss": 2134.347128598195,
      "epsilon": 0.2809240000058615
    },
    {
      "episode": 4532,
      "score": 133,
      "reward": -954.0,
      "steps": 47,
      "mean_loss": 9311.834057949958,
      "epsilon": 0.28087700000586274
    },
    {
      "episode": 4533,
      "score": 286,
      "reward": -831.0,
      "steps": 68,
      "mean_loss": 2340.365947779487,
      "epsilon": 0.28080900000586456
    },
    {
      "episode": 4534,
      "score": 113,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 2236.3049043308606,
      "epsilon": 0.28076500000586574
    },
    {
      "episode": 4535,
      "score": 177,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 2529.786340264713,
      "epsilon": 0.2807140000058671
    },
    {
      "episode": 4536,
      "score": 189,
      "reward": -924.0,
      "steps": 52,
      "mean_loss": 3403.5255439464863,
      "epsilon": 0.2806620000058685
    },
    {
      "episode": 4537,
      "score": 67,
      "reward": -985.0,
      "steps": 33,
      "mean_loss": 4234.092436010187,
      "epsilon": 0.2806290000058694
    },
    {
      "episode": 4538,
      "score": 75,
      "reward": -993.0,
      "steps": 36,
      "mean_loss": 6389.443277041118,
      "epsilon": 0.28059300000587034
    },
    {
      "episode": 4539,
      "score": 193,
      "reward": -910.0,
      "steps": 54,
      "mean_loss": 3998.472327126397,
      "epsilon": 0.2805390000058718
    },
    {
      "episode": 4540,
      "score": 121,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 5361.426309932362,
      "epsilon": 0.28049500000587296
    },
    {
      "episode": 4541,
      "score": 190,
      "reward": -906.0,
      "steps": 54,
      "mean_loss": 3516.042894716616,
      "epsilon": 0.2804410000058744
    },
    {
      "episode": 4542,
      "score": 158,
      "reward": -939.0,
      "steps": 49,
      "mean_loss": 6356.36367836777,
      "epsilon": 0.2803920000058757
    },
    {
      "episode": 4543,
      "score": 144,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 5122.6240074237185,
      "epsilon": 0.280344000005877
    },
    {
      "episode": 4544,
      "score": 114,
      "reward": -959.0,
      "steps": 44,
      "mean_loss": 4043.494111061096,
      "epsilon": 0.2803000000058782
    },
    {
      "episode": 4545,
      "score": 160,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 3707.015042162956,
      "epsilon": 0.28025300000587944
    },
    {
      "episode": 4546,
      "score": 185,
      "reward": -893.0,
      "steps": 51,
      "mean_loss": 5069.567383597879,
      "epsilon": 0.2802020000058808
    },
    {
      "episode": 4547,
      "score": 185,
      "reward": -904.0,
      "steps": 54,
      "mean_loss": 3433.253359264798,
      "epsilon": 0.28014800000588225
    },
    {
      "episode": 4548,
      "score": 15,
      "reward": -1007.0,
      "steps": 15,
      "mean_loss": 4385.0732345581055,
      "epsilon": 0.28013300000588265
    },
    {
      "episode": 4549,
      "score": 145,
      "reward": -933.0,
      "steps": 45,
      "mean_loss": 3699.389070722792,
      "epsilon": 0.28008800000588385
    },
    {
      "episode": 4550,
      "score": 81,
      "reward": -987.0,
      "steps": 35,
      "mean_loss": 6419.674919836862,
      "epsilon": 0.2800530000058848
    },
    {
      "episode": 4551,
      "score": 172,
      "reward": -920.0,
      "steps": 52,
      "mean_loss": 4253.235918925358,
      "epsilon": 0.2800010000058862
    },
    {
      "episode": 4552,
      "score": 127,
      "reward": -936.0,
      "steps": 44,
      "mean_loss": 2739.9874469583683,
      "epsilon": 0.27995700000588736
    },
    {
      "episode": 4553,
      "score": 154,
      "reward": -923.0,
      "steps": 47,
      "mean_loss": 3357.870092270222,
      "epsilon": 0.2799100000058886
    },
    {
      "episode": 4554,
      "score": 159,
      "reward": -933.0,
      "steps": 50,
      "mean_loss": 5339.464802169799,
      "epsilon": 0.27986000000588995
    },
    {
      "episode": 4555,
      "score": 180,
      "reward": -885.0,
      "steps": 49,
      "mean_loss": 4310.930595164396,
      "epsilon": 0.27981100000589126
    },
    {
      "episode": 4556,
      "score": 168,
      "reward": -920.0,
      "steps": 51,
      "mean_loss": 3162.596041585885,
      "epsilon": 0.27976000000589263
    },
    {
      "episode": 4557,
      "score": 234,
      "reward": -885.0,
      "steps": 61,
      "mean_loss": 6542.968062166307,
      "epsilon": 0.27969900000589426
    },
    {
      "episode": 4558,
      "score": 190,
      "reward": -897.0,
      "steps": 53,
      "mean_loss": 5690.218906330612,
      "epsilon": 0.2796460000058957
    },
    {
      "episode": 4559,
      "score": 96,
      "reward": -983.0,
      "steps": 40,
      "mean_loss": 3706.322696208954,
      "epsilon": 0.27960600000589675
    },
    {
      "episode": 4560,
      "score": 159,
      "reward": -939.0,
      "steps": 47,
      "mean_loss": 6719.878965621299,
      "epsilon": 0.279559000005898
    },
    {
      "episode": 4561,
      "score": 86,
      "reward": -971.0,
      "steps": 37,
      "mean_loss": 10360.124662657041,
      "epsilon": 0.279522000005899
    },
    {
      "episode": 4562,
      "score": 154,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 7253.649366455078,
      "epsilon": 0.27947200000590033
    },
    {
      "episode": 4563,
      "score": 122,
      "reward": -948.0,
      "steps": 42,
      "mean_loss": 5690.582915896461,
      "epsilon": 0.27943000000590146
    },
    {
      "episode": 4564,
      "score": 75,
      "reward": -1000.0,
      "steps": 37,
      "mean_loss": 4624.619782834439,
      "epsilon": 0.27939300000590245
    },
    {
      "episode": 4565,
      "score": 104,
      "reward": -961.0,
      "steps": 40,
      "mean_loss": 3476.3185908317564,
      "epsilon": 0.2793530000059035
    },
    {
      "episode": 4566,
      "score": 100,
      "reward": -964.0,
      "steps": 35,
      "mean_loss": 5434.215460532052,
      "epsilon": 0.27931800000590445
    },
    {
      "episode": 4567,
      "score": 129,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 4527.985247265209,
      "epsilon": 0.27927400000590563
    },
    {
      "episode": 4568,
      "score": 208,
      "reward": -900.0,
      "steps": 52,
      "mean_loss": 6199.09198317161,
      "epsilon": 0.279222000005907
    },
    {
      "episode": 4569,
      "score": 117,
      "reward": -950.0,
      "steps": 41,
      "mean_loss": 4769.859757911869,
      "epsilon": 0.2791810000059081
    },
    {
      "episode": 4570,
      "score": 220,
      "reward": -874.0,
      "steps": 58,
      "mean_loss": 5343.27943716378,
      "epsilon": 0.27912300000590967
    },
    {
      "episode": 4571,
      "score": 192,
      "reward": -902.0,
      "steps": 55,
      "mean_loss": 2526.791091780229,
      "epsilon": 0.27906800000591114
    },
    {
      "episode": 4572,
      "score": 146,
      "reward": -917.0,
      "steps": 44,
      "mean_loss": 5407.012476834384,
      "epsilon": 0.2790240000059123
    },
    {
      "episode": 4573,
      "score": 150,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 5338.051992893219,
      "epsilon": 0.2789760000059136
    },
    {
      "episode": 4574,
      "score": 163,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 2983.1940748253646,
      "epsilon": 0.2789270000059149
    },
    {
      "episode": 4575,
      "score": 144,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 2573.281121355422,
      "epsilon": 0.2788800000059162
    },
    {
      "episode": 4576,
      "score": 113,
      "reward": -955.0,
      "steps": 44,
      "mean_loss": 4320.478356794877,
      "epsilon": 0.27883600000591735
    },
    {
      "episode": 4577,
      "score": 80,
      "reward": -983.0,
      "steps": 39,
      "mean_loss": 3765.7079153305444,
      "epsilon": 0.2787970000059184
    },
    {
      "episode": 4578,
      "score": 124,
      "reward": -943.0,
      "steps": 43,
      "mean_loss": 7925.009957956713,
      "epsilon": 0.27875400000591954
    },
    {
      "episode": 4579,
      "score": 177,
      "reward": -897.0,
      "steps": 51,
      "mean_loss": 4224.442819894529,
      "epsilon": 0.2787030000059209
    },
    {
      "episode": 4580,
      "score": 142,
      "reward": -934.0,
      "steps": 46,
      "mean_loss": 5882.699986416361,
      "epsilon": 0.27865700000592214
    },
    {
      "episode": 4581,
      "score": 218,
      "reward": -883.0,
      "steps": 57,
      "mean_loss": 3529.565938782274,
      "epsilon": 0.27860000000592366
    },
    {
      "episode": 4582,
      "score": 171,
      "reward": -880.0,
      "steps": 48,
      "mean_loss": 3862.014317433039,
      "epsilon": 0.27855200000592495
    },
    {
      "episode": 4583,
      "score": 120,
      "reward": -965.0,
      "steps": 46,
      "mean_loss": 3966.6868827239327,
      "epsilon": 0.2785060000059262
    },
    {
      "episode": 4584,
      "score": 194,
      "reward": -889.0,
      "steps": 55,
      "mean_loss": 3423.0680861039596,
      "epsilon": 0.27845100000592765
    },
    {
      "episode": 4585,
      "score": 122,
      "reward": -951.0,
      "steps": 42,
      "mean_loss": 3841.4952082861037,
      "epsilon": 0.2784090000059288
    },
    {
      "episode": 4586,
      "score": 117,
      "reward": -956.0,
      "steps": 44,
      "mean_loss": 2762.7519152381205,
      "epsilon": 0.27836500000592995
    },
    {
      "episode": 4587,
      "score": 257,
      "reward": -850.0,
      "steps": 68,
      "mean_loss": 3595.635829364552,
      "epsilon": 0.27829700000593177
    },
    {
      "episode": 4588,
      "score": 130,
      "reward": -950.0,
      "steps": 46,
      "mean_loss": 3561.8191472758417,
      "epsilon": 0.278251000005933
    },
    {
      "episode": 4589,
      "score": 153,
      "reward": -916.0,
      "steps": 47,
      "mean_loss": 5204.423836566032,
      "epsilon": 0.27820400000593426
    },
    {
      "episode": 4590,
      "score": 248,
      "reward": -852.0,
      "steps": 61,
      "mean_loss": 3450.4228443395896,
      "epsilon": 0.2781430000059359
    },
    {
      "episode": 4591,
      "score": 138,
      "reward": -941.0,
      "steps": 46,
      "mean_loss": 5758.083154139312,
      "epsilon": 0.2780970000059371
    },
    {
      "episode": 4592,
      "score": 151,
      "reward": -914.0,
      "steps": 46,
      "mean_loss": 5831.089776744013,
      "epsilon": 0.27805100000593835
    },
    {
      "episode": 4593,
      "score": 134,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 4559.460100780834,
      "epsilon": 0.27800700000593953
    },
    {
      "episode": 4594,
      "score": 177,
      "reward": -904.0,
      "steps": 51,
      "mean_loss": 5114.002072053797,
      "epsilon": 0.2779560000059409
    },
    {
      "episode": 4595,
      "score": 88,
      "reward": -980.0,
      "steps": 40,
      "mean_loss": 3076.5279174804687,
      "epsilon": 0.27791600000594197
    },
    {
      "episode": 4596,
      "score": 84,
      "reward": -968.0,
      "steps": 34,
      "mean_loss": 2615.520029741175,
      "epsilon": 0.2778820000059429
    },
    {
      "episode": 4597,
      "score": 260,
      "reward": -839.0,
      "steps": 62,
      "mean_loss": 3101.6999319138067,
      "epsilon": 0.27782000000594453
    },
    {
      "episode": 4598,
      "score": 149,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 3527.6090018351874,
      "epsilon": 0.2777720000059458
    },
    {
      "episode": 4599,
      "score": 150,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 5701.290614188985,
      "epsilon": 0.2777250000059471
    },
    {
      "episode": 4600,
      "score": 110,
      "reward": -978.0,
      "steps": 45,
      "mean_loss": 2316.307329644097,
      "epsilon": 0.2776800000059483
    },
    {
      "episode": 4601,
      "score": 132,
      "reward": -936.0,
      "steps": 45,
      "mean_loss": 5000.290944417317,
      "epsilon": 0.2776350000059495
    },
    {
      "episode": 4602,
      "score": 166,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 3044.471213827328,
      "epsilon": 0.2775860000059508
    },
    {
      "episode": 4603,
      "score": 15,
      "reward": -1010.0,
      "steps": 17,
      "mean_loss": 6246.216110229492,
      "epsilon": 0.27756900000595125
    },
    {
      "episode": 4604,
      "score": 147,
      "reward": -943.0,
      "steps": 51,
      "mean_loss": 6783.735997069116,
      "epsilon": 0.2775180000059526
    },
    {
      "episode": 4605,
      "score": 164,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 4734.419399186677,
      "epsilon": 0.277467000005954
    },
    {
      "episode": 4606,
      "score": 143,
      "reward": -937.0,
      "steps": 47,
      "mean_loss": 3522.0209280785093,
      "epsilon": 0.27742000000595524
    },
    {
      "episode": 4607,
      "score": 164,
      "reward": -912.0,
      "steps": 48,
      "mean_loss": 2176.3820863962173,
      "epsilon": 0.2773720000059565
    },
    {
      "episode": 4608,
      "score": 160,
      "reward": -919.0,
      "steps": 50,
      "mean_loss": 4832.112167358398,
      "epsilon": 0.27732200000595786
    },
    {
      "episode": 4609,
      "score": 175,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 3577.1213288116455,
      "epsilon": 0.2772720000059592
    },
    {
      "episode": 4610,
      "score": 103,
      "reward": -955.0,
      "steps": 42,
      "mean_loss": 3954.272954940796,
      "epsilon": 0.2772300000059603
    },
    {
      "episode": 4611,
      "score": 87,
      "reward": -967.0,
      "steps": 34,
      "mean_loss": 4116.755212447222,
      "epsilon": 0.27719600000596123
    },
    {
      "episode": 4612,
      "score": 260,
      "reward": -837.0,
      "steps": 64,
      "mean_loss": 5519.688633143902,
      "epsilon": 0.27713200000596294
    },
    {
      "episode": 4613,
      "score": 134,
      "reward": -935.0,
      "steps": 44,
      "mean_loss": 2171.573250423778,
      "epsilon": 0.2770880000059641
    },
    {
      "episode": 4614,
      "score": 141,
      "reward": -942.0,
      "steps": 48,
      "mean_loss": 4507.8146322568255,
      "epsilon": 0.2770400000059654
    },
    {
      "episode": 4615,
      "score": 30,
      "reward": -994.0,
      "steps": 18,
      "mean_loss": 2393.260300954183,
      "epsilon": 0.2770220000059659
    },
    {
      "episode": 4616,
      "score": 138,
      "reward": -927.0,
      "steps": 44,
      "mean_loss": 4160.9401231245565,
      "epsilon": 0.27697800000596706
    },
    {
      "episode": 4617,
      "score": 144,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 4618.30034302692,
      "epsilon": 0.2769290000059684
    },
    {
      "episode": 4618,
      "score": 115,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 4469.695552609183,
      "epsilon": 0.27688500000596955
    },
    {
      "episode": 4619,
      "score": 147,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 4057.6626023848853,
      "epsilon": 0.27683700000597083
    },
    {
      "episode": 4620,
      "score": 203,
      "reward": -894.0,
      "steps": 56,
      "mean_loss": 4610.4994121960235,
      "epsilon": 0.27678100000597233
    },
    {
      "episode": 4621,
      "score": 130,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 3475.757867856459,
      "epsilon": 0.2767370000059735
    },
    {
      "episode": 4622,
      "score": 158,
      "reward": -915.0,
      "steps": 49,
      "mean_loss": 4074.8036172827897,
      "epsilon": 0.2766880000059748
    },
    {
      "episode": 4623,
      "score": 169,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 3715.346154098511,
      "epsilon": 0.27663800000597616
    },
    {
      "episode": 4624,
      "score": 216,
      "reward": -886.0,
      "steps": 57,
      "mean_loss": 4849.321129916007,
      "epsilon": 0.2765810000059777
    },
    {
      "episode": 4625,
      "score": 68,
      "reward": -988.0,
      "steps": 33,
      "mean_loss": 3007.8983533454666,
      "epsilon": 0.27654800000597857
    },
    {
      "episode": 4626,
      "score": 180,
      "reward": -899.0,
      "steps": 51,
      "mean_loss": 5226.317192339429,
      "epsilon": 0.27649700000597993
    },
    {
      "episode": 4627,
      "score": 229,
      "reward": -860.0,
      "steps": 57,
      "mean_loss": 3050.96564771418,
      "epsilon": 0.27644000000598146
    },
    {
      "episode": 4628,
      "score": 156,
      "reward": -934.0,
      "steps": 47,
      "mean_loss": 3184.7734920420544,
      "epsilon": 0.2763930000059827
    },
    {
      "episode": 4629,
      "score": 155,
      "reward": -921.0,
      "steps": 45,
      "mean_loss": 3143.4570164150664,
      "epsilon": 0.2763480000059839
    },
    {
      "episode": 4630,
      "score": 184,
      "reward": -901.0,
      "steps": 50,
      "mean_loss": 3830.169297027588,
      "epsilon": 0.27629800000598526
    },
    {
      "episode": 4631,
      "score": 93,
      "reward": -960.0,
      "steps": 33,
      "mean_loss": 3945.4906002391467,
      "epsilon": 0.27626500000598614
    },
    {
      "episode": 4632,
      "score": 179,
      "reward": -908.0,
      "steps": 53,
      "mean_loss": 6127.439751966945,
      "epsilon": 0.27621200000598756
    },
    {
      "episode": 4633,
      "score": 191,
      "reward": -887.0,
      "steps": 53,
      "mean_loss": 2306.8766426950133,
      "epsilon": 0.276159000005989
    },
    {
      "episode": 4634,
      "score": 168,
      "reward": -912.0,
      "steps": 50,
      "mean_loss": 4154.5179573440555,
      "epsilon": 0.2761090000059903
    },
    {
      "episode": 4635,
      "score": 123,
      "reward": -947.0,
      "steps": 43,
      "mean_loss": 3541.5780800664147,
      "epsilon": 0.27606600000599146
    },
    {
      "episode": 4636,
      "score": 100,
      "reward": -966.0,
      "steps": 39,
      "mean_loss": 4144.530876844357,
      "epsilon": 0.2760270000059925
    },
    {
      "episode": 4637,
      "score": 144,
      "reward": -943.0,
      "steps": 48,
      "mean_loss": 3009.414609750112,
      "epsilon": 0.2759790000059938
    },
    {
      "episode": 4638,
      "score": 287,
      "reward": -840.0,
      "steps": 69,
      "mean_loss": 5125.719844928686,
      "epsilon": 0.27591000000599564
    },
    {
      "episode": 4639,
      "score": 115,
      "reward": -967.0,
      "steps": 47,
      "mean_loss": 5809.76600030128,
      "epsilon": 0.2758630000059969
    },
    {
      "episode": 4640,
      "score": 131,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 3155.0579042434692,
      "epsilon": 0.27581900000599807
    },
    {
      "episode": 4641,
      "score": 122,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 5796.95016635548,
      "epsilon": 0.27577500000599925
    },
    {
      "episode": 4642,
      "score": 168,
      "reward": -928.0,
      "steps": 54,
      "mean_loss": 5703.257691136113,
      "epsilon": 0.2757210000060007
    },
    {
      "episode": 4643,
      "score": 159,
      "reward": -925.0,
      "steps": 47,
      "mean_loss": 3085.96533332987,
      "epsilon": 0.27567400000600195
    },
    {
      "episode": 4644,
      "score": 137,
      "reward": -945.0,
      "steps": 47,
      "mean_loss": 5449.859885925942,
      "epsilon": 0.2756270000060032
    },
    {
      "episode": 4645,
      "score": 245,
      "reward": -855.0,
      "steps": 62,
      "mean_loss": 5964.063286658256,
      "epsilon": 0.27556500000600487
    },
    {
      "episode": 4646,
      "score": 278,
      "reward": -841.0,
      "steps": 68,
      "mean_loss": 4326.184724443099,
      "epsilon": 0.2754970000060067
    },
    {
      "episode": 4647,
      "score": 185,
      "reward": -897.0,
      "steps": 55,
      "mean_loss": 5506.939088162509,
      "epsilon": 0.27544200000600816
    },
    {
      "episode": 4648,
      "score": 94,
      "reward": -968.0,
      "steps": 36,
      "mean_loss": 2381.8588537640044,
      "epsilon": 0.2754060000060091
    },
    {
      "episode": 4649,
      "score": 164,
      "reward": -936.0,
      "steps": 49,
      "mean_loss": 3636.667374513587,
      "epsilon": 0.27535700000601043
    },
    {
      "episode": 4650,
      "score": 139,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 3277.3959498304002,
      "epsilon": 0.2753100000060117
    },
    {
      "episode": 4651,
      "score": 105,
      "reward": -958.0,
      "steps": 38,
      "mean_loss": 4550.630482774031,
      "epsilon": 0.2752720000060127
    },
    {
      "episode": 4652,
      "score": 108,
      "reward": -957.0,
      "steps": 43,
      "mean_loss": 4300.6909648096835,
      "epsilon": 0.27522900000601386
    },
    {
      "episode": 4653,
      "score": 186,
      "reward": -885.0,
      "steps": 53,
      "mean_loss": 2293.9918366918023,
      "epsilon": 0.2751760000060153
    },
    {
      "episode": 4654,
      "score": 153,
      "reward": -932.0,
      "steps": 48,
      "mean_loss": 3254.499641338984,
      "epsilon": 0.27512800000601656
    },
    {
      "episode": 4655,
      "score": 197,
      "reward": -897.0,
      "steps": 55,
      "mean_loss": 3495.2212126298386,
      "epsilon": 0.27507300000601803
    },
    {
      "episode": 4656,
      "score": 188,
      "reward": -903.0,
      "steps": 54,
      "mean_loss": 2419.026906967163,
      "epsilon": 0.2750190000060195
    },
    {
      "episode": 4657,
      "score": 176,
      "reward": -924.0,
      "steps": 54,
      "mean_loss": 3749.141059451633,
      "epsilon": 0.2749650000060209
    },
    {
      "episode": 4658,
      "score": 162,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 5557.3298648834225,
      "epsilon": 0.27491500000602226
    },
    {
      "episode": 4659,
      "score": 229,
      "reward": -859.0,
      "steps": 60,
      "mean_loss": 3491.995616213481,
      "epsilon": 0.27485500000602386
    },
    {
      "episode": 4660,
      "score": 107,
      "reward": -965.0,
      "steps": 39,
      "mean_loss": 4250.194323417468,
      "epsilon": 0.2748160000060249
    },
    {
      "episode": 4661,
      "score": 227,
      "reward": -867.0,
      "steps": 59,
      "mean_loss": 3537.758826077995,
      "epsilon": 0.2747570000060265
    },
    {
      "episode": 4662,
      "score": 197,
      "reward": -901.0,
      "steps": 56,
      "mean_loss": 2569.692650113787,
      "epsilon": 0.274701000006028
    },
    {
      "episode": 4663,
      "score": 152,
      "reward": -930.0,
      "steps": 48,
      "mean_loss": 2252.1584597826004,
      "epsilon": 0.27465300000602927
    },
    {
      "episode": 4664,
      "score": 107,
      "reward": -953.0,
      "steps": 34,
      "mean_loss": 5191.2798862457275,
      "epsilon": 0.2746190000060302
    },
    {
      "episode": 4665,
      "score": 168,
      "reward": -900.0,
      "steps": 47,
      "mean_loss": 2067.9163157686276,
      "epsilon": 0.27457200000603144
    },
    {
      "episode": 4666,
      "score": 113,
      "reward": -964.0,
      "steps": 45,
      "mean_loss": 4467.59416648017,
      "epsilon": 0.27452700000603264
    },
    {
      "episode": 4667,
      "score": 173,
      "reward": -912.0,
      "steps": 52,
      "mean_loss": 4614.387739511637,
      "epsilon": 0.27447500000603403
    },
    {
      "episode": 4668,
      "score": 236,
      "reward": -852.0,
      "steps": 55,
      "mean_loss": 3972.4968285994096,
      "epsilon": 0.2744200000060355
    },
    {
      "episode": 4669,
      "score": 171,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 4245.942332194401,
      "epsilon": 0.2743680000060369
    },
    {
      "episode": 4670,
      "score": 162,
      "reward": -928.0,
      "steps": 49,
      "mean_loss": 6094.911509533318,
      "epsilon": 0.2743190000060382
    },
    {
      "episode": 4671,
      "score": 258,
      "reward": -844.0,
      "steps": 61,
      "mean_loss": 3949.9842381086505,
      "epsilon": 0.27425800000603984
    },
    {
      "episode": 4672,
      "score": 161,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 4613.857529771094,
      "epsilon": 0.2742070000060412
    },
    {
      "episode": 4673,
      "score": 180,
      "reward": -916.0,
      "steps": 52,
      "mean_loss": 4435.736378816458,
      "epsilon": 0.2741550000060426
    },
    {
      "episode": 4674,
      "score": 166,
      "reward": -920.0,
      "steps": 51,
      "mean_loss": 3362.9904281765807,
      "epsilon": 0.27410400000604396
    },
    {
      "episode": 4675,
      "score": 106,
      "reward": -967.0,
      "steps": 44,
      "mean_loss": 4472.211100925098,
      "epsilon": 0.27406000000604513
    },
    {
      "episode": 4676,
      "score": 171,
      "reward": -911.0,
      "steps": 50,
      "mean_loss": 3886.6095539093017,
      "epsilon": 0.2740100000060465
    },
    {
      "episode": 4677,
      "score": 205,
      "reward": -878.0,
      "steps": 54,
      "mean_loss": 4409.351800812616,
      "epsilon": 0.2739560000060479
    },
    {
      "episode": 4678,
      "score": 169,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 4622.769576946895,
      "epsilon": 0.2739080000060492
    },
    {
      "episode": 4679,
      "score": 184,
      "reward": -907.0,
      "steps": 53,
      "mean_loss": 3433.539123607132,
      "epsilon": 0.2738550000060506
    },
    {
      "episode": 4680,
      "score": 87,
      "reward": -961.0,
      "steps": 33,
      "mean_loss": 4106.879221945098,
      "epsilon": 0.2738220000060515
    },
    {
      "episode": 4681,
      "score": 236,
      "reward": -850.0,
      "steps": 57,
      "mean_loss": 2475.2366656587833,
      "epsilon": 0.273765000006053
    },
    {
      "episode": 4682,
      "score": 111,
      "reward": -966.0,
      "steps": 44,
      "mean_loss": 3680.49445958571,
      "epsilon": 0.2737210000060542
    },
    {
      "episode": 4683,
      "score": 146,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 5287.406467671297,
      "epsilon": 0.2736720000060555
    },
    {
      "episode": 4684,
      "score": 141,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 1897.6060935583982,
      "epsilon": 0.2736280000060567
    },
    {
      "episode": 4685,
      "score": 141,
      "reward": -940.0,
      "steps": 49,
      "mean_loss": 4872.074498468516,
      "epsilon": 0.273579000006058
    },
    {
      "episode": 4686,
      "score": 125,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 2516.1964443380184,
      "epsilon": 0.2735350000060592
    },
    {
      "episode": 4687,
      "score": 250,
      "reward": -853.0,
      "steps": 62,
      "mean_loss": 2457.449718352287,
      "epsilon": 0.27347300000606084
    },
    {
      "episode": 4688,
      "score": 167,
      "reward": -916.0,
      "steps": 50,
      "mean_loss": 6051.542149734497,
      "epsilon": 0.2734230000060622
    },
    {
      "episode": 4689,
      "score": 125,
      "reward": -948.0,
      "steps": 44,
      "mean_loss": 1388.82563049143,
      "epsilon": 0.27337900000606336
    },
    {
      "episode": 4690,
      "score": 116,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 3596.6175306493587,
      "epsilon": 0.27333500000606453
    },
    {
      "episode": 4691,
      "score": 170,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 2598.2672562408447,
      "epsilon": 0.27328500000606587
    },
    {
      "episode": 4692,
      "score": 159,
      "reward": -906.0,
      "steps": 46,
      "mean_loss": 1731.0033462358558,
      "epsilon": 0.2732390000060671
    },
    {
      "episode": 4693,
      "score": 183,
      "reward": -903.0,
      "steps": 52,
      "mean_loss": 5017.767907179319,
      "epsilon": 0.2731870000060685
    },
    {
      "episode": 4694,
      "score": 148,
      "reward": -931.0,
      "steps": 48,
      "mean_loss": 4383.925053358078,
      "epsilon": 0.2731390000060698
    },
    {
      "episode": 4695,
      "score": 110,
      "reward": -962.0,
      "steps": 40,
      "mean_loss": 5166.181605911255,
      "epsilon": 0.27309900000607085
    },
    {
      "episode": 4696,
      "score": 202,
      "reward": -886.0,
      "steps": 55,
      "mean_loss": 6440.698400011929,
      "epsilon": 0.2730440000060723
    },
    {
      "episode": 4697,
      "score": 208,
      "reward": -895.0,
      "steps": 57,
      "mean_loss": 4417.8804109138355,
      "epsilon": 0.27298700000607384
    },
    {
      "episode": 4698,
      "score": 80,
      "reward": -983.0,
      "steps": 33,
      "mean_loss": 3996.362587437485,
      "epsilon": 0.2729540000060747
    },
    {
      "episode": 4699,
      "score": 148,
      "reward": -931.0,
      "steps": 45,
      "mean_loss": 3798.841555701362,
      "epsilon": 0.27290900000607593
    },
    {
      "episode": 4700,
      "score": 137,
      "reward": -933.0,
      "steps": 46,
      "mean_loss": 2619.099495763364,
      "epsilon": 0.27286300000607716
    },
    {
      "episode": 4701,
      "score": 210,
      "reward": -899.0,
      "steps": 58,
      "mean_loss": 3354.8445721001463,
      "epsilon": 0.2728050000060787
    },
    {
      "episode": 4702,
      "score": 159,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 5157.573557951013,
      "epsilon": 0.27275600000608
    },
    {
      "episode": 4703,
      "score": 155,
      "reward": -941.0,
      "steps": 50,
      "mean_loss": 3010.336382141113,
      "epsilon": 0.27270600000608136
    },
    {
      "episode": 4704,
      "score": 129,
      "reward": -951.0,
      "steps": 46,
      "mean_loss": 3277.317018011342,
      "epsilon": 0.2726600000060826
    },
    {
      "episode": 4705,
      "score": 76,
      "reward": -989.0,
      "steps": 34,
      "mean_loss": 4708.775284262265,
      "epsilon": 0.2726260000060835
    },
    {
      "episode": 4706,
      "score": 173,
      "reward": -903.0,
      "steps": 51,
      "mean_loss": 5822.638847575468,
      "epsilon": 0.27257500000608487
    },
    {
      "episode": 4707,
      "score": 103,
      "reward": -970.0,
      "steps": 42,
      "mean_loss": 3994.0337274642216,
      "epsilon": 0.272533000006086
    },
    {
      "episode": 4708,
      "score": 91,
      "reward": -968.0,
      "steps": 37,
      "mean_loss": 5535.304271801098,
      "epsilon": 0.272496000006087
    },
    {
      "episode": 4709,
      "score": 148,
      "reward": -945.0,
      "steps": 49,
      "mean_loss": 6210.100984067333,
      "epsilon": 0.2724470000060883
    },
    {
      "episode": 4710,
      "score": 136,
      "reward": -954.0,
      "steps": 48,
      "mean_loss": 4278.281370004018,
      "epsilon": 0.2723990000060896
    },
    {
      "episode": 4711,
      "score": 157,
      "reward": -918.0,
      "steps": 51,
      "mean_loss": 3878.7146413466508,
      "epsilon": 0.27234800000609094
    },
    {
      "episode": 4712,
      "score": 234,
      "reward": -866.0,
      "steps": 62,
      "mean_loss": 4351.550332438561,
      "epsilon": 0.2722860000060926
    },
    {
      "episode": 4713,
      "score": 98,
      "reward": -975.0,
      "steps": 38,
      "mean_loss": 4092.922364485891,
      "epsilon": 0.2722480000060936
    },
    {
      "episode": 4714,
      "score": 159,
      "reward": -928.0,
      "steps": 50,
      "mean_loss": 3856.9462758636473,
      "epsilon": 0.27219800000609495
    },
    {
      "episode": 4715,
      "score": 133,
      "reward": -947.0,
      "steps": 45,
      "mean_loss": 5597.159484439426,
      "epsilon": 0.27215300000609616
    },
    {
      "episode": 4716,
      "score": 88,
      "reward": -981.0,
      "steps": 39,
      "mean_loss": 7808.102183708777,
      "epsilon": 0.2721140000060972
    },
    {
      "episode": 4717,
      "score": 117,
      "reward": -960.0,
      "steps": 44,
      "mean_loss": 2053.001147443598,
      "epsilon": 0.2720700000060984
    },
    {
      "episode": 4718,
      "score": 135,
      "reward": -950.0,
      "steps": 47,
      "mean_loss": 5368.174909875748,
      "epsilon": 0.27202300000609964
    },
    {
      "episode": 4719,
      "score": 279,
      "reward": -824.0,
      "steps": 67,
      "mean_loss": 3707.498488838993,
      "epsilon": 0.27195600000610143
    },
    {
      "episode": 4720,
      "score": 98,
      "reward": -977.0,
      "steps": 41,
      "mean_loss": 2799.2582864993956,
      "epsilon": 0.2719150000061025
    },
    {
      "episode": 4721,
      "score": 22,
      "reward": -1002.0,
      "steps": 18,
      "mean_loss": 5379.29605017768,
      "epsilon": 0.271897000006103
    },
    {
      "episode": 4722,
      "score": 127,
      "reward": -950.0,
      "steps": 48,
      "mean_loss": 3181.897220055262,
      "epsilon": 0.2718490000061043
    },
    {
      "episode": 4723,
      "score": 159,
      "reward": -917.0,
      "steps": 48,
      "mean_loss": 2669.7642737229667,
      "epsilon": 0.2718010000061056
    },
    {
      "episode": 4724,
      "score": 259,
      "reward": -850.0,
      "steps": 62,
      "mean_loss": 6801.651774529488,
      "epsilon": 0.27173900000610723
    },
    {
      "episode": 4725,
      "score": 110,
      "reward": -935.0,
      "steps": 37,
      "mean_loss": 5533.407482765816,
      "epsilon": 0.2717020000061082
    },
    {
      "episode": 4726,
      "score": 129,
      "reward": -958.0,
      "steps": 47,
      "mean_loss": 4626.221499098108,
      "epsilon": 0.2716550000061095
    },
    {
      "episode": 4727,
      "score": 159,
      "reward": -905.0,
      "steps": 45,
      "mean_loss": 4808.379931513468,
      "epsilon": 0.2716100000061107
    },
    {
      "episode": 4728,
      "score": 126,
      "reward": -941.0,
      "steps": 44,
      "mean_loss": 3973.549511389299,
      "epsilon": 0.27156600000611186
    },
    {
      "episode": 4729,
      "score": 180,
      "reward": -897.0,
      "steps": 52,
      "mean_loss": 3900.631348903363,
      "epsilon": 0.27151400000611325
    },
    {
      "episode": 4730,
      "score": 195,
      "reward": -896.0,
      "steps": 54,
      "mean_loss": 4358.620715529831,
      "epsilon": 0.2714600000061147
    },
    {
      "episode": 4731,
      "score": 169,
      "reward": -921.0,
      "steps": 52,
      "mean_loss": 4951.031646618476,
      "epsilon": 0.2714080000061161
    },
    {
      "episode": 4732,
      "score": 169,
      "reward": -949.0,
      "steps": 50,
      "mean_loss": 4531.3398712158205,
      "epsilon": 0.27135800000611743
    },
    {
      "episode": 4733,
      "score": 78,
      "reward": -994.0,
      "steps": 39,
      "mean_loss": 5789.836282387758,
      "epsilon": 0.27131900000611847
    },
    {
      "episode": 4734,
      "score": 169,
      "reward": -915.0,
      "steps": 52,
      "mean_loss": 2805.237867942223,
      "epsilon": 0.27126700000611986
    },
    {
      "episode": 4735,
      "score": 167,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 3937.260381469727,
      "epsilon": 0.2712170000061212
    },
    {
      "episode": 4736,
      "score": 82,
      "reward": -983.0,
      "steps": 35,
      "mean_loss": 2224.2282710484096,
      "epsilon": 0.27118200000612214
    },
    {
      "episode": 4737,
      "score": 128,
      "reward": -943.0,
      "steps": 44,
      "mean_loss": 4548.843625328757,
      "epsilon": 0.2711380000061233
    },
    {
      "episode": 4738,
      "score": 148,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 6542.05809656779,
      "epsilon": 0.2710900000061246
    },
    {
      "episode": 4739,
      "score": 272,
      "reward": -832.0,
      "steps": 66,
      "mean_loss": 6572.740410197865,
      "epsilon": 0.27102400000612636
    },
    {
      "episode": 4740,
      "score": 169,
      "reward": -897.0,
      "steps": 49,
      "mean_loss": 6235.565017933748,
      "epsilon": 0.2709750000061277
    },
    {
      "episode": 4741,
      "score": 104,
      "reward": -958.0,
      "steps": 38,
      "mean_loss": 3884.7516997487924,
      "epsilon": 0.2709370000061287
    },
    {
      "episode": 4742,
      "score": 222,
      "reward": -890.0,
      "steps": 59,
      "mean_loss": 3420.9381964085464,
      "epsilon": 0.27087800000613027
    },
    {
      "episode": 4743,
      "score": 106,
      "reward": -945.0,
      "steps": 36,
      "mean_loss": 3378.4518593682183,
      "epsilon": 0.27084200000613123
    },
    {
      "episode": 4744,
      "score": 95,
      "reward": -980.0,
      "steps": 41,
      "mean_loss": 5986.070510678175,
      "epsilon": 0.27080100000613233
    },
    {
      "episode": 4745,
      "score": 149,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 2113.1398096481958,
      "epsilon": 0.2707530000061336
    },
    {
      "episode": 4746,
      "score": 189,
      "reward": -910.0,
      "steps": 52,
      "mean_loss": 5582.189473885756,
      "epsilon": 0.270701000006135
    },
    {
      "episode": 4747,
      "score": 39,
      "reward": -1029.0,
      "steps": 32,
      "mean_loss": 2028.1825931072235,
      "epsilon": 0.27066900000613586
    },
    {
      "episode": 4748,
      "score": 162,
      "reward": -938.0,
      "steps": 50,
      "mean_loss": 5407.969558029175,
      "epsilon": 0.2706190000061372
    },
    {
      "episode": 4749,
      "score": 228,
      "reward": -849.0,
      "steps": 54,
      "mean_loss": 4719.092067930434,
      "epsilon": 0.27056500000613865
    },
    {
      "episode": 4750,
      "score": 180,
      "reward": -906.0,
      "steps": 52,
      "mean_loss": 4230.369790150569,
      "epsilon": 0.27051300000614004
    },
    {
      "episode": 4751,
      "score": 99,
      "reward": -988.0,
      "steps": 41,
      "mean_loss": 4105.382509557212,
      "epsilon": 0.27047200000614113
    },
    {
      "episode": 4752,
      "score": 128,
      "reward": -950.0,
      "steps": 45,
      "mean_loss": 5485.296535322401,
      "epsilon": 0.27042700000614234
    },
    {
      "episode": 4753,
      "score": 162,
      "reward": -922.0,
      "steps": 52,
      "mean_loss": 4316.7120463297915,
      "epsilon": 0.27037500000614373
    },
    {
      "episode": 4754,
      "score": 107,
      "reward": -973.0,
      "steps": 40,
      "mean_loss": 4104.430700874329,
      "epsilon": 0.2703350000061448
    },
    {
      "episode": 4755,
      "score": 221,
      "reward": -857.0,
      "steps": 54,
      "mean_loss": 5753.937724784569,
      "epsilon": 0.27028100000614624
    },
    {
      "episode": 4756,
      "score": 153,
      "reward": -927.0,
      "steps": 52,
      "mean_loss": 4352.743003551776,
      "epsilon": 0.27022900000614763
    },
    {
      "episode": 4757,
      "score": 126,
      "reward": -940.0,
      "steps": 43,
      "mean_loss": 5971.163580739221,
      "epsilon": 0.2701860000061488
    },
    {
      "episode": 4758,
      "score": 123,
      "reward": -947.0,
      "steps": 42,
      "mean_loss": 6318.572972706386,
      "epsilon": 0.2701440000061499
    },
    {
      "episode": 4759,
      "score": 130,
      "reward": -957.0,
      "steps": 47,
      "mean_loss": 6243.489838214631,
      "epsilon": 0.27009700000615117
    },
    {
      "episode": 4760,
      "score": 198,
      "reward": -889.0,
      "steps": 55,
      "mean_loss": 5439.809472933683,
      "epsilon": 0.27004200000615264
    },
    {
      "episode": 4761,
      "score": 170,
      "reward": -907.0,
      "steps": 49,
      "mean_loss": 5870.375684465681,
      "epsilon": 0.26999300000615395
    },
    {
      "episode": 4762,
      "score": 125,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 2356.907794518904,
      "epsilon": 0.2699490000061551
    },
    {
      "episode": 4763,
      "score": 129,
      "reward": -952.0,
      "steps": 48,
      "mean_loss": 4971.738059361775,
      "epsilon": 0.2699010000061564
    },
    {
      "episode": 4764,
      "score": 128,
      "reward": -954.0,
      "steps": 46,
      "mean_loss": 3394.338619398034,
      "epsilon": 0.26985500000615764
    },
    {
      "episode": 4765,
      "score": 188,
      "reward": -900.0,
      "steps": 54,
      "mean_loss": 3564.621869687681,
      "epsilon": 0.2698010000061591
    },
    {
      "episode": 4766,
      "score": 162,
      "reward": -920.0,
      "steps": 50,
      "mean_loss": 4016.011165161133,
      "epsilon": 0.2697510000061604
    },
    {
      "episode": 4767,
      "score": 101,
      "reward": -965.0,
      "steps": 37,
      "mean_loss": 4551.590490805136,
      "epsilon": 0.2697140000061614
    },
    {
      "episode": 4768,
      "score": 159,
      "reward": -921.0,
      "steps": 48,
      "mean_loss": 5124.795731544495,
      "epsilon": 0.2696660000061627
    },
    {
      "episode": 4769,
      "score": 229,
      "reward": -853.0,
      "steps": 58,
      "mean_loss": 4114.894202265246,
      "epsilon": 0.26960800000616425
    },
    {
      "episode": 4770,
      "score": 149,
      "reward": -944.0,
      "steps": 51,
      "mean_loss": 4894.3139136071295,
      "epsilon": 0.2695570000061656
    },
    {
      "episode": 4771,
      "score": 136,
      "reward": -921.0,
      "steps": 38,
      "mean_loss": 2892.3180228785463,
      "epsilon": 0.26951900000616663
    },
    {
      "episode": 4772,
      "score": 74,
      "reward": -972.0,
      "steps": 32,
      "mean_loss": 3447.7874224185944,
      "epsilon": 0.2694870000061675
    },
    {
      "episode": 4773,
      "score": 179,
      "reward": -917.0,
      "steps": 54,
      "mean_loss": 2305.951313795867,
      "epsilon": 0.26943300000616893
    },
    {
      "episode": 4774,
      "score": 144,
      "reward": -927.0,
      "steps": 46,
      "mean_loss": 3248.991472700368,
      "epsilon": 0.26938700000617016
    },
    {
      "episode": 4775,
      "score": 143,
      "reward": -936.0,
      "steps": 47,
      "mean_loss": 2671.2507759256564,
      "epsilon": 0.2693400000061714
    },
    {
      "episode": 4776,
      "score": 133,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 2707.246628674594,
      "epsilon": 0.2692960000061726
    },
    {
      "episode": 4777,
      "score": 155,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 3418.250003165387,
      "epsilon": 0.26924900000617386
    },
    {
      "episode": 4778,
      "score": 159,
      "reward": -923.0,
      "steps": 50,
      "mean_loss": 5294.825508041382,
      "epsilon": 0.2691990000061752
    },
    {
      "episode": 4779,
      "score": 76,
      "reward": -976.0,
      "steps": 33,
      "mean_loss": 3308.137390714703,
      "epsilon": 0.2691660000061761
    },
    {
      "episode": 4780,
      "score": 164,
      "reward": -911.0,
      "steps": 52,
      "mean_loss": 1857.680572949923,
      "epsilon": 0.26911400000617747
    },
    {
      "episode": 4781,
      "score": 184,
      "reward": -904.0,
      "steps": 52,
      "mean_loss": 3944.8484639387866,
      "epsilon": 0.26906200000617886
    },
    {
      "episode": 4782,
      "score": 138,
      "reward": -925.0,
      "steps": 44,
      "mean_loss": 3711.4996990724044,
      "epsilon": 0.26901800000618004
    },
    {
      "episode": 4783,
      "score": 159,
      "reward": -923.0,
      "steps": 51,
      "mean_loss": 2371.713062136781,
      "epsilon": 0.2689670000061814
    },
    {
      "episode": 4784,
      "score": 190,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 3160.4181700812446,
      "epsilon": 0.26891300000618285
    },
    {
      "episode": 4785,
      "score": 192,
      "reward": -886.0,
      "steps": 52,
      "mean_loss": 3039.322603592506,
      "epsilon": 0.26886100000618424
    },
    {
      "episode": 4786,
      "score": 157,
      "reward": -935.0,
      "steps": 50,
      "mean_loss": 3418.559976119995,
      "epsilon": 0.2688110000061856
    },
    {
      "episode": 4787,
      "score": 153,
      "reward": -919.0,
      "steps": 48,
      "mean_loss": 5473.6588933467865,
      "epsilon": 0.26876300000618686
    },
    {
      "episode": 4788,
      "score": 174,
      "reward": -907.0,
      "steps": 50,
      "mean_loss": 5744.72758769989,
      "epsilon": 0.2687130000061882
    },
    {
      "episode": 4789,
      "score": 173,
      "reward": -919.0,
      "steps": 51,
      "mean_loss": 3051.941535987106,
      "epsilon": 0.26866200000618956
    },
    {
      "episode": 4790,
      "score": 101,
      "reward": -975.0,
      "steps": 41,
      "mean_loss": 3708.148279236584,
      "epsilon": 0.26862100000619066
    },
    {
      "episode": 4791,
      "score": 172,
      "reward": -926.0,
      "steps": 54,
      "mean_loss": 4672.383213961566,
      "epsilon": 0.2685670000061921
    },
    {
      "episode": 4792,
      "score": 162,
      "reward": -922.0,
      "steps": 48,
      "mean_loss": 2540.7589652935662,
      "epsilon": 0.2685190000061934
    },
    {
      "episode": 4793,
      "score": 106,
      "reward": -962.0,
      "steps": 42,
      "mean_loss": 6814.995751244681,
      "epsilon": 0.2684770000061945
    },
    {
      "episode": 4794,
      "score": 95,
      "reward": -962.0,
      "steps": 35,
      "mean_loss": 4713.04932610648,
      "epsilon": 0.26844200000619545
    },
    {
      "episode": 4795,
      "score": 187,
      "reward": -922.0,
      "steps": 56,
      "mean_loss": 2305.4837318829127,
      "epsilon": 0.26838600000619695
    },
    {
      "episode": 4796,
      "score": 166,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 5918.125494308471,
      "epsilon": 0.2683360000061983
    },
    {
      "episode": 4797,
      "score": 122,
      "reward": -957.0,
      "steps": 45,
      "mean_loss": 1065.797423892551,
      "epsilon": 0.2682910000061995
    },
    {
      "episode": 4798,
      "score": 144,
      "reward": -945.0,
      "steps": 49,
      "mean_loss": 4291.101117503887,
      "epsilon": 0.2682420000062008
    },
    {
      "episode": 4799,
      "score": 144,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 4572.373504241307,
      "epsilon": 0.2681940000062021
    },
    {
      "episode": 4800,
      "score": 256,
      "reward": -848.0,
      "steps": 64,
      "mean_loss": 5051.394613206387,
      "epsilon": 0.2681300000062038
    },
    {
      "episode": 4801,
      "score": 152,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 2811.5631115436554,
      "epsilon": 0.2680820000062051
    },
    {
      "episode": 4802,
      "score": 172,
      "reward": -915.0,
      "steps": 52,
      "mean_loss": 2952.5437215658335,
      "epsilon": 0.26803000000620647
    },
    {
      "episode": 4803,
      "score": 150,
      "reward": -922.0,
      "steps": 49,
      "mean_loss": 2503.3481379528434,
      "epsilon": 0.2679810000062078
    },
    {
      "episode": 4804,
      "score": 171,
      "reward": -903.0,
      "steps": 48,
      "mean_loss": 3381.9510746002197,
      "epsilon": 0.26793300000620907
    },
    {
      "episode": 4805,
      "score": 189,
      "reward": -896.0,
      "steps": 52,
      "mean_loss": 5483.421410340529,
      "epsilon": 0.26788100000621046
    },
    {
      "episode": 4806,
      "score": 177,
      "reward": -917.0,
      "steps": 53,
      "mean_loss": 4427.055856812675,
      "epsilon": 0.2678280000062119
    },
    {
      "episode": 4807,
      "score": 119,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 3066.268885092302,
      "epsilon": 0.26778400000621305
    },
    {
      "episode": 4808,
      "score": 284,
      "reward": -806.0,
      "steps": 68,
      "mean_loss": 5110.892204509062,
      "epsilon": 0.26771600000621487
    },
    {
      "episode": 4809,
      "score": 109,
      "reward": -964.0,
      "steps": 42,
      "mean_loss": 7377.7686557769775,
      "epsilon": 0.267674000006216
    },
    {
      "episode": 4810,
      "score": 165,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 4170.635679366741,
      "epsilon": 0.26762700000621725
    },
    {
      "episode": 4811,
      "score": 185,
      "reward": -910.0,
      "steps": 55,
      "mean_loss": 4058.2936107982287,
      "epsilon": 0.2675720000062187
    },
    {
      "episode": 4812,
      "score": 173,
      "reward": -906.0,
      "steps": 49,
      "mean_loss": 5161.674781916093,
      "epsilon": 0.26752300000622004
    },
    {
      "episode": 4813,
      "score": 179,
      "reward": -932.0,
      "steps": 47,
      "mean_loss": 2712.8968154014424,
      "epsilon": 0.2674760000062213
    },
    {
      "episode": 4814,
      "score": 151,
      "reward": -926.0,
      "steps": 50,
      "mean_loss": 5256.708377952576,
      "epsilon": 0.26742600000622263
    },
    {
      "episode": 4815,
      "score": 166,
      "reward": -910.0,
      "steps": 50,
      "mean_loss": 4201.539965591431,
      "epsilon": 0.26737600000622397
    },
    {
      "episode": 4816,
      "score": 261,
      "reward": -835.0,
      "steps": 62,
      "mean_loss": 6283.025566716348,
      "epsilon": 0.2673140000062256
    },
    {
      "episode": 4817,
      "score": 231,
      "reward": -853.0,
      "steps": 59,
      "mean_loss": 5812.349917621936,
      "epsilon": 0.2672550000062272
    },
    {
      "episode": 4818,
      "score": 161,
      "reward": -908.0,
      "steps": 47,
      "mean_loss": 4677.977452379592,
      "epsilon": 0.26720800000622846
    },
    {
      "episode": 4819,
      "score": 111,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 5913.929702238603,
      "epsilon": 0.26716400000622964
    },
    {
      "episode": 4820,
      "score": 169,
      "reward": -916.0,
      "steps": 49,
      "mean_loss": 3770.0632962207405,
      "epsilon": 0.26711500000623095
    },
    {
      "episode": 4821,
      "score": 140,
      "reward": -935.0,
      "steps": 45,
      "mean_loss": 2882.841076575385,
      "epsilon": 0.26707000000623216
    },
    {
      "episode": 4822,
      "score": 247,
      "reward": -874.0,
      "steps": 65,
      "mean_loss": 3236.5504417125994,
      "epsilon": 0.2670050000062339
    },
    {
      "episode": 4823,
      "score": 158,
      "reward": -933.0,
      "steps": 49,
      "mean_loss": 4897.69218222949,
      "epsilon": 0.2669560000062352
    },
    {
      "episode": 4824,
      "score": 184,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 4733.622156216548,
      "epsilon": 0.2669040000062366
    },
    {
      "episode": 4825,
      "score": 139,
      "reward": -952.0,
      "steps": 47,
      "mean_loss": 3748.9943153300183,
      "epsilon": 0.26685700000623785
    },
    {
      "episode": 4826,
      "score": 116,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 3996.087324142456,
      "epsilon": 0.26681300000623903
    },
    {
      "episode": 4827,
      "score": 173,
      "reward": -908.0,
      "steps": 52,
      "mean_loss": 7195.864899415236,
      "epsilon": 0.2667610000062404
    },
    {
      "episode": 4828,
      "score": 119,
      "reward": -944.0,
      "steps": 44,
      "mean_loss": 2839.329245567322,
      "epsilon": 0.2667170000062416
    },
    {
      "episode": 4829,
      "score": 253,
      "reward": -853.0,
      "steps": 65,
      "mean_loss": 4290.133017085149,
      "epsilon": 0.26665200000624334
    },
    {
      "episode": 4830,
      "score": 169,
      "reward": -915.0,
      "steps": 50,
      "mean_loss": 4385.195567359924,
      "epsilon": 0.2666020000062447
    },
    {
      "episode": 4831,
      "score": 147,
      "reward": -914.0,
      "steps": 44,
      "mean_loss": 3142.0385994477706,
      "epsilon": 0.26655800000624585
    },
    {
      "episode": 4832,
      "score": 109,
      "reward": -958.0,
      "steps": 41,
      "mean_loss": 3143.3383724398727,
      "epsilon": 0.26651700000624695
    },
    {
      "episode": 4833,
      "score": 121,
      "reward": -928.0,
      "steps": 37,
      "mean_loss": 5084.740726677147,
      "epsilon": 0.26648000000624794
    },
    {
      "episode": 4834,
      "score": 157,
      "reward": -937.0,
      "steps": 51,
      "mean_loss": 4230.732250587613,
      "epsilon": 0.2664290000062493
    },
    {
      "episode": 4835,
      "score": 79,
      "reward": -971.0,
      "steps": 32,
      "mean_loss": 5470.637302041054,
      "epsilon": 0.26639700000625016
    },
    {
      "episode": 4836,
      "score": 86,
      "reward": -986.0,
      "steps": 37,
      "mean_loss": 4189.630459192636,
      "epsilon": 0.26636000000625115
    },
    {
      "episode": 4837,
      "score": 158,
      "reward": -915.0,
      "steps": 51,
      "mean_loss": 5358.2447602889115,
      "epsilon": 0.2663090000062525
    },
    {
      "episode": 4838,
      "score": 95,
      "reward": -960.0,
      "steps": 35,
      "mean_loss": 4690.915242222377,
      "epsilon": 0.26627400000625345
    },
    {
      "episode": 4839,
      "score": 138,
      "reward": -935.0,
      "steps": 43,
      "mean_loss": 6953.349168600038,
      "epsilon": 0.2662310000062546
    },
    {
      "episode": 4840,
      "score": 285,
      "reward": -819.0,
      "steps": 68,
      "mean_loss": 3886.0946429196524,
      "epsilon": 0.2661630000062564
    },
    {
      "episode": 4841,
      "score": 132,
      "reward": -951.0,
      "steps": 45,
      "mean_loss": 6376.134859042698,
      "epsilon": 0.2661180000062576
    },
    {
      "episode": 4842,
      "score": 29,
      "reward": -995.0,
      "steps": 18,
      "mean_loss": 3590.637456681993,
      "epsilon": 0.2661000000062581
    },
    {
      "episode": 4843,
      "score": 163,
      "reward": -905.0,
      "steps": 48,
      "mean_loss": 4280.671191453934,
      "epsilon": 0.2660520000062594
    },
    {
      "episode": 4844,
      "score": 27,
      "reward": -999.0,
      "steps": 18,
      "mean_loss": 8748.92695787218,
      "epsilon": 0.2660340000062599
    },
    {
      "episode": 4845,
      "score": 305,
      "reward": -791.0,
      "steps": 69,
      "mean_loss": 5085.091224172841,
      "epsilon": 0.2659650000062617
    },
    {
      "episode": 4846,
      "score": 79,
      "reward": -975.0,
      "steps": 33,
      "mean_loss": 3889.209791472464,
      "epsilon": 0.2659320000062626
    },
    {
      "episode": 4847,
      "score": 161,
      "reward": -910.0,
      "steps": 49,
      "mean_loss": 4960.928425380162,
      "epsilon": 0.2658830000062639
    },
    {
      "episode": 4848,
      "score": 155,
      "reward": -931.0,
      "steps": 49,
      "mean_loss": 5937.731918840992,
      "epsilon": 0.2658340000062652
    },
    {
      "episode": 4849,
      "score": 129,
      "reward": -936.0,
      "steps": 45,
      "mean_loss": 6258.703421529134,
      "epsilon": 0.26578900000626643
    },
    {
      "episode": 4850,
      "score": 122,
      "reward": -951.0,
      "steps": 39,
      "mean_loss": 4945.7989266224395,
      "epsilon": 0.2657500000062675
    },
    {
      "episode": 4851,
      "score": 107,
      "reward": -953.0,
      "steps": 39,
      "mean_loss": 4935.995966495611,
      "epsilon": 0.2657110000062685
    },
    {
      "episode": 4852,
      "score": 12,
      "reward": -1012.0,
      "steps": 15,
      "mean_loss": 4093.237158203125,
      "epsilon": 0.2656960000062689
    },
    {
      "episode": 4853,
      "score": 30,
      "reward": -993.0,
      "steps": 18,
      "mean_loss": 2085.4788873460557,
      "epsilon": 0.2656780000062694
    },
    {
      "episode": 4854,
      "score": 146,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 4164.319237882441,
      "epsilon": 0.2656340000062706
    },
    {
      "episode": 4855,
      "score": 137,
      "reward": -929.0,
      "steps": 42,
      "mean_loss": 5986.636225291661,
      "epsilon": 0.2655920000062717
    },
    {
      "episode": 4856,
      "score": 176,
      "reward": -902.0,
      "steps": 53,
      "mean_loss": 4132.585105104266,
      "epsilon": 0.2655390000062731
    },
    {
      "episode": 4857,
      "score": 162,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 1804.3158802275962,
      "epsilon": 0.2654920000062744
    },
    {
      "episode": 4858,
      "score": 137,
      "reward": -929.0,
      "steps": 45,
      "mean_loss": 3765.207523261176,
      "epsilon": 0.2654470000062756
    },
    {
      "episode": 4859,
      "score": 124,
      "reward": -940.0,
      "steps": 48,
      "mean_loss": 4006.5457197825112,
      "epsilon": 0.26539900000627686
    },
    {
      "episode": 4860,
      "score": 143,
      "reward": -936.0,
      "steps": 48,
      "mean_loss": 3383.07787056764,
      "epsilon": 0.26535100000627815
    },
    {
      "episode": 4861,
      "score": 144,
      "reward": -934.0,
      "steps": 45,
      "mean_loss": 4216.622622680664,
      "epsilon": 0.26530600000627935
    },
    {
      "episode": 4862,
      "score": 170,
      "reward": -926.0,
      "steps": 52,
      "mean_loss": 2493.3064502936145,
      "epsilon": 0.26525400000628074
    },
    {
      "episode": 4863,
      "score": 228,
      "reward": -870.0,
      "steps": 57,
      "mean_loss": 4580.392316985549,
      "epsilon": 0.26519700000628227
    },
    {
      "episode": 4864,
      "score": 210,
      "reward": -873.0,
      "steps": 53,
      "mean_loss": 6501.545719362654,
      "epsilon": 0.2651440000062837
    },
    {
      "episode": 4865,
      "score": 121,
      "reward": -954.0,
      "steps": 44,
      "mean_loss": 5910.703168522228,
      "epsilon": 0.26510000000628486
    },
    {
      "episode": 4866,
      "score": 154,
      "reward": -932.0,
      "steps": 50,
      "mean_loss": 2379.754795379639,
      "epsilon": 0.2650500000062862
    },
    {
      "episode": 4867,
      "score": 27,
      "reward": -998.0,
      "steps": 18,
      "mean_loss": 318.59725930955676,
      "epsilon": 0.2650320000062867
    },
    {
      "episode": 4868,
      "score": 194,
      "reward": -899.0,
      "steps": 54,
      "mean_loss": 4481.016829631947,
      "epsilon": 0.26497800000628813
    },
    {
      "episode": 4869,
      "score": 24,
      "reward": -1002.0,
      "steps": 19,
      "mean_loss": 3820.843833722566,
      "epsilon": 0.26495900000628864
    },
    {
      "episode": 4870,
      "score": 139,
      "reward": -933.0,
      "steps": 44,
      "mean_loss": 3344.107401934537,
      "epsilon": 0.2649150000062898
    },
    {
      "episode": 4871,
      "score": 185,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 2717.374692230225,
      "epsilon": 0.26486500000629115
    },
    {
      "episode": 4872,
      "score": 154,
      "reward": -916.0,
      "steps": 45,
      "mean_loss": 2820.0668367173935,
      "epsilon": 0.26482000000629236
    },
    {
      "episode": 4873,
      "score": 254,
      "reward": -849.0,
      "steps": 63,
      "mean_loss": 4852.458885313973,
      "epsilon": 0.26475700000629404
    },
    {
      "episode": 4874,
      "score": 72,
      "reward": -988.0,
      "steps": 34,
      "mean_loss": 6612.439536375158,
      "epsilon": 0.26472300000629495
    },
    {
      "episode": 4875,
      "score": 146,
      "reward": -919.0,
      "steps": 47,
      "mean_loss": 6231.046387043405,
      "epsilon": 0.2646760000062962
    },
    {
      "episode": 4876,
      "score": 139,
      "reward": -943.0,
      "steps": 47,
      "mean_loss": 3436.4339692541894,
      "epsilon": 0.26462900000629747
    },
    {
      "episode": 4877,
      "score": 156,
      "reward": -916.0,
      "steps": 47,
      "mean_loss": 4714.262540695515,
      "epsilon": 0.2645820000062987
    },
    {
      "episode": 4878,
      "score": 165,
      "reward": -925.0,
      "steps": 49,
      "mean_loss": 2173.4380893707275,
      "epsilon": 0.26453300000630003
    },
    {
      "episode": 4879,
      "score": 111,
      "reward": -963.0,
      "steps": 44,
      "mean_loss": 3694.4412798448043,
      "epsilon": 0.2644890000063012
    },
    {
      "episode": 4880,
      "score": 183,
      "reward": -912.0,
      "steps": 54,
      "mean_loss": 5577.291815157289,
      "epsilon": 0.26443500000630266
    },
    {
      "episode": 4881,
      "score": 264,
      "reward": -840.0,
      "steps": 67,
      "mean_loss": 6174.630259158006,
      "epsilon": 0.26436800000630445
    },
    {
      "episode": 4882,
      "score": 162,
      "reward": -920.0,
      "steps": 49,
      "mean_loss": 5022.896936066297,
      "epsilon": 0.26431900000630576
    },
    {
      "episode": 4883,
      "score": 187,
      "reward": -902.0,
      "steps": 53,
      "mean_loss": 3988.332938932023,
      "epsilon": 0.2642660000063072
    },
    {
      "episode": 4884,
      "score": 101,
      "reward": -959.0,
      "steps": 37,
      "mean_loss": 3498.9646143526643,
      "epsilon": 0.26422900000630817
    },
    {
      "episode": 4885,
      "score": 15,
      "reward": -1004.0,
      "steps": 14,
      "mean_loss": 9070.162731170654,
      "epsilon": 0.26421500000630854
    },
    {
      "episode": 4886,
      "score": 210,
      "reward": -890.0,
      "steps": 58,
      "mean_loss": 6620.590984410253,
      "epsilon": 0.2641570000063101
    },
    {
      "episode": 4887,
      "score": 133,
      "reward": -940.0,
      "steps": 47,
      "mean_loss": 5570.024084781078,
      "epsilon": 0.26411000000631135
    },
    {
      "episode": 4888,
      "score": 149,
      "reward": -926.0,
      "steps": 47,
      "mean_loss": 3307.358492019329,
      "epsilon": 0.2640630000063126
    },
    {
      "episode": 4889,
      "score": 164,
      "reward": -914.0,
      "steps": 49,
      "mean_loss": 3943.341974608752,
      "epsilon": 0.2640140000063139
    },
    {
      "episode": 4890,
      "score": 137,
      "reward": -931.0,
      "steps": 42,
      "mean_loss": 5634.517025720505,
      "epsilon": 0.26397200000631504
    },
    {
      "episode": 4891,
      "score": 162,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 4244.288474024558,
      "epsilon": 0.26392300000631636
    },
    {
      "episode": 4892,
      "score": 130,
      "reward": -949.0,
      "steps": 44,
      "mean_loss": 7768.69034836509,
      "epsilon": 0.26387900000631753
    },
    {
      "episode": 4893,
      "score": 161,
      "reward": -907.0,
      "steps": 48,
      "mean_loss": 5154.135119517644,
      "epsilon": 0.2638310000063188
    },
    {
      "episode": 4894,
      "score": 120,
      "reward": -943.0,
      "steps": 41,
      "mean_loss": 6680.6131563884455,
      "epsilon": 0.2637900000063199
    },
    {
      "episode": 4895,
      "score": 180,
      "reward": -925.0,
      "steps": 53,
      "mean_loss": 5288.876022338867,
      "epsilon": 0.26373700000632133
    },
    {
      "episode": 4896,
      "score": 237,
      "reward": -857.0,
      "steps": 60,
      "mean_loss": 5026.834098815918,
      "epsilon": 0.26367700000632294
    },
    {
      "episode": 4897,
      "score": 161,
      "reward": -909.0,
      "steps": 45,
      "mean_loss": 6768.572998216418,
      "epsilon": 0.26363200000632414
    },
    {
      "episode": 4898,
      "score": 268,
      "reward": -834.0,
      "steps": 65,
      "mean_loss": 4572.394392981896,
      "epsilon": 0.2635670000063259
    },
    {
      "episode": 4899,
      "score": 171,
      "reward": -922.0,
      "steps": 50,
      "mean_loss": 3259.136865081787,
      "epsilon": 0.2635170000063272
    },
    {
      "episode": 4900,
      "score": 161,
      "reward": -927.0,
      "steps": 47,
      "mean_loss": 2464.3492499006556,
      "epsilon": 0.2634700000063285
    },
    {
      "episode": 4901,
      "score": 137,
      "reward": -932.0,
      "steps": 44,
      "mean_loss": 2322.636451807889,
      "epsilon": 0.26342600000632965
    },
    {
      "episode": 4902,
      "score": 116,
      "reward": -963.0,
      "steps": 42,
      "mean_loss": 3931.9564294133866,
      "epsilon": 0.2633840000063308
    },
    {
      "episode": 4903,
      "score": 34,
      "reward": -989.0,
      "steps": 18,
      "mean_loss": 812.2777551015218,
      "epsilon": 0.26336600000633126
    },
    {
      "episode": 4904,
      "score": 75,
      "reward": -991.0,
      "steps": 34,
      "mean_loss": 4297.304587420295,
      "epsilon": 0.26333200000633217
    },
    {
      "episode": 4905,
      "score": 169,
      "reward": -909.0,
      "steps": 47,
      "mean_loss": 6052.084788220994,
      "epsilon": 0.2632850000063334
    },
    {
      "episode": 4906,
      "score": 154,
      "reward": -913.0,
      "steps": 50,
      "mean_loss": 5154.84800907135,
      "epsilon": 0.26323500000633476
    },
    {
      "episode": 4907,
      "score": 217,
      "reward": -891.0,
      "steps": 60,
      "mean_loss": 5298.77555586497,
      "epsilon": 0.26317500000633637
    },
    {
      "episode": 4908,
      "score": 107,
      "reward": -977.0,
      "steps": 41,
      "mean_loss": 6234.515156350485,
      "epsilon": 0.26313400000633747
    },
    {
      "episode": 4909,
      "score": 155,
      "reward": -924.0,
      "steps": 49,
      "mean_loss": 4311.441575575848,
      "epsilon": 0.2630850000063388
    },
    {
      "episode": 4910,
      "score": 151,
      "reward": -917.0,
      "steps": 47,
      "mean_loss": 3908.2775844817465,
      "epsilon": 0.26303800000634003
    },
    {
      "episode": 4911,
      "score": 237,
      "reward": -871.0,
      "steps": 60,
      "mean_loss": 6018.148587036133,
      "epsilon": 0.26297800000634164
    },
    {
      "episode": 4912,
      "score": 149,
      "reward": -939.0,
      "steps": 51,
      "mean_loss": 4167.007436901916,
      "epsilon": 0.262927000006343
    },
    {
      "episode": 4913,
      "score": 216,
      "reward": -882.0,
      "steps": 58,
      "mean_loss": 3070.66087331443,
      "epsilon": 0.26286900000634456
    },
    {
      "episode": 4914,
      "score": 152,
      "reward": -934.0,
      "steps": 48,
      "mean_loss": 4102.801007032394,
      "epsilon": 0.26282100000634584
    },
    {
      "episode": 4915,
      "score": 132,
      "reward": -941.0,
      "steps": 48,
      "mean_loss": 6217.828488032023,
      "epsilon": 0.2627730000063471
    },
    {
      "episode": 4916,
      "score": 158,
      "reward": -930.0,
      "steps": 49,
      "mean_loss": 3211.3286129698463,
      "epsilon": 0.26272400000634843
    },
    {
      "episode": 4917,
      "score": 177,
      "reward": -905.0,
      "steps": 52,
      "mean_loss": 4538.073462339548,
      "epsilon": 0.2626720000063498
    },
    {
      "episode": 4918,
      "score": 285,
      "reward": -814.0,
      "steps": 68,
      "mean_loss": 5367.522235421573,
      "epsilon": 0.26260400000635165
    },
    {
      "episode": 4919,
      "score": 102,
      "reward": -954.0,
      "steps": 39,
      "mean_loss": 3080.4069136595112,
      "epsilon": 0.2625650000063527
    },
    {
      "episode": 4920,
      "score": 77,
      "reward": -983.0,
      "steps": 34,
      "mean_loss": 2839.623903611127,
      "epsilon": 0.2625310000063536
    },
    {
      "episode": 4921,
      "score": 103,
      "reward": -977.0,
      "steps": 44,
      "mean_loss": 5712.337303421714,
      "epsilon": 0.2624870000063548
    },
    {
      "episode": 4922,
      "score": 119,
      "reward": -960.0,
      "steps": 46,
      "mean_loss": 4184.0284568952475,
      "epsilon": 0.262441000006356
    },
    {
      "episode": 4923,
      "score": 119,
      "reward": -947.0,
      "steps": 43,
      "mean_loss": 3382.1541827889378,
      "epsilon": 0.26239800000635716
    },
    {
      "episode": 4924,
      "score": 149,
      "reward": -926.0,
      "steps": 49,
      "mean_loss": 5658.915816715786,
      "epsilon": 0.26234900000635847
    },
    {
      "episode": 4925,
      "score": 117,
      "reward": -951.0,
      "steps": 44,
      "mean_loss": 6142.786354238337,
      "epsilon": 0.26230500000635965
    },
    {
      "episode": 4926,
      "score": 111,
      "reward": -962.0,
      "steps": 44,
      "mean_loss": 4624.529445994984,
      "epsilon": 0.2622610000063608
    },
    {
      "episode": 4927,
      "score": 130,
      "reward": -935.0,
      "steps": 44,
      "mean_loss": 5922.500173482028,
      "epsilon": 0.262217000006362
    },
    {
      "episode": 4928,
      "score": 118,
      "reward": -953.0,
      "steps": 42,
      "mean_loss": 2125.6410282679967,
      "epsilon": 0.2621750000063631
    },
    {
      "episode": 4929,
      "score": 156,
      "reward": -916.0,
      "steps": 45,
      "mean_loss": 2642.2331094529895,
      "epsilon": 0.2621300000063643
    },
    {
      "episode": 4930,
      "score": 172,
      "reward": -907.0,
      "steps": 51,
      "mean_loss": 3893.289588030647,
      "epsilon": 0.2620790000063657
    },
    {
      "episode": 4931,
      "score": 153,
      "reward": -924.0,
      "steps": 47,
      "mean_loss": 3303.502990032764,
      "epsilon": 0.26203200000636695
    },
    {
      "episode": 4932,
      "score": 125,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 3914.645414179022,
      "epsilon": 0.2619880000063681
    },
    {
      "episode": 4933,
      "score": 274,
      "reward": -827.0,
      "steps": 68,
      "mean_loss": 4049.1253624242895,
      "epsilon": 0.26192000000636995
    },
    {
      "episode": 4934,
      "score": 142,
      "reward": -924.0,
      "steps": 46,
      "mean_loss": 5391.6815017202625,
      "epsilon": 0.2618740000063712
    },
    {
      "episode": 4935,
      "score": 156,
      "reward": -934.0,
      "steps": 49,
      "mean_loss": 3491.982458114624,
      "epsilon": 0.2618250000063725
    },
    {
      "episode": 4936,
      "score": 118,
      "reward": -961.0,
      "steps": 44,
      "mean_loss": 5004.031820470636,
      "epsilon": 0.26178100000637367
    },
    {
      "episode": 4937,
      "score": 126,
      "reward": -956.0,
      "steps": 40,
      "mean_loss": 7021.729071712494,
      "epsilon": 0.26174100000637474
    },
    {
      "episode": 4938,
      "score": 151,
      "reward": -916.0,
      "steps": 45,
      "mean_loss": 4108.821145884196,
      "epsilon": 0.26169600000637594
    },
    {
      "episode": 4939,
      "score": 124,
      "reward": -961.0,
      "steps": 49,
      "mean_loss": 4122.131902733628,
      "epsilon": 0.26164700000637725
    },
    {
      "episode": 4940,
      "score": 156,
      "reward": -924.0,
      "steps": 48,
      "mean_loss": 2837.560558795929,
      "epsilon": 0.26159900000637853
    },
    {
      "episode": 4941,
      "score": 172,
      "reward": -912.0,
      "steps": 49,
      "mean_loss": 4204.478274598414,
      "epsilon": 0.26155000000637985
    },
    {
      "episode": 4942,
      "score": 109,
      "reward": -949.0,
      "steps": 37,
      "mean_loss": 5689.080852817845,
      "epsilon": 0.26151300000638084
    },
    {
      "episode": 4943,
      "score": 238,
      "reward": -852.0,
      "steps": 56,
      "mean_loss": 4628.938883917673,
      "epsilon": 0.26145700000638233
    },
    {
      "episode": 4944,
      "score": 176,
      "reward": -900.0,
      "steps": 50,
      "mean_loss": 5054.212445793152,
      "epsilon": 0.26140700000638367
    },
    {
      "episode": 4945,
      "score": 181,
      "reward": -912.0,
      "steps": 54,
      "mean_loss": 5526.548299083003,
      "epsilon": 0.2613530000063851
    },
    {
      "episode": 4946,
      "score": 152,
      "reward": -932.0,
      "steps": 49,
      "mean_loss": 4480.393675434346,
      "epsilon": 0.2613040000063864
    },
    {
      "episode": 4947,
      "score": 126,
      "reward": -950.0,
      "steps": 44,
      "mean_loss": 2509.9324425350537,
      "epsilon": 0.2612600000063876
    },
    {
      "episode": 4948,
      "score": 258,
      "reward": -840.0,
      "steps": 65,
      "mean_loss": 3760.638996887207,
      "epsilon": 0.26119500000638934
    },
    {
      "episode": 4949,
      "score": 157,
      "reward": -930.0,
      "steps": 50,
      "mean_loss": 4868.237747421264,
      "epsilon": 0.2611450000063907
    },
    {
      "episode": 4950,
      "score": 123,
      "reward": -942.0,
      "steps": 44,
      "mean_loss": 5360.588468725031,
      "epsilon": 0.26110100000639186
    },
    {
      "episode": 4951,
      "score": 175,
      "reward": -914.0,
      "steps": 50,
      "mean_loss": 3014.4154607391356,
      "epsilon": 0.2610510000063932
    },
    {
      "episode": 4952,
      "score": 165,
      "reward": -911.0,
      "steps": 48,
      "mean_loss": 5521.320725282033,
      "epsilon": 0.2610030000063945
    },
    {
      "episode": 4953,
      "score": 150,
      "reward": -929.0,
      "steps": 48,
      "mean_loss": 2516.550375302633,
      "epsilon": 0.26095500000639577
    },
    {
      "episode": 4954,
      "score": 97,
      "reward": -964.0,
      "steps": 38,
      "mean_loss": 2700.1777188150504,
      "epsilon": 0.2609170000063968
    },
    {
      "episode": 4955,
      "score": 194,
      "reward": -891.0,
      "steps": 54,
      "mean_loss": 4739.423367041129,
      "epsilon": 0.2608630000063982
    },
    {
      "episode": 4956,
      "score": 155,
      "reward": -916.0,
      "steps": 49,
      "mean_loss": 5260.19043011568,
      "epsilon": 0.26081400000639954
    },
    {
      "episode": 4957,
      "score": 139,
      "reward": -944.0,
      "steps": 48,
      "mean_loss": 2447.7565956910453,
      "epsilon": 0.2607660000064008
    },
    {
      "episode": 4958,
      "score": 207,
      "reward": -877.0,
      "steps": 53,
      "mean_loss": 4572.860291750926,
      "epsilon": 0.26071300000640224
    },
    {
      "episode": 4959,
      "score": 139,
      "reward": -945.0,
      "steps": 48,
      "mean_loss": 3646.2569485505423,
      "epsilon": 0.2606650000064035
    },
    {
      "episode": 4960,
      "score": 203,
      "reward": -885.0,
      "steps": 56,
      "mean_loss": 5097.569155693054,
      "epsilon": 0.260609000006405
    },
    {
      "episode": 4961,
      "score": 144,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 4995.340007470579,
      "epsilon": 0.26056000000640633
    },
    {
      "episode": 4962,
      "score": 179,
      "reward": -902.0,
      "steps": 52,
      "mean_loss": 3431.920852807852,
      "epsilon": 0.2605080000064077
    },
    {
      "episode": 4963,
      "score": 164,
      "reward": -924.0,
      "steps": 50,
      "mean_loss": 2233.9021161651613,
      "epsilon": 0.26045800000640906
    },
    {
      "episode": 4964,
      "score": 191,
      "reward": -885.0,
      "steps": 53,
      "mean_loss": 5868.4373521624875,
      "epsilon": 0.2604050000064105
    },
    {
      "episode": 4965,
      "score": 268,
      "reward": -860.0,
      "steps": 67,
      "mean_loss": 4746.822885370966,
      "epsilon": 0.2603380000064123
    },
    {
      "episode": 4966,
      "score": 102,
      "reward": -981.0,
      "steps": 43,
      "mean_loss": 5293.727044926133,
      "epsilon": 0.2602950000064134
    },
    {
      "episode": 4967,
      "score": 256,
      "reward": -851.0,
      "steps": 64,
      "mean_loss": 3303.5978887081146,
      "epsilon": 0.26023100000641514
    },
    {
      "episode": 4968,
      "score": 116,
      "reward": -958.0,
      "steps": 44,
      "mean_loss": 2567.0471579811788,
      "epsilon": 0.2601870000064163
    },
    {
      "episode": 4969,
      "score": 164,
      "reward": -896.0,
      "steps": 50,
      "mean_loss": 7090.20662475586,
      "epsilon": 0.26013700000641765
    },
    {
      "episode": 4970,
      "score": 160,
      "reward": -921.0,
      "steps": 50,
      "mean_loss": 5827.733782577515,
      "epsilon": 0.260087000006419
    },
    {
      "episode": 4971,
      "score": 166,
      "reward": -898.0,
      "steps": 48,
      "mean_loss": 4247.804280122121,
      "epsilon": 0.2600390000064203
    },
    {
      "episode": 4972,
      "score": 184,
      "reward": -907.0,
      "steps": 54,
      "mean_loss": 4829.016046947903,
      "epsilon": 0.2599850000064217
    },
    {
      "episode": 4973,
      "score": 106,
      "reward": -958.0,
      "steps": 37,
      "mean_loss": 5431.393769857046,
      "epsilon": 0.2599480000064227
    },
    {
      "episode": 4974,
      "score": 116,
      "reward": -962.0,
      "steps": 43,
      "mean_loss": 4910.109919703284,
      "epsilon": 0.25990500000642386
    },
    {
      "episode": 4975,
      "score": 260,
      "reward": -866.0,
      "steps": 68,
      "mean_loss": 6291.54631541757,
      "epsilon": 0.2598370000064257
    },
    {
      "episode": 4976,
      "score": 277,
      "reward": -853.0,
      "steps": 70,
      "mean_loss": 5022.036947086879,
      "epsilon": 0.25976700000642755
    },
    {
      "episode": 4977,
      "score": 154,
      "reward": -937.0,
      "steps": 48,
      "mean_loss": 4965.360028823216,
      "epsilon": 0.25971900000642884
    },
    {
      "episode": 4978,
      "score": 22,
      "reward": -1000.0,
      "steps": 16,
      "mean_loss": 5829.700736522675,
      "epsilon": 0.25970300000642926
    },
    {
      "episode": 4979,
      "score": 115,
      "reward": -965.0,
      "steps": 44,
      "mean_loss": 3559.0046107552266,
      "epsilon": 0.25965900000643044
    },
    {
      "episode": 4980,
      "score": 151,
      "reward": -937.0,
      "steps": 49,
      "mean_loss": 4573.058032989502,
      "epsilon": 0.25961000000643175
    },
    {
      "episode": 4981,
      "score": 256,
      "reward": -866.0,
      "steps": 66,
      "mean_loss": 6009.085374889952,
      "epsilon": 0.2595440000064335
    },
    {
      "episode": 4982,
      "score": 170,
      "reward": -917.0,
      "steps": 52,
      "mean_loss": 7729.37896156311,
      "epsilon": 0.2594920000064349
    },
    {
      "episode": 4983,
      "score": 245,
      "reward": -858.0,
      "steps": 62,
      "mean_loss": 6959.23252148782,
      "epsilon": 0.25943000000643657
    },
    {
      "episode": 4984,
      "score": 96,
      "reward": -977.0,
      "steps": 40,
      "mean_loss": 3628.874774503708,
      "epsilon": 0.25939000000643764
    },
    {
      "episode": 4985,
      "score": 158,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 7055.910007043319,
      "epsilon": 0.2593460000064388
    },
    {
      "episode": 4986,
      "score": 164,
      "reward": -925.0,
      "steps": 46,
      "mean_loss": 8587.351803323498,
      "epsilon": 0.25930000000644005
    },
    {
      "episode": 4987,
      "score": 106,
      "reward": -969.0,
      "steps": 43,
      "mean_loss": 5327.646108849104,
      "epsilon": 0.2592570000064412
    },
    {
      "episode": 4988,
      "score": 27,
      "reward": -990.0,
      "steps": 17,
      "mean_loss": 3464.044278088738,
      "epsilon": 0.25924000000644165
    },
    {
      "episode": 4989,
      "score": 105,
      "reward": -963.0,
      "steps": 40,
      "mean_loss": 2806.407910776138,
      "epsilon": 0.2592000000064427
    },
    {
      "episode": 4990,
      "score": 152,
      "reward": -944.0,
      "steps": 49,
      "mean_loss": 6863.735033307757,
      "epsilon": 0.25915100000644403
    },
    {
      "episode": 4991,
      "score": 238,
      "reward": -877.0,
      "steps": 62,
      "mean_loss": 4758.120232243692,
      "epsilon": 0.2590890000064457
    },
    {
      "episode": 4992,
      "score": 246,
      "reward": -860.0,
      "steps": 60,
      "mean_loss": 5107.524358940124,
      "epsilon": 0.2590290000064473
    },
    {
      "episode": 4993,
      "score": 154,
      "reward": -915.0,
      "steps": 47,
      "mean_loss": 4052.572075864102,
      "epsilon": 0.25898200000644855
    },
    {
      "episode": 4994,
      "score": 258,
      "reward": -851.0,
      "steps": 62,
      "mean_loss": 5103.467090791271,
      "epsilon": 0.2589200000064502
    },
    {
      "episode": 4995,
      "score": 164,
      "reward": -906.0,
      "steps": 50,
      "mean_loss": 3564.8296952819824,
      "epsilon": 0.25887000000645155
    },
    {
      "episode": 4996,
      "score": 131,
      "reward": -947.0,
      "steps": 44,
      "mean_loss": 4616.272480444474,
      "epsilon": 0.2588260000064527
    },
    {
      "episode": 4997,
      "score": 177,
      "reward": -898.0,
      "steps": 52,
      "mean_loss": 2028.8514909744263,
      "epsilon": 0.2587740000064541
    },
    {
      "episode": 4998,
      "score": 103,
      "reward": -963.0,
      "steps": 39,
      "mean_loss": 2164.327578666883,
      "epsilon": 0.25873500000645516
    },
    {
      "episode": 4999,
      "score": 147,
      "reward": -938.0,
      "steps": 47,
      "mean_loss": 5783.536115037634,
      "epsilon": 0.2586880000064564
    },
    {
      "episode": 5000,
      "score": 278,
      "reward": -820.0,
      "steps": 65,
      "mean_loss": 3133.7378168839673,
      "epsilon": 0.25862300000645816
    }
  ],
  "validation": [
    {
      "episode": 0,
      "mean_score": 89.1,
      "std_score": 70.86529474996911,
      "mean_reward": 39.2,
      "std_reward": 44.525947491322405,
      "max_score": 217,
      "min_score": 12
    },
    {
      "episode": 100,
      "mean_score": 148.7,
      "std_score": 38.173420072086806,
      "mean_reward": 69.5,
      "std_reward": 29.54064995899718,
      "max_score": 238,
      "min_score": 102
    },
    {
      "episode": 200,
      "mean_score": 149.8,
      "std_score": 47.92869704049965,
      "mean_reward": 73.5,
      "std_reward": 38.642593080692706,
      "max_score": 223,
      "min_score": 74
    },
    {
      "episode": 300,
      "mean_score": 186.3,
      "std_score": 43.46504342572316,
      "mean_reward": 95.1,
      "std_reward": 32.482148943689054,
      "max_score": 289,
      "min_score": 143
    },
    {
      "episode": 400,
      "mean_score": 154.2,
      "std_score": 45.02621458661609,
      "mean_reward": 70.6,
      "std_reward": 31.190383133267215,
      "max_score": 210,
      "min_score": 49
    },
    {
      "episode": 500,
      "mean_score": 202.3,
      "std_score": 41.90238656687707,
      "mean_reward": 110.5,
      "std_reward": 34.85756732762629,
      "max_score": 296,
      "min_score": 145
    },
    {
      "episode": 600,
      "mean_score": 213.3,
      "std_score": 66.95528358539003,
      "mean_reward": 118.8,
      "std_reward": 54.658576637157324,
      "max_score": 302,
      "min_score": 124
    },
    {
      "episode": 700,
      "mean_score": 186.0,
      "std_score": 60.24782153738009,
      "mean_reward": 89.8,
      "std_reward": 44.95731308697173,
      "max_score": 269,
      "min_score": 97
    },
    {
      "episode": 800,
      "mean_score": 183.7,
      "std_score": 61.9371455590262,
      "mean_reward": 95.9,
      "std_reward": 49.02132189160142,
      "max_score": 272,
      "min_score": 96
    },
    {
      "episode": 900,
      "mean_score": 187.4,
      "std_score": 68.27327441979035,
      "mean_reward": 100.9,
      "std_reward": 51.139906139921685,
      "max_score": 328,
      "min_score": 127
    },
    {
      "episode": 1000,
      "mean_score": 170.5,
      "std_score": 44.746508243660756,
      "mean_reward": 85.6,
      "std_reward": 38.466088961577576,
      "max_score": 256,
      "min_score": 93
    },
    {
      "episode": 1100,
      "mean_score": 177.4,
      "std_score": 37.731154236254156,
      "mean_reward": 92.0,
      "std_reward": 32.02499024199695,
      "max_score": 244,
      "min_score": 113
    },
    {
      "episode": 1200,
      "mean_score": 178.7,
      "std_score": 56.37206755122612,
      "mean_reward": 86.8,
      "std_reward": 45.483623426459765,
      "max_score": 309,
      "min_score": 91
    },
    {
      "episode": 1300,
      "mean_score": 181.7,
      "std_score": 36.30991600100447,
      "mean_reward": 96.5,
      "std_reward": 28.24977876019563,
      "max_score": 249,
      "min_score": 128
    },
    {
      "episode": 1400,
      "mean_score": 182.7,
      "std_score": 39.557679406153234,
      "mean_reward": 95.7,
      "std_reward": 32.4316203727165,
      "max_score": 231,
      "min_score": 111
    },
    {
      "episode": 1500,
      "mean_score": 153.7,
      "std_score": 26.495471311150514,
      "mean_reward": 70.0,
      "std_reward": 22.68038800373574,
      "max_score": 192,
      "min_score": 97
    },
    {
      "episode": 1600,
      "mean_score": 183.7,
      "std_score": 50.05606856316225,
      "mean_reward": 100.9,
      "std_reward": 39.052400694451556,
      "max_score": 292,
      "min_score": 125
    },
    {
      "episode": 1700,
      "mean_score": 172.0,
      "std_score": 51.59651150998486,
      "mean_reward": 84.6,
      "std_reward": 46.00695599580568,
      "max_score": 279,
      "min_score": 105
    },
    {
      "episode": 1800,
      "mean_score": 181.0,
      "std_score": 50.58062870309146,
      "mean_reward": 94.5,
      "std_reward": 37.49466628735346,
      "max_score": 287,
      "min_score": 97
    },
    {
      "episode": 1900,
      "mean_score": 167.3,
      "std_score": 30.870860046328477,
      "mean_reward": 81.7,
      "std_reward": 24.588818597077818,
      "max_score": 204,
      "min_score": 100
    },
    {
      "episode": 2000,
      "mean_score": 188.2,
      "std_score": 69.09819100381716,
      "mean_reward": 91.6,
      "std_reward": 55.7515919055232,
      "max_score": 356,
      "min_score": 111
    },
    {
      "episode": 2100,
      "mean_score": 175.8,
      "std_score": 53.19172868031269,
      "mean_reward": 83.1,
      "std_reward": 37.753013124782505,
      "max_score": 299,
      "min_score": 111
    },
    {
      "episode": 2200,
      "mean_score": 156.0,
      "std_score": 43.31281565541543,
      "mean_reward": 72.2,
      "std_reward": 37.830675383873334,
      "max_score": 249,
      "min_score": 87
    },
    {
      "episode": 2300,
      "mean_score": 202.2,
      "std_score": 71.73534693580285,
      "mean_reward": 110.0,
      "std_reward": 53.490186015754325,
      "max_score": 307,
      "min_score": 74
    },
    {
      "episode": 2400,
      "mean_score": 192.5,
      "std_score": 39.45947288041238,
      "mean_reward": 100.5,
      "std_reward": 34.02425605358624,
      "max_score": 254,
      "min_score": 129
    },
    {
      "episode": 2500,
      "mean_score": 196.6,
      "std_score": 45.991738388541044,
      "mean_reward": 103.8,
      "std_reward": 35.968875434186145,
      "max_score": 286,
      "min_score": 112
    },
    {
      "episode": 2600,
      "mean_score": 210.7,
      "std_score": 42.080993334283356,
      "mean_reward": 113.7,
      "std_reward": 36.61161018037858,
      "max_score": 297,
      "min_score": 171
    },
    {
      "episode": 2700,
      "mean_score": 166.2,
      "std_score": 45.91034741754848,
      "mean_reward": 78.9,
      "std_reward": 33.907078906918535,
      "max_score": 246,
      "min_score": 105
    },
    {
      "episode": 2800,
      "mean_score": 157.8,
      "std_score": 50.97607281852929,
      "mean_reward": 76.6,
      "std_reward": 42.804672642131024,
      "max_score": 265,
      "min_score": 98
    },
    {
      "episode": 2900,
      "mean_score": 181.0,
      "std_score": 54.16641025580336,
      "mean_reward": 90.1,
      "std_reward": 44.7514245583311,
      "max_score": 265,
      "min_score": 86
    },
    {
      "episode": 3000,
      "mean_score": 193.4,
      "std_score": 64.97722677984956,
      "mean_reward": 107.0,
      "std_reward": 45.00444422498738,
      "max_score": 292,
      "min_score": 65
    },
    {
      "episode": 3100,
      "mean_score": 205.6,
      "std_score": 43.2393339449164,
      "mean_reward": 113.3,
      "std_reward": 36.18577068406862,
      "max_score": 276,
      "min_score": 145
    },
    {
      "episode": 3200,
      "mean_score": 177.7,
      "std_score": 68.87096630656492,
      "mean_reward": 97.8,
      "std_reward": 53.06750418099573,
      "max_score": 296,
      "min_score": 21
    },
    {
      "episode": 3300,
      "mean_score": 115.5,
      "std_score": 86.24528972645405,
      "mean_reward": 51.3,
      "std_reward": 52.32981941493779,
      "max_score": 276,
      "min_score": 9
    },
    {
      "episode": 3400,
      "mean_score": 141.6,
      "std_score": 67.8589714039345,
      "mean_reward": 59.0,
      "std_reward": 36.52396473549935,
      "max_score": 225,
      "min_score": 9
    },
    {
      "episode": 3500,
      "mean_score": 190.1,
      "std_score": 59.8539054699023,
      "mean_reward": 101.5,
      "std_reward": 47.710061831861005,
      "max_score": 284,
      "min_score": 107
    },
    {
      "episode": 3600,
      "mean_score": 112.8,
      "std_score": 95.592677543837,
      "mean_reward": 48.6,
      "std_reward": 58.09509445727755,
      "max_score": 264,
      "min_score": 5
    },
    {
      "episode": 3700,
      "mean_score": 218.6,
      "std_score": 54.22766821466695,
      "mean_reward": 118.4,
      "std_reward": 37.39304748211892,
      "max_score": 328,
      "min_score": 159
    },
    {
      "episode": 3800,
      "mean_score": 172.2,
      "std_score": 48.377267388722984,
      "mean_reward": 83.4,
      "std_reward": 39.661568299803776,
      "max_score": 253,
      "min_score": 83
    },
    {
      "episode": 3900,
      "mean_score": 150.2,
      "std_score": 78.6216255237705,
      "mean_reward": 70.9,
      "std_reward": 50.961652249510124,
      "max_score": 256,
      "min_score": 9
    },
    {
      "episode": 4000,
      "mean_score": 157.7,
      "std_score": 76.74770354870562,
      "mean_reward": 81.0,
      "std_reward": 50.6596486367602,
      "max_score": 253,
      "min_score": 12
    },
    {
      "episode": 4100,
      "mean_score": 168.8,
      "std_score": 79.04656855297388,
      "mean_reward": 83.7,
      "std_reward": 61.681520733522774,
      "max_score": 280,
      "min_score": 9
    },
    {
      "episode": 4200,
      "mean_score": 153.9,
      "std_score": 41.44743659142264,
      "mean_reward": 69.2,
      "std_reward": 29.77851574541619,
      "max_score": 210,
      "min_score": 75
    },
    {
      "episode": 4300,
      "mean_score": 172.4,
      "std_score": 62.37820132065367,
      "mean_reward": 85.9,
      "std_reward": 47.3,
      "max_score": 294,
      "min_score": 52
    },
    {
      "episode": 4400,
      "mean_score": 172.9,
      "std_score": 40.74174763065522,
      "mean_reward": 82.4,
      "std_reward": 36.8976964050603,
      "max_score": 279,
      "min_score": 122
    },
    {
      "episode": 4500,
      "mean_score": 162.6,
      "std_score": 43.41013706497596,
      "mean_reward": 76.1,
      "std_reward": 41.606369704649794,
      "max_score": 241,
      "min_score": 79
    },
    {
      "episode": 4600,
      "mean_score": 153.5,
      "std_score": 52.152181162440364,
      "mean_reward": 69.7,
      "std_reward": 31.818390908403902,
      "max_score": 223,
      "min_score": 37
    },
    {
      "episode": 4700,
      "mean_score": 202.3,
      "std_score": 53.74020841046302,
      "mean_reward": 108.1,
      "std_reward": 41.81494947982121,
      "max_score": 313,
      "min_score": 119
    },
    {
      "episode": 4800,
      "mean_score": 144.7,
      "std_score": 47.84359936292418,
      "mean_reward": 64.6,
      "std_reward": 30.030651008594536,
      "max_score": 208,
      "min_score": 31
    },
    {
      "episode": 4900,
      "mean_score": 147.2,
      "std_score": 71.54411226648912,
      "mean_reward": 65.8,
      "std_reward": 47.31553656041533,
      "max_score": 280,
      "min_score": 27
    },
    {
      "episode": 5000,
      "mean_score": 161.9,
      "std_score": 48.65480449040978,
      "mean_reward": 74.5,
      "std_reward": 29.780026863654776,
      "max_score": 209,
      "min_score": 27
    }
  ],
  "test": [
    {
      "episode": 5000,
      "mean_score": 177.9,
      "std_score": 78.20031969244116,
      "mean_reward": 89.7,
      "std_reward": 55.81764953847483,
      "max_score": 261,
      "min_score": 9
    }
  ]
}