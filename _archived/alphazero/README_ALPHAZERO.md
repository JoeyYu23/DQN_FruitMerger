# AlphaZero for Suika Game (æ°´æœåˆæˆæ¸¸æˆ)

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å°† **AlphaZero æ¡†æ¶**è¿ç§»åˆ° **Suika Game (æ°´æœåˆæˆæ¸¸æˆ)**ï¼Œå®ç°äº†ï¼š

- âœ… **ç¥ç»ç½‘ç»œ** - CNNæ¶æ„ï¼Œè¾“å‡º Policy P(a|s) å’Œ Value V(s)
- âœ… **MCTSæœç´¢** - PUCTç®—æ³•ï¼Œç½‘ç»œé©±åŠ¨çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢
- âœ… **Self-Play** - è‡ªæˆ‘åšå¼ˆæ”¶é›†è®­ç»ƒæ•°æ®
- âœ… **è®­ç»ƒå¾ªç¯** - è¿­ä»£ä¼˜åŒ–ç½‘ç»œç­–ç•¥
- âœ… **è¯„ä¼°å¯¹æ¯”** - ä¸DQNã€éšæœºã€å¯å‘å¼MCTSå¯¹æ¯”

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
DQN_FruitMerger/
â”œâ”€â”€ Core Modules (æ–°å¢)
â”‚   â”œâ”€â”€ SuikaNet.py              # ç¥ç»ç½‘ç»œ (Policy + Value)
â”‚   â”œâ”€â”€ AlphaZeroMCTS.py         # AlphaZero MCTSæœç´¢
â”‚   â”œâ”€â”€ StateConverter.py        # çŠ¶æ€è½¬æ¢å·¥å…·
â”‚   â”œâ”€â”€ SelfPlay.py              # è‡ªæˆ‘åšå¼ˆæ¨¡å—
â”‚   â”œâ”€â”€ TrainAlphaZero.py        # è®­ç»ƒä¸»å¾ªç¯
â”‚   â””â”€â”€ CompareAgents.py         # è¯„ä¼°å¯¹æ¯”è„šæœ¬
â”‚
â”œâ”€â”€ Original Modules (ä¿ç•™)
â”‚   â”œâ”€â”€ Game.py                  # æ¸¸æˆç‰©ç†å¼•æ“
â”‚   â”œâ”€â”€ GameInterface.py         # RLæ¥å£
â”‚   â”œâ”€â”€ DQN.py                   # DQN agent
â”‚   â””â”€â”€ mcts/MCTS.py             # å¯å‘å¼MCTS
â”‚
â”œâ”€â”€ Deployment
â”‚   â”œâ”€â”€ requirements_alphazero.txt  # ä¾èµ–åŒ…
â”‚   â”œâ”€â”€ train_cloud.sh              # äº‘ç«¯è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ README_ALPHAZERO.md         # æœ¬æ–‡æ¡£
â”‚
â””â”€â”€ Outputs
    â”œâ”€â”€ weights/alphazero/       # AlphaZeroæ¨¡å‹
    â”œâ”€â”€ logs/                    # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ evaluation_results.json  # è¯„ä¼°ç»“æœ
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
conda create -n alphazero python=3.8
conda activate alphazero

# å®‰è£…ä¾èµ–
pip install -r requirements_alphazero.txt

# GPUç‰ˆæœ¬ (å¦‚æœæœ‰GPU)
# pip install paddlepaddle-gpu
```

### 2. æµ‹è¯•ç½‘ç»œ

```bash
# æµ‹è¯•SuikaNetç½‘ç»œ
python SuikaNet.py

# æœŸæœ›è¾“å‡ºï¼š
# [SuikaNet] Initialized: ...
# All tests passed!
```

### 3. å¿«é€Ÿè®­ç»ƒ (æœ¬åœ°æµ‹è¯•)

```bash
# å°è§„æ¨¡è®­ç»ƒæµ‹è¯• (2è½®è¿­ä»£)
python TrainAlphaZero.py \
    --iterations 2 \
    --games 10 \
    --simulations 50 \
    --batch-size 16 \
    --epochs 3

# è®­ç»ƒçº¦10-20åˆ†é’Ÿå®Œæˆ
```

---

## â˜ï¸ äº‘ç«¯è®­ç»ƒ (æ¨èé…ç½®)

### æœåŠ¡å™¨è¦æ±‚

- **CPU**: 4æ ¸ä»¥ä¸Š
- **å†…å­˜**: 8GBä»¥ä¸Š
- **GPU**: å¯é€‰ï¼Œä½†æ¨è (åŠ é€Ÿç½‘ç»œè®­ç»ƒ)
- **ç£ç›˜**: 5GBä»¥ä¸Š

### è®­ç»ƒå‘½ä»¤

```bash
# æ–¹å¼1: ä½¿ç”¨è„šæœ¬ (æ¨è)
./train_cloud.sh 20 50 200 32 5 10

# å‚æ•°è¯´æ˜:
# 20  - è¿­ä»£æ¬¡æ•°
# 50  - æ¯è½®æ¸¸æˆæ•°
# 200 - MCTSæ¨¡æ‹Ÿæ¬¡æ•°
# 32  - æ‰¹é‡å¤§å°
# 5   - æ¯è½®epochæ•°
# 10  - è¯„ä¼°æ¸¸æˆæ•°

# æ–¹å¼2: ç›´æ¥è¿è¡Œ
python TrainAlphaZero.py \
    --iterations 20 \
    --games 50 \
    --simulations 200 \
    --batch-size 32 \
    --epochs 5 \
    --eval-games 10
```

### åå°è¿è¡Œ

```bash
# ä½¿ç”¨ nohup åå°è¿è¡Œ
nohup ./train_cloud.sh 20 50 200 32 5 10 > train.log 2>&1 &

# æŸ¥çœ‹è¿›åº¦
tail -f train.log

# æˆ–è€…ä½¿ç”¨ tmux/screen
tmux new -s train
./train_cloud.sh 20 50 200 32 5 10
# Ctrl+B, D åˆ†ç¦»ä¼šè¯
```

### ç›‘æ§è®­ç»ƒ

```bash
# æŸ¥çœ‹GPUä½¿ç”¨ (å¦‚æœæœ‰GPU)
nvidia-smi

# æŸ¥çœ‹è®­ç»ƒå†å²
cat weights/alphazero/history.json | python -m json.tool

# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f logs/train_*.log
```

---

## ğŸ“Š è¯„ä¼°ä¸å¯¹æ¯”

### è¯„ä¼°å•ä¸ªæ¨¡å‹

```bash
python CompareAgents.py \
    --num-games 50 \
    --alphazero-model weights/alphazero/iter_20.pdparams \
    --alphazero-sims 200
```

### å®Œæ•´å¯¹æ¯” (AlphaZero vs DQN vs Random vs MCTS)

```bash
python CompareAgents.py \
    --num-games 50 \
    --alphazero-model weights/alphazero/iter_20.pdparams \
    --dqn-model weights/final.pdparams \
    --alphazero-sims 200 \
    --mcts-sims 200 \
    --output evaluation_results.json
```

### é¢„æœŸç»“æœ

| Agent | Mean Score | Max Score | è¯´æ˜ |
|-------|------------|-----------|------|
| Random | 150 | 300 | åŸºçº¿ |
| DQN | 500 | 1200 | ç»éªŒå›æ”¾å­¦ä¹  |
| MCTS Baseline | 800 | 2000 | å¯å‘å¼æœç´¢ |
| **AlphaZero** | **1200+** | **3500+** | ç½‘ç»œ+MCTS |

---

## ğŸ”§ é«˜çº§é…ç½®

### è°ƒæ•´è®­ç»ƒå‚æ•°

**åŠ å¿«è®­ç»ƒé€Ÿåº¦:**
```python
# å‡å°‘æ¨¡æ‹Ÿæ¬¡æ•°
--simulations 100  # é»˜è®¤200

# å‡å°‘æ¯è½®æ¸¸æˆæ•°
--games 30  # é»˜è®¤50

# å‡å°‘ç½‘ç»œå¤æ‚åº¦
# ä¿®æ”¹ SuikaNet.py:
hidden_channels=32  # é»˜è®¤64
```

**æé«˜æœ€ç»ˆæ€§èƒ½:**
```python
# å¢åŠ æ¨¡æ‹Ÿæ¬¡æ•°
--simulations 400

# å¢åŠ æ¯è½®æ¸¸æˆæ•°
--games 100

# æ›´å¤šè®­ç»ƒepoch
--epochs 10

# æ›´å¤šè¿­ä»£
--iterations 50
```

### æ¢å¤è®­ç»ƒ

```bash
# ä»ç¬¬10è½®ç»§ç»­
python TrainAlphaZero.py \
    --resume 10 \
    --iterations 20 \
    --checkpoint-dir weights/alphazero
```

---

## ğŸ“ˆ è®­ç»ƒæµç¨‹è¯¦è§£

### å•è½®è¿­ä»£

```
è¿­ä»£ i:
â”œâ”€ [1/3] Self-Play (30-60åˆ†é’Ÿ)
â”‚   â”œâ”€ ç© 50 å±€æ¸¸æˆ
â”‚   â”œâ”€ æ¯æ­¥ç”¨MCTS(200æ¬¡æ¨¡æ‹Ÿ)é€‰æ‹©åŠ¨ä½œ
â”‚   â””â”€ æ”¶é›† (s, Ï€, z) è®­ç»ƒæ•°æ®
â”‚
â”œâ”€ [2/3] Train (5-10åˆ†é’Ÿ)
â”‚   â”œâ”€ 5 ä¸ª epoch
â”‚   â”œâ”€ Loss = MSE(V, z) + CrossEntropy(P, Ï€)
â”‚   â””â”€ æ›´æ–°ç½‘ç»œå‚æ•°
â”‚
â””â”€ [3/3] Evaluate (10-15åˆ†é’Ÿ)
    â”œâ”€ æµ‹è¯• 10 å±€æ¸¸æˆ
    â”œâ”€ è®¡ç®—å¹³å‡å¾—åˆ†
    â””â”€ ä¿å­˜æ£€æŸ¥ç‚¹
```

### å®Œæ•´è®­ç»ƒæ—¶é—´ä¼°ç®—

| é…ç½® | å•è½®æ—¶é—´ | 20è½®æ€»æ—¶é—´ |
|------|---------|-----------|
| å¿«é€Ÿ (sim=100, games=30) | ~30åˆ†é’Ÿ | ~10å°æ—¶ |
| æ ‡å‡† (sim=200, games=50) | ~60åˆ†é’Ÿ | ~20å°æ—¶ |
| é«˜è´¨é‡ (sim=400, games=100) | ~120åˆ†é’Ÿ | ~40å°æ—¶ |

---

## ğŸ§ª æ ¸å¿ƒæŠ€æœ¯è§£æ

### 1. ç¥ç»ç½‘ç»œè®¾è®¡

```python
Input: [13, 20, 16]
  â”œâ”€ 0-10: æ°´æœç­‰çº§ (one-hot)
  â”œâ”€ 11: å½“å‰æ°´æœç±»å‹
  â””â”€ 12: é«˜åº¦ä¿¡æ¯

Network:
  Conv2D(13â†’64) â†’ BN â†’ ReLU
  Conv2D(64â†’64) â†’ BN â†’ ReLU
  Conv2D(64â†’64) â†’ BN â†’ ReLU
  â”œâ”€ Policy Head â†’ [16] åŠ¨ä½œæ¦‚ç‡
  â””â”€ Value Head â†’ [1] çŠ¶æ€ä»·å€¼
```

### 2. MCTS + PUCT

```python
# Selection
UCB(s,a) = Q(s,a) + c Ã— P(a|s) Ã— âˆšN(s) / (1 + N(s,a))

# Expansion
ç”¨ç½‘ç»œ (P, V) = f(s) è¯„ä¼°å¶å­èŠ‚ç‚¹

# Backup
åå‘ä¼ æ’­ V åˆ°è·¯å¾„ä¸Šæ‰€æœ‰èŠ‚ç‚¹
```

### 3. è®­ç»ƒLoss

```python
Loss = MSE(V(s), z) + CrossEntropy(P(s), Ï€) + L2_reg

where:
  V(s) - ç½‘ç»œä»·å€¼è¾“å‡º
  z - æœ€ç»ˆå¾—åˆ†ï¼ˆå½’ä¸€åŒ–ï¼‰
  P(s) - ç½‘ç»œç­–ç•¥è¾“å‡º
  Ï€ - MCTSæœç´¢å¾—åˆ°çš„å¢å¼ºç­–ç•¥
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠ?

**A:**
- å‡å°‘`--simulations`åˆ°100
- å‡å°‘`--games`åˆ°30
- ä½¿ç”¨GPUç‰ˆæœ¬PaddlePaddle
- å…³é—­å¯è§†åŒ–æ¸²æŸ“

### Q2: å†…å­˜ä¸è¶³?

**A:**
- å‡å°‘`--batch-size`åˆ°16
- å‡å°‘`hidden_channels`åˆ°32
- é™åˆ¶å†å²æ•°æ®bufferå¤§å°

### Q3: å¾—åˆ†æ²¡æœ‰æå‡?

**A:**
- æ£€æŸ¥ç½‘ç»œæ˜¯å¦æ”¶æ•› (lossä¸‹é™)
- å¢åŠ è®­ç»ƒè¿­ä»£æ¬¡æ•°
- å¢åŠ MCTSæ¨¡æ‹Ÿæ¬¡æ•°
- æ£€æŸ¥çŠ¶æ€è½¬æ¢æ˜¯å¦æ­£ç¡®

### Q4: å¦‚ä½•å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹?

**A:**
```python
# è¯»å–å†å²
import json
with open('weights/alphazero/history.json') as f:
    history = json.load(f)

# ç»˜å›¾
import matplotlib.pyplot as plt
plt.plot(history['iterations'], history['eval_scores'])
plt.xlabel('Iteration')
plt.ylabel('Evaluation Score')
plt.show()
```

---

## ğŸ“š è®ºæ–‡å‚è€ƒ

1. **AlphaGo Zero** - Silver et al., Nature 2017
   - PUCTç®—æ³•
   - Self-playè®­ç»ƒ

2. **AlphaZero** - Silver et al., Science 2018
   - é€šç”¨æ¡†æ¶
   - å•ä¸€ç½‘ç»œæ¶æ„

3. **MuZero** - Schrittwieser et al., Nature 2020
   - æ¨¡å‹å­¦ä¹ 
   - Planning in latent space

---

## ğŸ¤ è´¡çŒ®ä¸æ‰©å±•

### å¯èƒ½çš„æ”¹è¿›æ–¹å‘

1. **ç½‘ç»œç»“æ„**
   - ResNetæ®‹å·®è¿æ¥
   - Attentionæœºåˆ¶
   - æ›´æ·±çš„ç½‘ç»œ

2. **MCTSä¼˜åŒ–**
   - Virtual loss (å¹¶è¡Œæœç´¢)
   - RAVE (å¿«é€Ÿè¡ŒåŠ¨å€¼ä¼°è®¡)
   - Progressive wideningæ”¹è¿›

3. **è®­ç»ƒæŠ€å·§**
   - ä¼˜å…ˆçº§ç»éªŒå›æ”¾
   - è¯¾ç¨‹å­¦ä¹ 
   - å¯¹æŠ—è®­ç»ƒ

4. **å·¥ç¨‹ä¼˜åŒ–**
   - åˆ†å¸ƒå¼è®­ç»ƒ
   - æ··åˆç²¾åº¦è®­ç»ƒ
   - æ¨¡å‹å‹ç¼©

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿ï¼š
- æIssue
- Pull Request
- é‚®ä»¶è”ç³»

---

## âš–ï¸ å¼€æºåè®®

æœ¬é¡¹ç›®åŸºäºåŸDQN_FruitMergeré¡¹ç›®æ‰©å±•ï¼Œéµå¾ªç›¸åŒçš„å¼€æºåè®®ã€‚

---

## ğŸ‰ è‡´è°¢

- PaddlePaddleæ·±åº¦å­¦ä¹ æ¡†æ¶
- AlphaGo/AlphaZeroå›¢é˜Ÿ
- Pymunkç‰©ç†å¼•æ“
- åŸDQN_FruitMergeré¡¹ç›®

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**
