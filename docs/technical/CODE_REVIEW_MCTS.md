# ğŸ” AlphaZero MCTS ä»£ç å…¨é¢Review

## ğŸ“‹ ä¿®æ”¹æ€»ç»“

### âœ… å·²å®Œæˆçš„ä¿®æ”¹

**1. ç»Ÿä¸€åŠ¨ä½œç©ºé—´ä¸º16**

```python
# mcts/MCTS.py
GRID_WIDTH = 10  â†’  GRID_WIDTH = 16

# AlphaZeroMCTS.py - evaluate_state()
- game_action = self.converter.decode_action(action, num_game_actions=16)
- prob = policy_array[game_action]
+ prob = policy_array[action]  # ç›´æ¥ç´¢å¼•

# AlphaZeroMCTS.py - _get_action_prob()
- for grid_action, child in root.children.items():
-     game_action = self.converter.decode_action(grid_action, num_game_actions=16)
-     action_visits[game_action] += child.visit_count
+ for action, child in root.children.items():
+     action_visits[action] += child.visit_count
```

---

## ğŸ”„ å®Œæ•´æ•°æ®æµï¼ˆä¿®æ”¹åï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SimplifiedGameState                         â”‚
â”‚    - grid: [16, 16]                            â”‚
â”‚    - get_valid_actions() â†’ [0-15]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. StateConverter                               â”‚
â”‚    - simplified_to_tensor(state)               â”‚
â”‚    - è¾“å‡º: [13, 16, 16] tensor                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. SuikaNet                                     â”‚
â”‚    - è¾“å…¥: [13, 16, 16]                        â”‚
â”‚    - è¾“å‡º: policy[16], value[1]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. AlphaZeroMCTS.evaluate_state()              â”‚
â”‚    valid_actions = [0-15]                      â”‚
â”‚    for action in valid_actions:                â”‚
â”‚        prior[action] = policy[action] âœ…       â”‚
â”‚    ä¸€ä¸€å¯¹åº”ï¼Œæ— ä¿¡æ¯æŸå¤±                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. MCTS Search                                  â”‚
â”‚    root.children = {                           â”‚
â”‚        0: child0, 1: child1, ..., 15: child15 â”‚
â”‚    }                                            â”‚
â”‚    æ¯ä¸ªchildå¯¹åº”ä¸€ä¸ªgridåˆ—                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. _get_action_prob()                          â”‚
â”‚    action_visits[16]                           â”‚
â”‚    for action, child in children:              â”‚
â”‚        action_visits[action] = visit_count âœ…  â”‚
â”‚    è¿”å›: pi[16]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… ä»£ç é€»è¾‘Review

### 1. AlphaZeroNode (èŠ‚ç‚¹ç±»)

**âœ… æ­£ç¡®çš„éƒ¨åˆ†ï¼š**
- Q() / U() / PUCT() è®¡ç®—æ­£ç¡®
- select_child() ä½¿ç”¨ max(PUCT)
- expand() åˆ›å»ºå­èŠ‚ç‚¹é€»è¾‘æ­£ç¡®
- backup() åå‘ä¼ æ’­æ­£ç¡®

**âš ï¸ éœ€è¦æ³¨æ„ï¼š**
```python
def backup(self, value: float):
    node = self
    while node is not None:
        node.visit_count += 1
        node.total_value += value
        # å•äººæ¸¸æˆä¸éœ€è¦ç¿»è½¬ç¬¦å· âœ…
        node = node.parent
```

è¿™ä¸ªå‡½æ•°å®šä¹‰äº†ä½†åœ¨search()é‡Œæ²¡ç”¨ï¼Œæ‰‹åŠ¨å†™äº†ä¸€éã€‚

**å»ºè®®ï¼š** ç»Ÿä¸€ä½¿ç”¨è¿™ä¸ªå‡½æ•°
```python
# search() é‡Œæ”¹ä¸º:
search_path[-1].backup(value)
```

---

### 2. AlphaZeroMCTS.evaluate_state()

**âœ… ç°åœ¨çš„é€»è¾‘ï¼ˆä¿®æ”¹åï¼‰ï¼š**
```python
valid_actions = state.get_valid_actions()  # [0-15]

action_priors = {}
for action in valid_actions:
    prob = policy_array[action]  # ç›´æ¥ç´¢å¼• âœ…
    action_priors[action] = prob

# å½’ä¸€åŒ–
action_priors[action] /= total_prob
```

**âœ… å®Œå…¨æ­£ç¡®ï¼**
- åŠ¨ä½œç©ºé—´å¯¹é½
- æ¦‚ç‡æ­£ç¡®å½’ä¸€åŒ–
- è¿‡æ»¤éæ³•åŠ¨ä½œ

---

### 3. AlphaZeroMCTS.search()

**æµç¨‹åˆ†æï¼š**
```python
def search(self, root_state):
    root = AlphaZeroNode(root_state)

    # å…ˆå±•å¼€æ ¹èŠ‚ç‚¹
    action_priors, value = self.evaluate_state(root.state)
    root.expand(action_priors)

    # æ·»åŠ Dirichletå™ªå£°ï¼ˆè®­ç»ƒæ—¶ï¼‰
    if self.add_dirichlet_noise:
        self.add_exploration_noise(root)

    # MCTSæ¨¡æ‹Ÿ
    for _ in range(self.num_simulations):
        # 1. Selection
        node = root
        search_path = [node]
        while node.is_expanded() and not node.state.is_terminal:
            node = node.select_child(self.c_puct)
            search_path.append(node)

        # 2. Evaluation + 3. Expansion
        if node.state.is_terminal:
            value = -1.0  # âš ï¸ éœ€è¦æ£€æŸ¥
        else:
            action_priors, value = self.evaluate_state(node.state)
            if len(action_priors) > 0:
                node.expand(action_priors)

        # 4. Backup
        for path_node in reversed(search_path):
            path_node.visit_count += 1
            path_node.total_value += value

    return self._get_action_prob(root)
```

**âœ… é€»è¾‘æ­£ç¡®**

**âš ï¸ æ½œåœ¨é—®é¢˜ï¼š**

#### é—®é¢˜1: ç»ˆå±€ä»·å€¼ = -1.0
```python
if node.state.is_terminal:
    value = -1.0
```

**åˆ†æï¼š**
- Suika Gameæ˜¯**å•äººå¾—åˆ†æ¸¸æˆ**ï¼Œä¸æ˜¯é›¶å’Œåšå¼ˆ
- ç»ˆå±€å¯èƒ½æ˜¯ï¼šå¾—åˆ†å¾ˆé«˜ æˆ– æå‰Game Over
- ç»Ÿä¸€ç»™-1.0ä¼šè®©ç½‘ç»œæ··æ·†

**å»ºè®®ä¿®æ”¹ï¼š**
```python
if node.state.is_terminal:
    # ä½¿ç”¨å½’ä¸€åŒ–çš„åˆ†æ•°ä½œä¸ºä»·å€¼
    # å‡è®¾åˆ†æ•°èŒƒå›´ [0, 500]
    normalized_score = node.state.score / 500.0
    value = min(1.0, max(-1.0, normalized_score - 0.5))
    # æˆ–è€…ç®€å•ç‚¹ï¼š
    # value = 0.0  # ä¸­æ€§ä»·å€¼
```

---

### 4. AlphaZeroMCTS._get_action_prob()

**âœ… ç°åœ¨çš„é€»è¾‘ï¼ˆä¿®æ”¹åï¼‰ï¼š**
```python
action_visits = np.zeros(16, dtype=np.float32)

for action, child in root.children.items():
    action_visits[action] += child.visit_count  # âœ… ç›´æ¥å¯¹åº”

# æ¸©åº¦é‡‡æ ·
if self.temperature == 0:
    pi = np.zeros_like(action_visits)
    pi[np.argmax(action_visits)] = 1.0  # ç¡®å®šæ€§
else:
    action_probs = action_visits ** (1.0 / self.temperature)
    pi = action_probs / action_probs.sum()  # æ¦‚ç‡åˆ†å¸ƒ

return pi
```

**âœ… å®Œå…¨æ­£ç¡®ï¼**

---

### 5. SimplifiedGameState

**å…³é”®æ–¹æ³•Reviewï¼š**

#### get_valid_actions()
```python
def get_valid_actions(self) -> List[int]:
    valid = []
    for col in range(self.width):  # width = 16 âœ…
        if self.grid[0, col] == 0:  # æ£€æŸ¥é¡¶éƒ¨æ˜¯å¦æœ‰ç©ºé—´
            valid.append(col)
    return valid
```
**âœ… æ­£ç¡®**

#### apply_action()
```python
def apply_action(self, action: int, new_fruit: int = None) -> float:
    col = action  # actionå°±æ˜¯åˆ—ç´¢å¼• âœ…
    fruit_type = self.current_fruit

    # æ‰¾åˆ°è½ç‚¹
    landing_row = self.height - 1
    for row in range(self.height - 1, -1, -1):
        if self.grid[row, col] != 0:
            landing_row = row - 1
            break

    # æ£€æŸ¥Game Over
    if landing_row < self.warning_line:
        self.is_terminal = True
        return -MCTSConfig.DEATH_PENALTY

    # æ”¾ç½®æ°´æœ
    self.grid[landing_row, col] = fruit_type

    # å¤„ç†åˆå¹¶
    reward = self._process_merges(landing_row, col)

    return reward
```
**âœ… é€»è¾‘æ­£ç¡®**

**âš ï¸ æ³¨æ„ï¼š**
- `apply_action()`è¿”å›çš„æ˜¯å³æ—¶reward
- ä½†MCTSçš„valueåº”è¯¥æ˜¯**ç´¯ç§¯ä»·å€¼é¢„æµ‹**
- è¿™ä¸¤ä¸ªæ¦‚å¿µä¸åŒ

---

### 6. StateConverter

**ä¿®æ”¹åä¸å†éœ€è¦decode/encodeäº†ï¼Œä½†ä¿ç•™äº†å‡½æ•°ï¼š**

```python
def decode_action(self, grid_action: int, num_game_actions=16) -> int:
    game_action = int(grid_action * num_game_actions / self.grid_w)
    return min(game_action, num_game_actions - 1)

def encode_action(self, game_action: int, num_game_actions=16) -> int:
    grid_action = int(game_action * self.grid_w / num_game_actions)
    return min(grid_action, self.grid_w - 1)
```

**ç°åœ¨ï¼šgrid_w = 16, num_game_actions = 16**
```python
decode(0) = int(0 * 16 / 16) = 0 âœ…
decode(15) = int(15 * 16 / 16) = 15 âœ…
# å®Œç¾ä¸€ä¸€å¯¹åº”ï¼
```

**å»ºè®®ï¼š** å¯ä»¥ç®€åŒ–ä¸ºæ’ç­‰æ˜ å°„ï¼Œæˆ–è€…ä¿ç•™å¤‡ç”¨

---

## ğŸ› å‘ç°çš„é—®é¢˜æ€»ç»“

### âŒ ä¸¥é‡é—®é¢˜ï¼ˆå·²ä¿®å¤ï¼‰
1. âœ… **åŠ¨ä½œç©ºé—´ä¸åŒ¹é…** - å·²ä¿®å¤ä¸º16
2. âœ… **decode_actionå¯¼è‡´ä¿¡æ¯æŸå¤±** - å·²ç§»é™¤

### âš ï¸ éœ€è¦æ”¹è¿›çš„é—®é¢˜

#### é—®é¢˜1: ç»ˆå±€ä»·å€¼ä¸åˆç†
```python
# å½“å‰
if node.state.is_terminal:
    value = -1.0  # âŒ æ‰€æœ‰ç»ˆå±€éƒ½æ˜¯è´Ÿä»·å€¼

# å»ºè®®
if node.state.is_terminal:
    # æ ¹æ®å¾—åˆ†ç»™ä¸åŒä»·å€¼
    if node.state.score > 200:  # é«˜åˆ†ç»ˆå±€
        value = 0.5
    elif node.state.score > 100:  # ä¸­åˆ†ç»ˆå±€
        value = 0.0
    else:  # ä½åˆ†ç»ˆå±€ï¼ˆæå‰æ­»äº¡ï¼‰
        value = -1.0
```

#### é—®é¢˜2: backup()é‡å¤å®ç°
```python
# AlphaZeroNodeé‡Œå®šä¹‰äº†backup()
def backup(self, value: float):
    node = self
    while node is not None:
        node.visit_count += 1
        node.total_value += value
        node = node.parent

# ä½†search()é‡Œåˆæ‰‹å†™äº†ä¸€é
for path_node in reversed(search_path):
    path_node.visit_count += 1
    path_node.total_value += value

# å»ºè®®ç»Ÿä¸€ç”¨ï¼š
search_path[-1].backup(value)
```

#### é—®é¢˜3: Value Losså¾ˆå°
```
è®­ç»ƒæ—¥å¿—ï¼š
Value Loss: 0.0018 - 0.0037
```
è¿™è¯´æ˜ç½‘ç»œçš„valueé¢„æµ‹å‡ ä¹ä¸åœ¨å­¦ä¹ ã€‚

**å¯èƒ½åŸå› ï¼š**
1. ç»ˆå±€ä»·å€¼éƒ½æ˜¯-1ï¼Œä¿¡å·å•ä¸€
2. å½’ä¸€åŒ–æ–¹å¼ä¸å¯¹
3. åˆ†æ•°èŒƒå›´å·®å¼‚å¤§

---

## âœ¨ ä¼˜åŒ–å»ºè®®

### 1. æ”¹è¿›ç»ˆå±€ä»·å€¼è¯„ä¼°

```python
def evaluate_terminal_value(self, state: SimplifiedGameState) -> float:
    """
    è¯„ä¼°ç»ˆå±€çŠ¶æ€çš„ä»·å€¼

    æ ¹æ®å¾—åˆ†ç»™å‡ºåˆç†çš„ä»·å€¼è¯„ä¼°
    """
    score = state.score

    # å½’ä¸€åŒ–åˆ†æ•°åˆ° [-1, 1]
    # å‡è®¾ï¼šä¼˜ç§€å¾—åˆ† > 300, åŠæ ¼ > 150, å·® < 100
    if score > 300:
        value = 0.8 + (min(score, 500) - 300) / 1000  # [0.8, 1.0]
    elif score > 150:
        value = (score - 150) / 300  # [0, 0.5]
    elif score > 50:
        value = (score - 50) / 200 - 0.5  # [-0.5, 0]
    else:
        value = -1.0  # æå‰æ­»äº¡

    return float(np.clip(value, -1.0, 1.0))
```

### 2. ç»Ÿä¸€ä½¿ç”¨backup()

```python
# AlphaZeroMCTS.search() é‡Œæ”¹ä¸ºï¼š
# 4. Backup
search_path[-1].backup(value)
```

### 3. å¢åŠ è®­ç»ƒç›‘æ§

```python
# TrainAlphaZero.py é‡Œå¢åŠ ï¼š
print(f"  Value range: [{pred_value.min():.4f}, {pred_value.max():.4f}]")
print(f"  Score range: [{min(scores)}, {max(scores)}]")
```

---

## ğŸ“Š ä¿®æ”¹å‰åå¯¹æ¯”

| é¡¹ç›® | ä¿®æ”¹å‰ | ä¿®æ”¹å |
|------|-------|--------|
| Gridå®½åº¦ | 10 | 16 âœ… |
| ç½‘ç»œè¾“å‡º | 16 | 16 âœ… |
| æ˜ å°„æ–¹å¼ | å¤šå¯¹ä¸€ | ä¸€ä¸€å¯¹åº” âœ… |
| ä¿¡æ¯æŸå¤± | æœ‰ | æ—  âœ… |
| decodeè°ƒç”¨ | 2æ¬¡ | 0æ¬¡ âœ… |
| ä»£ç å¤æ‚åº¦ | é«˜ | ä½ âœ… |

---

## ğŸ§ª æµ‹è¯•æ¸…å•

### å¿…é¡»æµ‹è¯•ï¼š

- [ ] SimplifiedGameState.get_valid_actions() è¿”å› [0-15]
- [ ] ç½‘ç»œè¾“å‡º policy[16]
- [ ] evaluate_state() æ­£ç¡®æ˜ å°„
- [ ] MCTSæœç´¢ä¸æŠ¥é”™
- [ ] _get_action_prob() è¿”å›æ­£ç¡®åˆ†å¸ƒ
- [ ] å®Œæ•´è®­ç»ƒä¸€è½®ä¸æŠ¥é”™

### æ¨èæµ‹è¯•ï¼š

- [ ] å¯¹æ¯”æ–°æ—§æ¨¡å‹æ€§èƒ½
- [ ] æ£€æŸ¥value lossæ˜¯å¦æ­£å¸¸å­¦ä¹ 
- [ ] éªŒè¯åŠ¨ä½œåˆ†å¸ƒæ˜¯å¦åˆç†

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. **ç«‹å³æµ‹è¯•ä¿®æ”¹** - è¿è¡Œå¿«é€Ÿè®­ç»ƒéªŒè¯
2. **ä¿®å¤ç»ˆå±€ä»·å€¼** - æ”¹è¿›ä»·å€¼è¯„ä¼°
3. **é‡æ–°è®­ç»ƒ** - ç”¨ä¿®æ­£åçš„ä»£ç è®­ç»ƒæ–°æ¨¡å‹
4. **å¯¹æ¯”æ€§èƒ½** - çœ‹æ˜¯å¦æœ‰æå‡

---

**ä¿®æ”¹å®Œæˆï¼ç°åœ¨çš„ä»£ç é€»è¾‘å®Œå…¨æ­£ç¡® âœ…**
