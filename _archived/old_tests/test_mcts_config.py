#!/usr/bin/env python3
"""
æµ‹è¯•MCTSé…ç½®å’Œrolloutç­–ç•¥
"""

from GameInterface import GameInterface
from mcts.MCTS_real_physics import RealPhysicsMCTSAgent, RealPhysicsConfig
import numpy as np

print("="*70)
print("ğŸ” æ£€æŸ¥MCTSé…ç½®")
print("="*70)

# 1. æ£€æŸ¥é…ç½®
print("\nğŸ“Š å½“å‰é…ç½®:")
print(f"  ROLLOUT_STEPS: {RealPhysicsConfig.ROLLOUT_STEPS}")
print(f"  MERGE_REWARD: {RealPhysicsConfig.MERGE_REWARD}")
print(f"  HEIGHT_PENALTY: {RealPhysicsConfig.HEIGHT_PENALTY}")
print(f"  POSITION_REWARD: {RealPhysicsConfig.POSITION_REWARD}")
print(f"  æ¯”ä¾‹ MERGE/HEIGHT: {RealPhysicsConfig.MERGE_REWARD/RealPhysicsConfig.HEIGHT_PENALTY:.1f}:1")

# 2. æµ‹è¯•rolloutç­–ç•¥
print("\nğŸ¯ æµ‹è¯•Rolloutç­–ç•¥:")
env = GameInterface()
env.reset(seed=888)

# ç¬¬ä¸€æ­¥éšæœº
env.next(8)

# æ¨¡æ‹Ÿä¸€ä¸ªå¯ä»¥mergeçš„åœºæ™¯
print(f"\nå½“å‰åœºä¸Šæ°´æœ:")
for i, (ball, fruit) in enumerate(zip(env.game.balls, env.game.fruits)):
    print(f"  æ°´æœ{i}: type={fruit.type}, x={ball.body.position.x:.1f}")

print(f"\næ‰‹é‡Œçš„æ°´æœ: type={env.game.current_fruit_type}")

# åˆ›å»ºagentå¹¶æµ‹è¯•rolloutç­–ç•¥
agent = RealPhysicsMCTSAgent(num_simulations=10)

# æµ‹è¯•rolloutç­–ç•¥100æ¬¡ï¼Œçœ‹æƒé‡åˆ†å¸ƒ
print(f"\næµ‹è¯•rolloutç­–ç•¥ï¼ˆ100æ¬¡é‡‡æ ·ï¼‰:")
actions = []
for _ in range(100):
    action = agent.mcts._rollout_policy(env)
    actions.append(action)

# ç»Ÿè®¡
from collections import Counter
action_counts = Counter(actions)
print(f"åŠ¨ä½œåˆ†å¸ƒ:")
for action in sorted(action_counts.keys()):
    count = action_counts[action]
    bar = "â–ˆ" * (count // 2)
    print(f"  Action {action:2d}: {count:3d} {bar}")

# 3. æµ‹è¯•ä¸€æ­¥MCTS
print(f"\nğŸ® è¿è¡Œä¸€æ­¥MCTS (10 sims):")
action = agent.predict(env)[0]
print(f"  é€‰æ‹©çš„åŠ¨ä½œ: {action}")

print("\n" + "="*70)
