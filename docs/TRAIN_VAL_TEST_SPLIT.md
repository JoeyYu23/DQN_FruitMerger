# Train/Validation/Test Split - Proper Seed Management

## ğŸš¨ Current Problem

**è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„ç§å­æ²¡æœ‰æ­£ç¡®åˆ†ç¦»ï¼**

### What's Wrong?

åœ¨å½“å‰ä»£ç ä¸­ï¼š

```python
# DQN.py å’Œ evaluate.py éƒ½ä½¿ç”¨ç›¸åŒçš„PRNGç§å­
evaluate_random = PRNG()
evaluate_random.seed("RedContritio")  # âŒ åŒä¸€ä¸ªç§å­ï¼

# è®­ç»ƒä¸­è¯„ä¼°ï¼ˆ25æ¬¡ï¼‰
for i in range(25):
    seed = evaluate_random.random()  # ç”Ÿæˆseed[0], seed[1], ..., seed[24]
    evaluate(env, agent, seed)

# æœ€ç»ˆæµ‹è¯•ï¼ˆ200æ¬¡ï¼‰
for i in range(200):
    seed = evaluate_random.random()  # ç”Ÿæˆseed[0], seed[1], ..., seed[199]
    evaluate(env, agent, seed)
```

**é—®é¢˜ï¼šå‰25ä¸ªæµ‹è¯•ç§å­åœ¨è®­ç»ƒæœŸé—´å·²ç»è¢«çœ‹è¿‡äº†ï¼**

è¿™å¯¼è‡´ï¼š
- âŒ **æ•°æ®æ³„éœ²ï¼ˆData Leakageï¼‰**ï¼šæ¨¡å‹é—´æ¥çœ‹åˆ°äº†æµ‹è¯•é›†
- âŒ **è¿‡æ‹Ÿåˆé£é™©**ï¼šæ¨¡å‹å¯èƒ½è®°ä½äº†è¿™äº›ç‰¹å®šåœºæ™¯
- âŒ **è¯„ä¼°ä¸å‡†ç¡®**ï¼šæµ‹è¯•åˆ†æ•°å¯èƒ½è¢«é«˜ä¼°
- âŒ **ä¸ç¬¦åˆMLæœ€ä½³å®è·µ**

---

## âœ… Correct Approach

### Principle: ä¸‰ä¸ªæ•°æ®é›†å¿…é¡»å®Œå…¨ç‹¬ç«‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training Dataset                         â”‚
â”‚  - ç”¨é€”: è®­ç»ƒæ¨¡å‹ï¼Œæ›´æ–°å‚æ•°                                    â”‚
â”‚  - ç§å­: éšæœºï¼ˆæ¯æ¬¡episodeä¸åŒï¼‰                               â”‚
â”‚  - æ•°é‡: è¶Šå¤šè¶Šå¥½ï¼ˆ500-2000+ episodesï¼‰                        â”‚
â”‚  - ç‰¹ç‚¹: é«˜åº¦å¤šæ ·åŒ–ï¼Œé¿å…è¿‡æ‹Ÿåˆ                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Validation Dataset                        â”‚
â”‚  - ç”¨é€”: ç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œæ—©åœï¼Œè¶…å‚æ•°è°ƒä¼˜                          â”‚
â”‚  - ç§å­: å›ºå®šï¼ˆPRNG("VALIDATION_2024")ï¼‰                      â”‚
â”‚  - æ•°é‡: ä¸­ç­‰ï¼ˆ50-100 episodesï¼‰                              â”‚
â”‚  - ç‰¹ç‚¹: è®­ç»ƒæœŸé—´å¯ä»¥çœ‹ï¼Œä½†ä¸ç”¨äºæ›´æ–°å‚æ•°                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Test Dataset                           â”‚
â”‚  - ç”¨é€”: æœ€ç»ˆè¯„ä¼°ï¼ŒæŠ¥å‘Šæ¨¡å‹æ€§èƒ½                                 â”‚
â”‚  - ç§å­: å›ºå®šï¼ˆPRNG("TEST_2024")ï¼Œä¸éªŒè¯é›†ä¸åŒï¼ï¼‰               â”‚
â”‚  - æ•°é‡: è¾ƒå¤šï¼ˆ200-500 episodesï¼‰                             â”‚
â”‚  - ç‰¹ç‚¹: è®­ç»ƒæœŸé—´ç»ä¸ä½¿ç”¨ï¼Œå®Œå…¨ç‹¬ç«‹                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Rules

1. **è®­ç»ƒé›†ï¼ˆTrainingï¼‰**: éšæœºç§å­ï¼Œæ¯æ¬¡éƒ½ä¸åŒ
2. **éªŒè¯é›†ï¼ˆValidationï¼‰**: å›ºå®šç§å­é›†Aï¼Œè®­ç»ƒæœŸé—´å¯ç”¨
3. **æµ‹è¯•é›†ï¼ˆTestï¼‰**: å›ºå®šç§å­é›†Bï¼Œä¸Aå®Œå…¨ä¸åŒï¼Œè®­ç»ƒåæ‰ç”¨

**ç»å¯¹ä¸èƒ½ï¼šè®­ç»ƒä¸­çœ‹åˆ°çš„åœºæ™¯å‡ºç°åœ¨æµ‹è¯•é›†ä¸­ï¼**

---

## ğŸ”§ Implementation

### Using SeedManager (Recommended)

æˆ‘ä»¬æä¾›äº† `seed_management.py` æ¥æ­£ç¡®ç®¡ç†ç§å­ï¼š

```python
from seed_management import SeedManager

# 1. åˆå§‹åŒ–ç§å­ç®¡ç†å™¨
seed_mgr = SeedManager(
    val_seed="VALIDATION_2024",    # éªŒè¯é›†ä¸»ç§å­
    test_seed="TEST_2024",          # æµ‹è¯•é›†ä¸»ç§å­ï¼ˆå¿…é¡»ä¸åŒï¼ï¼‰
    num_val=50,                     # 50ä¸ªéªŒè¯åœºæ™¯
    num_test=200                    # 200ä¸ªæµ‹è¯•åœºæ™¯
)

# 2. è®­ç»ƒæœŸé—´
for episode in range(num_train_episodes):
    # ä½¿ç”¨éšæœºç§å­è®­ç»ƒ
    train_seed = seed_mgr.get_train_seed()  # è¿”å›None
    env.reset(seed=train_seed)
    # ... è®­ç»ƒä»£ç  ...

    # æ¯Nä¸ªepisodeï¼Œåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    if episode % 100 == 0:
        val_seeds = seed_mgr.get_val_seeds()
        val_scores = []
        for seed in val_seeds:
            env.reset(seed=seed)
            score, _ = evaluate(env, agent)
            val_scores.append(score)
        print(f"Validation mean: {np.mean(val_scores)}")

# 3. è®­ç»ƒå®Œæˆåï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
test_seeds = seed_mgr.get_test_seeds()
test_scores = []
for seed in test_seeds:
    env.reset(seed=seed)
    score, _ = evaluate(env, agent)
    test_scores.append(score)

print(f"Final test mean: {np.mean(test_scores)}")
```

### Manual Implementation

å¦‚æœä¸æƒ³ç”¨SeedManagerï¼Œå¯ä»¥æ‰‹åŠ¨è®¾ç½®ï¼š

```python
from PRNG import PRNG

# ç”ŸæˆéªŒè¯é›†ç§å­ï¼ˆå›ºå®šï¼‰
val_prng = PRNG()
val_prng.seed("VALIDATION_2024")
val_seeds = [val_prng.random() for _ in range(50)]

# ç”Ÿæˆæµ‹è¯•é›†ç§å­ï¼ˆå›ºå®šï¼Œä½†ä¸åŒï¼‰
test_prng = PRNG()
test_prng.seed("TEST_2024")
test_seeds = [test_prng.random() for _ in range(200)]

# ç¡®ä¿æ²¡æœ‰é‡å 
assert len(set(val_seeds) & set(test_seeds)) == 0, "Val and test overlap!"
```

---

## ğŸ“Š Recommended Configuration

### For Quick Experiments

```python
seed_mgr = SeedManager(
    val_seed="VAL_QUICK",
    test_seed="TEST_QUICK",
    num_val=20,      # å¿«é€ŸéªŒè¯
    num_test=50      # å¿«é€Ÿæµ‹è¯•
)
```

### For Standard Research

```python
seed_mgr = SeedManager(
    val_seed="VALIDATION_2024",
    test_seed="TEST_2024",
    num_val=50,      # æ ‡å‡†éªŒè¯
    num_test=200     # æ ‡å‡†æµ‹è¯•
)
```

### For Publication-Quality Results

```python
seed_mgr = SeedManager(
    val_seed="VALIDATION_FINAL",
    test_seed="TEST_FINAL",
    num_val=100,     # å……åˆ†éªŒè¯
    num_test=500     # å……åˆ†æµ‹è¯•
)
```

---

## ğŸ”„ Migration Guide

### Updating Existing Code

**Before (âŒ Wrong):**

```python
# DQN.py
evaluate_random = PRNG()
evaluate_random.seed("RedContritio")

def compare_with_random(env, agent, action_count):
    for _ in range(25):
        seed = evaluate_random.random()  # âŒ ä¸æµ‹è¯•é›†é‡å ï¼
        evaluate(env, agent, seed)
```

**After (âœ… Correct):**

```python
# DQN.py
from seed_management import get_default_seed_manager

seed_mgr = get_default_seed_manager()

def compare_with_random(env, agent, action_count):
    val_seeds = seed_mgr.get_val_seeds()[:25]  # åªç”¨å‰25ä¸ª
    for seed in val_seeds:
        evaluate(env, agent, seed)
```

---

**Before (âŒ Wrong):**

```python
# evaluate.py
evaluate_random = PRNG()
evaluate_random.seed("RedContritio")

for _ in range(200):
    seed = evaluate_random.random()  # âŒ ä¸éªŒè¯é›†é‡å ï¼
    evaluate(env, agent, seed)
```

**After (âœ… Correct):**

```python
# evaluate.py
from seed_management import get_default_seed_manager

seed_mgr = get_default_seed_manager()
test_seeds = seed_mgr.get_test_seeds()

for seed in test_seeds:
    evaluate(env, agent, seed)
```

---

## ğŸ“ˆ Example: Complete Training Script

```python
"""
æ­£ç¡®çš„è®­ç»ƒæµç¨‹ç¤ºä¾‹
"""
import numpy as np
from DQN import Agent, build_model, ReplayMemory, run_episode
from GameInterface import GameInterface
from seed_management import SeedManager

# åˆå§‹åŒ–
env = GameInterface()
agent = Agent(build_model, feature_dim, action_dim)
memory = ReplayMemory()

# ç§å­ç®¡ç†
seed_mgr = SeedManager(
    val_seed="VALIDATION_2024",
    test_seed="TEST_2024",
    num_val=50,
    num_test=200
)

# ===== è®­ç»ƒé˜¶æ®µ =====
print("Training...")
best_val_score = 0

for episode in range(2000):
    # è®­ç»ƒï¼šä½¿ç”¨éšæœºç§å­
    train_seed = seed_mgr.get_train_seed()  # None
    env.reset(seed=train_seed)
    run_episode(env, agent, memory, episode)

    # éªŒè¯ï¼šæ¯100 episodes
    if episode % 100 == 0:
        val_seeds = seed_mgr.get_val_seeds()
        val_scores = []

        for seed in val_seeds:
            env.reset(seed=seed)
            score, _ = evaluate(env, agent)
            val_scores.append(score)

        val_mean = np.mean(val_scores)
        print(f"Episode {episode} - Val score: {val_mean:.1f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºéªŒè¯é›†ï¼‰
        if val_mean > best_val_score:
            best_val_score = val_mean
            paddle.save(agent.policy_net.state_dict(), "best_model.pdparams")
            print(f"  âœ… New best model saved!")

# ===== æµ‹è¯•é˜¶æ®µï¼ˆè®­ç»ƒå®Œæˆåï¼‰ =====
print("\nFinal Testing...")

# åŠ è½½æœ€ä½³æ¨¡å‹
agent.policy_net.set_state_dict(paddle.load("best_model.pdparams"))

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼ˆå®Œå…¨ç‹¬ç«‹çš„ç§å­ï¼‰
test_seeds = seed_mgr.get_test_seeds()
test_scores = []

for seed in test_seeds:
    env.reset(seed=seed)
    score, _ = evaluate(env, agent)
    test_scores.append(score)

print(f"Final Test Results:")
print(f"  Mean: {np.mean(test_scores):.1f} Â± {np.std(test_scores):.1f}")
print(f"  Max: {np.max(test_scores)}")
print(f"  Median: {np.median(test_scores):.1f}")

# ä¿å­˜ç§å­é…ç½®ï¼ˆç”¨äºè®ºæ–‡å¤ç°ï¼‰
seed_mgr.save_seeds("final_seeds.txt")
```

---

## ğŸ¯ Best Practices

### âœ… DO

1. **ä½¿ç”¨SeedManageræˆ–æ‰‹åŠ¨ç¡®ä¿ç§å­åˆ†ç¦»**
   ```python
   seed_mgr = SeedManager(val_seed="VAL", test_seed="TEST")
   ```

2. **è®­ç»ƒæ—¶ä½¿ç”¨éšæœºç§å­**
   ```python
   env.reset(seed=None)  # æˆ– env.reset()
   ```

3. **ä¿å­˜ç§å­é…ç½®**
   ```python
   seed_mgr.save_seeds("seeds.txt")  # ä¾¿äºå¤ç°
   ```

4. **éªŒè¯æ²¡æœ‰é‡å **
   ```python
   seed_mgr.verify_no_overlap()
   ```

5. **æ–‡æ¡£åŒ–ä½ çš„ç§å­ç­–ç•¥**
   ```python
   # åœ¨è®ºæ–‡ä¸­å†™æ˜ï¼š
   # "We used 50 validation episodes (seed: VALIDATION_2024)
   #  and 200 test episodes (seed: TEST_2024), ensuring no overlap."
   ```

### âŒ DON'T

1. **ä¸è¦åœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­ä½¿ç”¨ç›¸åŒçš„PRNGç§å­**
   ```python
   # âŒ é”™è¯¯
   prng = PRNG()
   prng.seed("SAME_SEED")
   train_seeds = [prng.random() for _ in range(100)]
   test_seeds = [prng.random() for _ in range(100)]  # ä¼šé‡å ï¼
   ```

2. **ä¸è¦åœ¨è®­ç»ƒä¸­ä½¿ç”¨æµ‹è¯•é›†**
   ```python
   # âŒ é”™è¯¯
   test_seeds = seed_mgr.get_test_seeds()
   # åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨test_seedsåšä»»ä½•äº‹æƒ…
   ```

3. **ä¸è¦å¿˜è®°å›ºå®šéšæœºç§å­ï¼ˆéªŒè¯/æµ‹è¯•æ—¶ï¼‰**
   ```python
   # âŒ é”™è¯¯ï¼šæµ‹è¯•æ—¶ç”¨éšæœºç§å­
   env.reset()  # æ¯æ¬¡æµ‹è¯•ç»“æœéƒ½ä¸åŒï¼
   ```

4. **ä¸è¦ç”¨sequential seeds**
   ```python
   # âŒ é”™è¯¯ï¼šå®¹æ˜“é‡å 
   val_seeds = list(range(0, 50))
   test_seeds = list(range(50, 250))
   # è™½ç„¶çœ‹èµ·æ¥åˆ†å¼€äº†ï¼Œä½†å»ºè®®ç”¨PRNGç”Ÿæˆæ›´éšæœºçš„ç§å­
   ```

---

## ğŸ“ For Your Report/Paper

åœ¨è®ºæ–‡ä¸­ï¼Œåº”è¯¥è¿™æ ·æè¿°ï¼š

### Method Section

```
We split our evaluation into validation and test sets to prevent
data leakage. During training, we used randomly seeded episodes
to maximize diversity. For validation (monitoring training progress),
we used 50 episodes with seeds generated from PRNG("VALIDATION_2024").
For final testing, we used 200 completely independent episodes with
seeds from PRNG("TEST_2024"). We verified no overlap between
validation and test sets. All seeds are saved for reproducibility.
```

### Results Section

```
Table 1: Performance on Test Set (200 episodes, seed: TEST_2024)

Model          Mean Score   Std Dev   Max    Median
---------------------------------------------------
DQN            245.3Â±42.1   42.1      368    238.5
Smart MCTS     223.7Â±38.5   38.5      319    220.0
Random         145.8Â±28.7   28.7      203    142.0

Note: Test set was completely independent from training and validation,
ensuring unbiased evaluation.
```

---

## ğŸ” Verification

è¿è¡Œä»¥ä¸‹ä»£ç éªŒè¯ä½ çš„è®¾ç½®ï¼š

```bash
python seed_management.py
```

è¾“å‡ºåº”è¯¥æ˜¾ç¤ºï¼š
```
âœ… Seed Manager initialized:
   Validation: 50 episodes (seed: 'VALIDATION_2024')
   Test: 200 episodes (seed: 'TEST_2024')
âœ… Verified: No overlap between validation and test sets
```

---

## ğŸ“š Summary

| Dataset | Purpose | Seed | Size | Usage |
|---------|---------|------|------|-------|
| **Train** | è®­ç»ƒæ¨¡å‹ | éšæœºï¼ˆNoneï¼‰ | 500-2000+ | æ›´æ–°å‚æ•° |
| **Validation** | ç›‘æ§è¿›åº¦ | PRNG("VAL") | 50-100 | è°ƒä¼˜ã€æ—©åœ |
| **Test** | æœ€ç»ˆè¯„ä¼° | PRNG("TEST") | 200-500 | æŠ¥å‘Šæ€§èƒ½ |

**å…³é”®åŸåˆ™ï¼šä¸‰ä¸ªé›†åˆå®Œå…¨ç‹¬ç«‹ï¼Œè®­ç»ƒä¸­ç»ä¸ä½¿ç”¨æµ‹è¯•é›†ï¼**

---

## ğŸ”— Related Files

- `seed_management.py` - Seed management implementation
- `docs/evaluation_methodology.tex` - Full evaluation methodology
- `docs/EVALUATION_GUIDE.md` - Evaluation guide
- `benchmark_all.py` - Update this to use SeedManager!

---

## â“ FAQ

**Q: ä¸ºä»€ä¹ˆè¦ç”¨PRNGè€Œä¸æ˜¯ç›´æ¥ç”¨list(range(200))?**

A: PRNGç”Ÿæˆçš„ç§å­æ›´éšæœºï¼Œé¿å…é¡ºåºåå·®ã€‚æ¯”å¦‚range(0, 50)å¯èƒ½éƒ½æ˜¯ç®€å•åœºæ™¯ï¼Œè€Œrange(150, 200)éƒ½æ˜¯å¤æ‚åœºæ™¯ã€‚

**Q: éªŒè¯é›†å’Œæµ‹è¯•é›†å¯ä»¥ç”¨ç›¸åŒçš„ç§å­å—ï¼Ÿ**

A: ç»å¯¹ä¸è¡Œï¼è¿™æ ·ä¼šå¯¼è‡´ä½ åœ¨éªŒè¯é›†ä¸Šè°ƒä¼˜çš„æ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸Šå¾—åˆ°è™šé«˜çš„åˆ†æ•°ã€‚

**Q: è®­ç»ƒæ—¶å¯ä»¥å¶å°”åœ¨æµ‹è¯•é›†ä¸Šçœ‹çœ‹æ•ˆæœå—ï¼Ÿ**

A: ä¸å»ºè®®ï¼å¦‚æœä½ æ ¹æ®æµ‹è¯•é›†è¡¨ç°è°ƒæ•´æ¨¡å‹ï¼Œé‚£æµ‹è¯•é›†å°±å˜æˆäº†éªŒè¯é›†ã€‚

**Q: æˆ‘å·²ç»è®­ç»ƒå¥½äº†æ¨¡å‹ï¼Œç°åœ¨æ‰å‘ç°ç§å­æœ‰é—®é¢˜ï¼Œæ€ä¹ˆåŠï¼Ÿ**

A: ç”¨æ–°çš„æµ‹è¯•é›†ï¼ˆä¸åŒçš„ç§å­ï¼‰é‡æ–°è¯„ä¼°ã€‚æŠ¥å‘Šæ—¶è¯´æ˜è¿™æ˜¯ç‹¬ç«‹çš„æµ‹è¯•é›†ã€‚

---

**Remember: Proper data splitting is crucial for honest, reproducible research!**
