#!/usr/bin/env python3
"""
å¯¹æ¯”ä¼˜åŒ–å‰åçš„MCTSæ€§èƒ½
"""

from GameInterface import GameInterface
from mcts.MCTS_optimized import FastMCTSAgent as OldMCTS
from mcts.MCTS_tuned import TunedMCTSAgent as NewMCTS
import numpy as np
import matplotlib.pyplot as plt

def test_agent(agent, name, seeds, num_simulations=200):
    """æµ‹è¯•æ™ºèƒ½ä½“"""
    print(f"\n{'='*70}")
    print(f"æµ‹è¯• {name}")
    print(f"{'='*70}")

    env = GameInterface()
    scores = []
    steps_list = []

    for i, seed in enumerate(seeds, 1):
        env.reset(seed=seed)

        # ç¬¬ä¸€æ­¥éšæœº
        action = np.random.randint(0, env.action_num)
        feature, _, alive = env.next(action)

        steps = 0
        while alive and steps < 200:
            action = agent.predict(env)[0]
            feature, reward, alive = env.next(action)
            steps += 1

        scores.append(env.game.score)
        steps_list.append(steps)

        print(f"  [{i:2d}/{len(seeds)}] Seed={seed:4d}: Score={env.game.score:3d}, Steps={steps:2d}")

    print(f"\n{'='*70}")
    print(f"{name} ç»Ÿè®¡:")
    print(f"  å¹³å‡å¾—åˆ†: {np.mean(scores):.1f} Â± {np.std(scores):.1f}")
    print(f"  æœ€é«˜å¾—åˆ†: {max(scores)}")
    print(f"  æœ€ä½å¾—åˆ†: {min(scores)}")
    print(f"  å¹³å‡æ­¥æ•°: {np.mean(steps_list):.1f}")
    print(f"{'='*70}")

    return scores, steps_list


def main():
    print("="*70)
    print("MCTSä¼˜åŒ–ç‰ˆæœ¬å¯¹æ¯”æµ‹è¯•")
    print("="*70)

    # æµ‹è¯•ç§å­ï¼ˆä½¿ç”¨ç›¸åŒç§å­ç¡®ä¿å…¬å¹³å¯¹æ¯”ï¼‰
    test_seeds = [1000 + i for i in range(20)]  # 20å±€æµ‹è¯•

    print(f"\né…ç½®:")
    print(f"  æµ‹è¯•å±€æ•°: {len(test_seeds)}")
    print(f"  MCTSæ¨¡æ‹Ÿæ¬¡æ•°: 200")
    print(f"  æœ€å¤§æ­¥æ•°: 200")

    # åˆ›å»ºæ™ºèƒ½ä½“
    old_agent = OldMCTS(num_simulations=200)
    new_agent = NewMCTS(num_simulations=200)

    # æµ‹è¯•
    old_scores, old_steps = test_agent(old_agent, "æ—§ç‰ˆMCTS (çº¿æ€§penalty)", test_seeds)
    new_scores, new_steps = test_agent(new_agent, "æ–°ç‰ˆMCTS (æŒ‡æ•°penalty)", test_seeds)

    # å¯è§†åŒ–å¯¹æ¯”
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. åˆ†æ•°å¯¹æ¯”
    ax1 = axes[0, 0]
    x = np.arange(len(test_seeds))
    ax1.plot(x, old_scores, 'b-o', label='Old MCTS', alpha=0.7)
    ax1.plot(x, new_scores, 'r-s', label='New MCTS (Tuned)', alpha=0.7)
    ax1.set_xlabel('Game Index', fontsize=11)
    ax1.set_ylabel('Score', fontsize=11)
    ax1.set_title('Score Comparison', fontsize=13, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. åˆ†æ•°åˆ†å¸ƒ
    ax2 = axes[0, 1]
    bins = np.arange(0, max(max(old_scores), max(new_scores)) + 20, 20)
    ax2.hist(old_scores, bins=bins, alpha=0.5, label='Old MCTS', color='blue')
    ax2.hist(new_scores, bins=bins, alpha=0.5, label='New MCTS', color='red')
    ax2.axvline(np.mean(old_scores), color='blue', linestyle='--', linewidth=2,
                label=f'Old Mean={np.mean(old_scores):.1f}')
    ax2.axvline(np.mean(new_scores), color='red', linestyle='--', linewidth=2,
                label=f'New Mean={np.mean(new_scores):.1f}')
    ax2.set_xlabel('Score', fontsize=11)
    ax2.set_ylabel('Frequency', fontsize=11)
    ax2.set_title('Score Distribution', fontsize=13, fontweight='bold')
    ax2.legend(fontsize=9)
    ax2.grid(True, alpha=0.3, axis='y')

    # 3. æ­¥æ•°å¯¹æ¯”
    ax3 = axes[1, 0]
    ax3.plot(x, old_steps, 'b-o', label='Old MCTS', alpha=0.7)
    ax3.plot(x, new_steps, 'r-s', label='New MCTS (Tuned)', alpha=0.7)
    ax3.set_xlabel('Game Index', fontsize=11)
    ax3.set_ylabel('Steps', fontsize=11)
    ax3.set_title('Steps Comparison', fontsize=13, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # 4. ç»Ÿè®¡å¯¹æ¯”
    ax4 = axes[1, 1]
    ax4.axis('off')

    # è®¡ç®—æ”¹è¿›
    score_improvement = (np.mean(new_scores) - np.mean(old_scores)) / np.mean(old_scores) * 100
    step_improvement = (np.mean(new_steps) - np.mean(old_steps)) / np.mean(old_steps) * 100

    stats_text = f"""
    ğŸ“Š Statistical Comparison

    {'â”€'*45}
    Score Statistics:
    {'â”€'*45}
      Old MCTS:  {np.mean(old_scores):6.1f} Â± {np.std(old_scores):5.1f}
      New MCTS:  {np.mean(new_scores):6.1f} Â± {np.std(new_scores):5.1f}

      Improvement: {score_improvement:+.1f}%
      {'âœ… Better!' if score_improvement > 0 else 'âŒ Worse'}

    {'â”€'*45}
    Step Statistics:
    {'â”€'*45}
      Old MCTS:  {np.mean(old_steps):6.1f} Â± {np.std(old_steps):5.1f}
      New MCTS:  {np.mean(new_steps):6.1f} Â± {np.std(new_steps):5.1f}

      Improvement: {step_improvement:+.1f}%
      {'âœ… Longer!' if step_improvement > 0 else 'âŒ Shorter'}

    {'â”€'*45}
    Win Rate (New > Old):
    {'â”€'*45}
      Wins:  {sum(1 for n, o in zip(new_scores, old_scores) if n > o):2d} / {len(test_seeds)} = {sum(1 for n, o in zip(new_scores, old_scores) if n > o)/len(test_seeds)*100:.1f}%
      Ties:  {sum(1 for n, o in zip(new_scores, old_scores) if n == o):2d} / {len(test_seeds)}
      Loses: {sum(1 for n, o in zip(new_scores, old_scores) if n < o):2d} / {len(test_seeds)}
    """

    ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes,
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    plt.savefig('mcts_tuned_comparison.png', dpi=150, bbox_inches='tight')
    print(f"\nâœ… å¯¹æ¯”å›¾å·²ä¿å­˜: mcts_tuned_comparison.png")

    # æ€»ç»“
    print(f"\n{'='*70}")
    print("ğŸ¯ æ€»ç»“:")
    print(f"{'='*70}")
    print(f"  åˆ†æ•°æå‡: {score_improvement:+.1f}%")
    print(f"  æ­¥æ•°æå‡: {step_improvement:+.1f}%")
    print(f"  èƒœç‡: {sum(1 for n, o in zip(new_scores, old_scores) if n > o)/len(test_seeds)*100:.1f}%")

    if score_improvement > 5:
        print(f"\n  ğŸ‰ æ–°ç‰ˆMCTSæ˜æ˜¾ä¼˜äºæ—§ç‰ˆï¼")
    elif score_improvement > 0:
        print(f"\n  âœ… æ–°ç‰ˆMCTSç•¥ä¼˜äºæ—§ç‰ˆ")
    elif score_improvement > -5:
        print(f"\n  âš ï¸  æ–°ç‰ˆä¸æ—§ç‰ˆæ€§èƒ½æ¥è¿‘")
    else:
        print(f"\n  âŒ æ–°ç‰ˆéœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")

    print(f"{'='*70}")


if __name__ == "__main__":
    main()
